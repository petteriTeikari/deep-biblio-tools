<?xml version="1.0" encoding="utf-8"?><testsuites name="pytest tests"><testsuite name="pytest" errors="0" failures="1" skipped="0" tests="7" time="6.476" timestamp="2025-10-31T14:23:46.528110+01:00" hostname="petteri-XPS-Ubu"><testcase classname="tests.test_rdf_parser_emergency_mode" name="test_rdf_parser_finds_all_665_entries" time="0.180"><failure message="AssertionError: RDF parser should find exactly 665 entries (per Zotero), got 664&#10;assert 664 == 665&#10; +  where 664 = len([{'id': 'arxiv_2311.14570', 'title': 'RAISE -- Radiology AI Safety, an End-to-end lifecycle approach', 'URL': 'http://arxiv.org/abs/2311.14570', 'extra_urls': ['http://arxiv.org/abs/2311.14570'], 'type': 'article', 'author': [{'family': 'Cardoso', 'given': 'M. Jorge'}, {'family': 'Moosbauer', 'given': 'Julia'}, {'family': 'Cook', 'given': 'Tessa S.'}, {'family': 'Erdal', 'given': 'B. Selnur'}, {'family': 'Genereaux', 'given': 'Brad'}, {'family': 'Gupta', 'given': 'Vikash'}, {'family': 'Landman', 'given': 'Bennett A.'}, {'family': 'Lee', 'given': 'Tiarna'}, {'family': 'Nachev', 'given': 'Parashkev'}, {'family': 'Somasundaram', 'given': 'Elanchezhian'}, {'family': 'Summers', 'given': 'Ronald M.'}, {'family': 'Younis', 'given': 'Khaled'}, {'family': 'Ourselin', 'given': 'Sebastien'}, {'family': 'Pfister', 'given': 'Franz MJ'}], 'publisher': 'arXiv', 'abstract': 'The integration of AI into radiology introduces opportunities for improved clinical care provision and efficiency but it demands a meticulous approach to mitigate potential risks as with any other new technology. Beginning with rigorous pre-deployment evaluation and validation, the focus should be on ensuring models meet the highest standards of safety, effectiveness and efficacy for their intended applications. Input and output guardrails implemented during production usage act as an additional layer of protection, identifying and addressing individual failures as they occur. Continuous post-deployment monitoring allows for tracking population-level performance (data drift), fairness, and value delivery over time. Scheduling reviews of post-deployment model performance and educating radiologists about new algorithmic-driven findings is critical for AI to be effective in clinical practice. Recognizing that no single AI solution can provide absolute assurance even when limited to its intended use, the synergistic application of quality assurance at multiple levels - regulatory, clinical, technical, and ethical - is emphasized. Collaborative efforts between stakeholders spanning healthcare systems, industry, academia, and government are imperative to address the multifaceted challenges involved. Trust in AI is an earned privilege, contingent on a broad set of goals, among them transparently demonstrating that the AI adheres to the same rigorous safety, effectiveness and efficacy standards as other established medical technologies. By doing so, developers can instil confidence among providers and patients alike, enabling the responsible scaling of AI and the realization of its potential benefits. The roadmap presented herein aims to expedite the achievement of deployable, reliable, and safe AI in radiology.'}, {'id': 'arxiv_2402.00809v4', 'title': 'Position: Bayesian Deep Learning is Needed in the Age of Large-Scale AI', 'URL': 'https://arxiv.org/abs/2402.00809v4', 'extra_urls': ['https://arxiv.org/abs/2402.00809v4'], 'type': 'article', 'author': [{'family': 'Papamarkou', 'given': 'Theodore'}, {'family': 'Skoularidou', 'given': 'Maria'}, {'family': 'Palla', 'given': 'Konstantina'}, {'family': 'Aitchison', 'given': 'Laurence'}, {'family': 'Arbel', 'given': 'Julyan'}, {'family': 'Dunson', 'given': 'David'}, {'family': 'Filippone', 'given': 'Maurizio'}, {'family': 'Fortuin', 'given': 'Vincent'}, {'family': 'Hennig', 'given': 'Philipp'}, {'family': 'Hern\xe1ndez-Lobato', 'given': 'Jos\xe9 Miguel'}, {'family': 'Hubin', 'given': 'Aliaksandr'}, {'family': 'Immer', 'given': 'Alexander'}, {'family': 'Karaletsos', 'given': 'Theofanis'}, {'family': 'Khan', 'given': 'Mohammad Emtiyaz'}, {'family': 'Kristiadi', 'given': 'Agustinus'}, {'family': 'Li', 'given': 'Yingzhen'}, {'family': 'Mandt', 'given': 'Stephan'}, {'family': 'Nemeth', 'given': 'Christopher'}, {'family': 'Osborne', 'given': 'Michael A.'}, {'family': 'Rudner', 'given': 'Tim G. J.'}, {'family': 'R\xfcgamer', 'given': 'David'}, {'family': 'Teh', 'given': 'Yee Whye'}, {'family': 'Welling', 'given': 'Max'}, {'family': 'Wilson', 'given': 'Andrew Gordon'}, {'family': 'Zhang', 'given': 'Ruqi'}], 'abstract': 'In the current landscape of deep learning research, there is a predominant emphasis on achieving high predictive accuracy in supervised tasks involving large image and language datasets. However, a broader perspective reveals a multitude of overlooked metrics, tasks, and data types, such as uncertainty, active and continual learning, and scientific data, that demand attention. Bayesian deep learning (BDL) constitutes a promising avenue, offering advantages across these diverse settings. This paper posits that BDL can elevate the capabilities of deep learning. It revisits the strengths of BDL, acknowledges existing challenges, and highlights some exciting research avenues aimed at addressing these obstacles. Looking ahead, the discussion focuses on possible ways to combine large-scale foundation models with BDL to unlock their full potential.'}, {'id': 'arxiv_2510.10409', 'title': 'Trace Length is a Simple Uncertainty Signal in Reasoning Models', 'URL': 'http://arxiv.org/abs/2510.10409', 'extra_urls': ['http://arxiv.org/abs/2510.10409'], 'type': 'article', 'author': [{'family': 'Devic', 'given': 'Siddartha'}, {'family': 'Peale', 'given': 'Charlotte'}, {'family': 'Bradley', 'given': 'Arwen'}, {'family': 'Williamson', 'given': 'Sinead'}, {'family': 'Nakkiran', 'given': 'Preetum'}, {'family': 'Gollakota', 'given': 'Aravind'}], 'publisher': 'arXiv', 'abstract': 'Uncertainty quantification for LLMs is a key research direction towards addressing hallucination and other issues that limit their reliable deployment. In this work, we show that reasoning trace length is a simple and useful confidence estimator in large reasoning models. Through comprehensive experiments across multiple models, datasets, and prompts, we show that trace length performs in comparable but complementary ways to other zero-shot confidence estimators such as verbalized confidence. Our work reveals that reasoning post-training fundamentally alters the relationship between trace length and accuracy, going beyond prior work that had shown that post-training causes traces to grow longer in general (e.g., &quot;overthinking&quot;). We investigate the mechanisms behind trace length\'s performance as a confidence signal, observing that the effect remains even after adjusting for confounders such as problem difficulty and GRPO-induced length bias. We identify high-entropy or &quot;forking&quot; tokens as playing a key role in the mechanism. Our findings demonstrate that reasoning post-training enhances uncertainty quantification beyond verbal expressions, and establish trace length as a practical confidence measure for large reasoning models.'}, {'id': 'arxiv_2508.08204', 'title': 'Human-Alignment and Calibration of Inference-Time Uncertainty in Large Language Models', 'URL': 'http://arxiv.org/abs/2508.08204', 'extra_urls': ['http://arxiv.org/abs/2508.08204'], 'type': 'article', 'author': [{'family': 'Moore', 'given': 'Kyle'}, {'family': 'Roberts', 'given': 'Jesse'}, {'family': 'Watson', 'given': 'Daryl'}], 'publisher': 'arXiv', 'abstract': 'There has been much recent interest in evaluating large language models for uncertainty calibration to facilitate model control and modulate user trust. Inference time uncertainty, which may provide a real-time signal to the model or external control modules, is particularly important for applying these concepts to improve LLM-user experience in practice. While many of the existing papers consider model calibration, comparatively little work has sought to evaluate how closely model uncertainty aligns to human uncertainty. In this work, we evaluate a collection of inference-time uncertainty measures, using both established metrics and novel variations, to determine how closely they align with both human group-level uncertainty and traditional notions of model calibration. We find that numerous measures show evidence of strong alignment to human uncertainty, even despite the lack of alignment to human answer preference. For those successful metrics, we find moderate to strong evidence of model calibration in terms of both correctness correlation and distributional analysis.'}, {'id': 'arxiv_2503.15850', 'title': 'Uncertainty Quantification and Confidence Calibration in Large Language Models: A Survey', 'URL': 'http://arxiv.org/abs/2503.15850', 'extra_urls': ['http://arxiv.org/abs/2503.15850'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Xiaoou'}, {'family': 'Chen', 'given': 'Tiejin'}, {'family': 'Da', 'given': 'Longchao'}, {'family': 'Chen', 'given': 'Chacha'}, {'family': 'Lin', 'given': 'Zhen'}, {'family': 'Wei', 'given': 'Hua'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) excel in text generation, reasoning, and decision-making, enabling their adoption in high-stakes domains such as healthcare, law, and transportation. However, their reliability is a major concern, as they often produce plausible but incorrect responses. Uncertainty quantification (UQ) enhances trustworthiness by estimating confidence in outputs, enabling risk mitigation and selective prediction. However, traditional UQ methods struggle with LLMs due to computational constraints and decoding inconsistencies. Moreover, LLMs introduce unique uncertainty sources, such as input ambiguity, reasoning path divergence, and decoding stochasticity, that extend beyond classical aleatoric and epistemic uncertainty. To address this, we introduce a new taxonomy that categorizes UQ methods based on computational efficiency and uncertainty dimensions (input, reasoning, parameter, and prediction uncertainty). We evaluate existing techniques, assess their real-world applicability, and identify open challenges, emphasizing the need for scalable, interpretable, and robust UQ approaches to enhance LLM reliability.'}, {'id': 'arxiv_2509.22272', 'title': 'Fine-Grained Uncertainty Decomposition in Large Language Models: A Spectral Approach', 'URL': 'http://arxiv.org/abs/2509.22272', 'extra_urls': ['http://arxiv.org/abs/2509.22272'], 'type': 'article', 'author': [{'family': 'Walha', 'given': 'Nassim'}, {'family': 'Gruber', 'given': 'Sebastian G.'}, {'family': 'Decker', 'given': 'Thomas'}, {'family': 'Yang', 'given': 'Yinchong'}, {'family': 'Javanmardi', 'given': 'Alireza'}, {'family': 'H\xfcllermeier', 'given': 'Eyke'}, {'family': 'Buettner', 'given': 'Florian'}], 'publisher': 'arXiv', 'abstract': 'As Large Language Models (LLMs) are increasingly integrated in diverse applications, obtaining reliable measures of their predictive uncertainty has become critically important. A precise distinction between aleatoric uncertainty, arising from inherent ambiguities within input data, and epistemic uncertainty, originating exclusively from model limitations, is essential to effectively address each uncertainty source. In this paper, we introduce Spectral Uncertainty, a novel approach to quantifying and decomposing uncertainties in LLMs. Leveraging the Von Neumann entropy from quantum information theory, Spectral Uncertainty provides a rigorous theoretical foundation for separating total uncertainty into distinct aleatoric and epistemic components. Unlike existing baseline methods, our approach incorporates a fine-grained representation of semantic similarity, enabling nuanced differentiation among various semantic interpretations in model responses. Empirical evaluations demonstrate that Spectral Uncertainty outperforms state-of-the-art methods in estimating both aleatoric and total uncertainty across diverse models and benchmark datasets.'}, {'id': 'arxiv_2510.05566', 'title': 'Domain-Shift-Aware Conformal Prediction for Large Language Models', 'URL': 'http://arxiv.org/abs/2510.05566', 'extra_urls': ['http://arxiv.org/abs/2510.05566'], 'type': 'article', 'author': [{'family': 'Lin', 'given': 'Zhexiao'}, {'family': 'Li', 'given': 'Yuanyuan'}, {'family': 'Sarna', 'given': 'Neeraj'}, {'family': 'Gao', 'given': 'Yuanyuan'}, {'family': 'Gablenz', 'given': 'Michael von'}], 'publisher': 'arXiv', 'abstract': 'Large language models have achieved impressive performance across diverse tasks. However, their tendency to produce overconfident and factually incorrect outputs, known as hallucinations, poses risks in real world applications. Conformal prediction provides finite-sample, distribution-free coverage guarantees, but standard conformal prediction breaks down under domain shift, often leading to under-coverage and unreliable prediction sets. We propose a new framework called Domain-Shift-Aware Conformal Prediction (DS-CP). Our framework adapts conformal prediction to large language models under domain shift, by systematically reweighting calibration samples based on their proximity to the test prompt, thereby preserving validity while enhancing adaptivity. Our theoretical analysis and experiments on the MMLU benchmark demonstrate that the proposed method delivers more reliable coverage than standard conformal prediction, especially under substantial distribution shifts, while maintaining efficiency. This provides a practical step toward trustworthy uncertainty quantification for large language models in real-world deployment.'}, {'id': 'arxiv_2509.04439', 'title': 'ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory', 'URL': 'http://arxiv.org/abs/2509.04439', 'extra_urls': ['http://arxiv.org/abs/2509.04439'], 'type': 'article', 'author': [{'family': 'Ho', 'given': 'Matthew'}, {'family': 'Si', 'given': 'Chen'}, {'family': 'Feng', 'given': 'Zhaoxiang'}, {'family': 'Yu', 'given': 'Fangxu'}, {'family': 'Yang', 'given': 'Yichi'}, {'family': 'Liu', 'given': 'Zhijian'}, {'family': 'Hu', 'given': 'Zhiting'}, {'family': 'Qin', 'given': 'Lianhui'}], 'publisher': 'arXiv', 'abstract': 'While inference-time scaling enables LLMs to carry out increasingly long and capable reasoning traces, the patterns and insights uncovered during these traces are immediately discarded once the context window is reset for a new query. External memory is a natural way to persist these discoveries, and recent work has shown clear benefits for reasoning-intensive tasks. We see an opportunity to make such memories more broadly reusable and scalable by moving beyond instance-based memory entries (e.g. exact query/response pairs, or summaries tightly coupled with the original problem context) toward concept-level memory: reusable, modular abstractions distilled from solution traces and stored in natural language. For future queries, relevant concepts are selectively retrieved and integrated into the prompt, enabling test-time continual learning without weight updates. Our design introduces new strategies for abstracting takeaways from rollouts and retrieving entries for new queries, promoting reuse and allowing memory to expand with additional experiences. We evaluate on ARC-AGI, a benchmark that stresses compositional generalization and abstract reasoning, making it a natural fit for concept memory. Our method yields a 7.5% relative gain over a strong no-memory baseline with performance continuing to scale with inference compute. We find abstract concepts to be the most consistent memory design, outscoring the baseline at all tested inference compute scales. Moreover, dynamically updating memory during test-time outperforms fixed settings, supporting the hypothesis that accumulating and abstracting patterns enables further solutions in a form of self-improvement. Code is available at https://github.com/matt-seb-ho/arc_memo.'}, {'id': 'arxiv_2510.04851', 'title': 'LEGOMem: Modular Procedural Memory for Multi-agent LLM Systems for Workflow Automation', 'URL': 'http://arxiv.org/abs/2510.04851', 'extra_urls': ['http://arxiv.org/abs/2510.04851'], 'type': 'article', 'author': [{'family': 'Han', 'given': 'Dongge'}, {'family': 'Couturier', 'given': 'Camille'}, {'family': 'Diaz', 'given': 'Daniel Madrigal'}, {'family': 'Zhang', 'given': 'Xuchao'}, {'family': 'R\xfchle', 'given': 'Victor'}, {'family': 'Rajmohan', 'given': 'Saravan'}], 'publisher': 'arXiv', 'abstract': 'We introduce LEGOMem, a modular procedural memory framework for multi-agent large language model (LLM) systems in workflow automation. LEGOMem decomposes past task trajectories into reusable memory units and flexibly allocates them across orchestrators and task agents to support planning and execution. To explore the design space of memory in multi-agent systems, we use LEGOMem as a lens and conduct a systematic study of procedural memory in multi-agent systems, examining where memory should be placed, how it should be retrieved, and which agents benefit most. Experiments on the OfficeBench benchmark show that orchestrator memory is critical for effective task decomposition and delegation, while fine-grained agent memory improves execution accuracy. We find that even teams composed of smaller language models can benefit substantially from procedural memory, narrowing the performance gap with stronger agents by leveraging prior execution traces for more accurate planning and tool use. These results position LEGOMem as both a practical framework for memory-augmented agent systems and a research tool for understanding memory design in multi-agent workflow automation.'}, {'id': 'arxiv_2508.03341', 'title': 'Nemori: Self-Organizing Agent Memory Inspired by Cognitive Science', 'URL': 'http://arxiv.org/abs/2508.03341', 'extra_urls': ['http://arxiv.org/abs/2508.03341'], 'type': 'article', 'author': [{'family': 'Nan', 'given': 'Jiayan'}, {'family': 'Ma', 'given': 'Wenquan'}, {'family': 'Wu', 'given': 'Wenlong'}, {'family': 'Chen', 'given': 'Yize'}], 'publisher': 'arXiv', 'abstract': &quot;Large Language Models (LLMs) demonstrate remarkable capabilities, yet their inability to maintain persistent memory in long contexts limits their effectiveness as autonomous agents in long-term interactions. While existing memory systems have made progress, their reliance on arbitrary granularity for defining the basic memory unit and passive, rule-based mechanisms for knowledge extraction limits their capacity for genuine learning and evolution. To address these foundational limitations, we present Nemori, a novel self-organizing memory architecture inspired by human cognitive principles. Nemori's core innovation is twofold: First, its Two-Step Alignment Principle, inspired by Event Segmentation Theory, provides a principled, top-down method for autonomously organizing the raw conversational stream into semantically coherent episodes, solving the critical issue of memory granularity. Second, its Predict-Calibrate Principle, inspired by the Free-energy Principle, enables the agent to proactively learn from prediction gaps, moving beyond pre-defined heuristics to achieve adaptive knowledge evolution. This offers a viable path toward handling the long-term, dynamic workflows of autonomous agents. Extensive experiments on the LoCoMo and LongMemEval benchmarks demonstrate that Nemori significantly outperforms prior state-of-the-art systems, with its advantage being particularly pronounced in longer contexts.&quot;}, {'id': 'arxiv_2510.07713', 'title': 'MemWeaver: A Hierarchical Memory from Textual Interactive Behaviors for Personalized Generation', 'URL': 'http://arxiv.org/abs/2510.07713', 'extra_urls': ['http://arxiv.org/abs/2510.07713'], 'type': 'article', 'author': [{'family': 'Yu', 'given': 'Shuo'}, {'family': 'Cheng', 'given': 'Mingyue'}, {'family': 'Wang', 'given': 'Daoyu'}, {'family': 'Liu', 'given': 'Qi'}, {'family': 'Liu', 'given': 'Zirui'}, {'family': 'Guo', 'given': 'Ze'}, {'family': 'Tao', 'given': 'Xiaoyu'}], 'publisher': 'arXiv', 'abstract': &quot;The primary form of user-internet engagement is shifting from leveraging implicit feedback signals, such as browsing and clicks, to harnessing the rich explicit feedback provided by textual interactive behaviors. This shift unlocks a rich source of user textual history, presenting a profound opportunity for a deeper form of personalization. However, prevailing approaches offer only a shallow form of personalization, as they treat user history as a flat list of texts for retrieval and fail to model the rich temporal and semantic structures reflecting dynamic nature of user interests. In this work, we propose \\textbf{MemWeaver}, a framework that weaves the user's entire textual history into a hierarchical memory to power deeply personalized generation. The core innovation of our memory lies in its ability to capture both the temporal evolution of interests and the semantic relationships between different activities. To achieve this, MemWeaver builds two complementary memory components that both integrate temporal and semantic information, but at different levels of abstraction: behavioral memory, which captures specific user actions, and cognitive memory, which represents long-term preferences. This dual-component memory serves as a unified representation of the user, allowing large language models (LLMs) to reason over both concrete behaviors and abstracted traits. Experiments on the Language Model Personalization (LaMP) benchmark validate the efficacy of MemWeaver. Our code is available\\footnote{https://github.com/fishsure/MemWeaver}.&quot;}, {'id': 'arxiv_2509.13235', 'title': 'A Scenario-Driven Cognitive Approach to Next-Generation AI Memory', 'URL': 'http://arxiv.org/abs/2509.13235', 'extra_urls': ['http://arxiv.org/abs/2509.13235'], 'type': 'article', 'author': [{'family': 'Cai', 'given': 'Linyue'}, {'family': 'Cheng', 'given': 'Yuyang'}, {'family': 'Shao', 'given': 'Xiaoding'}, {'family': 'Wang', 'given': 'Huiming'}, {'family': 'Zhao', 'given': 'Yong'}, {'family': 'Zhang', 'given': 'Wei'}, {'family': 'Li', 'given': 'Kang'}], 'publisher': 'arXiv', 'abstract': 'As artificial intelligence advances toward artificial general intelligence (AGI), the need for robust and human-like memory systems has become increasingly evident. Current memory architectures often suffer from limited adaptability, insufficient multimodal integration, and an inability to support continuous learning. To address these limitations, we propose a scenario-driven methodology that extracts essential functional requirements from representative cognitive scenarios, leading to a unified set of design principles for next-generation AI memory systems. Based on this approach, we introduce the \\textbf{COgnitive Layered Memory Architecture (COLMA)}, a novel framework that integrates cognitive scenarios, memory processes, and storage mechanisms into a cohesive design. COLMA provides a structured foundation for developing AI systems capable of lifelong learning and human-like reasoning, thereby contributing to the pragmatic development of AGI.'}, {'id': 'arxiv_2510.11967', 'title': 'Scaling Long-Horizon LLM Agent via Context-Folding', 'URL': 'http://arxiv.org/abs/2510.11967', 'extra_urls': ['http://arxiv.org/abs/2510.11967'], 'type': 'article', 'author': [{'family': 'Sun', 'given': 'Weiwei'}, {'family': 'Lu', 'given': 'Miao'}, {'family': 'Ling', 'given': 'Zhan'}, {'family': 'Liu', 'given': 'Kang'}, {'family': 'Yao', 'given': 'Xuesong'}, {'family': 'Yang', 'given': 'Yiming'}, {'family': 'Chen', 'given': 'Jiecao'}], 'publisher': 'arXiv', 'abstract': 'Large language model (LLM) agents are fundamentally constrained by context length on long-horizon tasks. We introduce Context-Folding, a framework that empowers agents to actively manage their working context. An agent can procedurally branch into a sub-trajectory to handle a subtask and then fold it upon completion, collapsing the intermediate steps while retaining a concise summary of the outcome. To make this behavior learnable, we develop an end-to-end reinforcement learning framework FoldGRPO with specific process rewards to encourage effective task decomposition and context management. On complex long-horizon tasks (Deep Research and SWE), our folding agent matches or outperforms the ReAct baselines while using an active context 10$\\times$ smaller and significantly outperforms models that rely on summarization-based context management.'}, {'id': 'arxiv_2510.06727', 'title': 'Scaling LLM Multi-turn RL with End-to-end Summarization-based Context Management', 'URL': 'http://arxiv.org/abs/2510.06727', 'extra_urls': ['http://arxiv.org/abs/2510.06727'], 'type': 'article', 'author': [{'family': 'Lu', 'given': 'Miao'}, {'family': 'Sun', 'given': 'Weiwei'}, {'family': 'Du', 'given': 'Weihua'}, {'family': 'Ling', 'given': 'Zhan'}, {'family': 'Yao', 'given': 'Xuesong'}, {'family': 'Liu', 'given': 'Kang'}, {'family': 'Chen', 'given': 'Jiecao'}], 'publisher': 'arXiv', 'abstract': 'We study reinforcement learning (RL) fine-tuning of large language model (LLM) agents for long-horizon multi-turn tool use, where context length quickly becomes a fundamental bottleneck. Existing RL pipelines can suffer from degraded instruction following, excessive rollout costs, and most importantly, strict context limits. To address these challenges, we introduce summarization-based context management to training. In specific, it periodically compresses the tool using history by LLM-generated summaries that retain task-relevant information to keep a compact context while enabling the agent to scale beyond the fixed context window. Building on this formulation, we derive a policy gradient representation that seamlessly enables standard LLM RL infrastructures to optimize both tool-use behaviors as well as summarization strategies in an end-to-end fashion. We instantiate this framework with \\underline{SU}mmarization augmented \\underline{P}olicy \\underline{O}ptimization (\\texttt{SUPO}), an LLM RL algorithm that enables long-horizon training beyond a fixed context limit. Experiments on interactive function calling and searching tasks demonstrate that \\texttt{SUPO} significantly improves the success rate while maintaining the same or even lower working context length compared to baselines. We also demonstrate that for complex searching tasks, \\texttt{SUPO} can further improve the evaluation performance when scaling test-time maximum round of summarization beyond that of training time. Our results establish summarization-based context management as a principled and scalable approach for training RL agents beyond a fixed context length limit.'}, {'id': 'arxiv_2509.18970', 'title': 'LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions', 'URL': 'http://arxiv.org/abs/2509.18970', 'extra_urls': ['http://arxiv.org/abs/2509.18970'], 'type': 'article', 'author': [{'family': 'Lin', 'given': 'Xixun'}, {'family': 'Ning', 'given': 'Yucheng'}, {'family': 'Zhang', 'given': 'Jingwen'}, {'family': 'Dong', 'given': 'Yan'}, {'family': 'Liu', 'given': 'Yilong'}, {'family': 'Wu', 'given': 'Yongxuan'}, {'family': 'Qi', 'given': 'Xiaohua'}, {'family': 'Sun', 'given': 'Nan'}, {'family': 'Shang', 'given': 'Yanmin'}, {'family': 'Cao', 'given': 'Pengfei'}, {'family': 'Zou', 'given': 'Lixin'}, {'family': 'Chen', 'given': 'Xu'}, {'family': 'Zhou', 'given': 'Chuan'}, {'family': 'Wu', 'given': 'Jia'}, {'family': 'Pan', 'given': 'Shirui'}, {'family': 'Wang', 'given': 'Bin'}, {'family': 'Cao', 'given': 'Yanan'}, {'family': 'Chen', 'given': 'Kai'}, {'family': 'Hu', 'given': 'Songlin'}, {'family': 'Guo', 'given': 'Li'}], 'publisher': 'arXiv', 'abstract': 'Driven by the rapid advancements of Large Language Models (LLMs), LLM-based agents have emerged as powerful intelligent systems capable of human-like cognition, reasoning, and interaction. These agents are increasingly being deployed across diverse real-world applications, including student education, scientific research, and financial analysis. However, despite their remarkable potential, LLM-based agents remain vulnerable to hallucination issues, which can result in erroneous task execution and undermine the reliability of the overall system design. Addressing this critical challenge requires a deep understanding and a systematic consolidation of recent advances on LLM-based agents. To this end, we present the first comprehensive survey of hallucinations in LLM-based agents. By carefully analyzing the complete workflow of agents, we propose a new taxonomy that identifies different types of agent hallucinations occurring at different stages. Furthermore, we conduct an in-depth examination of eighteen triggering causes underlying the emergence of agent hallucinations. Through a detailed review of a large number of existing studies, we summarize approaches for hallucination mitigation and detection, and highlight promising directions for future research. We hope this survey will inspire further efforts toward addressing hallucinations in LLM-based agents, ultimately contributing to the development of more robust and reliable agent systems.'}, {'id': 'arxiv_2509.11914', 'title': 'EgoMem: Lifelong Memory Agent for Full-duplex Omnimodal Models', 'URL': 'http://arxiv.org/abs/2509.11914', 'extra_urls': ['http://arxiv.org/abs/2509.11914'], 'type': 'article', 'author': [{'family': 'Yao', 'given': 'Yiqun'}, {'family': 'Yu', 'given': 'Naitong'}, {'family': 'Li', 'given': 'Xiang'}, {'family': 'Jiang', 'given': 'Xin'}, {'family': 'Fang', 'given': 'Xuezhi'}, {'family': 'Ma', 'given': 'Wenjia'}, {'family': 'Meng', 'given': 'Xuying'}, {'family': 'Li', 'given': 'Jing'}, {'family': 'Sun', 'given': 'Aixin'}, {'family': 'Wang', 'given': 'Yequan'}], 'publisher': 'arXiv', 'abstract': &quot;We introduce EgoMem, the first lifelong memory agent tailored for full-duplex models that process real-time omnimodal streams. EgoMem enables real-time models to recognize multiple users directly from raw audiovisual streams, to provide personalized response, and to maintain long-term knowledge of users' facts, preferences, and social relationships extracted from audiovisual history. EgoMem operates with three asynchronous processes: (i) a retrieval process that dynamically identifies user via face and voice, and gathers relevant context from a long-term memory; (ii) an omnimodal dialog process that generates personalized audio responses based on the retrieved context; and (iii) a memory management process that automatically detects dialog boundaries from omnimodal streams, and extracts necessary information to update the long-term memory. Unlike existing memory agents for LLMs, EgoMem relies entirely on raw audiovisual streams, making it especially suitable for lifelong, real-time, and embodied scenarios. Experimental results demonstrate that EgoMem's retrieval and memory management modules achieve over 95% accuracy on the test set. When integrated with a fine-tuned RoboEgo omnimodal chatbot, the system achieves fact-consistency scores above 87% in real-time personalized dialogs, establishing a strong baseline for future research.&quot;}, {'id': 'arxiv_2503.22458', 'title': 'Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey', 'URL': 'http://arxiv.org/abs/2503.22458', 'extra_urls': ['http://arxiv.org/abs/2503.22458'], 'type': 'article', 'author': [{'family': 'Guan', 'given': 'Shengyue'}, {'family': 'Xiong', 'given': 'Haoyi'}, {'family': 'Wang', 'given': 'Jindong'}, {'family': 'Bian', 'given': 'Jiang'}, {'family': 'Zhu', 'given': 'Bin'}, {'family': 'Lou', 'given': 'Jian-guang'}], 'publisher': 'arXiv', 'abstract': 'This survey examines evaluation methods for large language model (LLM)-based agents in multi-turn conversational settings. Using a PRISMA-inspired framework, we systematically reviewed nearly 250 scholarly sources, capturing the state of the art from various venues of publication, and establishing a solid foundation for our analysis. Our study offers a structured approach by developing two interrelated taxonomy systems: one that defines \\emph{what to evaluate} and another that explains \\emph{how to evaluate}. The first taxonomy identifies key components of LLM-based agents for multi-turn conversations and their evaluation dimensions, including task completion, response quality, user experience, memory and context retention, as well as planning and tool integration. These components ensure that the performance of conversational agents is assessed in a holistic and meaningful manner. The second taxonomy system focuses on the evaluation methodologies. It categorizes approaches into annotation-based evaluations, automated metrics, hybrid strategies that combine human assessments with quantitative measures, and self-judging methods utilizing LLMs. This framework not only captures traditional metrics derived from language understanding, such as BLEU and ROUGE scores, but also incorporates advanced techniques that reflect the dynamic, interactive nature of multi-turn dialogues.'}, {'id': 'arxiv_2510.07777', 'title': 'Drift No More? Context Equilibria in Multi-Turn LLM Interactions', 'URL': 'http://arxiv.org/abs/2510.07777', 'extra_urls': ['http://arxiv.org/abs/2510.07777'], 'type': 'article', 'author': [{'family': 'Dongre', 'given': 'Vardhan'}, {'family': 'Rossi', 'given': 'Ryan A.'}, {'family': 'Lai', 'given': 'Viet Dac'}, {'family': 'Yoon', 'given': 'David Seunghyun'}, {'family': 'Hakkani-T\xfcr', 'given': 'Dilek'}, {'family': 'Bui', 'given': 'Trung'}], 'publisher': 'arXiv', 'abstract': &quot;Large Language Models (LLMs) excel at single-turn tasks such as instruction following and summarization, yet real-world deployments require sustained multi-turn interactions where user goals and conversational context persist and evolve. A recurring challenge in this setting is context drift: the gradual divergence of a model's outputs from goal-consistent behavior across turns. Unlike single-turn errors, drift unfolds temporally and is poorly captured by static evaluation metrics. In this work, we present a study of context drift in multi-turn interactions and propose a simple dynamical framework to interpret its behavior. We formalize drift as the turn-wise KL divergence between the token-level predictive distributions of the test model and a goal-consistent reference model, and propose a recurrence model that interprets its evolution as a bounded stochastic process with restoring forces and controllable interventions. We instantiate this framework in both synthetic long-horizon rewriting tasks and realistic user-agent simulations such as in $\\tau$-Bench, measuring drift for several open-weight LLMs that are used as user simulators. Our experiments consistently reveal stable, noise-limited equilibria rather than runaway degradation, and demonstrate that simple reminder interventions reliably reduce divergence in line with theoretical predictions. Together, these results suggest that multi-turn drift can be understood as a controllable equilibrium phenomenon rather than as inevitable decay, providing a foundation for studying and mitigating context drift in extended interactions.&quot;}, {'id': 'a_realistic', 'title': 'MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs', 'URL': 'https://aclanthology.org/2025.findings-acl.958/', 'type': 'article', 'author': [{'family': 'Deshpande', 'given': 'Kaustubh'}, {'family': 'Sirdeshmukh', 'given': 'Ved'}, {'family': 'Mols', 'given': 'Johannes Baptist'}, {'family': 'Jin', 'given': 'Lifeng'}, {'family': 'Hernandez-Cardona', 'given': 'Ed-Yeremai'}, {'family': 'Lee', 'given': 'Dean'}, {'family': 'Kritz', 'given': 'Jeremy'}, {'family': 'Primack', 'given': 'Willow E.'}, {'family': 'Yue', 'given': 'Summer'}, {'family': 'Xing', 'given': 'Chen'}], 'publisher': 'Association for Computational Linguistics', 'abstract': 'We present MultiChallenge, a pioneering benchmark evaluating large language models (LLMs) on conducting multi-turn conversations with human users, a crucial yet underexamined capability for their applications. MultiChallenge identifies four categories of challenges in multi-turn conversations that are not only common and realistic among current human-LLM interactions, but are also challenging to all current frontier LLMs. All 4 challenges require accurate instruction-following, context allocation, and in-context reasoning at the same time.We also develop LLM as judge with instance-level rubrics to facilitate an automatic evaluation method with fair agreement with experienced human raters. Despite achieving near perfect scores on existing multi-turn evaluation benchmarks, all frontier models have less than 50% accuracy on MultiChallenge, with the top-performing Claude 3.5 Sonnet (October 2024) achieving just a 41.4% average accuracy.'}, {'id': 'arxiv_2502.07077', 'title': 'Multi-turn Evaluation of Anthropomorphic Behaviours in Large Language Models', 'URL': 'http://arxiv.org/abs/2502.07077', 'extra_urls': ['http://arxiv.org/abs/2502.07077'], 'type': 'article', 'author': [{'family': 'Ibrahim', 'given': 'Lujain'}, {'family': 'Akbulut', 'given': 'Canfer'}, {'family': 'Elasmar', 'given': 'Rasmi'}, {'family': 'Rastogi', 'given': 'Charvi'}, {'family': 'Kahng', 'given': 'Minsuk'}, {'family': 'Morris', 'given': 'Meredith Ringel'}, {'family': 'McKee', 'given': 'Kevin R.'}, {'family': 'Rieser', 'given': 'Verena'}, {'family': 'Shanahan', 'given': 'Murray'}, {'family': 'Weidinger', 'given': 'Laura'}], 'publisher': 'arXiv', 'abstract': &quot;The tendency of users to anthropomorphise large language models (LLMs) is of growing interest to AI developers, researchers, and policy-makers. Here, we present a novel method for empirically evaluating anthropomorphic LLM behaviours in realistic and varied settings. Going beyond single-turn static benchmarks, we contribute three methodological advances in state-of-the-art (SOTA) LLM evaluation. First, we develop a multi-turn evaluation of 14 anthropomorphic behaviours. Second, we present a scalable, automated approach by employing simulations of user interactions. Third, we conduct an interactive, large-scale human subject study (N=1101) to validate that the model behaviours we measure predict real users' anthropomorphic perceptions. We find that all SOTA LLMs evaluated exhibit similar behaviours, characterised by relationship-building (e.g., empathy and validation) and first-person pronoun use, and that the majority of behaviours only first occur after multiple turns. Our work lays an empirical foundation for investigating how design choices influence anthropomorphic model behaviours and for progressing the ethical debate on the desirability of these behaviours. It also showcases the necessity of multi-turn evaluations for complex social phenomena in human-AI interaction.&quot;}, {'id': 'arxiv_2504.04717', 'title': 'Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large Language Models', 'URL': 'http://arxiv.org/abs/2504.04717', 'extra_urls': ['http://arxiv.org/abs/2504.04717'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Yubo'}, {'family': 'Shen', 'given': 'Xiaobin'}, {'family': 'Yao', 'given': 'Xinyu'}, {'family': 'Ding', 'given': 'Xueying'}, {'family': 'Miao', 'given': 'Yidi'}, {'family': 'Krishnan', 'given': 'Ramayya'}, {'family': 'Padman', 'given': 'Rema'}], 'publisher': 'arXiv', 'abstract': 'Recent advancements in large language models (LLMs) have revolutionized their ability to handle single-turn tasks, yet real-world applications demand sophisticated multi-turn interactions. This survey provides a comprehensive review of recent advancements in evaluating and enhancing multi-turn interactions in LLMs. Focusing on task-specific scenarios, from instruction following in diverse domains such as math and coding to complex conversational engagements in roleplay, healthcare, education, and even adversarial jailbreak settings, we systematically examine the challenges of maintaining context, coherence, fairness, and responsiveness over prolonged dialogues. The paper organizes current benchmarks and datasets into coherent categories that reflect the evolving landscape of multi-turn dialogue evaluation. In addition, we review a range of enhancement methodologies under multi-turn settings, including model-centric strategies (contextual learning, supervised fine-tuning, reinforcement learning, and new architectures), external integration approaches (memory-augmented, retrieval-based methods, and knowledge graph), and agent-based techniques for collaborative interactions. Finally, we discuss open challenges and propose future directions for research to further advance the robustness and effectiveness of multi-turn interactions in LLMs. Related resources and papers are available at https://github.com/yubol-cmu/Awesome-Multi-Turn-LLMs.'}, {'id': 'how_do_microservice', 'title': 'How Do Microservice API Patterns Impact Understandability? A Controlled Experiment', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10592780', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10592780'], 'type': 'article', 'author': [{'family': 'Bogner', 'given': 'Justus'}, {'family': 'W\xf3jcik', 'given': 'Pawel'}, {'family': 'Zimmermann', 'given': 'Olaf'}], 'abstract': 'Microservices expose their functionality via remote Application Programming Interfaces (APIs), e.g., based on HTTP or asynchronous messaging technology. To solve recurring problems in this design space, Microservice API Patterns (MAPs) have emerged to capture the collective experience of the API design community. At present, there is a lack of empirical evidence for the effectiveness of these patterns, e.g., how they impact understandability and API usability. We therefore conducted a controlled experiment with 6 microservice patterns to evaluate their impact on understandability with 65 diverse participants. Additionally, we wanted to study how demographics like years of professional experience or experience with MAPs influence the effects of the patterns. Per pattern, we constructed two API examples, each in a pattern version P and a functionally equivalent non-pattern version N (24 in total). Based on a crossover design, participants had to answer comprehension Questions, while we measured the time. For five of the six patterns, we identified a significant positive impact on understandability, i.e., participants answered faster and / or more correctly for P. However, effect sizes were mostly small, with one pattern showing a medium effect. The correlations between performance and demographics seem to suggest that certain patterns may introduce additional complexity; people experienced with MAPs will profit more from their effects. This has important implications for training and education around MAPs and other patterns.'}, {'id': 'arxiv_2505.24716', 'title': 'Towards Scalable Schema Mapping using Large Language Models', 'URL': 'http://arxiv.org/abs/2505.24716', 'extra_urls': ['http://arxiv.org/abs/2505.24716'], 'type': 'article', 'author': [{'family': 'Buss', 'given': 'Christopher'}, {'family': 'Safari', 'given': 'Mahdis'}, {'family': 'Termehchy', 'given': 'Arash'}, {'family': 'Lee', 'given': 'Stefan'}, {'family': 'Maier', 'given': 'David'}], 'publisher': 'arXiv', 'abstract': 'The growing need to integrate information from a large number of diverse sources poses significant scalability challenges for data integration systems. These systems often rely on manually written schema mappings, which are complex, source-specific, and costly to maintain as sources evolve. While recent advances suggest that large language models (LLMs) can assist in automating schema matching by leveraging both structural and natural language cues, key challenges remain. In this paper, we identify three core issues with using LLMs for schema mapping: (1) inconsistent outputs due to sensitivity to input phrasing and structure, which we propose methods to address through sampling and aggregation techniques; (2) the need for more expressive mappings (e.g., GLaV), which strain the limited context windows of LLMs; and (3) the computational cost of repeated LLM calls, which we propose to mitigate through strategies like data type prefiltering.'}, {'id': 'arxiv_2406.04845', 'title': 'FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models', 'URL': 'http://arxiv.org/abs/2406.04845', 'extra_urls': ['http://arxiv.org/abs/2406.04845'], 'type': 'article', 'author': [{'family': 'Ye', 'given': 'Rui'}, {'family': 'Ge', 'given': 'Rui'}, {'family': 'Zhu', 'given': 'Xinyu'}, {'family': 'Chai', 'given': 'Jingyi'}, {'family': 'Du', 'given': 'Yaxin'}, {'family': 'Liu', 'given': 'Yang'}, {'family': 'Wang', 'given': 'Yanfeng'}, {'family': 'Chen', 'given': 'Siheng'}], 'publisher': 'arXiv', 'abstract': 'Federated learning has enabled multiple parties to collaboratively train large language models without directly sharing their data (FedLLM). Following this training paradigm, the community has put massive efforts from diverse aspects including framework, performance, and privacy. However, an unpleasant fact is that there are currently no realistic datasets and benchmarks for FedLLM and previous works all rely on artificially constructed datasets, failing to capture properties in real-world scenarios. Addressing this, we propose FedLLM-Bench, which involves 8 training methods, 4 training datasets, and 6 evaluation metrics, to offer a comprehensive testbed for the FedLLM community. FedLLM-Bench encompasses three datasets (e.g., user-annotated multilingual dataset) for federated instruction tuning and one dataset (e.g., user-annotated preference dataset) for federated preference alignment, whose scale of client number ranges from 38 to 747. Our datasets incorporate several representative diversities: language, quality, quantity, instruction, length, embedding, and preference, capturing properties in real-world scenarios. Based on FedLLM-Bench, we conduct experiments on all datasets to benchmark existing FL methods and provide empirical insights (e.g., multilingual collaboration). We believe that our FedLLM-Bench can benefit the FedLLM community by reducing required efforts, providing a practical testbed, and promoting fair comparisons. Code and datasets are available at https://github.com/rui-ye/FedLLM-Bench.'}, {'id': 'doi_10_1145_2674377_2674382', 'title': 'Improving Performance of Rural Supply Chains Using Mobile Phones: Reducing Information Asymmetry to Improve Stock Availability in Low-resource Environments', 'URL': 'https://doi.org/10.1145/2674377.2674382', 'type': 'article', 'author': [{'family': 'Ramanujapuram', 'given': 'Arun'}, {'family': 'Akkihal', 'given': 'Anup'}], 'issued': {'date-parts': [[2014]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Ensuring availability of essential goods, such as medicines or vaccines, at the point of care in the villages is a significant challenge in rural supply chains. The crux of the problem lies in information asymmetry of supply and demand, as well as ad hoc distribution practices. These supply chains are not managed efficiently, and often information flows upstream in the chain in an incomplete, incorrect and untimely manner. This ultimately affects procurement and distribution decisions, consequently leading to stock outs of important goods at the point of care.To address the problem of stock availability, we have implemented a &quot;Bulletin Board&quot; that digitally captures needs (demand) and availability (supply) of goods in real-time from any location using low-end mobile phones, and broadcasts this information to vendors and managers, upstream in the supply chain. We demonstrate that by reducing information asymmetry between supply and demand, the overall system &quot;self-organizes&quot; in a manner that stocks are appropriately re-distributed, thereby improving availability at the point of care. We demonstrate these concepts in the context of vaccine and medicine availability in a public health supply chain. In a study in Karnataka, India, we have observed vaccine stock availability increase to 99% and replenishment responsiveness improve by 64%. However, such an approach relies on obtaining high quality of data from the last mile, which is a big challenge in low-resource environments, where mobile networks are unreliable and human capacity is low. We describe the design of a mobile phone based service that leverages insights from information asymmetry theory and effective service design to achieve sustainable supply chain performance in low-resource environments.', 'DOI': '10.1145/2674377.2674382'}, {'id': 'arxiv_2504.18875', 'title': 'Generative to Agentic AI: Survey, Conceptualization, and Challenges', 'URL': 'http://arxiv.org/abs/2504.18875', 'extra_urls': ['http://arxiv.org/abs/2504.18875'], 'type': 'article', 'author': [{'family': 'Schneider', 'given': 'Johannes'}], 'publisher': 'arXiv', 'abstract': &quot;Agentic Artificial Intelligence (AI) builds upon Generative AI (GenAI). It constitutes the next major step in the evolution of AI with much stronger reasoning and interaction capabilities that enable more autonomous behavior to tackle complex tasks. Since the initial release of ChatGPT (3.5), Generative AI has seen widespread adoption, giving users firsthand experience. However, the distinction between Agentic AI and GenAI remains less well understood. To address this gap, our survey is structured in two parts. In the first part, we compare GenAI and Agentic AI using existing literature, discussing their key characteristics, how Agentic AI remedies limitations of GenAI, and the major steps in GenAI's evolution toward Agentic AI. This section is intended for a broad audience, including academics in both social sciences and engineering, as well as industry professionals. It provides the necessary insights to comprehend novel applications that are possible with Agentic AI but not with GenAI. In the second part, we deep dive into novel aspects of Agentic AI, including recent developments and practical concerns such as defining agents. Finally, we discuss several challenges that could serve as a future research agenda, while cautioning against risks that can emerge when exceeding human intelligence.&quot;}, {'id': 'enhancing_digital_product', 'title': 'Enhancing Digital Product Passport Through Decentralized Digital Twins', 'URL': 'https://ieeexplore.ieee.org/document/11076730', 'extra_urls': ['https://ieeexplore.ieee.org/document/11076730'], 'type': 'article', 'author': [{'family': 'Kannappan', 'given': 'Ranjit'}, {'family': 'Hatin', 'given': 'Julien'}, {'family': 'Bertin', 'given': 'Emmanuel'}, {'family': 'Crespi', 'given': 'Noel'}], 'abstract': 'The Digital Product Passport (DPP) is a key enabler of the European Union\u2019s vision for a circular economy. Achieving the full potential of DPP requires addressing the challenges of traditional product lifecycle systems (PLM). Traditional PLM focuses on streamlining data management and decision making. However, their centralized architecture limits transparent, crossorganizational collaboration, impacting the circular economy efforts. This paper proposes a blockchain based framework, tailored to support DPP implementation by enabling the creation and sharing of lifecycle data using digital twin technology. The proposed architecture implements two types of digital twins - Component Digital Twin and Product Digital Twin modeled using the Asset Administration Shell (AAS) standard to ensure interoperability. The architecture leverages Ethereum smart contracts for blockchain interaction and IPFS for off-chain decentralized storage. Two approaches for secure data sharing are implemented: Direct and Signature-based data sharing. Performance evaluation shows low latency for key operations like twin creation (167 ms) and data sharing (64 ms). By leveraging decentralization in DPPs, the proposed framework fosters collaboration, transparency, and circular economy practices, empowering stakeholders to access and share critical product data throughout the lifecycle.'}, {'id': 'arxiv_2410.15758', 'title': 'Digital Product Passport Management with Decentralised Identifiers and Verifiable Credentials', 'URL': 'http://arxiv.org/abs/2410.15758', 'extra_urls': ['http://arxiv.org/abs/2410.15758'], 'type': 'article', 'author': [{'family': 'Garc\xeda', 'given': 'Ismael Ill\xe1n'}, {'family': 'Mu\xf1oz-Esco\xed', 'given': 'Francesc D.'}, {'family': 'Aroca', 'given': 'Jordi Arjona'}, {'family': 'Pe\xf1uela', 'given': 'F. Javier Fern\xe1ndez-Bravo'}], 'publisher': 'arXiv', 'abstract': 'Digital product passports (DPP) have been proposed in the European Ecodesign for Sustainable Products Regulation (ESPR) as a means to keep and provide product information that facilitates product reusage, reparation, and recycling. Thus, DPPs should provide a positive effect on the environmental impact of future manufactured products, preventing waste and promoting a circular economy (CE) model. ESPR settles a set of requirements in collecting and administering product-related data. Decentralised identifiers (DID) and verifiable credentials (VC) are two self-sovereign-identity-related elements that may help in that DPP management since they introduce a decentralised administration of identity that may enhance the overall scalability of the resulting system, improving also its reliability. This paper analyses the ESPR requirements and describes how they may be achieved using DIDs and VCs, assessing their performance in some scenarios.'}, {'id': 'doi_10_1007_978-3-030-01614-2_19', 'title': 'Digital Twin Requirements in the Context of Industry 4.0', 'URL': 'https://doi.org/10.1007/978-3-030-01614-2_19', 'type': 'article', 'author': [{'family': 'Dur\xe3o', 'given': 'Luiz Fernando C. S.'}, {'family': 'Haag', 'given': 'Sebastian'}, {'family': 'Anderl', 'given': 'Reiner'}, {'family': 'Sch\xfctzer', 'given': 'Klaus'}, {'family': 'Zancul', 'given': 'Eduardo'}], 'issued': {'date-parts': [[2018]]}, 'publisher': 'Springer International Publishing', 'abstract': 'Digital Twin (DT) is being considered a significant enabler for Industry 4.0 initiatives. Within Industry 4.0, the amount of digital product information generated and collected over the entire lifecycle has been growing. Current information and communication technologies, including data storage, data processing, and wireless data transmission, may be leveraged to digitally mirror the lifecycle of a corresponding physical product with increasing level of detail. A DT creates a link between physical products and their virtual models with more comprehensive data and accumulation of knowledge. Therefore, a DT may be applied to enhance simulation, traceability and to support the offering of value-added services along the lifecycle. However, the definition of a DT and its requirements are not yet fully established. The characteristics a DT model should possess to be widely used in manufacturing remains an open question in the literature. The concept is still broad and dependent on the lifecycle stage and industry sector of application. Therefore, the objective of this paper is to propose an initial synthesis of DT requirements based on a literature review and industry interviews. The literature review focuses on the content analysis of papers published from 2010 to 2018 and indexed in the ISI Web of Science database. The interviews were conducted with industry representatives in Brazil. The results show that DT requirements are related to real-time data, integration, and fidelity. Besides, it shows that industry requirements are close to literature and the actual implementation of DT is the future of research in this field.', 'DOI': '10.1007/978-3-030-01614-2_19'}, {'id': 'effective_vocabulary', 'title': 'VEEF-Multi-LLM: Effective Vocabulary Expansion and Parameter Efficient Finetuning Towards Multilingual Large Language Models', 'URL': 'https://aclanthology.org/2025.coling-main.533/', 'extra_urls': ['https://aclanthology.org/2025.coling-main.533/'], 'type': 'article', 'author': [{'family': 'Sha', 'given': 'Jiu'}, {'family': 'Zhu', 'given': 'Mengxiao'}, {'family': 'Feng', 'given': 'Chong'}, {'family': 'Shang', 'given': 'Yuming'}], 'publisher': 'Association for Computational Linguistics', 'abstract': 'Large Language Models(LLMs) have brought significant transformations to various aspects of human life and productivity. However, the heavy reliance on vast amounts of data in developing these models has resulted in a notable disadvantage for low-resource languages, such as Nuosu and others, which lack large datasets. Moreover, many LLMs exhibit significant performance discrepancies between high-and lowresource languages, thereby restricting equitable access to technological advances for all linguistic communities. To address these challenges, this paper propose a low-resource multilingual large language model, termed VEEF-Multi-LLM, constructed through effective vocabulary expansion and parameter-efficient fine-tuning. We introduce a series of innovative methods to address challenges in low-resource languages. First, we adopt Byte-level Byte-Pair Encoding to expand the vocabulary for broader multilingual support. We separate input and output embedding weights to boost performance, and apply RoPE for long-context handling, as well as RMSNorm for efficient training. To generate high-quality supervised fine-tuning (SFT) data, we use self-training and selective translation, and refine the resulting dataset with the assistance of native speakers to ensure cultural and linguistic accuracy. Our model, VEEF-Multi-LLM-8B, is trained on 600 billion tokens across 50 natural and 16 programming languages. Experimental results show that the model excels in multilingual instruction-following tasks, particularly in translation, outperforming competing models in benchmarks such as XCOPA and XStoryCloze. Although it lags slightly behind English-centric models in some tasks (e.g., m-MMLU), it prioritizes safety, reliability, and inclusivity, making it valuable for diverse linguistic communities. We open-source our models on GitHub and Huggingface.'}, {'id': 'arxiv_2502.08650', 'title': 'Who is Responsible? The Data, Models, Users or Regulations? A Comprehensive Survey on Responsible Generative AI for a Sustainable Future', 'URL': 'http://arxiv.org/abs/2502.08650', 'extra_urls': ['http://arxiv.org/abs/2502.08650'], 'type': 'article', 'author': [{'family': 'Raza', 'given': 'Shaina'}, {'family': 'Qureshi', 'given': 'Rizwan'}, {'family': 'Zahid', 'given': 'Anam'}, {'family': 'Kamawal', 'given': 'Safiullah'}, {'family': 'Sadak', 'given': 'Ferhat'}, {'family': 'Fioresi', 'given': 'Joseph'}, {'family': 'Saeed', 'given': 'Muhammaed'}, {'family': 'Sapkota', 'given': 'Ranjan'}, {'family': 'Jain', 'given': 'Aditya'}, {'family': 'Zafar', 'given': 'Anas'}, {'family': 'Hassan', 'given': 'Muneeb Ul'}, {'family': 'Zafar', 'given': 'Aizan'}, {'family': 'Maqbool', 'given': 'Hasan'}, {'family': 'Vayani', 'given': 'Ashmal'}, {'family': 'Wu', 'given': 'Jia'}, {'family': 'Shoman', 'given': 'Maged'}], 'publisher': 'arXiv', 'abstract': 'Generative AI is moving rapidly from research into real world deployment across sectors, which elevates the need for responsible development, deployment, evaluation, and governance. To address this pressing challenge, in this study, we synthesize the landscape of responsible generative AI across methods, benchmarks, and policies, and connects governance expectations to concrete engineering practice. We follow a prespecified search and screening protocol focused on post-ChatGPT era with selective inclusion of foundational work for definitions, and we conduct a narrative and thematic synthesis. Three findings emerge; First, benchmark and practice coverage is dense for bias and toxicity but relatively sparse for privacy and provenance, deepfake and media integrity risk, and system level failure in tool using and agentic settings. Second, many evaluations remain static and task local, which limits evidence portability for audit and lifecycle assurance. Third, documentation and metric validity are inconsistent, which complicates comparison across releases and domains. We outline a research and practice agenda that prioritizes adaptive and multimodal evaluation, privacy and provenance testing, deepfake risk assessment, calibration and uncertainty reporting, versioned and documented artifacts, and continuous monitoring. Limitations include reliance on public artifacts and the focus period, which may under represent capabilities reported later. The survey offers a path to align development and evaluation with governance needs and to support safe, transparent, and accountable deployment across domains. Project page: https://anas-zafar.github.io/responsible-ai.github.io , GitHub: https://github.com/anas-zafar/Responsible-AI'}, {'id': 'business_simulation', 'title': 'AI-Enhanced Business Simulation Models for Strategic Decision-Making in Uncertain Environments', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11156362', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11156362'], 'type': 'article', 'author': [{'family': 'Lahoti', 'given': 'Yuvraj'}, {'family': 'Kalshetti', 'given': 'Prashant'}, {'family': 'Anute', 'given': 'Nilesh'}, {'family': 'Limbore', 'given': 'Nilesh Vitthal'}], 'abstract': &quot;Uncertainty and complexity make it hard to make effective decisions in today's business world, which changes quickly. Even though traditional business computer models can teach us a lot, they don't always capture how dynamic and unclear real-life situations are. This article talks about a new AI-enhanced business exercise system that is meant to help people make smart decisions when they don't know what will happen. By adding advanced AI methods like machine learning and reinforcement learning to business models, the framework makes it possible for data-driven, adaptable decision support that learns and changes as market conditions do. The suggested method uses random processes and scenario analysis to model unpredictability. This lets decision-makers look at a range of possible futures and see how well tactics work when faced with different risks and problems. To show what the framework can do, a sample simulation model was made using carefully chosen AI algorithms that are best at making predictions and using computers quickly. The modeling setting was set up to look like complicated business situations, including important organizational and market factors that affect the results. The results of the experiments show that the framework can improve the quality of decisions by giving us practical insights, making risk assessment better, and letting us evaluate strategies in a variety of situations. This work adds to management study by connecting new developments in AI with real-world business simulations. This makes strategy planning more adaptable and well-informed. The approach could be used in multi-agent systems, and real-time data merging could help with ongoing learning in the future. This AI-based method looks like it could help leaders and researchers deal with uncertainty and improve business success in unstable markets.&quot;}, {'id': 'arxiv_2507.00951', 'title': 'Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact', 'URL': 'http://arxiv.org/abs/2507.00951', 'extra_urls': ['http://arxiv.org/abs/2507.00951'], 'type': 'article', 'author': [{'family': 'Qureshi', 'given': 'Rizwan'}, {'family': 'Sapkota', 'given': 'Ranjan'}, {'family': 'Shah', 'given': 'Abbas'}, {'family': 'Muneer', 'given': 'Amgad'}, {'family': 'Zafar', 'given': 'Anas'}, {'family': 'Vayani', 'given': 'Ashmal'}, {'family': 'Shoman', 'given': 'Maged'}, {'family': 'Eldaly', 'given': 'Abdelrahman B. M.'}, {'family': 'Zhang', 'given': 'Kai'}, {'family': 'Sadak', 'given': 'Ferhat'}, {'family': 'Raza', 'given': 'Shaina'}, {'family': 'Fan', 'given': 'Xinqi'}, {'family': 'Shwartz-Ziv', 'given': 'Ravid'}, {'family': 'Yan', 'given': 'Hong'}, {'family': 'Jain', 'given': 'Vinjia'}, {'family': 'Chadha', 'given': 'Aman'}, {'family': 'Karkee', 'given': 'Manoj'}, {'family': 'Wu', 'given': 'Jia'}, {'family': 'Mirjalili', 'given': 'Seyedali'}], 'publisher': 'arXiv', 'abstract': 'Can machines truly think, reason and act in domains like humans? This enduring question continues to shape the pursuit of Artificial General Intelligence (AGI). Despite the growing capabilities of models such as GPT-4.5, DeepSeek, Claude 3.5 Sonnet, Phi-4, and Grok 3, which exhibit multimodal fluency and partial reasoning, these systems remain fundamentally limited by their reliance on token-level prediction and lack of grounded agency. This paper offers a cross-disciplinary synthesis of AGI development, spanning artificial intelligence, cognitive neuroscience, psychology, generative models, and agent-based systems. We analyze the architectural and cognitive foundations of general intelligence, highlighting the role of modular reasoning, persistent memory, and multi-agent coordination. In particular, we emphasize the rise of Agentic RAG frameworks that combine retrieval, planning, and dynamic tool use to enable more adaptive behavior. We discuss generalization strategies, including information compression, test-time adaptation, and training-free methods, as critical pathways toward flexible, domain-agnostic intelligence. Vision-Language Models (VLMs) are reexamined not just as perception modules but as evolving interfaces for embodied understanding and collaborative task completion. We also argue that true intelligence arises not from scale alone but from the integration of memory and reasoning: an orchestration of modular, interactive, and self-improving components where compression enables adaptive behavior. Drawing on advances in neurosymbolic systems, reinforcement learning, and cognitive scaffolding, we explore how recent architectures begin to bridge the gap between statistical learning and goal-directed cognition. Finally, we identify key scientific, technical, and ethical challenges on the path to AGI.'}, {'id': 'how_to_choose', 'title': 'How to Choose Among Technologies With Learning Curves: Making Better Investment Decisions', 'URL': 'https://papers.ssrn.com/abstract=5168106', 'extra_urls': ['https://papers.ssrn.com/abstract=5168106'], 'type': 'article', 'author': [{'family': 'Kaps', 'given': 'Christian'}, {'family': 'Anderer', 'given': 'Arielle'}], 'publisher': 'Social Science Research Network', 'abstract': 'Learning curves, the fact that technologies improve as a function of cumulative experience or investment, are desirable-think inexpensive solar panels or higher performing semiconductors. But, for firms that need to pick one technology among several candidates, such as R&amp;D labs or venture capital firms, learning curves make it hard to make the optimal technology investment choice. This paper addresses this challenge and provides the first formal analysis of how to invest in a set of technologies over multiple periods if (i) the cost of a technology decreases with cumulative investment and (ii) the decision maker only benefits from the estimated lowest-cost technology at the end of the investment horizon. We develop a dynamic programming framework to model this problem and, for a 2-technology case, are able to identify a closed-form ratio that managers can compute to choose the optimal technology to invest in. We then leverage these insights to develop a policy that can be employed to find the best investment choice for settings with any number of technologies and decision periods. Our policy has the added benefit of making the value of exploration versus exploitation visible to the decision-maker. We provide detailed numerical comparisons of our Technology Learning Curve Optimization (TELCO) policy and find it performs, on average, 8% better than the second-best policy across 1200 different scenarios. Additionally, we apply our methodology to the real-world problem of lithium-ion chemistries for battery production, demonstrating its robustness and effectiveness.'}, {'id': 'arxiv_2510.03469', 'title': 'Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification', 'URL': 'http://arxiv.org/abs/2510.03469', 'extra_urls': ['http://arxiv.org/abs/2510.03469'], 'type': 'article', 'author': [{'family': 'Ramani', 'given': 'Keshav'}, {'family': 'Tawosi', 'given': 'Vali'}, {'family': 'Alamir', 'given': 'Salwa'}, {'family': 'Borrajo', 'given': 'Daniel'}], 'publisher': 'arXiv', 'abstract': 'We introduce a novel framework for evaluating the alignment between natural language plans and their expected behavior by converting them into Kripke structures and Linear Temporal Logic (LTL) using Large Language Models (LLMs) and performing model checking. We systematically evaluate this framework on a simplified version of the PlanBench plan verification dataset and report on metrics like Accuracy, Precision, Recall and F1 scores. Our experiments demonstrate that GPT-5 achieves excellent classification performance (F1 score of 96.3%) while almost always producing syntactically perfect formal representations that can act as guarantees. However, the synthesis of semantically perfect formal models remains an area for future exploration.'}, {'id': 'arxiv_2509.23864', 'title': 'AgentGuard: Runtime Verification of AI Agents', 'URL': 'http://arxiv.org/abs/2509.23864', 'extra_urls': ['http://arxiv.org/abs/2509.23864'], 'type': 'article', 'author': [{'family': 'Koohestani', 'given': 'Roham'}], 'publisher': 'arXiv', 'abstract': &quot;The rapid evolution to autonomous, agentic AI systems introduces significant risks due to their inherent unpredictability and emergent behaviors; this also renders traditional verification methods inadequate and necessitates a shift towards probabilistic guarantees where the question is no longer if a system will fail, but the probability of its failure within given constraints. This paper presents AgentGuard, a framework for runtime verification of Agentic AI systems that provides continuous, quantitative assurance through a new paradigm called Dynamic Probabilistic Assurance. AgentGuard operates as an inspection layer that observes an agent's raw I/O and abstracts it into formal events corresponding to transitions in a state model. It then uses online learning to dynamically build and update a Markov Decision Process (MDP) that formally models the agent's emergent behavior. Using probabilistic model checking, the framework then verifies quantitative properties in real-time.&quot;}, {'id': 'arxiv_2509.20364', 'title': 'An Approach to Checking Correctness for Agentic Systems', 'URL': 'http://arxiv.org/abs/2509.20364', 'extra_urls': ['http://arxiv.org/abs/2509.20364'], 'type': 'article', 'author': [{'family': 'Sheffler', 'given': 'Thomas J.'}], 'publisher': 'arXiv', 'abstract': &quot;This paper presents a temporal expression language for monitoring AI agent behavior, enabling systematic error-detection of LLM-based agentic systems that exhibit variable outputs due to stochastic generation processes. Drawing from temporal logic techniques used in hardware verification, this approach monitors execution traces of agent tool calls and state transitions to detect deviations from expected behavioral patterns. Current error-detection approaches rely primarily on text matching of inputs and outputs, which proves fragile due to the natural language variability inherent in LLM responses. The proposed method instead focuses on the sequence of agent actions -- such as tool invocations and inter-agent communications -- allowing verification of system behavior independent of specific textual outputs. The temporal expression language provides assertions that capture correct behavioral patterns across multiple execution scenarios. These assertions serve dual purposes: validating prompt engineering and guardrail effectiveness during development, and providing regression testing when agents are updated with new LLMs or modified logic. The approach is demonstrated using a three-agent system, where agents coordinate to solve multi-step reasoning tasks. When powered by large, capable models, all temporal assertions were satisfied across many test runs. However, when smaller models were substituted in two of the three agents, executions violated behavioral assertions, primarily due to improper tool sequencing and failed coordination handoffs. The temporal expressions successfully flagged these anomalies, demonstrating the method's effectiveness for detecting behavioral regressions in production agentic systems. This approach provides a foundation for systematic monitoring of AI agent reliability as these systems become increasingly deployed in critical applications.&quot;}, {'id': 'verifying', 'title': 'LLMV-AgE: Verifying LLM-Guided Planning for Agentic Exploration in Open-World RL', 'URL': 'https://openreview.net/forum?id=dA7a3eKkKg', 'extra_urls': ['https://openreview.net/forum?id=dA7a3eKkKg'], 'type': 'article', 'author': [{'family': 'Chi', 'given': 'Haotian'}, {'family': 'Zhao', 'given': 'Songwei'}, {'family': 'Tsang', 'given': 'Ivor'}, {'family': 'Ong', 'given': 'Yew-Soon'}, {'family': 'Chen', 'given': 'Hechang'}, {'family': 'Chang', 'given': 'Yi'}, {'family': 'Yin', 'given': 'Haiyan'}], 'abstract': 'Large language models (LLMs) have shown promise in enhancing reinforcement learning (RL) through task decomposition, yet their generated subgoals often lack reliability, leading to inefficient exploration and suboptimal policy learning. In this paper, we propose LLMV-AgE (Verification of LLM-guided planning for Agentic Exploration), an RL framework that integrates LLM-guided subgoal planning with a hierarchical verification process to ensure both semantic validity and environmental feasibility. LLMV-AgE systematically assesses subgoal coherence, corrects invalid plans through iterative refinement, and aligns policy learning with reliable, goal-driven objectives. Empirical results on the procedurally generated Crafter benchmark demonstrate that LLMV-AgE significantly improves exploration efficiency and policy robustness by mitigating the impact of hallucinated subgoals and guiding agents toward more achievable goals.'}, {'id': 'arxiv_2502.16662', 'title': 'Saarthi: The First AI Formal Verification Engineer', 'URL': 'http://arxiv.org/abs/2502.16662', 'extra_urls': ['http://arxiv.org/abs/2502.16662'], 'type': 'article', 'author': [{'family': 'Kumar', 'given': 'Aman'}, {'family': 'Gadde', 'given': 'Deepak Narayan'}, {'family': 'Radhakrishna', 'given': 'Keerthan Kopparam'}, {'family': 'Lettnin', 'given': 'Djones'}], 'publisher': 'arXiv', 'abstract': &quot;Recently, Devin has made a significant buzz in the Artificial Intelligence (AI) community as the world's first fully autonomous AI software engineer, capable of independently developing software code. Devin uses the concept of agentic workflow in Generative AI (GenAI), which empowers AI agents to engage in a more dynamic, iterative, and self-reflective process. In this paper, we present a similar fully autonomous AI formal verification engineer, Saarthi, capable of verifying a given RTL design end-to-end using an agentic workflow. With Saarthi, verification engineers can focus on more complex problems, and verification teams can strive for more ambitious goals. The domain-agnostic implementation of Saarthi makes it scalable for use across various domains such as RTL design, UVM-based verification, and others.&quot;}, {'id': 'arxiv_2510.03463', 'title': 'ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering Framework', 'URL': 'http://arxiv.org/abs/2510.03463', 'extra_urls': ['http://arxiv.org/abs/2510.03463'], 'type': 'article', 'author': [{'family': 'Tawosi', 'given': 'Vali'}, {'family': 'Ramani', 'given': 'Keshav'}, {'family': 'Alamir', 'given': 'Salwa'}, {'family': 'Liu', 'given': 'Xiaomo'}], 'publisher': 'arXiv', 'abstract': 'Multi-agent Large Language Model (LLM) systems have been leading the way in applied LLM research across a number of fields. One notable area is software development, where researchers have advanced the automation of code implementation, code testing, code maintenance, inter alia, using LLM agents. However, software development is a multifaceted environment that extends beyond just code. As such, a successful LLM system must factor in multiple stages of the software development life-cycle (SDLC). In this paper, we propose a vision for ALMAS, an Autonomous LLM-based Multi-Agent Software Engineering framework, which follows the above SDLC philosophy such that it may work within an agile software development team to perform several tasks end-to-end. ALMAS aligns its agents with agile roles, and can be used in a modular fashion to seamlessly integrate with human developers and their development environment. We showcase the progress towards ALMAS through our published works and a use case demonstrating the framework, where ALMAS is able to seamlessly generate an application and add a new feature.'}, {'id': 'arxiv_2506.09755', 'title': 'Intelligent Design 4.0: Paradigm Evolution Toward the Agentic AI Era', 'URL': 'http://arxiv.org/abs/2506.09755', 'extra_urls': ['http://arxiv.org/abs/2506.09755'], 'type': 'article', 'author': [{'family': 'Jiang', 'given': 'Shuo'}, {'family': 'Xie', 'given': 'Min'}, {'family': 'Chen', 'given': 'Frank Youhua'}, {'family': 'Ma', 'given': 'Jian'}, {'family': 'Luo', 'given': 'Jianxi'}], 'publisher': 'arXiv', 'abstract': &quot;Research and practice in Intelligent Design (ID) have significantly enhanced engineering innovation, efficiency, quality, and productivity over recent decades, fundamentally reshaping how engineering designers think, behave, and interact with design processes. The recent emergence of Foundation Models (FMs), particularly Large Language Models (LLMs), has demonstrated general knowledge-based reasoning capabilities, and open new paths and avenues for further transformation in engineering design. In this context, this paper introduces Intelligent Design 4.0 (ID 4.0) as an emerging paradigm empowered by agentic AI systems. We review the historical evolution of ID across four distinct stages: rule-based expert systems, task-specific machine learning models, large-scale foundation AI models, and the recent emerging paradigm of multi-agent collaboration. We propose a conceptual framework for ID 4.0 and discuss its potential to support end-to-end automation of engineering design processes through coordinated, autonomous multi-agent-based systems. Furthermore, we discuss future perspectives to enhance and fully realize ID 4.0's potential, including more complex design scenarios, more practical design implementations, novel agent coordination mechanisms, and autonomous design goal-setting with better human value alignment. In sum, these insights lay a foundation for advancing Intelligent Design toward greater adaptivity, autonomy, and effectiveness in addressing increasingly complex design challenges.&quot;}, {'id': 'arxiv_2505.08137', 'title': 'Large Language Models for Computer-Aided Design: A Survey', 'URL': 'http://arxiv.org/abs/2505.08137', 'extra_urls': ['http://arxiv.org/abs/2505.08137'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Licheng'}, {'family': 'Le', 'given': 'Bach'}, {'family': 'Akhtar', 'given': 'Naveed'}, {'family': 'Lam', 'given': 'Siew-Kei'}, {'family': 'Ngo', 'given': 'Tuan'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) have seen rapid advancements in recent years, with models like ChatGPT and DeepSeek, showcasing their remarkable capabilities across diverse domains. While substantial research has been conducted on LLMs in various fields, a comprehensive review focusing on their integration with Computer-Aided Design (CAD) remains notably absent. CAD is the industry standard for 3D modeling and plays a vital role in the design and development of products across different industries. As the complexity of modern designs increases, the potential for LLMs to enhance and streamline CAD workflows presents an exciting frontier. This article presents the first systematic survey exploring the intersection of LLMs and CAD. We begin by outlining the industrial significance of CAD, highlighting the need for AI-driven innovation. Next, we provide a detailed overview of the foundation of LLMs. We also examine both closed-source LLMs as well as publicly available models. The core of this review focuses on the various applications of LLMs in CAD, providing a taxonomy of six key areas where these models are making considerable impact. Finally, we propose several promising future directions for further advancements, which offer vast opportunities for innovation and are poised to shape the future of CAD technology. Github: https://github.com/lichengzhanguom/LLMs-CAD-Survey-Taxonomy'}, {'id': 'arxiv_2501.12202', 'title': 'Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D Assets Generation', 'URL': 'http://arxiv.org/abs/2501.12202', 'extra_urls': ['http://arxiv.org/abs/2501.12202'], 'type': 'article', 'author': [{'family': 'Zhao', 'given': 'Zibo'}, {'family': 'Lai', 'given': 'Zeqiang'}, {'family': 'Lin', 'given': 'Qingxiang'}, {'family': 'Zhao', 'given': 'Yunfei'}, {'family': 'Liu', 'given': 'Haolin'}, {'family': 'Yang', 'given': 'Shuhui'}, {'family': 'Feng', 'given': 'Yifei'}, {'family': 'Yang', 'given': 'Mingxin'}, {'family': 'Zhang', 'given': 'Sheng'}, {'family': 'Yang', 'given': 'Xianghui'}, {'family': 'Shi', 'given': 'Huiwen'}, {'family': 'Liu', 'given': 'Sicong'}, {'family': 'Wu', 'given': 'Junta'}, {'family': 'Lian', 'given': 'Yihang'}, {'family': 'Yang', 'given': 'Fan'}, {'family': 'Tang', 'given': 'Ruining'}, {'family': 'He', 'given': 'Zebin'}, {'family': 'Wang', 'given': 'Xinzhou'}, {'family': 'Liu', 'given': 'Jian'}, {'family': 'Zuo', 'given': 'Xuhui'}, {'family': 'Chen', 'given': 'Zhuo'}, {'family': 'Lei', 'given': 'Biwen'}, {'family': 'Weng', 'given': 'Haohan'}, {'family': 'Xu', 'given': 'Jing'}, {'family': 'Zhu', 'given': 'Yiling'}, {'family': 'Liu', 'given': 'Xinhai'}, {'family': 'Xu', 'given': 'Lixin'}, {'family': 'Hu', 'given': 'Changrong'}, {'family': 'Yang', 'given': 'Shaoxiong'}, {'family': 'Zhang', 'given': 'Song'}, {'family': 'Liu', 'given': 'Yang'}, {'family': 'Huang', 'given': 'Tianyu'}, {'family': 'Wang', 'given': 'Lifu'}, {'family': 'Zhang', 'given': 'Jihong'}, {'family': 'Chen', 'given': 'Meng'}, {'family': 'Dong', 'given': 'Liang'}, {'family': 'Jia', 'given': 'Yiwen'}, {'family': 'Cai', 'given': 'Yulin'}, {'family': 'Yu', 'given': 'Jiaao'}, {'family': 'Tang', 'given': 'Yixuan'}, {'family': 'Zhang', 'given': 'Hao'}, {'family': 'Ye', 'given': 'Zheng'}, {'family': 'He', 'given': 'Peng'}, {'family': 'Wu', 'given': 'Runzhou'}, {'family': 'Zhang', 'given': 'Chao'}, {'family': 'Tan', 'given': 'Yonghao'}, {'family': 'Xiao', 'given': 'Jie'}, {'family': 'Tao', 'given': 'Yangyu'}, {'family': 'Zhu', 'given': 'Jianchen'}, {'family': 'Xue', 'given': 'Jinbao'}, {'family': 'Liu', 'given': 'Kai'}, {'family': 'Zhao', 'given': 'Chongqing'}, {'family': 'Wu', 'given': 'Xinming'}, {'family': 'Hu', 'given': 'Zhichao'}, {'family': 'Qin', 'given': 'Lei'}, {'family': 'Peng', 'given': 'Jianbing'}, {'family': 'Li', 'given': 'Zhan'}, {'family': 'Chen', 'given': 'Minghui'}, {'family': 'Zhang', 'given': 'Xipeng'}, {'family': 'Niu', 'given': 'Lin'}, {'family': 'Wang', 'given': 'Paige'}, {'family': 'Wang', 'given': 'Yingkai'}, {'family': 'Kuang', 'given': 'Haozhao'}, {'family': 'Fan', 'given': 'Zhongyi'}, {'family': 'Zheng', 'given': 'Xu'}, {'family': 'Zhuang', 'given': 'Weihao'}, {'family': 'He', 'given': 'YingPing'}, {'family': 'Liu', 'given': 'Tian'}, {'family': 'Yang', 'given': 'Yong'}, {'family': 'Wang', 'given': 'Di'}, {'family': 'Liu', 'given': 'Yuhong'}, {'family': 'Jiang', 'given': 'Jie'}, {'family': 'Huang', 'given': 'Jingwei'}, {'family': 'Guo', 'given': 'Chunchao'}], 'publisher': 'arXiv', 'abstract': 'We present Hunyuan3D 2.0, an advanced large-scale 3D synthesis system for generating high-resolution textured 3D assets. This system includes two foundation components: a large-scale shape generation model -- Hunyuan3D-DiT, and a large-scale texture synthesis model -- Hunyuan3D-Paint. The shape generative model, built on a scalable flow-based diffusion transformer, aims to create geometry that properly aligns with a given condition image, laying a solid foundation for downstream applications. The texture synthesis model, benefiting from strong geometric and diffusion priors, produces high-resolution and vibrant texture maps for either generated or hand-crafted meshes. Furthermore, we build Hunyuan3D-Studio -- a versatile, user-friendly production platform that simplifies the re-creation process of 3D assets. It allows both professional and amateur users to manipulate or even animate their meshes efficiently. We systematically evaluate our models, showing that Hunyuan3D 2.0 outperforms previous state-of-the-art models, including the open-source models and closed-source models in geometry details, condition alignment, texture quality, and etc. Hunyuan3D 2.0 is publicly released in order to fill the gaps in the open-source 3D community for large-scale foundation generative models. The code and pre-trained weights of our models are available at: https://github.com/Tencent/Hunyuan3D-2'}, {'id': 'arxiv_2411.04954', 'title': 'CAD-MLLM: Unifying Multimodality-Conditioned CAD Generation With MLLM', 'URL': 'http://arxiv.org/abs/2411.04954', 'extra_urls': ['http://arxiv.org/abs/2411.04954'], 'type': 'article', 'author': [{'family': 'Xu', 'given': 'Jingwei'}, {'family': 'Wang', 'given': 'Chenyu'}, {'family': 'Zhao', 'given': 'Zibo'}, {'family': 'Liu', 'given': 'Wen'}, {'family': 'Ma', 'given': 'Yi'}, {'family': 'Gao', 'given': 'Shenghua'}], 'publisher': 'arXiv', 'abstract': &quot;This paper aims to design a unified Computer-Aided Design (CAD) generation system that can easily generate CAD models based on the user's inputs in the form of textual description, images, point clouds, or even a combination of them. Towards this goal, we introduce the CAD-MLLM, the first system capable of generating parametric CAD models conditioned on the multimodal input. Specifically, within the CAD-MLLM framework, we leverage the command sequences of CAD models and then employ advanced large language models (LLMs) to align the feature space across these diverse multi-modalities data and CAD models' vectorized representations. To facilitate the model training, we design a comprehensive data construction and annotation pipeline that equips each CAD model with corresponding multimodal data. Our resulting dataset, named Omni-CAD, is the first multimodal CAD dataset that contains textual description, multi-view images, points, and command sequence for each CAD model. It contains approximately 450K instances and their CAD construction sequences. To thoroughly evaluate the quality of our generated CAD models, we go beyond current evaluation metrics that focus on reconstruction quality by introducing additional metrics that assess topology quality and surface enclosure extent. Extensive experimental results demonstrate that CAD-MLLM significantly outperforms existing conditional generative methods and remains highly robust to noises and missing points. The project page and more visualizations can be found at: https://cad-mllm.github.io/&quot;}, {'id': 'arxiv_2405.02580', 'title': 'PropertyGPT: LLM-driven Formal Verification of Smart Contracts through Retrieval-Augmented Property Generation', 'URL': 'http://arxiv.org/abs/2405.02580', 'extra_urls': ['http://arxiv.org/abs/2405.02580'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Ye'}, {'family': 'Xue', 'given': 'Yue'}, {'family': 'Wu', 'given': 'Daoyuan'}, {'family': 'Sun', 'given': 'Yuqiang'}, {'family': 'Li', 'given': 'Yi'}, {'family': 'Shi', 'given': 'Miaolei'}, {'family': 'Liu', 'given': 'Yang'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'With recent advances in large language models (LLMs), this paper explores the potential of leveraging state-of-the-art LLMs,such as GPT-4, to transfer existing human-written properties (e.g.,those from Certora auditing reports) and automatically generate customized properties for unknown code. To this end, we embed existing properties into a vector database and retrieve a reference property for LLM-based in-context learning to generate a new property for a given code. While this basic process is relatively straightforward, ensuring that the generated properties are (i) compilable, (ii) appropriate, and (iii) verifiable presents challenges. To address (i), we use the compilation and static analysis feedback as an external oracle to guide LLMs in iteratively revising the generated properties. For (ii), we consider multiple dimensions of similarity to rank the properties and employ a weighted algorithm to identify the top-K properties as the final result. For (iii), we design a dedicated prover to formally verify the correctness of the generated properties. We have implemented these strategies into a novel LLM-based property generation tool called PropertyGPT. Our experiments show that PropertyGPT can generate comprehensive and high-quality properties, achieving an 80% recall compared to the ground truth. It successfully detected 26 CVEs/attack incidents out of 37 tested and also uncovered 12 zero-day vulnerabilities, leading to $8,256 in bug bounty rewards.'}, {'id': 'arxiv_2508.19870', 'title': 'Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey', 'URL': 'http://arxiv.org/abs/2508.19870', 'extra_urls': ['http://arxiv.org/abs/2508.19870'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Yinqiu'}, {'family': 'Zhang', 'given': 'Ruichen'}, {'family': 'Luo', 'given': 'Haoxiang'}, {'family': 'Lin', 'given': 'Yijing'}, {'family': 'Sun', 'given': 'Geng'}, {'family': 'Niyato', 'given': 'Dusit'}, {'family': 'Du', 'given': 'Hongyang'}, {'family': 'Xiong', 'given': 'Zehui'}, {'family': 'Wen', 'given': 'Yonggang'}, {'family': 'Jamalipour', 'given': 'Abbas'}, {'family': 'Kim', 'given': 'Dong In'}, {'family': 'Zhang', 'given': 'Ping'}], 'publisher': 'arXiv', 'abstract': &quot;Agentification serves as a critical enabler of Edge General Intelligence (EGI), transforming massive edge devices into cognitive agents through integrating Large Language Models (LLMs) and perception, reasoning, and acting modules. These agents collaborate across heterogeneous edge infrastructures, forming multi-LLM agentic AI systems that leverage collective intelligence and specialized capabilities to tackle complex, multi-step tasks. However, the collaborative nature of multi-LLM systems introduces critical security vulnerabilities, including insecure inter-LLM communications, expanded attack surfaces, and cross-domain data leakage that traditional perimeter-based security cannot adequately address. To this end, this survey introduces zero-trust security of multi-LLM in EGI, a paradigmatic shift following the ``never trust, always verify'' principle. We begin by systematically analyzing the security risks in multi-LLM systems within EGI contexts. Subsequently, we present the vision of a zero-trust multi-LLM framework in EGI. We then survey key technical progress to facilitate zero-trust multi-LLM systems in EGI. Particularly, we categorize zero-trust security mechanisms into model- and system-level approaches. The former and latter include strong identification, context-aware access control, etc., and proactive maintenance, blockchain-based management, etc., respectively. Finally, we identify critical research directions. This survey serves as the first systematic treatment of zero-trust applied to multi-LLM systems, providing both theoretical foundations and practical strategies.&quot;}, {'id': 'arxiv_2508.01351', 'title': 'NATLM: Detecting Defects in NFT Smart Contracts Leveraging LLM', 'URL': 'http://arxiv.org/abs/2508.01351', 'extra_urls': ['http://arxiv.org/abs/2508.01351'], 'type': 'article', 'author': [{'family': 'Niu', 'given': 'Yuanzheng'}, {'family': 'Li', 'given': 'Xiaoqi'}, {'family': 'Li', 'given': 'Wenkai'}], 'publisher': 'arXiv', 'abstract': 'Security issues are becoming increasingly significant with the rapid evolution of Non-fungible Tokens (NFTs). As NFTs are traded as digital assets, they have emerged as prime targets for cyber attackers. In the development of NFT smart contracts, there may exist undiscovered defects that could lead to substantial financial losses if exploited. To tackle this issue, this paper presents a framework called NATLM(NFT Assistant LLM), designed to detect potential defects in NFT smart contracts. The framework effectively identifies four common types of vulnerabilities in NFT smart contracts: ERC-721 Reentrancy, Public Burn, Risky Mutable Proxy, and Unlimited Minting. Relying exclusively on large language models (LLMs) for defect detection can lead to a high false-positive rate. To enhance detection performance, NATLM integrates static analysis with LLMs, specifically Gemini Pro 1.5. Initially, NATLM employs static analysis to extract structural, syntactic, and execution flow information from the code, represented through Abstract Syntax Trees (AST) and Control Flow Graphs (CFG). These extracted features are then combined with vectors of known defect examples to create a matrix for input into the knowledge base. Subsequently, the feature vectors and code vectors of the analyzed contract are compared with the contents of the knowledge base. Finally, the LLM performs deep semantic analysis to enhance detection capabilities, providing a more comprehensive and accurate identification of potential security issues. Experimental results indicate that NATLM analyzed 8,672 collected NFT smart contracts, achieving an overall precision of 87.72%, a recall of 89.58%, and an F1 score of 88.94%. The results outperform other baseline experiments, successfully identifying four common types of defects.'}, {'id': 'arxiv_2508.05188', 'title': 'Incident Response Planning Using a Lightweight Large Language Model with Reduced Hallucination', 'URL': 'http://arxiv.org/abs/2508.05188', 'extra_urls': ['http://arxiv.org/abs/2508.05188'], 'type': 'article', 'author': [{'family': 'Hammar', 'given': 'Kim'}, {'family': 'Alpcan', 'given': 'Tansu'}, {'family': 'Lupu', 'given': 'Emil C.'}], 'publisher': 'arXiv', 'abstract': 'Timely and effective incident response is key to managing the growing frequency of cyberattacks. However, identifying the right response actions for complex systems is a major technical challenge. A promising approach to mitigate this challenge is to use the security knowledge embedded in large language models (LLMs) to assist security operators during incident handling. Recent research has demonstrated the potential of this approach, but current methods are mainly based on prompt engineering of frontier LLMs, which is costly and prone to hallucinations. We address these limitations by presenting a novel way to use an LLM for incident response planning with reduced hallucination. Our method includes three steps: fine-tuning, information retrieval, and lookahead planning. We prove that our method generates response plans with a bounded probability of hallucination and that this probability can be made arbitrarily small at the expense of increased planning time under certain assumptions. Moreover, we show that our method is lightweight and can run on commodity hardware. We evaluate our method on logs from incidents reported in the literature. The experimental results show that our method a) achieves up to 22% shorter recovery times than frontier LLMs and b) generalizes to a broad range of incident types and response actions.'}, {'id': 'arxiv_2509.24698', 'title': 'LISA Technical Report: An Agentic Framework for Smart Contract Auditing', 'URL': 'http://arxiv.org/abs/2509.24698', 'extra_urls': ['http://arxiv.org/abs/2509.24698'], 'type': 'article', 'author': [{'family': 'Sun', 'given': 'Izaiah'}, {'family': 'Tan', 'given': 'Daniel'}, {'family': 'Deng', 'given': 'Andy'}], 'publisher': 'arXiv', 'abstract': 'We present LISA, an agentic smart contract vulnerability detection framework that combines rule-based and logic-based methods to address a broad spectrum of vulnerabilities in smart contracts. LISA leverages data from historical audit reports to learn the detection experience (without model fine-tuning), enabling it to generalize learned patterns to unseen projects and evolving threat profiles. In our evaluation, LISA significantly outperforms both LLM-based approaches and traditional static analysis tools, achieving superior coverage of vulnerability types and higher detection accuracy. Our results suggest that LISA offers a compelling solution for industry: delivering more reliable and comprehensive vulnerability detection while reducing the dependence on manual effort.'}, {'id': 'framework', 'title': 'Knowledge-Based Multi-Agent Framework for Automated Software Architecture Design', 'URL': 'https://dl.acm.org/doi/10.1145/3696630.3728493', 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Yiran'}, {'family': 'Li', 'given': 'Ruiyin'}, {'family': 'Liang', 'given': 'Peng'}, {'family': 'Sun', 'given': 'Weisong'}, {'family': 'Liu', 'given': 'Yang'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Architecture design is a critical step in software development. However, creating a high-quality architecture is often costly due to the significant need for human expertise and manual effort. Recently, agents built upon Large Language Models (LLMs) have achieved remarkable success in various software engineering tasks. Despite this progress, the use of agents to automate the architecture design process remains largely unexplored. To address this gap, we envision a Knowledge-based Multi-Agent Architecture Design (MAAD) framework. MAAD uses agents to simulate human roles in the traditional software architecture design process, thereby automating the design process. To empower these agents, MAAD incorporates knowledge extracted from three key sources: 1) existing system designs, 2) authoritative literature, and 3) architecture experts. By envisioning the MAAD framework, we aim to advance the full automation of application-level system development.'}, {'id': 'arxiv_2507.15822', 'title': 'Do AI models help produce verified bug fixes?', 'URL': 'http://arxiv.org/abs/2507.15822', 'extra_urls': ['http://arxiv.org/abs/2507.15822'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Li'}, {'family': 'Mustafin', 'given': 'Ilgiz'}, {'family': 'Piccioni', 'given': 'Marco'}, {'family': 'Schena', 'given': 'Alessandro'}, {'family': 'Weber', 'given': 'Reto'}, {'family': 'Meyer', 'given': 'Bertrand'}], 'publisher': 'arXiv', 'abstract': 'Among areas of software engineering where AI techniques -- particularly, Large Language Models -- seem poised to yield dramatic improvements, an attractive candidate is Automatic Program Repair (APR), the production of satisfactory corrections to software bugs. Does this expectation materialize in practice? How do we find out, making sure that proposed corrections actually work? If programmers have access to LLMs, how do they actually use them to complement their own skills? To answer these questions, we took advantage of the availability of a program-proving environment, which formally determines the correctness of proposed fixes, to conduct a study of program debugging with two randomly assigned groups of programmers, one with access to LLMs and the other without, both validating their answers through the proof tools. The methodology relied on a division into general research questions (Goals in the Goal-Query-Metric approach), specific elements admitting specific answers (Queries), and measurements supporting these answers (Metrics). While applied so far to a limited sample size, the results are a first step towards delineating a proper role for AI and LLMs in providing guaranteed-correct fixes to program bugs. These results caused surprise as compared to what one might expect from the use of AI for debugging and APR. The contributions also include: a detailed methodology for experiments in the use of LLMs for debugging, which other projects can reuse; a fine-grain analysis of programmer behavior, made possible by the use of full-session recording; a definition of patterns of use of LLMs, with 7 distinct categories; and validated advice for getting the best of LLMs for debugging and Automatic Program Repair.'}, {'id': 'arxiv_2503.10784', 'title': 'Vulnerability Detection: From Formal Verification to Large Language Models and Hybrid Approaches: A Comprehensive Overview', 'URL': 'http://arxiv.org/abs/2503.10784', 'extra_urls': ['http://arxiv.org/abs/2503.10784'], 'type': 'article', 'author': [{'family': 'Tihanyi', 'given': 'Norbert'}, {'family': 'Bisztray', 'given': 'Tamas'}, {'family': 'Ferrag', 'given': 'Mohamed Amine'}, {'family': 'Cherif', 'given': 'Bilel'}, {'family': 'Dubniczky', 'given': 'Richard A.'}, {'family': 'Jain', 'given': 'Ridhi'}, {'family': 'Cordeiro', 'given': 'Lucas C.'}], 'publisher': 'arXiv', 'abstract': &quot;Software testing and verification are critical for ensuring the reliability and security of modern software systems. Traditionally, formal verification techniques, such as model checking and theorem proving, have provided rigorous frameworks for detecting bugs and vulnerabilities. However, these methods often face scalability challenges when applied to complex, real-world programs. Recently, the advent of Large Language Models (LLMs) has introduced a new paradigm for software analysis, leveraging their ability to understand insecure coding practices. Although LLMs demonstrate promising capabilities in tasks such as bug prediction and invariant generation, they lack the formal guarantees of classical methods. This paper presents a comprehensive study of state-of-the-art software testing and verification, focusing on three key approaches: classical formal methods, LLM-based analysis, and emerging hybrid techniques, which combine their strengths. We explore each approach's strengths, limitations, and practical applications, highlighting the potential of hybrid systems to address the weaknesses of standalone methods. We analyze whether integrating formal rigor with LLM-driven insights can enhance the effectiveness and scalability of software verification, exploring their viability as a pathway toward more robust and adaptive testing frameworks.&quot;}, {'id': 'arxiv_2509.18934', 'title': 'Generic Adversarial Smart Contract Detection with Semantics and Uncertainty-Aware LLM', 'URL': 'http://arxiv.org/abs/2509.18934', 'extra_urls': ['http://arxiv.org/abs/2509.18934'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Yating'}, {'family': 'Su', 'given': 'Xing'}, {'family': 'Wu', 'given': 'Hao'}, {'family': 'Li', 'given': 'Sijin'}, {'family': 'Cheng', 'given': 'Yuxi'}, {'family': 'Xu', 'given': 'Fengyuan'}, {'family': 'Zhong', 'given': 'Sheng'}], 'publisher': 'arXiv', 'abstract': &quot;Adversarial smart contracts, mostly on EVM-compatible chains like Ethereum and BSC, are deployed as EVM bytecode to exploit vulnerable smart contracts typically for financial gains. Detecting such malicious contracts at the time of deployment is an important proactive strategy preventing loss from victim contracts. It offers a better cost-benefit than detecting vulnerabilities on diverse potential victims. However, existing works are not generic with limited detection types and effectiveness due to imbalanced samples, while the emerging LLM technologies, which show its potentials in generalization, have two key problems impeding its application in this task: hard digestion of compiled-code inputs, especially those with task-specific logic, and hard assessment of LLMs' certainty in their binary answers, i.e., yes-or-no answers. Therefore, we propose a generic adversarial smart contracts detection framework FinDet, which leverages LLMs with two enhancements addressing above two problems. FinDet takes as input only the EVM-bytecode contracts and identifies adversarial ones among them with high balanced accuracy. The first enhancement extracts concise semantic intentions and high-level behavioral logic from the low-level bytecode inputs, unleashing the LLM reasoning capability restricted by the task input. The second enhancement probes and measures the LLM uncertainty to its multi-round answering to the same query, improving the LLM answering robustness for binary classifications required by the task output. Our comprehensive evaluation shows that FinDet achieves a BAC of 0.9223 and a TPR of 0.8950, significantly outperforming existing baselines. It remains robust under challenging conditions including unseen attack patterns, low-data settings, and feature obfuscation. FinDet detects all 5 public and 20+ unreported adversarial contracts in a 10-day real-world test, confirmed manually.&quot;}, {'id': 'arxiv_2506.10998', 'title': 'Towards Automated Formal Verification of Backend Systems with LLMs', 'URL': 'http://arxiv.org/abs/2506.10998', 'extra_urls': ['http://arxiv.org/abs/2506.10998'], 'type': 'article', 'author': [{'family': 'Xu', 'given': 'Kangping'}, {'family': 'Luo', 'given': 'Yifan'}, {'family': 'Yuan', 'given': 'Yang'}, {'family': 'Yao', 'given': 'Andrew Chi-Chih'}], 'publisher': 'arXiv', 'abstract': &quot;Software testing plays a critical role in ensuring that systems behave as intended. However, existing automated testing approaches struggle to match the capabilities of human engineers due to key limitations such as test locality, lack of general reliability, and business logic blindness. In this work, we propose a novel framework that leverages functional programming and type systems to translate Scala backend code into formal Lean representations. Our pipeline automatically generates theorems that specify the intended behavior of APIs and database operations, and uses LLM-based provers to verify them. When a theorem is proved, the corresponding logic is guaranteed to be correct and no further testing is needed. If the negation of a theorem is proved instead, it confirms a bug. In cases where neither can be proved, human intervention is required. We evaluate our method on realistic backend systems and find that it can formally verify over 50% of the test requirements, which suggests that half of a testing engineer's workload can be automated. Additionally, with an average cost of only $2.19 per API, LLM-based verification is significantly more cost-effective than manual testing and can be scaled easily through parallel execution. Our results indicate a promising direction for scalable, AI-powered software testing, with the potential to greatly improve engineering productivity as models continue to advance.&quot;}, {'id': 'arxiv_2508.17329', 'title': 'Risk Assessment and Security Analysis of Large Language Models', 'URL': 'http://arxiv.org/abs/2508.17329', 'extra_urls': ['http://arxiv.org/abs/2508.17329'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Xiaoyan'}, {'family': 'Lyu', 'given': 'Dongyang'}, {'family': 'Li', 'given': 'Xiaoqi'}], 'publisher': 'arXiv', 'abstract': 'As large language models (LLMs) expose systemic security challenges in high risk applications, including privacy leaks, bias amplification, and malicious abuse, there is an urgent need for a dynamic risk assessment and collaborative defence framework that covers their entire life cycle. This paper focuses on the security problems of large language models (LLMs) in critical application scenarios, such as the possibility of disclosure of user data, the deliberate input of harmful instructions, or the models bias. To solve these problems, we describe the design of a system for dynamic risk assessment and a hierarchical defence system that allows different levels of protection to cooperate. This paper presents a risk assessment system capable of evaluating both static and dynamic indicators simultaneously. It uses entropy weighting to calculate essential data, such as the frequency of sensitive words, whether the API call is typical, the realtime risk entropy value is significant, and the degree of context deviation. The experimental results show that the system is capable of identifying concealed attacks, such as role escape, and can perform rapid risk evaluation. The paper uses a hybrid model called BERT-CRF (Bidirectional Encoder Representation from Transformers) at the input layer to identify and filter malicious commands. The model layer uses dynamic adversarial training and differential privacy noise injection technology together. The output layer also has a neural watermarking system that can track the source of the content. In practice, the quality of this method, especially important in terms of customer service in the financial industry.'}, {'id': 'arxiv_2510.03819', 'title': 'Security Analysis of Ponzi Schemes in Ethereum Smart Contracts', 'URL': 'http://arxiv.org/abs/2510.03819', 'extra_urls': ['http://arxiv.org/abs/2510.03819'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Chunyi'}, {'family': 'Wei', 'given': 'Qinghong'}, {'family': 'Li', 'given': 'Xiaoqi'}], 'publisher': 'arXiv', 'abstract': 'The rapid advancement of blockchain technology has precipitated the widespread adoption of Ethereum and smart contracts across a variety of sectors. However, this has also given rise to numerous fraudulent activities, with many speculators embedding Ponzi schemes within smart contracts, resulting in significant financial losses for investors. Currently, there is a lack of effective methods for identifying and analyzing such new types of fraudulent activities. This paper categorizes these scams into four structural types and explores the intrinsic characteristics of Ponzi scheme contract source code from a program analysis perspective. The Mythril tool is employed to conduct static and dynamic analyses of representative cases, thereby revealing their vulnerabilities and operational mechanisms. Furthermore, this paper employs shell scripts and command patterns to conduct batch detection of open-source smart contract code, thereby unveiling the common characteristics of Ponzi scheme smart contracts.'}, {'id': 'arxiv_2508.14385', 'title': 'Online Incident Response Planning under Model Misspecification through Bayesian Learning and Belief Quantization', 'URL': 'http://arxiv.org/abs/2508.14385', 'extra_urls': ['http://arxiv.org/abs/2508.14385'], 'type': 'article', 'author': [{'family': 'Hammar', 'given': 'Kim'}, {'family': 'Li', 'given': 'Tao'}], 'abstract': 'Effective responses to cyberattacks require fast decisions, even when information about the attack is incomplete or inaccurate. However, most decision-support frameworks for incident response rely on a detailed system model that describes the incident, which restricts their practical utility. In this paper, we address this limitation and present an online method for incident response planning under model misspecification, which we call MOBAL: Misspecified Online Bayesian Learning. MOBAL iteratively refines a conjecture about the model through Bayesian learning as new information becomes available, which facilitates model adaptation as the incident unfolds. To determine effective responses online, we quantize the conjectured model into a finite Markov model, which enables efficient response planning through dynamic programming. We prove that Bayesian learning is asymptotically consistent with respect to the information feedback. Additionally, we establish bounds on misspecification and quantization errors. Experiments on the CAGE-2 benchmark show that MOBAL outperforms the state of the art in terms of adaptability and robustness to model misspecification.'}, {'id': 'arxiv_2507.13081', 'title': 'iReDev: A Knowledge-Driven Multi-Agent Framework for Intelligent Requirements Development', 'URL': 'http://arxiv.org/abs/2507.13081', 'extra_urls': ['http://arxiv.org/abs/2507.13081'], 'type': 'article', 'author': [{'family': 'Jin', 'given': 'Dongming'}, {'family': 'Sun', 'given': 'Weisong'}, {'family': 'Huang', 'given': 'Jiangping'}, {'family': 'Liang', 'given': 'Peng'}, {'family': 'Xuan', 'given': 'Jifeng'}, {'family': 'Liu', 'given': 'Yang'}, {'family': 'Jin', 'given': 'Zhi'}], 'publisher': 'arXiv', 'abstract': 'Requirements development is a critical phase as it is responsible for providing a clear understanding of what stakeholders need. It involves collaboration among stakeholders to extract explicit requirements and address potential conflicts, which is time-consuming and labor-intensive. Recently, multi-agent systems for software development have attracted much attention. However, existing research provides limited support for requirements development and overlooks the injection of human knowledge into agents and the human-agent collaboration. % To address these issues, this paper proposes a knowledge-driven multi-agent framework for intelligent requirement development, named iReDev. iReDev features: iReDev consists of six knowledge-driven agents to support the entire requirements development. They collaboratively perform various tasks to produce a software requirements specification. iReDev focuses on integrating human knowledge for agents, enabling them to simulate real-world stakeholders. iReDev uses an event-driven communication mechanism based on an artifact pool. Agents continuously monitor the pool and autonomously trigger the next action based on its changes, enabling iReDev to handle new requirements quickly. iReDev introduces a human-in-the-loop mechanism to support human-agent collaboration, ensuring that the generated artifacts align with the expectations of stakeholders. We evaluated the generated artifacts and results show that iReDev outperforms existing baselines in multiple aspects. We further envision three key directions and hope this work can facilitate the development of intelligent requirements development.'}, {'id': 'arxiv_2508.18675', 'title': 'Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision', 'URL': 'http://arxiv.org/abs/2508.18675', 'extra_urls': ['http://arxiv.org/abs/2508.18675'], 'type': 'article', 'author': [{'family': 'Lu', 'given': 'Xu'}, {'family': 'Sun', 'given': 'Weisong'}, {'family': 'Zhang', 'given': 'Yiran'}, {'family': 'Hu', 'given': 'Ming'}, {'family': 'Tian', 'given': 'Cong'}, {'family': 'Jin', 'given': 'Zhi'}, {'family': 'Liu', 'given': 'Yang'}], 'publisher': 'arXiv', 'abstract': 'Automated code generation has long been considered the holy grail of software engineering. The emergence of Large Language Models (LLMs) has catalyzed a revolutionary breakthrough in this area. However, existing methods that only rely on LLMs remain inadequate in the quality of generated code, offering no guarantees of satisfying practical requirements. They lack a systematic strategy for requirements development and modeling. Recently, LLM-based agents typically possess powerful abilities and play an essential role in facilitating the alignment of LLM outputs with user requirements. In this paper, we envision the first multi-agent framework for reliable code generation based on \\textsc{re}quirements \\textsc{de}velopment and \\textsc{fo}rmalization, named \\textsc{ReDeFo}. This framework incorporates three agents, highlighting their augmentation with knowledge and techniques of formal methods, into the requirements-to-code generation pipeline to strengthen quality assurance. The core of \\textsc{ReDeFo} is the use of formal specifications to bridge the gap between potentially ambiguous natural language requirements and precise executable code. \\textsc{ReDeFo} enables rigorous reasoning about correctness, uncovering hidden bugs, and enforcing critical properties throughout the development process. In general, our framework aims to take a promising step toward realizing the long-standing vision of reliable, auto-generated software.'}, {'id': 'arxiv_2509.11238', 'title': 'UserTrace: User-Level Requirements Generation and Traceability Recovery from Software Project Repositories', 'URL': 'http://arxiv.org/abs/2509.11238', 'extra_urls': ['http://arxiv.org/abs/2509.11238'], 'type': 'article', 'author': [{'family': 'Jin', 'given': 'Dongming'}, {'family': 'Jin', 'given': 'Zhi'}, {'family': 'Zhang', 'given': 'Yiran'}, {'family': 'Fang', 'given': 'Zheng'}, {'family': 'Li', 'given': 'Linyu'}, {'family': 'He', 'given': 'Yuanpeng'}, {'family': 'Chen', 'given': 'Xiaohong'}, {'family': 'Sun', 'given': 'Weisong'}], 'publisher': 'arXiv', 'abstract': 'Software maintainability critically depends on high-quality requirements descriptions and explicit traceability between requirements and code. Although automated code summarization (ACS) and requirements traceability (RT) techniques have been widely studied, existing ACS methods mainly generate implementation-level (i.e., developer-oriented) requirements (IRs) for fine-grained units (e.g., methods), while RT techniques often overlook the impact of project evolution. As a result, user-level (i.e., end user-oriented) requirements (URs) and live trace links remain underexplored, despite their importance for supporting user understanding and for validating whether AI-generated software aligns with user intent. To address this gap, we propose UserTrace, a multi-agent system that automatically generates URs and recovers live trace links (from URs to IRs to code) from software repositories. UserTrace coordinates four specialized agents (i.e., Code Reviewer, Searcher, Writer, and Verifier) through a three-phase process: structuring repository dependencies, deriving IRs for code units, and synthesizing URs with domain-specific context. Our comparative evaluation shows that UserTrace produces URs with higher completeness, correctness, and helpfulness than an established baseline, and achieves superior precision in trace link recovery compared to five state-of-the-art RT approaches. A user study further demonstrates that UserTrace helps end users validate whether the AI-generated repositories align with their intent.'}, {'id': 'arxiv_2510.12399', 'title': 'A Survey of Vibe Coding with Large Language Models', 'URL': 'http://arxiv.org/abs/2510.12399', 'extra_urls': ['http://arxiv.org/abs/2510.12399'], 'type': 'article', 'author': [{'family': 'Ge', 'given': 'Yuyao'}, {'family': 'Mei', 'given': 'Lingrui'}, {'family': 'Duan', 'given': 'Zenghao'}, {'family': 'Li', 'given': 'Tianhao'}, {'family': 'Zheng', 'given': 'Yujia'}, {'family': 'Wang', 'given': 'Yiwei'}, {'family': 'Wang', 'given': 'Lexin'}, {'family': 'Yao', 'given': 'Jiayu'}, {'family': 'Liu', 'given': 'Tianyu'}, {'family': 'Cai', 'given': 'Yujun'}, {'family': 'Bi', 'given': 'Baolong'}, {'family': 'Guo', 'given': 'Fangda'}, {'family': 'Guo', 'given': 'Jiafeng'}, {'family': 'Liu', 'given': 'Shenghua'}, {'family': 'Cheng', 'given': 'Xueqi'}], 'publisher': 'arXiv', 'abstract': 'The advancement of large language models (LLMs) has catalyzed a paradigm shift from code generation assistance to autonomous coding agents, enabling a novel development methodology termed &quot;Vibe Coding&quot; where developers validate AI-generated implementations through outcome observation rather than line-by-line code comprehension. Despite its transformative potential, the effectiveness of this emergent paradigm remains under-explored, with empirical evidence revealing unexpected productivity losses and fundamental challenges in human-AI collaboration. To address this gap, this survey provides the first comprehensive and systematic review of Vibe Coding with large language models, establishing both theoretical foundations and practical frameworks for this transformative development approach. Drawing from systematic analysis of over 1000 research papers, we survey the entire vibe coding ecosystem, examining critical infrastructure components including LLMs for coding, LLM-based coding agent, development environment of coding agent, and feedback mechanisms. We first introduce Vibe Coding as a formal discipline by formalizing it through a Constrained Markov Decision Process that captures the dynamic triadic relationship among human developers, software projects, and coding agents. Building upon this theoretical foundation, we then synthesize existing practices into five distinct development models: Unconstrained Automation, Iterative Conversational Collaboration, Planning-Driven, Test-Driven, and Context-Enhanced Models, thus providing the first comprehensive taxonomy in this domain. Critically, our analysis reveals that successful Vibe Coding depends not merely on agent capabilities but on systematic context engineering, well-established development environments, and human-agent collaborative development models.'}, {'id': 'arxiv_2502.02533', 'title': 'Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies', 'URL': 'http://arxiv.org/abs/2502.02533', 'extra_urls': ['http://arxiv.org/abs/2502.02533'], 'type': 'article', 'author': [{'family': 'Zhou', 'given': 'Han'}, {'family': 'Wan', 'given': 'Xingchen'}, {'family': 'Sun', 'given': 'Ruoxi'}, {'family': 'Palangi', 'given': 'Hamid'}, {'family': 'Iqbal', 'given': 'Shariq'}, {'family': 'Vuli\u0107', 'given': 'Ivan'}, {'family': 'Korhonen', 'given': 'Anna'}, {'family': 'Ar\u0131k', 'given': 'Sercan \xd6'}], 'publisher': 'arXiv', 'abstract': 'Large language models, employed as multiple agents that interact and collaborate with each other, have excelled at solving complex tasks. The agents are programmed with prompts that declare their functionality, along with the topologies that orchestrate interactions across agents. Designing prompts and topologies for multi-agent systems (MAS) is inherently complex. To automate the entire design process, we first conduct an in-depth analysis of the design space aiming to understand the factors behind building effective MAS. We reveal that prompts together with topologies play critical roles in enabling more effective MAS design. Based on the insights, we propose Multi-Agent System Search (MASS), a MAS optimization framework that efficiently exploits the complex MAS design space by interleaving its optimization stages, from local to global, from prompts to topologies, over three stages: 1) block-level (local) prompt optimization; 2) workflow topology optimization; 3) workflow-level (global) prompt optimization, where each stage is conditioned on the iteratively optimized prompts/topologies from former stages. We show that MASS-optimized multi-agent systems outperform a spectrum of existing alternatives by a substantial margin. Based on the MASS-found systems, we finally propose design principles behind building effective multi-agent systems.'}, {'id': 'arxiv_2508.12683', 'title': 'A Taxonomy of Hierarchical Multi-Agent Systems: Design Patterns, Coordination Mechanisms, and Industrial Applications', 'URL': 'http://arxiv.org/abs/2508.12683', 'extra_urls': ['http://arxiv.org/abs/2508.12683'], 'type': 'article', 'author': [{'family': 'Moore', 'given': 'David J.'}], 'publisher': 'arXiv', 'abstract': 'Hierarchical multi-agent systems (HMAS) organize collections of agents into layered structures that help manage complexity and scale. These hierarchies can simplify coordination, but they also can introduce trade-offs that are not always obvious. This paper proposes a multi-dimensional taxonomy for HMAS along five axes: control hierarchy, information flow, role and task delegation, temporal layering, and communication structure. The intent is not to prescribe a single &quot;best&quot; design but to provide a lens for comparing different approaches. Rather than treating these dimensions in isolation, the taxonomy is connected to concrete coordination mechanisms - from the long-standing contract-net protocol for task allocation to more recent work in hierarchical reinforcement learning. Industrial contexts illustrate the framework, including power grids and oilfield operations, where agents at production, maintenance, and supply levels coordinate to diagnose well issues or balance energy demand. These cases suggest that hierarchical structures may achieve global efficiency while preserving local autonomy, though the balance is delicate. The paper closes by identifying open challenges: making hierarchical decisions explainable to human operators, scaling to very large agent populations, and assessing whether learning-based agents such as large language models can be safely integrated into layered frameworks. This paper presents what appears to be the first taxonomy that unifies structural, temporal, and communication dimensions of hierarchical MAS into a single design framework, bridging classical coordination mechanisms with modern reinforcement learning and large language model agents.'}, {'id': 'arxiv_2510.10991', 'title': 'A Survey on Agentic Multimodal Large Language Models', 'URL': 'http://arxiv.org/abs/2510.10991', 'extra_urls': ['http://arxiv.org/abs/2510.10991'], 'type': 'article', 'author': [{'family': 'Yao', 'given': 'Huanjin'}, {'family': 'Zhang', 'given': 'Ruifei'}, {'family': 'Huang', 'given': 'Jiaxing'}, {'family': 'Zhang', 'given': 'Jingyi'}, {'family': 'Wang', 'given': 'Yibo'}, {'family': 'Fang', 'given': 'Bo'}, {'family': 'Zhu', 'given': 'Ruolin'}, {'family': 'Jing', 'given': 'Yongcheng'}, {'family': 'Liu', 'given': 'Shunyu'}, {'family': 'Li', 'given': 'Guanbin'}, {'family': 'Tao', 'given': 'Dacheng'}], 'publisher': 'arXiv', 'abstract': &quot;With the recent emergence of revolutionary autonomous agentic systems, research community is witnessing a significant shift from traditional static, passive, and domain-specific AI agents toward more dynamic, proactive, and generalizable agentic AI. Motivated by the growing interest in agentic AI and its potential trajectory toward AGI, we present a comprehensive survey on Agentic Multimodal Large Language Models (Agentic MLLMs). In this survey, we explore the emerging paradigm of agentic MLLMs, delineating their conceptual foundations and distinguishing characteristics from conventional MLLM-based agents. We establish a conceptual framework that organizes agentic MLLMs along three fundamental dimensions: (i) Agentic internal intelligence functions as the system's commander, enabling accurate long-horizon planning through reasoning, reflection, and memory; (ii) Agentic external tool invocation, whereby models proactively use various external tools to extend their problem-solving capabilities beyond their intrinsic knowledge; and (iii) Agentic environment interaction further situates models within virtual or physical environments, allowing them to take actions, adapt strategies, and sustain goal-directed behavior in dynamic real-world scenarios. To further accelerate research in this area for the community, we compile open-source training frameworks, training and evaluation datasets for developing agentic MLLMs. Finally, we review the downstream applications of agentic MLLMs and outline future research directions for this rapidly evolving field. To continuously track developments in this rapidly evolving field, we will also actively update a public repository at https://github.com/HJYao00/Awesome-Agentic-MLLMs.&quot;}, {'id': 'arxiv_2410.20199', 'title': 'Rethinking the Uncertainty: A Critical Review and Analysis in the Era of Large Language Models', 'URL': 'http://arxiv.org/abs/2410.20199', 'extra_urls': ['http://arxiv.org/abs/2410.20199'], 'type': 'article', 'author': [{'family': 'Beigi', 'given': 'Mohammad'}, {'family': 'Wang', 'given': 'Sijia'}, {'family': 'Shen', 'given': 'Ying'}, {'family': 'Lin', 'given': 'Zihao'}, {'family': 'Kulkarni', 'given': 'Adithya'}, {'family': 'He', 'given': 'Jianfeng'}, {'family': 'Chen', 'given': 'Feng'}, {'family': 'Jin', 'given': 'Ming'}, {'family': 'Cho', 'given': 'Jin-Hee'}, {'family': 'Zhou', 'given': 'Dawei'}, {'family': 'Lu', 'given': 'Chang-Tien'}, {'family': 'Huang', 'given': 'Lifu'}], 'publisher': 'arXiv', 'abstract': 'In recent years, Large Language Models (LLMs) have become fundamental to a broad spectrum of artificial intelligence applications. As the use of LLMs expands, precisely estimating the uncertainty in their predictions has become crucial. Current methods often struggle to accurately identify, measure, and address the true uncertainty, with many focusing primarily on estimating model confidence. This discrepancy is largely due to an incomplete understanding of where, when, and how uncertainties are injected into models. This paper introduces a comprehensive framework specifically designed to identify and understand the types and sources of uncertainty, aligned with the unique characteristics of LLMs. Our framework enhances the understanding of the diverse landscape of uncertainties by systematically categorizing and defining each type, establishing a solid foundation for developing targeted methods that can precisely quantify these uncertainties. We also provide a detailed introduction to key related concepts and examine the limitations of current methods in mission-critical and safety-sensitive applications. The paper concludes with a perspective on future directions aimed at enhancing the reliability and practical adoption of these methods in real-world scenarios.'}, {'id': 'arxiv_2507.03724', 'title': 'MemOS: A Memory OS for AI System', 'URL': 'http://arxiv.org/abs/2507.03724', 'extra_urls': ['http://arxiv.org/abs/2507.03724'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Zhiyu'}, {'family': 'Song', 'given': 'Shichao'}, {'family': 'Xi', 'given': 'Chenyang'}, {'family': 'Wang', 'given': 'Hanyu'}, {'family': 'Tang', 'given': 'Chen'}, {'family': 'Niu', 'given': 'Simin'}, {'family': 'Chen', 'given': 'Ding'}, {'family': 'Yang', 'given': 'Jiawei'}, {'family': 'Li', 'given': 'Chunyu'}, {'family': 'Yu', 'given': 'Qingchen'}, {'family': 'Zhao', 'given': 'Jihao'}, {'family': 'Wang', 'given': 'Yezhaohui'}, {'family': 'Liu', 'given': 'Peng'}, {'family': 'Lin', 'given': 'Zehao'}, {'family': 'Wang', 'given': 'Pengyuan'}, {'family': 'Huo', 'given': 'Jiahao'}, {'family': 'Chen', 'given': 'Tianyi'}, {'family': 'Chen', 'given': 'Kai'}, {'family': 'Li', 'given': 'Kehang'}, {'family': 'Tao', 'given': 'Zhen'}, {'family': 'Lai', 'given': 'Huayi'}, {'family': 'Wu', 'given': 'Hao'}, {'family': 'Tang', 'given': 'Bo'}, {'family': 'Wang', 'given': 'Zhenren'}, {'family': 'Fan', 'given': 'Zhaoxin'}, {'family': 'Zhang', 'given': 'Ningyu'}, {'family': 'Zhang', 'given': 'Linfeng'}, {'family': 'Yan', 'given': 'Junchi'}, {'family': 'Yang', 'given': 'Mingchuan'}, {'family': 'Xu', 'given': 'Tong'}, {'family': 'Xu', 'given': 'Wei'}, {'family': 'Chen', 'given': 'Huajun'}, {'family': 'Wang', 'given': 'Haofen'}, {'family': 'Yang', 'given': 'Hongkang'}, {'family': 'Zhang', 'given': 'Wentao'}, {'family': 'Xu', 'given': 'Zhi-Qin John'}, {'family': 'Chen', 'given': 'Siheng'}, {'family': 'Xiong', 'given': 'Feiyu'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) have become an essential infrastructure for Artificial General Intelligence (AGI), yet their lack of well-defined memory management systems hinders the development of long-context reasoning, continual personalization, and knowledge consistency.Existing models mainly rely on static parameters and short-lived contextual states, limiting their ability to track user preferences or update knowledge over extended periods.While Retrieval-Augmented Generation (RAG) introduces external knowledge in plain text, it remains a stateless workaround without lifecycle control or integration with persistent representations.Recent work has modeled the training and inference cost of LLMs from a memory hierarchy perspective, showing that introducing an explicit memory layer between parameter memory and external retrieval can substantially reduce these costs by externalizing specific knowledge. Beyond computational efficiency, LLMs face broader challenges arising from how information is distributed over time and context, requiring systems capable of managing heterogeneous knowledge spanning different temporal scales and sources. To address this challenge, we propose MemOS, a memory operating system that treats memory as a manageable system resource. It unifies the representation, scheduling, and evolution of plaintext, activation-based, and parameter-level memories, enabling cost-efficient storage and retrieval. As the basic unit, a MemCube encapsulates both memory content and metadata such as provenance and versioning. MemCubes can be composed, migrated, and fused over time, enabling flexible transitions between memory types and bridging retrieval with parameter-based learning. MemOS establishes a memory-centric system framework that brings controllability, plasticity, and evolvability to LLMs, laying the foundation for continual learning and personalized modeling.'}, {'id': 'arxiv_2504.15965', 'title': 'From Human Memory to AI Memory: A Survey on Memory Mechanisms in the Era of LLMs', 'URL': 'http://arxiv.org/abs/2504.15965', 'extra_urls': ['http://arxiv.org/abs/2504.15965'], 'type': 'article', 'author': [{'family': 'Wu', 'given': 'Yaxiong'}, {'family': 'Liang', 'given': 'Sheng'}, {'family': 'Zhang', 'given': 'Chen'}, {'family': 'Wang', 'given': 'Yichao'}, {'family': 'Zhang', 'given': 'Yongyue'}, {'family': 'Guo', 'given': 'Huifeng'}, {'family': 'Tang', 'given': 'Ruiming'}, {'family': 'Liu', 'given': 'Yong'}], 'publisher': 'arXiv', 'abstract': 'Memory is the process of encoding, storing, and retrieving information, allowing humans to retain experiences, knowledge, skills, and facts over time, and serving as the foundation for growth and effective interaction with the world. It plays a crucial role in shaping our identity, making decisions, learning from past experiences, building relationships, and adapting to changes. In the era of large language models (LLMs), memory refers to the ability of an AI system to retain, recall, and use information from past interactions to improve future responses and interactions. Although previous research and reviews have provided detailed descriptions of memory mechanisms, there is still a lack of a systematic review that summarizes and analyzes the relationship between the memory of LLM-driven AI systems and human memory, as well as how we can be inspired by human memory to construct more powerful memory systems. To achieve this, in this paper, we propose a comprehensive survey on the memory of LLM-driven AI systems. In particular, we first conduct a detailed analysis of the categories of human memory and relate them to the memory of AI systems. Second, we systematically organize existing memory-related work and propose a categorization method based on three dimensions (object, form, and time) and eight quadrants. Finally, we illustrate some open problems regarding the memory of current AI systems and outline possible future directions for memory in the era of large language models.'}, {'id': 'arxiv_2508.10824', 'title': 'Memory-Augmented Transformers: A Systematic Review from Neuroscience Principles to Enhanced Model Architectures', 'URL': 'http://arxiv.org/abs/2508.10824', 'extra_urls': ['http://arxiv.org/abs/2508.10824'], 'type': 'article', 'author': [{'family': 'Omidi', 'given': 'Parsa'}, {'family': 'Huang', 'given': 'Xingshuai'}, {'family': 'Laborieux', 'given': 'Axel'}, {'family': 'Nikpour', 'given': 'Bahareh'}, {'family': 'Shi', 'given': 'Tianyu'}, {'family': 'Eshaghi', 'given': 'Armaghan'}], 'publisher': 'arXiv', 'abstract': 'Memory is fundamental to intelligence, enabling learning, reasoning, and adaptability across biological and artificial systems. While Transformer architectures excel at sequence modeling, they face critical limitations in long-range context retention, continual learning, and knowledge integration. This review presents a unified framework bridging neuroscience principles, including dynamic multi-timescale memory, selective attention, and consolidation, with engineering advances in Memory-Augmented Transformers. We organize recent progress through three taxonomic dimensions: functional objectives (context extension, reasoning, knowledge integration, adaptation), memory representations (parameter-encoded, state-based, explicit, hybrid), and integration mechanisms (attention fusion, gated control, associative retrieval). Our analysis of core memory operations (reading, writing, forgetting, and capacity management) reveals a shift from static caches toward adaptive, test-time learning systems. We identify persistent challenges in scalability and interference, alongside emerging solutions including hierarchical buffering and surprise-gated updates. This synthesis provides a roadmap toward cognitively-inspired, lifelong-learning Transformer architectures.'}, {'id': 'arxiv_2509.18133', 'title': 'Self-Evolving LLMs via Continual Instruction Tuning', 'URL': 'http://arxiv.org/abs/2509.18133', 'extra_urls': ['http://arxiv.org/abs/2509.18133'], 'type': 'article', 'author': [{'family': 'Kang', 'given': 'Jiazheng'}, {'family': 'Huang', 'given': 'Le'}, {'family': 'Hou', 'given': 'Cheng'}, {'family': 'Zhao', 'given': 'Zhe'}, {'family': 'Yan', 'given': 'Zhenxiang'}, {'family': 'Shi', 'given': 'Chuan'}, {'family': 'Bai', 'given': 'Ting'}], 'publisher': 'arXiv', 'abstract': 'In real-world industrial settings, large language models (LLMs) must learn continually to keep pace with diverse and evolving tasks, requiring self-evolution to refine knowledge under dynamic data distributions. However, existing continual learning (CL) approaches, such as replay and parameter isolation, often suffer from catastrophic forgetting: training on new tasks degrades performance on earlier ones by overfitting to the new distribution and weakening generalization.We propose MoE-CL, a parameter-efficient adversarial mixture-of-experts framework for industrial-scale, self-evolving continual instruction tuning of LLMs. MoE-CL uses a dual-expert design: (1) a dedicated LoRA expert per task to preserve task-specific knowledge via parameter independence, mitigating forgetting; and (2) a shared LoRA expert to enable cross-task transfer. To prevent transferring task-irrelevant noise through the shared pathway, we integrate a task-aware discriminator within a GAN. The discriminator encourages the shared expert to pass only task-aligned information during sequential training. Through adversarial learning, the shared expert acquires generalized representations that mimic the discriminator, while dedicated experts retain task-specific details, balancing knowledge retention and cross-task generalization and thereby supporting self-evolution.Extensive experiments on the public MTL5 benchmark and an industrial Tencent3 benchmark validate the effectiveness of MoE-CL for continual instruction tuning. In real-world A/B testing for content compliance review on the Tencent Video platform, MoE-CL reduced manual review costs by 15.3%. These results demonstrate that MoE-CL is practical for large-scale industrial deployment where continual adaptation and stable transfer are critical.'}, {'id': 'arxiv_2502.06975', 'title': 'Position: Episodic Memory is the Missing Piece for Long-Term LLM Agents', 'URL': 'http://arxiv.org/abs/2502.06975', 'extra_urls': ['http://arxiv.org/abs/2502.06975'], 'type': 'article', 'author': [{'family': 'Pink', 'given': 'Mathis'}, {'family': 'Wu', 'given': 'Qinyuan'}, {'family': 'Vo', 'given': 'Vy Ai'}, {'family': 'Turek', 'given': 'Javier'}, {'family': 'Mu', 'given': 'Jianing'}, {'family': 'Huth', 'given': 'Alexander'}, {'family': 'Toneva', 'given': 'Mariya'}], 'publisher': 'arXiv', 'abstract': 'As Large Language Models (LLMs) evolve from text-completion tools into fully fledged agents operating in dynamic environments, they must address the challenge of continually learning and retaining long-term knowledge. Many biological systems solve these challenges with episodic memory, which supports single-shot learning of instance-specific contexts. Inspired by this, we present an episodic memory framework for LLM agents, centered around five key properties of episodic memory that underlie adaptive and context-sensitive behavior. With various research efforts already partially covering these properties, this position paper argues that now is the right time for an explicit, integrated focus on episodic memory to catalyze the development of long-term agents. To this end, we outline a roadmap that unites several research directions under the goal to support all five properties of episodic memory for more efficient long-term LLM agents.'}, {'id': 'arxiv_2507.22925', 'title': 'Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents', 'URL': 'http://arxiv.org/abs/2507.22925', 'extra_urls': ['http://arxiv.org/abs/2507.22925'], 'type': 'article', 'author': [{'family': 'Sun', 'given': 'Haoran'}, {'family': 'Zeng', 'given': 'Shaoning'}], 'publisher': 'arXiv', 'abstract': 'Long-term memory is one of the key factors influencing the reasoning capabilities of Large Language Model Agents (LLM Agents). Incorporating a memory mechanism that effectively integrates past interactions can significantly enhance decision-making and contextual coherence of LLM Agents. While recent works have made progress in memory storage and retrieval, such as encoding memory into dense vectors for similarity-based search or organizing knowledge in the form of graph, these approaches often fall short in structured memory organization and efficient retrieval. To address these limitations, we propose a Hierarchical Memory (H-MEM) architecture for LLM Agents that organizes and updates memory in a multi-level fashion based on the degree of semantic abstraction. Each memory vector is embedded with a positional index encoding pointing to its semantically related sub-memories in the next layer. During the reasoning phase, an index-based routing mechanism enables efficient, layer-by-layer retrieval without performing exhaustive similarity computations. We evaluate our method on five task settings from the LoCoMo dataset. Experimental results show that our approach consistently outperforms five baseline methods, demonstrating its effectiveness in long-term dialogue scenarios.'}, {'id': 'arxiv_2507.07957', 'title': 'MIRIX: Multi-Agent Memory System for LLM-Based Agents', 'URL': 'http://arxiv.org/abs/2507.07957', 'extra_urls': ['http://arxiv.org/abs/2507.07957'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Yu'}, {'family': 'Chen', 'given': 'Xi'}], 'publisher': 'arXiv', 'abstract': &quot;Although memory capabilities of AI agents are gaining increasing attention, existing solutions remain fundamentally limited. Most rely on flat, narrowly scoped memory components, constraining their ability to personalize, abstract, and reliably recall user-specific information over time. To this end, we introduce MIRIX, a modular, multi-agent memory system that redefines the future of AI memory by solving the field's most critical challenge: enabling language models to truly remember. Unlike prior approaches, MIRIX transcends text to embrace rich visual and multimodal experiences, making memory genuinely useful in real-world scenarios. MIRIX consists of six distinct, carefully structured memory types: Core, Episodic, Semantic, Procedural, Resource Memory, and Knowledge Vault, coupled with a multi-agent framework that dynamically controls and coordinates updates and retrieval. This design enables agents to persist, reason over, and accurately retrieve diverse, long-term user data at scale. We validate MIRIX in two demanding settings. First, on ScreenshotVQA, a challenging multimodal benchmark comprising nearly 20,000 high-resolution computer screenshots per sequence, requiring deep contextual understanding and where no existing memory systems can be applied, MIRIX achieves 35% higher accuracy than the RAG baseline while reducing storage requirements by 99.9%. Second, on LOCOMO, a long-form conversation benchmark with single-modal textual input, MIRIX attains state-of-the-art performance of 85.4%, far surpassing existing baselines. These results show that MIRIX sets a new performance standard for memory-augmented LLM agents. To allow users to experience our memory system, we provide a packaged application powered by MIRIX. It monitors the screen in real time, builds a personalized memory base, and offers intuitive visualization and secure local storage to ensure privacy.&quot;}, {'id': 'arxiv_2506.01442', 'title': 'Agentic Episodic Control', 'URL': 'http://arxiv.org/abs/2506.01442', 'extra_urls': ['http://arxiv.org/abs/2506.01442'], 'type': 'article', 'author': [{'family': 'Yang', 'given': 'Xidong'}, {'family': 'Li', 'given': 'Wenhao'}, {'family': 'Sheng', 'given': 'Junjie'}, {'family': 'Shen', 'given': 'Chuyun'}, {'family': 'Hua', 'given': 'Yun'}, {'family': 'Wang', 'given': 'Xiangfeng'}], 'publisher': 'arXiv', 'abstract': 'Reinforcement learning (RL) has driven breakthroughs in AI, from game-play to scientific discovery and AI alignment. However, its broader applicability remains limited by challenges such as low data efficiency and poor generalizability. Recent advances suggest that large language models, with their rich world knowledge and reasoning capabilities, could complement RL by enabling semantic state modeling and task-agnostic planning. In this work, we propose the Agentic Episodic Control (AEC), a novel architecture that integrates RL with LLMs to enhance decision-making. The AEC can leverage a large language model (LLM) to map the observations into language-grounded embeddings, which further can be stored in an episodic memory for rapid retrieval of high-value experiences. Simultaneously, a World-Graph working memory module is utilized to capture structured environmental dynamics in order to enhance relational reasoning. Furthermore, a lightweight critical state detector dynamically arbitrates between the episodic memory recall and the world-model-guided exploration. On the whole, by combining the trial-and-error learning scheme with LLM-derived semantic priors, the proposed AEC can improve both data efficiency and generalizability in reinforcement learning. In experiments on BabyAI-Text benchmark tasks, AEC demonstrates substantial improvements over existing baselines, especially on complex and generalization tasks like FindObj, where it outperforms the best baseline by up to 76%. The proposed AEC framework bridges the strengths of numeric reinforcement learning and symbolic reasoning, which provides a pathway toward more adaptable and sample-efficient agents.'}, {'id': 'arxiv_2505.00472', 'title': 'UserCentrix: An Agentic Memory-augmented AI Framework for Smart Spaces', 'URL': 'http://arxiv.org/abs/2505.00472', 'extra_urls': ['http://arxiv.org/abs/2505.00472'], 'type': 'article', 'author': [{'family': 'Saleh', 'given': 'Alaa'}, {'family': 'Tarkoma', 'given': 'Sasu'}, {'family': 'Donta', 'given': 'Praveen Kumar'}, {'family': 'Motlagh', 'given': 'Naser Hossein'}, {'family': 'Dustdar', 'given': 'Schahram'}, {'family': 'Pirttikangas', 'given': 'Susanna'}, {'family': 'Lov\xe9n', 'given': 'Lauri'}], 'publisher': 'arXiv', 'abstract': 'Agentic AI, with its autonomous and proactive decision-making, has transformed smart environments. By integrating Generative AI (GenAI) and multi-agent systems, modern AI frameworks can dynamically adapt to user preferences, optimize data management, and improve resource allocation. This paper introduces UserCentrix, an agentic memory-augmented AI framework designed to enhance smart spaces through dynamic, context-aware decision-making. This framework integrates personalized Large Language Model (LLM) agents that leverage user preferences and LLM memory management to deliver proactive and adaptive assistance. Furthermore, it incorporates a hybrid hierarchical control system, balancing centralized and distributed processing to optimize real-time responsiveness while maintaining global situational awareness. UserCentrix achieves resource-efficient AI interactions by embedding memory-augmented reasoning, cooperative agent negotiation, and adaptive orchestration strategies. Our key contributions include (i) a self-organizing framework with proactive scaling based on task urgency, (ii) a Value of Information (VoI)-driven decision-making process, (iii) a meta-reasoning personal LLM agent, and (iv) an intelligent multi-agent coordination system for seamless environment adaptation. Experimental results across various models confirm the effectiveness of our approach in enhancing response accuracy, system efficiency, and computational resource management in real-world application.'}, {'id': 'procedural_memory_is', 'title': 'Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in LLM-Based Agents', 'URL': 'https://dl.acm.org/doi/10.1145/3708319.3734172', 'type': 'article', 'author': [{'family': 'Wheeler', 'given': 'Schaun'}, {'family': 'Jeunen', 'given': 'Olivier'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Large Language Models (LLMs) represent a landmark achievement in Artificial Intelligence (AI), demonstrating unprecedented proficiency in procedural tasks such as text generation, code completion, and conversational coherence. These capabilities stem from their architecture, which mirrors human procedural memory\u2014the brain\u2019s ability to automate repetitive, pattern-driven tasks through practice. However, as LLMs are increasingly deployed in real-world applications, it becomes impossible to ignore their limitations operating in complex, unpredictable environments. This paper argues that LLMs, while transformative, are fundamentally constrained by their reliance on procedural memory. To create agents capable of navigating \u201cwicked\u201d learning environments\u2014where rules shift, feedback is ambiguous, and novelty is the norm\u2014we must augment LLMs with semantic memory and associative learning systems. By adopting a modular architecture that decouples these cognitive functions, we can bridge the gap between narrow procedural expertise and the adaptive intelligence required for real-world problem-solving.'}, {'id': 'arxiv_2507.05257', 'title': 'Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions', 'URL': 'http://arxiv.org/abs/2507.05257', 'extra_urls': ['http://arxiv.org/abs/2507.05257'], 'type': 'article', 'author': [{'family': 'Hu', 'given': 'Yuanzhe'}, {'family': 'Wang', 'given': 'Yu'}, {'family': 'McAuley', 'given': 'Julian'}], 'publisher': 'arXiv', 'abstract': 'Recent benchmarks for Large Language Model (LLM) agents primarily focus on evaluating reasoning, planning, and execution capabilities, while another critical component-memory, encompassing how agents memorize, update, and retrieve long-term information-is under-evaluated due to the lack of benchmarks. We term agents with memory mechanisms as memory agents. In this paper, based on classic theories from memory science and cognitive science, we identify four core competencies essential for memory agents: accurate retrieval, test-time learning, long-range understanding, and selective forgetting. Existing benchmarks either rely on limited context lengths or are tailored for static, long-context settings like book-based QA, which do not reflect the interactive, multi-turn nature of memory agents that incrementally accumulate information. Moreover, no existing benchmarks cover all four competencies. We introduce MemoryAgentBench, a new benchmark specifically designed for memory agents. Our benchmark transforms existing long-context datasets and incorporates newly constructed datasets into a multi-turn format, effectively simulating the incremental information processing characteristic of memory agents. By carefully selecting and curating datasets, our benchmark provides comprehensive coverage of the four core memory competencies outlined above, thereby offering a systematic and challenging testbed for assessing memory quality. We evaluate a diverse set of memory agents, ranging from simple context-based and retrieval-augmented generation (RAG) systems to advanced agents with external memory modules and tool integration. Empirical results reveal that current methods fall short of mastering all four competencies, underscoring the need for further research into comprehensive memory mechanisms for LLM agents.'}, {'id': 'arxiv_2510.05520', 'title': 'CAM: A Constructivist View of Agentic Memory for LLM-Based Reading Comprehension', 'URL': 'http://arxiv.org/abs/2510.05520', 'extra_urls': ['http://arxiv.org/abs/2510.05520'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Rui'}, {'family': 'Zhang', 'given': 'Zeyu'}, {'family': 'Bo', 'given': 'Xiaohe'}, {'family': 'Tian', 'given': 'Zihang'}, {'family': 'Chen', 'given': 'Xu'}, {'family': 'Dai', 'given': 'Quanyu'}, {'family': 'Dong', 'given': 'Zhenhua'}, {'family': 'Tang', 'given': 'Ruiming'}], 'publisher': 'arXiv', 'abstract': &quot;Current Large Language Models (LLMs) are confronted with overwhelming information volume when comprehending long-form documents. This challenge raises the imperative of a cohesive memory module, which can elevate vanilla LLMs into autonomous reading agents. Despite the emergence of some heuristic approaches, a systematic design principle remains absent. To fill this void, we draw inspiration from Jean Piaget's Constructivist Theory, illuminating three traits of the agentic memory -- structured schemata, flexible assimilation, and dynamic accommodation. This blueprint forges a clear path toward a more robust and efficient memory system for LLM-based reading comprehension. To this end, we develop CAM, a prototype implementation of Constructivist Agentic Memory that simultaneously embodies the structurality, flexibility, and dynamicity. At its core, CAM is endowed with an incremental overlapping clustering algorithm for structured memory development, supporting both coherent hierarchical summarization and online batch integration. During inference, CAM adaptively explores the memory structure to activate query-relevant information for contextual response, akin to the human associative process. Compared to existing approaches, our design demonstrates dual advantages in both performance and efficiency across diverse long-text reading comprehension tasks, including question answering, query-based summarization, and claim verification.&quot;}, {'id': 'arxiv_2509.09505', 'title': 'Combating the Memory Walls: Optimization Pathways for Long-Context Agentic LLM Inference', 'URL': 'http://arxiv.org/abs/2509.09505', 'extra_urls': ['http://arxiv.org/abs/2509.09505'], 'type': 'article', 'author': [{'family': 'Wu', 'given': 'Haoran'}, {'family': 'Xiao', 'given': 'Can'}, {'family': 'Nie', 'given': 'Jiayi'}, {'family': 'Guo', 'given': 'Xuan'}, {'family': 'Lou', 'given': 'Binglei'}, {'family': 'Wong', 'given': 'Jeffrey T. H.'}, {'family': 'Mo', 'given': 'Zhiwen'}, {'family': 'Zhang', 'given': 'Cheng'}, {'family': 'Forys', 'given': 'Przemyslaw'}, {'family': 'Luk', 'given': 'Wayne'}, {'family': 'Fan', 'given': 'Hongxiang'}, {'family': 'Cheng', 'given': 'Jianyi'}, {'family': 'Jones', 'given': 'Timothy M.'}, {'family': 'Antonova', 'given': 'Rika'}, {'family': 'Mullins', 'given': 'Robert'}, {'family': 'Zhao', 'given': 'Aaron'}], 'publisher': 'arXiv', 'abstract': 'LLMs now form the backbone of AI agents for a diverse array of applications, including tool use, command-line agents, and web or computer use agents. These agentic LLM inference tasks are fundamentally different from chatbot-focused inference -- they often have much larger context lengths to capture complex, prolonged inputs, such as entire webpage DOMs or complicated tool call trajectories. This, in turn, generates significant off-chip memory traffic for the underlying hardware at the inference stage and causes the workload to be constrained by two memory walls, namely the bandwidth and capacity memory walls, preventing the on-chip compute units from achieving high utilization. In this paper, we introduce PLENA, a hardware-software co-designed system that applies three core optimization pathways to tackle these challenges. PLENA includes an efficient hardware implementation of compute and memory units supporting an asymmetric quantization scheme. PLENA also features a novel flattened systolic array architecture that has native support for FlashAttention to tackle these memory walls in the scenario of inference serving for long-context LLMs. Additionally, PLENA is developed with a complete stack, including a custom ISA, a compiler, a cycle-emulated simulator, and an automated design space exploration flow. The simulated results show that PLENA achieves up to 8.5x higher utilization than existing accelerators, and delivers 2.24x higher throughput than the A100 GPU and 3.85x higher throughput than the TPU v6e, under the same multiplier count and memory settings. The full PLENA system will also be open-sourced.'}, {'id': 'arxiv_2502.12110', 'title': 'A-MEM: Agentic Memory for LLM Agents', 'URL': 'http://arxiv.org/abs/2502.12110', 'extra_urls': ['http://arxiv.org/abs/2502.12110'], 'type': 'article', 'author': [{'family': 'Xu', 'given': 'Wujiang'}, {'family': 'Liang', 'given': 'Zujie'}, {'family': 'Mei', 'given': 'Kai'}, {'family': 'Gao', 'given': 'Hang'}, {'family': 'Tan', 'given': 'Juntao'}, {'family': 'Zhang', 'given': 'Yongfeng'}], 'publisher': 'arXiv', 'abstract': &quot;While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences. Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases. Moreover, these systems' fixed operations and structures limit their adaptability across diverse tasks. To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way. Following the basic principles of the Zettelkasten method, we designed our memory system to create interconnected knowledge networks through dynamic indexing and linking. When a new memory is added, we generate a comprehensive note containing multiple structured attributes, including contextual descriptions, keywords, and tags. The system then analyzes historical memories to identify relevant connections, establishing links where meaningful similarities exist. Additionally, this process enables memory evolution - as new memories are integrated, they can trigger updates to the contextual representations and attributes of existing historical memories, allowing the memory network to continuously refine its understanding. Our approach combines the structured organization principles of Zettelkasten with the flexibility of agent-driven decision making, allowing for more adaptive and context-aware memory management. Empirical experiments on six foundation models show superior improvement against existing SOTA baselines. The source code for evaluating performance is available at https://github.com/WujiangXu/A-mem, while the source code of the agentic memory system is available at https://github.com/WujiangXu/A-mem-sys.&quot;}, {'id': 'arxiv_2508.19828', 'title': 'Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning', 'URL': 'http://arxiv.org/abs/2508.19828', 'extra_urls': ['http://arxiv.org/abs/2508.19828'], 'type': 'article', 'author': [{'family': 'Yan', 'given': 'Sikuan'}, {'family': 'Yang', 'given': 'Xiufeng'}, {'family': 'Huang', 'given': 'Zuchao'}, {'family': 'Nie', 'given': 'Ercong'}, {'family': 'Ding', 'given': 'Zifeng'}, {'family': 'Li', 'given': 'Zonggen'}, {'family': 'Ma', 'given': 'Xiaowen'}, {'family': 'Kersting', 'given': 'Kristian'}, {'family': 'Pan', 'given': 'Jeff Z.'}, {'family': 'Sch\xfctze', 'given': 'Hinrich'}, {'family': 'Tresp', 'given': 'Volker'}, {'family': 'Ma', 'given': 'Yunpu'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) have demonstrated impressive capabilities across a wide range of NLP tasks, but they remain fundamentally stateless, constrained by limited context windows that hinder long-horizon reasoning. Recent efforts to address this limitation often augment LLMs with an external memory bank, yet most existing pipelines are static and heuristic-driven, lacking a learned mechanism for deciding what to store, update, or retrieve. We present Memory-R1, a reinforcement learning (RL) framework that equips LLMs with the ability to actively manage and utilize external memory through two specialized agents: a Memory Manager that learns structured operations, including ADD, UPDATE, DELETE, and NOOP; and an Answer Agent that pre-selects and reasons over relevant entries. Both agents are fine-tuned with outcome-driven RL (PPO and GRPO), enabling adaptive memory management with minimal supervision. With only 152 training QA pairs, Memory-R1 outperforms strong baselines and generalizes across diverse question types, three benchmarks (LoCoMo, MSC, LongMemEval), and multiple model scales (3B-14B).'}, {'id': '3d_scan_technology', 'title': '3D Scan Technology to Enhance Body to Pattern Theory: Comparing the Conventional Bespoke Jacket Method with a Novel Parametric Method', 'URL': 'urn:isbn:978-3-032-00839-8', 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Renhao'}, {'family': 'Gill', 'given': 'Simeon'}, {'family': 'Hayes', 'given': 'Steven G.'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Springer Nature Switzerland', 'abstract': 'The conventional pattern drafting methods rely on manual anthropometric approaches and fail to fit the diverse body forms. The 3D body scanning technologies provide the opportunity to optimise the pattern theory. Body scanning generates a digital model allowing a great depth of measurement data of human body dimensions for the drafting process. The bespoke jacket with body shaping function typically causes fit issues, following traditional manual drafts. Compared to the male, a women\u2019s upper body shows more varied contours. However, there is limited study focused on increasing the women bespoke jacket functionality through novel anthropometric technology with an engineering approach. This study starts to address this gap.'}, {'id': 'arxiv_2501.19329', 'title': 'Let Human Sketches Help: Empowering Challenging Image Segmentation Task with Freehand Sketches', 'URL': 'http://arxiv.org/abs/2501.19329', 'extra_urls': ['http://arxiv.org/abs/2501.19329'], 'type': 'article', 'author': [{'family': 'Zang', 'given': 'Ying'}, {'family': 'Cao', 'given': 'Runlong'}, {'family': 'Zhang', 'given': 'Jianqi'}, {'family': 'Han', 'given': 'Yidong'}, {'family': 'Cao', 'given': 'Ziyue'}, {'family': 'Hu', 'given': 'Wenjun'}, {'family': 'Zhu', 'given': 'Didi'}, {'family': 'Zhu', 'given': 'Lanyun'}, {'family': 'Li', 'given': 'Zejian'}, {'family': 'Ji', 'given': 'Deyi'}, {'family': 'Chen', 'given': 'Tianrun'}], 'publisher': 'arXiv', 'abstract': &quot;Sketches, with their expressive potential, allow humans to convey the essence of an object through even a rough contour. For the first time, we harness this expressive potential to improve segmentation performance in challenging tasks like camouflaged object detection (COD). Our approach introduces an innovative sketch-guided interactive segmentation framework, allowing users to intuitively annotate objects with freehand sketches (drawing a rough contour of the object) instead of the traditional bounding boxes or points used in classic interactive segmentation models like SAM. We demonstrate that sketch input can significantly improve performance in existing iterative segmentation methods, outperforming text or bounding box annotations. Additionally, we introduce key modifications to network architectures and a novel sketch augmentation technique to fully harness the power of sketch input and further boost segmentation accuracy. Remarkably, our model' s output can be directly used to train other neural networks, achieving results comparable to pixel-by-pixel annotations--while reducing annotation time by up to 120 times, which shows great potential in democratizing the annotation process and enabling model training with less reliance on resource-intensive, laborious pixel-level annotations. We also present KOSCamo+, the first freehand sketch dataset for camouflaged object detection. The dataset, code, and the labeling tool will be open sourced.&quot;}, {'id': 'fast_modeling', 'title': 'Fast Physics-Based Modeling of Knots and Ties using Templates', 'URL': 'https://dl.acm.org/doi/10.1145/3721238.3730622', 'type': 'article', 'author': [{'family': 'Guo', 'given': 'Dewen'}, {'family': 'Wang', 'given': 'Zhendong'}, {'family': 'Liu', 'given': 'Zegao'}, {'family': 'Li', 'given': 'Sheng'}, {'family': 'Wang', 'given': 'Guoping'}, {'family': 'Yang', 'given': 'Yin'}, {'family': 'Wang', 'given': 'Huamin'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Knots and ties are captivating elements of digital garments and accessories, but they have been notoriously challenging and computationally expensive to model manually. In this paper, we propose a physics-based modeling system for knots and ties using templates. The primary challenge lies in transforming cloth pieces into desired knot and tie configurations in a controllable, penetration-free manner, particularly when interacting with surrounding meshes. To address this, we introduce a pipe-like parametric knot template representation, defined by a B\xe9zier curve as its medial axis and an adaptively adjustable radius for enhanced flexibility and variation. This representation enables customizable knot sizes, shapes, and styles while ensuring intersection-free results through robust collision detection techniques. Using the defined knot template, we present a mapping and penetration-free initialization method to transform selected cloth regions from UV space into the initial 3D knot shape. We further enable quasistatic simulation of knots and their surrounding meshes through a fast and reliable collision handling and simulation scheme. Our experiments demonstrate the system\u2019s effectiveness and efficiency in modeling a wide range of digital knots and ties with diverse styles and shapes, including configurations that were previously impractical to create manually.'}, {'id': 'learning_universal', 'title': 'SketchFusion: Learning Universal Sketch Features through Fusing Foundation Models', 'URL': 'https://openaccess.thecvf.com/content/CVPR2025/html/Koley_SketchFusion_Learning_Universal_Sketch_Features_through_Fusing_Foundation_Models_CVPR_2025_paper.html', 'extra_urls': ['https://openaccess.thecvf.com/content/CVPR2025/html/Koley_SketchFusion_Learning_Universal_Sketch_Features_through_Fusing_Foundation_Models_CVPR_2025_paper.html'], 'type': 'article', 'author': [{'family': 'Koley', 'given': 'Subhadeep'}, {'family': 'Dutta', 'given': 'Tapas Kumar'}, {'family': 'Sain', 'given': 'Aneeshan'}, {'family': 'Chowdhury', 'given': 'Pinaki Nath'}, {'family': 'Bhunia', 'given': 'Ayan Kumar'}, {'family': 'Song', 'given': 'Yi-Zhe'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'all_about', 'title': &quot;It's All About Your Sketch: Democratising Sketch Control in Diffusion Models&quot;, 'URL': 'https://openaccess.thecvf.com/content/CVPR2024/html/Koley_Its_All_About_Your_Sketch_Democratising_Sketch_Control_in_Diffusion_CVPR_2024_paper.html', 'extra_urls': ['https://openaccess.thecvf.com/content/CVPR2024/html/Koley_Its_All_About_Your_Sketch_Democratising_Sketch_Control_in_Diffusion_CVPR_2024_paper.html'], 'type': 'article', 'author': [{'family': 'Koley', 'given': 'Subhadeep'}, {'family': 'Bhunia', 'given': 'Ayan Kumar'}, {'family': 'Sekhri', 'given': 'Deeptanshu'}, {'family': 'Sain', 'given': 'Aneeshan'}, {'family': 'Chowdhury', 'given': 'Pinaki Nath'}, {'family': 'Xiang', 'given': 'Tao'}, {'family': 'Song', 'given': 'Yi-Zhe'}], 'issued': {'date-parts': [[2024]]}}, {'id': 'garment_retargeting', 'title': 'Intersection-Free Garment Retargeting', 'URL': 'https://dl.acm.org/doi/10.1145/3721238.3730590', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3721238.3730590'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Zizhou'}, {'family': 'Ara\xfajo', 'given': 'Chrystiano'}, {'family': 'Kunz', 'given': 'Andrew'}, {'family': 'Zorin', 'given': 'Denis'}, {'family': 'Panozzo', 'given': 'Daniele'}, {'family': 'Zordan', 'given': 'Victor'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Manual design of garments for avatars requires a large effort. Garment retargeting methods can save manual efforts by automatically deforming an existing garment design from one avatar to another. Previous methods are limited to human avatars with small variations in body shapes, while non-human avatars with unrealistic characteristics widely appear in games and animations. In this paper, the goal is to retarget artist-designed garments on a standard mannequin to a more general class of avatars. While there is a lack of training data of various avatars wearing garments, we propose a training-free method that performs optimizations on the mesh representation of the garments, with a combination of loss functions that preserve the geometrical features in the original design, guarantee intersection-free, and fit the garment adaptively to the avatars. Our method produces simulation-ready garment models that can be used later in avatar animations.'}, {'id': 'computational_garment', 'title': 'Rags2Riches: Computational Garment Reuse', 'URL': 'https://dl.acm.org/doi/10.1145/3721238.3730703', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3721238.3730703'], 'type': 'article', 'author': [{'family': 'Qi', 'given': 'Anran'}, {'family': 'Pietroni', 'given': 'Nico'}, {'family': 'Korosteleva', 'given': 'Maria'}, {'family': 'Sorkine-Hornung', 'given': 'Olga'}, {'family': 'Bousseau', 'given': 'Adrien'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'We present the first algorithm to automatically compute sewing patterns for upcycling existing garments into new designs. Our algorithm takes as input two garment designs along with their corresponding sewing patterns and determines how to cut one of them to match the other by following garment reuse principles. Specifically, our algorithm favors the reuse of seams and hems present in the existing garment, thereby preserving the embedded value of these structural components and simplifying the fabrication of the new garment. Finding optimal reused pattern is computationally challenging because it involves both discrete and continuous quantities. Discrete decisions include the choice of existing panels to cut from and the choice of seams and hems to reuse. Continuous variables include the precise placement of the new panels along seams and hems, and potential deformations of these panels to maximize reuse. Our key idea for making this optimization tractable is quantizing the shape of garment panels. This allows us to frame the search for an optimal reused pattern as a discrete assignment problem, which we solve efficiently with an ILP solver. We showcase our proposed pipeline on several reuse examples, including comparisons with reused patterns crafted by a professional garment designer. Additionally, we manufacture a physical reused garment to demonstrate the practical effectiveness of our approach.'}, {'id': 'arxiv_1806.11335', 'title': 'Learning a Shared Shape Space for Multimodal Garment Design', 'URL': 'http://arxiv.org/abs/1806.11335', 'extra_urls': ['http://arxiv.org/abs/1806.11335'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Tuanfeng Y.'}, {'family': 'Ceylan', 'given': 'Duygu'}, {'family': 'Popovic', 'given': 'Jovan'}, {'family': 'Mitra', 'given': 'Niloy J.'}], 'publisher': 'arXiv', 'abstract': 'Designing real and virtual garments is becoming extremely demanding with rapidly changing fashion trends and increasing need for synthesizing realistic dressed digital humans for various applications. This necessitates creating simple and effective workflows to facilitate authoring sewing patterns customized to garment and target body shapes to achieve desired looks. Traditional workflow involves a trial-and-error procedure wherein a mannequin is draped to judge the resultant folds and the sewing pattern iteratively adjusted until the desired look is achieved. This requires time and experience. Instead, we present a data-driven approach wherein the user directly indicates desired fold patterns simply by sketching while our system estimates corresponding garment and body shape parameters at interactive rates. The recovered parameters can then be further edited and the updated draped garment previewed. Technically, we achieve this via a novel shared shape space that allows the user to seamlessly specify desired characteristics across multimodal input {\\em without} requiring to run garment simulation at design time. We evaluate our approach qualitatively via a user study and quantitatively against test datasets, and demonstrate how our system can generate a rich quality of on-body garments targeted for a range of body shapes while achieving desired fold characteristics.'}, {'id': 'arxiv_2501.16177', 'title': 'BAG: Body-Aligned 3D Wearable Asset Generation', 'URL': 'http://arxiv.org/abs/2501.16177', 'extra_urls': ['http://arxiv.org/abs/2501.16177'], 'type': 'article', 'author': [{'family': 'Luo', 'given': 'Zhongjin'}, {'family': 'Li', 'given': 'Yang'}, {'family': 'Zhang', 'given': 'Mingrui'}, {'family': 'Wang', 'given': 'Senbo'}, {'family': 'Yan', 'given': 'Han'}, {'family': 'Song', 'given': 'Xibin'}, {'family': 'Shang', 'given': 'Taizhang'}, {'family': 'Mao', 'given': 'Wei'}, {'family': 'Li', 'given': 'Hongdong'}, {'family': 'Han', 'given': 'Xiaoguang'}, {'family': 'Ji', 'given': 'Pan'}], 'publisher': 'arXiv', 'abstract': 'While recent advancements have shown remarkable progress in general 3D shape generation models, the challenge of leveraging these approaches to automatically generate wearable 3D assets remains unexplored. To this end, we present BAG, a Body-aligned Asset Generation method to output 3D wearable asset that can be automatically dressed on given 3D human bodies. This is achived by controlling the 3D generation process using human body shape and pose information. Specifically, we first build a general single-image to consistent multiview image diffusion model, and train it on the large Objaverse dataset to achieve diversity and generalizability. Then we train a Controlnet to guide the multiview generator to produce body-aligned multiview images. The control signal utilizes the multiview 2D projections of the target human body, where pixel values represent the XYZ coordinates of the body surface in a canonical space. The body-conditioned multiview diffusion generates body-aligned multiview images, which are then fed into a native 3D diffusion model to produce the 3D shape of the asset. Finally, by recovering the similarity transformation using multiview silhouette supervision and addressing asset-body penetration with physics simulators, the 3D asset can be accurately fitted onto the target human body. Experimental results demonstrate significant advantages over existing methods in terms of image prompt-following capability, shape diversity, and shape quality. Our project page is available at https://bag-3d.github.io/.'}, {'id': 'raster_encoding', 'title': 'GarmentImage: Raster Encoding of Garment Sewing Patterns with Diverse Topologies', 'URL': 'https://dl.acm.org/doi/10.1145/3721238.3730632', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3721238.3730632'], 'type': 'article', 'author': [{'family': 'Tatsukawa', 'given': 'Yuki'}, {'family': 'Qi', 'given': 'Anran'}, {'family': 'Shen', 'given': 'I-Chao'}, {'family': 'Igarashi', 'given': 'Takeo'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Garment sewing patterns are the design language behind clothing, yet their current vector-based digital representations weren\u2019t built with machine learning in mind. Vector-based representation encodes a sewing pattern as a discrete set of panels, each defined as a sequence of lines and curves, stitching information between panels and the placement of each panel around a body. However, this representation causes two major challenges for neural networks: discontinuity in latent space between patterns with different topologies and limited generalization to garments with unseen topologies in the training data. In this work, we introduce GarmentImage, a unified raster-based sewing pattern representation. GarmentImage encodes a garment sewing pattern\u2019s geometry, topology and placement into multi-channel regular grids. Machine learning models trained on GarmentImage achieve seamless transitions between patterns with different topologies and show better generalization capabilities compared to models trained on vector-based representation. We demonstrate the effectiveness of GarmentImage across three applications: pattern exploration in latent space, text-based pattern editing, and image-to-pattern prediction. The results show that GarmentImage achieves superior performance on these applications using only simple convolutional networks.'}, {'id': 'computational_for', 'title': 'Computational Tailor-Making for Personalized, Shape-changing, and Sustainable Fabrics', 'URL': 'https://dl.acm.org/doi/10.1145/3746058.3758470', 'type': 'article', 'author': [{'family': 'Narumi', 'given': 'Koya'}, {'family': 'Hirose', 'given': 'Yuichi'}, {'family': 'Lee', 'given': 'Hsuanling'}, {'family': 'Larsson', 'given': 'Maria'}, {'family': 'He', 'given': 'Liang'}, {'family': 'Leake', 'given': 'Mackenzie'}, {'family': 'Forman', 'given': 'Jack'}, {'family': 'Farahi', 'given': 'Behnaz'}, {'family': 'Yao', 'given': 'Lining'}, {'family': 'Igarashi', 'given': 'Takeo'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Fabrics are fundamental elements of our daily lives, which are woven, knitted, or embroidered into diverse products like clothing and furniture. Recent advances in materials science and digital fabrication have enabled us to fabricate personalized and responsive fabric products computationally and interactively, which we call \u201ccomputational tailor-making.\u201d In this workshop, we will build an interdisciplinary network of researchers on computational tailor-making and discuss (1) computational fabric design, (2) novel fabric fabrication tools, (3) shape-changing fabrics, and (4) sustainable fabric production, from the viewpoint of HCI. The workshop session will help attendees build a shared vision, recognize potential challenges, find unexpected solutions and ideas, collaborate beyond disciplines, and explore the possible connection to industries.'}, {'id': 'arxiv_2509.05030', 'title': 'LUIVITON: Learned Universal Interoperable VIrtual Try-ON', 'URL': 'http://arxiv.org/abs/2509.05030', 'extra_urls': ['http://arxiv.org/abs/2509.05030'], 'type': 'article', 'author': [{'family': 'Cao', 'given': 'Cong'}, {'family': 'Cheng', 'given': 'Xianhang'}, {'family': 'Liu', 'given': 'Jingyuan'}, {'family': 'Zheng', 'given': 'Yujian'}, {'family': 'Lin', 'given': 'Zhenhui'}, {'family': 'Chkir', 'given': 'Meriem'}, {'family': 'Li', 'given': 'Hao'}], 'publisher': 'arXiv', 'abstract': 'We present LUIVITON, an end-to-end system for fully automated virtual try-on, capable of draping complex, multi-layer clothing onto diverse and arbitrarily posed humanoid characters. To address the challenge of aligning complex garments with arbitrary and highly diverse body shapes, we use SMPL as a proxy representation and separate the clothing-to-body draping problem into two correspondence tasks: 1) clothing-to-SMPL and 2) body-to-SMPL correspondence, where each has its unique challenges. While we address the clothing-to-SMPL fitting problem using a geometric learning-based approach for partial-to-complete shape correspondence prediction, we introduce a diffusion model-based approach for body-to-SMPL correspondence using multi-view consistent appearance features and a pre-trained 2D foundation model. Our method can handle complex geometries, non-manifold meshes, and generalizes effectively to a wide range of humanoid characters -- including humans, robots, cartoon subjects, creatures, and aliens, while maintaining computational efficiency for practical adoption. In addition to offering a fully automatic fitting solution, LUIVITON supports fast customization of clothing size, allowing users to adjust clothing sizes and material properties after they have been draped. We show that our system can produce high-quality 3D clothing fittings without any human labor, even when 2D clothing sewing patterns are not available.'}, {'id': 'arxiv_2506.05210', 'title': 'Towards Vision-Language-Garment Models for Web Knowledge Garment Understanding and Generation', 'URL': 'http://arxiv.org/abs/2506.05210', 'extra_urls': ['http://arxiv.org/abs/2506.05210'], 'type': 'article', 'author': [{'family': 'Ackermann', 'given': 'Jan'}, {'family': 'Nakayama', 'given': 'Kiyohiro'}, {'family': 'Yang', 'given': 'Guandao'}, {'family': 'Wu', 'given': 'Tong'}, {'family': 'Wetzstein', 'given': 'Gordon'}], 'publisher': 'arXiv', 'abstract': &quot;Multimodal foundation models have demonstrated strong generalization, yet their ability to transfer knowledge to specialized domains such as garment generation remains underexplored. We introduce VLG, a vision-language-garment model that synthesizes garments from textual descriptions and visual imagery. Our experiments assess VLG's zero-shot generalization, investigating its ability to transfer web-scale reasoning to unseen garment styles and prompts. Preliminary results indicate promising transfer capabilities, highlighting the potential for multimodal foundation models to adapt effectively to specialized domains like fashion design.&quot;}, {'id': 'doi_10_36227_techrxiv_175790711_13089436_v1', 'title': 'CuttingEdgeAI RL for Unique 2D Cutting Stock Problems', 'URL': 'https://doi.org/10.36227/techrxiv.175790711.13089436/v1', 'extra_urls': ['https://doi.org/10.36227/techrxiv.175790711.13089436/v1'], 'type': 'article', 'author': [{'family': 'Bateham', 'given': 'Greg'}, {'family': 'Acharya', 'given': 'Sunim'}, {'family': 'Thakur', 'given': 'Satyam'}, {'family': 'Champie', 'given': 'Joyce'}, {'family': 'Dmytryk', 'given': 'Anastasiya'}, {'family': 'Karaman', 'given': 'Bayazit'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Fashion manufacturing, in the case of small businesses and solo seamstresses, typically remains muddled in labor-consuming, time-wasting techniques that suppress creativity and encourage material waste. This project considers the cutting stock problem', 'DOI': '10.36227/techrxiv.175790711.13089436/v1'}, {'id': 'hidden_layer', 'title': 'Hidden Layer Interaction: A Technique to Explore the Material of Generative AI', 'URL': 'https://dl.acm.org/doi/10.1145/3715336.3735437', 'type': 'article', 'author': [{'family': 'Grabe', 'given': 'Imke'}, {'family': 'Jenkins', 'given': 'Tom'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'This pictorial describes the process of developing an interaction technique for directly engaging with the hidden layers of a generative AI model for image synthesis. First, we give some background to generative AI in HCI, arguing that current interaction techniques prevent us from directly interacting with the material of AI, foreclosing its use in design. Drawing on inspiration from the Computer Science field of feature visualization, we investigate the materiality of our prototype, a GAN model trained to generate fashion imagery, and show how Hidden Layer Interaction offers an alternative to standard prompting. In doing so, we illustrate how this change in approach leads to new forms of interaction with the internal semantics of generative AI, and demonstrate how one might use Hidden Layer Interaction to engage with AI as a material in design.'}, {'id': 'arxiv_2509.04705', 'title': 'Transforming Fashion with AI: A Comparative Study of Large Language Models in Apparel Design', 'URL': 'http://arxiv.org/abs/2509.04705', 'extra_urls': ['http://arxiv.org/abs/2509.04705'], 'type': 'article', 'author': [{'family': 'Lamia', 'given': 'Nusrat Jahan'}, {'family': 'Mim', 'given': 'Sadia Afrin'}], 'publisher': 'arXiv', 'abstract': &quot;Fashion has evolved from handcrafted designs to automated production over the years, where AI has added another dimension to it. Nowadays, practically every industry uses artificial models to automate their operations. To explore their role, we examined three prominent LLMs (OpenAI, GeminiAI, Deepseek) in multiple stages of textile manufacturing (e.g., sustainable choice, cost effectiveness, production planning, etc.). We assessed the models' ability to replicate garment design using certain parameters (fabric construction, shade, weave, silhouette, etc.). We compared the models in terms of different body types and functional purposes (e.g., fashionwear, sportswear) so that designers could evaluate effectiveness before developing actual patterns, make necessary modifications, and conduct fashion forecasting beforehand. To facilitate deeper analysis, we created a custom dataset specifically for fabric image generation and classification. Our analysis revealed that, in terms of fabric construction, the OpenAI DALL-E model integrated with ChatGPT outperformed other models, achieving a lower LPIPS (Learned Perceptual Image Patch Similarity) score of approximately $0.2$. In fabric classification from images, we found OpenAI offered the best results by breaking down certain factors (e.g., breathability, moisture-wicking, and tactile comfort), achieving approximately $80\\%$ accuracy for base construction and $55\\%$ for detailed construction. However, our results indicate that Deepseek faced significant challenges in generating and recognizing fabric images. Overall, all the models struggled to recognize complex fabric constructions and intricate designs from images, and relying too much on AI might hinder human creativity. We also observed that all three models performed effectively in providing recommendations and insights for fabric design in textual form.&quot;}, {'id': 'a_group', 'title': 'GDE-TP: a group design evaluation method based on triplet-based preference handling the uncertainty of group-level preference data', 'URL': 'https://papers.ssrn.com/abstract=5545480', 'extra_urls': ['https://papers.ssrn.com/abstract=5545480'], 'type': 'article', 'author': [{'family': 'Qi', 'given': 'Jin'}, {'family': 'Huang', 'given': 'Haiqing'}, {'family': 'Hu', 'given': 'Jie'}, {'family': 'Peng', 'given': 'Yinhong'}], 'publisher': 'Social Science Research Network', 'abstract': 'The use of AI-generated design has resulted in a large number of design candidates, which in turn has driven the development of more efficient design evaluation method that involves multiple decision-makers (DMs). Traditional uncertain information treatment methods have been employed into group design evaluation (GDE) to handle the uncertainty of DM\u2019s individual linguistic preference opinion, but overlooked the uncertainty hidden in a group of preferences given by different DMs. To address this problem, this study attempts to characterize such uncertainty as the fuzziness of group-level preference data. Based on linguistic D-number (LDN) theory, we propose a new triplet-based preference (T-preference) that consists of preference, reliability and fuzziness information. Accordingly, the T-preference generation method and T-preference-based GDE method (GDE-TP) are presented as well. The objective of GDE-TP is to make the design evaluation more rational by comprehensively considering the preference, reliability, and fuzziness factors. Under the principle of GDE-TP, the optimal design candidate is the one with high and reliable preference, while maintaining low fuzziness. Actual example and four empirical comparisons have been carried out in this paper, which prove the feasibility of GDE-TP as well as its superiority by comparing with i) different evaluation factors, ii) different decision-making models, iii) different uncertain information treatment methods and iv) different design attributes.'}, {'id': 'arxiv_2508.18733', 'title': 'Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vector Drawings', 'URL': 'http://arxiv.org/abs/2508.18733', 'extra_urls': ['http://arxiv.org/abs/2508.18733'], 'type': 'article', 'author': [{'family': 'Qin', 'given': 'Feiwei'}, {'family': 'Lu', 'given': 'Shichao'}, {'family': 'Hou', 'given': 'Junhao'}, {'family': 'Wang', 'given': 'Changmiao'}, {'family': 'Fang', 'given': 'Meie'}, {'family': 'Liu', 'given': 'Ligang'}], 'publisher': 'arXiv', 'abstract': 'Computer-Aided Design (CAD) generative modeling is driving significant innovations across industrial applications. Recent works have shown remarkable progress in creating solid models from various inputs such as point clouds, meshes, and text descriptions. However, these methods fundamentally diverge from traditional industrial workflows that begin with 2D engineering drawings. The automatic generation of parametric CAD models from these 2D vector drawings remains underexplored despite being a critical step in engineering design. To address this gap, our key insight is to reframe CAD generation as a sequence-to-sequence learning problem where vector drawing primitives directly inform the generation of parametric CAD operations, preserving geometric precision and design intent throughout the transformation process. We propose Drawing2CAD, a framework with three key technical components: a network-friendly vector primitive representation that preserves precise geometric information, a dual-decoder transformer architecture that decouples command type and parameter generation while maintaining precise correspondence, and a soft target distribution loss function accommodating inherent flexibility in CAD parameters. To train and evaluate Drawing2CAD, we create CAD-VGDrawing, a dataset of paired engineering drawings and parametric CAD models, and conduct thorough experiments to demonstrate the effectiveness of our method. Code and dataset are available at https://github.com/lllssc/Drawing2CAD.'}, {'id': 'arxiv_2504.13893', 'title': 'Semantic Direct Modeling', 'URL': 'http://arxiv.org/abs/2504.13893', 'extra_urls': ['http://arxiv.org/abs/2504.13893'], 'type': 'article', 'author': [{'family': 'Zou', 'given': 'Qiang'}, {'family': 'Liu', 'given': 'Shuo'}], 'publisher': 'arXiv', 'abstract': 'Current direct modeling systems limit users to low-level interactions with vertices, edges, and faces, forcing designers to manage detailed geometric elements rather than focusing on high-level design intent. This paper introduces semantic direct modeling (SDM), a novel approach that lifts direct modeling from low-level geometric modifications to high-level semantic interactions. This is achieved by utilizing a large language model (LLM) fine-tuned with CAD-specific prompts, which can guide the LLM to reason through design intent and accurately interpret CAD commands, thereby allowing designers to express their intent using natural language. Additionally, SDM maps design intent to the corresponding geometric features in the CAD model through a new conditional, context-sensitive feature recognition method, which uses generative AI to dynamically assign feature labels based on design intent. Together, they enable a seamless flow from high-level design intent to low-level geometric modifications, bypassing tedious software interactions. The effectiveness of SDM has been validated through real mechanical design cases.'}, {'id': 'arxiv_2505.17702', 'title': 'Seek-CAD: A Self-refined Generative Modeling for 3D Parametric CAD Using Local Inference via DeepSeek', 'URL': 'http://arxiv.org/abs/2505.17702', 'extra_urls': ['http://arxiv.org/abs/2505.17702'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Xueyang'}, {'family': 'Li', 'given': 'Jiahao'}, {'family': 'Song', 'given': 'Yu'}, {'family': 'Lou', 'given': 'Yunzhong'}, {'family': 'Zhou', 'given': 'Xiangdong'}], 'publisher': 'arXiv', 'abstract': 'The advent of Computer-Aided Design (CAD) generative modeling will significantly transform the design of industrial products. The recent research endeavor has extended into the realm of Large Language Models (LLMs). In contrast to fine-tuning methods, training-free approaches typically utilize the advanced closed-source LLMs, thereby offering enhanced flexibility and efficiency in the development of AI agents for generating CAD parametric models. However, the substantial cost and limitations of local deployment of the top-tier closed-source LLMs pose challenges in practical applications. The Seek-CAD is the pioneer exploration of locally deployed open-source inference LLM DeepSeek-R1 for CAD parametric model generation with a training-free methodology. This study is the first investigation to incorporate both visual and Chain-of-Thought (CoT) feedback within the self-refinement mechanism for generating CAD models. Specifically, the initial generated parametric CAD model is rendered into a sequence of step-wise perspective images, which are subsequently processed by a Vision Language Model (VLM) alongside the corresponding CoTs derived from DeepSeek-R1 to assess the CAD model generation. Then, the feedback is utilized by DeepSeek-R1 to refine the initial generated model for the next round of generation. Moreover, we present an innovative 3D CAD model dataset structured around the SSR (Sketch, Sketch-based feature, and Refinements) triple design paradigm. This dataset encompasses a wide range of CAD commands, thereby aligning effectively with industrial application requirements and proving suitable for the generation of LLMs. Extensive experiments validate the effectiveness of Seek-CAD under various metrics.'}, {'id': 'arxiv_2508.04002', 'title': 'CAD-Judge: Toward Efficient Morphological Grading and Verification for Text-to-CAD Generation', 'URL': 'http://arxiv.org/abs/2508.04002', 'extra_urls': ['http://arxiv.org/abs/2508.04002'], 'type': 'article', 'author': [{'family': 'Zhou', 'given': 'Zheyuan'}, {'family': 'Han', 'given': 'Jiayi'}, {'family': 'Du', 'given': 'Liang'}, {'family': 'Fang', 'given': 'Naiyu'}, {'family': 'Qiu', 'given': 'Lemiao'}, {'family': 'Zhang', 'given': 'Shuyou'}], 'publisher': 'arXiv', 'abstract': 'Computer-Aided Design (CAD) models are widely used across industrial design, simulation, and manufacturing processes. Text-to-CAD systems aim to generate editable, general-purpose CAD models from textual descriptions, significantly reducing the complexity and entry barrier associated with traditional CAD workflows. However, rendering CAD models can be slow, and deploying VLMs to review CAD models can be expensive and may introduce reward hacking that degrades the systems. To address these challenges, we propose CAD-Judge, a novel, verifiable reward system for efficient and effective CAD preference grading and grammatical validation. We adopt the Compiler-as-a-Judge Module (CJM) as a fast, direct reward signal, optimizing model alignment by maximizing generative utility through prospect theory. To further improve the robustness of Text-to-CAD in the testing phase, we introduce a simple yet effective agentic CAD generation approach and adopt the Compiler-as-a-Review Module (CRM), which efficiently verifies the generated CAD models, enabling the system to refine them accordingly. Extensive experiments on challenging CAD datasets demonstrate that our method achieves state-of-the-art performance while maintaining superior efficiency.'}, {'id': 'arxiv_2502.03997', 'title': 'CAD-Editor: A Locate-then-Infill Framework with Automated Training Data Synthesis for Text-Based CAD Editing', 'URL': 'http://arxiv.org/abs/2502.03997', 'extra_urls': ['http://arxiv.org/abs/2502.03997'], 'type': 'article', 'author': [{'family': 'Yuan', 'given': 'Yu'}, {'family': 'Sun', 'given': 'Shizhao'}, {'family': 'Liu', 'given': 'Qi'}, {'family': 'Bian', 'given': 'Jiang'}], 'publisher': 'arXiv', 'abstract': 'Computer Aided Design (CAD) is indispensable across various industries. \\emph{Text-based CAD editing}, which automates the modification of CAD models based on textual instructions, holds great potential but remains underexplored. Existing methods primarily focus on design variation generation or text-based CAD generation, either lacking support for text-based control or neglecting existing CAD models as constraints. We introduce \\emph{CAD-Editor}, the first framework for text-based CAD editing. To address the challenge of demanding triplet data with accurate correspondence for training, we propose an automated data synthesis pipeline. This pipeline utilizes design variation models to generate pairs of original and edited CAD models and employs Large Vision-Language Models (LVLMs) to summarize their differences into editing instructions. To tackle the composite nature of text-based CAD editing, we propose a locate-then-infill framework that decomposes the task into two focused sub-tasks: locating regions requiring modification and infilling these regions with appropriate edits. Large Language Models (LLMs) serve as the backbone for both sub-tasks, leveraging their capabilities in natural language understanding and CAD knowledge. Experiments show that CAD-Editor achieves superior performance both quantitatively and qualitatively. The code is available at \\url {https://github.com/microsoft/CAD-Editor}.'}, {'id': 'arxiv_2509.01350', 'title': 'Error Notebook-Guided, Training-Free Part Retrieval in 3D CAD Assemblies via Vision-Language Models', 'URL': 'http://arxiv.org/abs/2509.01350', 'extra_urls': ['http://arxiv.org/abs/2509.01350'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Yunqing'}, {'family': 'Zhang', 'given': 'Nan'}, {'family': 'Tan', 'given': 'Zhiming'}], 'publisher': 'arXiv', 'abstract': &quot;Effective specification-aware part retrieval within complex CAD assemblies is essential for automated design verification and downstream engineering tasks. However, directly using LLMs/VLMs to this task presents some challenges: the input sequences may exceed model token limits, and even after processing, performance remains unsatisfactory. Moreover, fine-tuning LLMs/VLMs requires significant computational resources, and for many high-performing general-use proprietary models (e.g., GPT or Gemini), fine-tuning access is not available. In this paper, we propose a novel part retrieval framework that requires no extra training, but using Error Notebooks + RAG for refined prompt engineering to help improve the existing general model's retrieval performance. The construction of Error Notebooks consists of two steps: (1) collecting historical erroneous CoTs and their incorrect answers, and (2) connecting these CoTs through reflective corrections until the correct solutions are obtained. As a result, the Error Notebooks serve as a repository of tasks along with their corrected CoTs and final answers. RAG is then employed to retrieve specification-relevant records from the Error Notebooks and incorporate them into the inference process. Another major contribution of our work is a human-in-the-loop CAD dataset, which is used to evaluate our method. In addition, the engineering value of our novel framework lies in its ability to effectively handle 3D models with lengthy, non-natural language metadata. Experiments with proprietary models, including GPT-4o and the Gemini series, show substantial gains, with GPT-4o (Omni) achieving up to a 23.4% absolute accuracy improvement on the human preference dataset. Moreover, ablation studies confirm that CoT reasoning provides benefits especially in challenging cases with higher part counts (&gt;10).&quot;}, {'id': 'leveraging_large', 'title': 'CAD-Llama: Leveraging Large Language Models for Computer-Aided Design Parametric 3D Model Generation', 'URL': 'https://openaccess.thecvf.com/content/CVPR2025/html/Li_CAD-Llama_Leveraging_Large_Language_Models_for_Computer-Aided_Design_Parametric_3D_CVPR_2025_paper.html', 'extra_urls': ['https://openaccess.thecvf.com/content/CVPR2025/html/Li_CAD-Llama_Leveraging_Large_Language_Models_for_Computer-Aided_Design_Parametric_3D_CVPR_2025_paper.html'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Jiahao'}, {'family': 'Ma', 'given': 'Weijian'}, {'family': 'Li', 'given': 'Xueyang'}, {'family': 'Lou', 'given': 'Yunzhong'}, {'family': 'Zhou', 'given': 'Guichun'}, {'family': 'Zhou', 'given': 'Xiangdong'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'arxiv_2501.19054', 'title': 'Text-to-CAD Generation Through Infusing Visual Feedback in Large Language Models', 'URL': 'http://arxiv.org/abs/2501.19054', 'extra_urls': ['http://arxiv.org/abs/2501.19054'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Ruiyu'}, {'family': 'Yuan', 'given': 'Yu'}, {'family': 'Sun', 'given': 'Shizhao'}, {'family': 'Bian', 'given': 'Jiang'}], 'publisher': 'arXiv', 'abstract': 'Creating Computer-Aided Design (CAD) models requires significant expertise and effort. Text-to-CAD, which converts textual descriptions into CAD parametric sequences, is crucial in streamlining this process. Recent studies have utilized ground-truth parametric sequences, known as sequential signals, as supervision to achieve this goal. However, CAD models are inherently multimodal, comprising parametric sequences and corresponding rendered visual objects. Besides,the rendering process from parametric sequences to visual objects is many-to-one. Therefore, both sequential and visual signals are critical for effective training. In this work, we introduce CADFusion, a framework that uses Large Language Models (LLMs) as the backbone and alternates between two training stages: the sequential learning (SL) stage and the visual feedback (VF) stage. In the SL stage, we train LLMs using ground-truth parametric sequences, enabling the generation of logically coherent parametric sequences. In the VF stage, we reward parametric sequences that render into visually preferred objects and penalize those that do not, allowing LLMs to learn how rendered visual objects are perceived and evaluated. These two stages alternate throughout the training, ensuring balanced learning and preserving benefits of both signals. Experiments demonstrate that CADFusion significantly improves performance, both qualitatively and quantitatively.'}, {'id': 'arxiv_2509.21150', 'title': 'CAD-Tokenizer: Towards Text-based CAD Prototyping via Modality-Specific Tokenization', 'URL': 'http://arxiv.org/abs/2509.21150', 'extra_urls': ['http://arxiv.org/abs/2509.21150'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Ruiyu'}, {'family': 'Sun', 'given': 'Shizhao'}, {'family': 'Ma', 'given': 'Weijian'}, {'family': 'Bian', 'given': 'Jiang'}], 'publisher': 'arXiv', 'abstract': &quot;Computer-Aided Design (CAD) is a foundational component of industrial prototyping, where models are defined not by raw coordinates but by construction sequences such as sketches and extrusions. This sequential structure enables both efficient prototype initialization and subsequent editing. Text-guided CAD prototyping, which unifies Text-to-CAD generation and CAD editing, has the potential to streamline the entire design pipeline. However, prior work has not explored this setting, largely because standard large language model (LLM) tokenizers decompose CAD sequences into natural-language word pieces, failing to capture primitive-level CAD semantics and hindering attention modules from modeling geometric structure. We conjecture that a multimodal tokenization strategy, aligned with CAD's primitive and structural nature, can provide more effective representations. To this end, we propose CAD-Tokenizer, a framework that represents CAD data with modality-specific tokens using a sequence-based VQ-VAE with primitive-level pooling and constrained decoding. This design produces compact, primitive-aware representations that align with CAD's structural nature. Applied to unified text-guided CAD prototyping, CAD-Tokenizer significantly improves instruction following and generation quality, achieving better quantitative and qualitative performance over both general-purpose LLMs and task-specific baselines.&quot;}, {'id': 'arxiv_2503.05161', 'title': 'GaussianCAD: Robust Self-Supervised CAD Reconstruction from Three Orthographic Views Using 3D Gaussian Splatting', 'URL': 'http://arxiv.org/abs/2503.05161', 'extra_urls': ['http://arxiv.org/abs/2503.05161'], 'type': 'article', 'author': [{'family': 'Zhou', 'given': 'Zheng'}, {'family': 'Li', 'given': 'Zhe'}, {'family': 'Yu', 'given': 'Bo'}, {'family': 'Hu', 'given': 'Lina'}, {'family': 'Dong', 'given': 'Liang'}, {'family': 'Yang', 'given': 'Zijian'}, {'family': 'Liu', 'given': 'Xiaoli'}, {'family': 'Xu', 'given': 'Ning'}, {'family': 'Wang', 'given': 'Ziwei'}, {'family': 'Dang', 'given': 'Yonghao'}, {'family': 'Yin', 'given': 'Jianqin'}], 'publisher': 'arXiv', 'abstract': 'The automatic reconstruction of 3D computer-aided design (CAD) models from CAD sketches has recently gained significant attention in the computer vision community. Most existing methods, however, rely on vector CAD sketches and 3D ground truth for supervision, which are often difficult to be obtained in industrial applications and are sensitive to noise inputs. We propose viewing CAD reconstruction as a specific instance of sparse-view 3D reconstruction to overcome these limitations. While this reformulation offers a promising perspective, existing 3D reconstruction methods typically require natural images and corresponding camera poses as inputs, which introduces two major significant challenges: (1) modality discrepancy between CAD sketches and natural images, and (2) difficulty of accurate camera pose estimation for CAD sketches. To solve these issues, we first transform the CAD sketches into representations resembling natural images and extract corresponding masks. Next, we manually calculate the camera poses for the orthographic views to ensure accurate alignment within the 3D coordinate system. Finally, we employ a customized sparse-view 3D reconstruction method to achieve high-quality reconstructions from aligned orthographic views. By leveraging raster CAD sketches for self-supervision, our approach eliminates the reliance on vector CAD sketches and 3D ground truth. Experiments on the Sub-Fusion360 dataset demonstrate that our proposed method significantly outperforms previous approaches in CAD reconstruction performance and exhibits strong robustness to noisy inputs.'}, {'id': 'arxiv_2504.13178', 'title': 'Aligning Constraint Generation with Design Intent in Parametric CAD', 'URL': 'http://arxiv.org/abs/2504.13178', 'extra_urls': ['http://arxiv.org/abs/2504.13178'], 'type': 'article', 'author': [{'family': 'Casey', 'given': 'Evan'}, {'family': 'Zhang', 'given': 'Tianyu'}, {'family': 'Ishida', 'given': 'Shu'}, {'family': 'McCarthy', 'given': 'William P.'}, {'family': 'Thompson', 'given': 'John Roger'}, {'family': 'Khasahmadi', 'given': 'Amir'}, {'family': 'Lambourne', 'given': 'Joseph George'}, {'family': 'Jayaraman', 'given': 'Pradeep Kumar'}, {'family': 'Willis', 'given': 'Karl D. D.'}], 'publisher': 'arXiv', 'abstract': &quot;We adapt alignment techniques from reasoning LLMs to the task of generating engineering sketch constraints found in computer-aided design (CAD) models. Engineering sketches consist of geometric primitives (e.g. points, lines) connected by constraints (e.g. perpendicular, tangent) that define the relationships between them. For a design to be easily editable, the constraints must effectively capture design intent, ensuring the geometry updates predictably when parameters change. Although current approaches can generate CAD designs, an open challenge remains to align model outputs with design intent, we label this problem 'design alignment'. A critical first step towards aligning generative CAD models is to generate constraints which fully-constrain all geometric primitives, without over-constraining or distorting sketch geometry. Using alignment techniques to train an existing constraint generation model with feedback from a constraint solver, we are able to fully-constrain 93% of sketches compared to 34% when using a naive supervised fine-tuning (SFT) baseline and only 8.9% without SFT. Our approach can be applied to any existing constraint generation model and sets the stage for further research bridging alignment strategies between the language and design domains. Additional results can be found at https://autodeskailab.github.io/aligning-constraint-generation/.&quot;}, {'id': 'a', 'title': 'PICASSO: A Feed-Forward Framework for Parametric Inference of CAD Sketches via Rendering Self-Supervision', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10943515', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10943515'], 'type': 'article', 'author': [{'family': 'Karadeniz', 'given': 'Ahmet Serdar'}, {'family': 'Mallis', 'given': 'Dimitrios'}, {'family': 'Mejri', 'given': 'Nesryne'}, {'family': 'Cherenkova', 'given': 'Kseniya'}, {'family': 'Kacem', 'given': 'Anis'}, {'family': 'Aouada', 'given': 'Djamila'}], 'abstract': 'This work introduces PICASSO, a framework for the parameterization of 2D CAD sketches from hand-drawn and precise sketch images. PICASSO converts a given CAD sketch image into parametric primitives that can be seamlessly integrated into CAD software. Our framework leverages rendering self-supervision to enable the pre-training of a CAD sketch parameterization network using sketch renderings only, thereby eliminating the need for corresponding CAD parameterization. Thus, we significantly reduce reliance on parameter-level annotations, which are often unavailable, particularly for hand-drawn sketches. The two primary components of PICASSO are (1) a Sketch Parameterization Network (SPN) that predicts a series of parametric primitives from CAD sketch images, and (2) a Sketch Rendering Network (SRN) that renders parametric CAD sketches in a differentiable manner and facilitates the computation of a rendering (image-level) loss for self-supervision. We demonstrate that the proposed PICASSO can achieve reasonable performance even when finetuned with only a small number of parametric CAD sketches. Extensive evaluation on the widely used SketchGraphs [37] and CAD as Language [14] datasets validates the effectiveness of the proposed approach on zero- and few-shot learning scenarios.'}, {'id': 'arxiv_2505.24838', 'title': 'VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and 3D Reasoning from CAD Software', 'URL': 'http://arxiv.org/abs/2505.24838', 'extra_urls': ['http://arxiv.org/abs/2505.24838'], 'type': 'article', 'author': [{'family': 'Man', 'given': 'Brandon'}, {'family': 'Nehme', 'given': 'Ghadi'}, {'family': 'Alam', 'given': 'Md Ferdous'}, {'family': 'Ahmed', 'given': 'Faez'}], 'publisher': 'arXiv', 'abstract': &quot;Computer-Aided Design (CAD) is a time-consuming and complex process, requiring precise, long-horizon user interactions with intricate 3D interfaces. While recent advances in AI-driven user interface (UI) agents show promise, most existing datasets and methods focus on short, low-complexity tasks in mobile or web applications, failing to capture the demands of professional engineering tools. In this work, we introduce VideoCAD, the first attempt at engineering UI interaction learning for precision tasks. Specifically, VideoCAD is a large-scale synthetic dataset consisting of over 41K annotated video recordings of CAD operations, generated using an automated framework for collecting high-fidelity UI action data from human-made CAD designs. Compared to existing datasets, VideoCAD offers an order of magnitude higher complexity in UI interaction learning for real-world engineering tasks, having up to a 20x longer time horizon than other datasets. We show two important downstream applications of VideoCAD: learning UI interactions from professional precision 3D CAD tools and a visual question-answering (VQA) benchmark designed to evaluate multimodal large language models' (LLM) spatial reasoning and video understanding abilities. To learn the UI interactions, we propose VideoCADFormer - a state-of-the-art model in learning CAD interactions directly from video, which outperforms multiple behavior cloning baselines. Both VideoCADFormer and the VQA benchmark derived from VideoCAD reveal key challenges in the current state of video-based UI understanding, including the need for precise action grounding, multi-modal and spatial reasoning, and long-horizon dependencies.&quot;}, {'id': 'arxiv_2505.22914', 'title': 'cadrille: Multi-modal CAD Reconstruction with Online Reinforcement Learning', 'URL': 'http://arxiv.org/abs/2505.22914', 'extra_urls': ['http://arxiv.org/abs/2505.22914'], 'type': 'article', 'author': [{'family': 'Kolodiazhnyi', 'given': 'Maksim'}, {'family': 'Tarasov', 'given': 'Denis'}, {'family': 'Zhemchuzhnikov', 'given': 'Dmitrii'}, {'family': 'Nikulin', 'given': 'Alexander'}, {'family': 'Zisman', 'given': 'Ilya'}, {'family': 'Vorontsova', 'given': 'Anna'}, {'family': 'Konushin', 'given': 'Anton'}, {'family': 'Kurenkov', 'given': 'Vladislav'}, {'family': 'Rukhovich', 'given': 'Danila'}], 'publisher': 'arXiv', 'abstract': 'Computer-Aided Design (CAD) plays a central role in engineering and manufacturing, making it possible to create precise and editable 3D models. Using a variety of sensor or user-provided data as inputs for CAD reconstruction can democratize access to design applications. However, existing methods typically focus on a single input modality, such as point clouds, images, or text, which limits their generalizability and robustness. Leveraging recent advances in vision-language models (VLM), we propose a multi-modal CAD reconstruction model that simultaneously processes all three input modalities. Inspired by large language model (LLM) training paradigms, we adopt a two-stage pipeline: supervised fine-tuning (SFT) on large-scale procedurally generated data, followed by reinforcement learning (RL) fine-tuning using online feedback, obtained programatically. Furthermore, we are the first to explore RL fine-tuning of LLMs for CAD tasks demonstrating that online RL algorithms such as Group Relative Preference Optimization (GRPO) outperform offline alternatives. In the DeepCAD benchmark, our SFT model outperforms existing single-modal approaches in all three input modalities simultaneously. More importantly, after RL fine-tuning, cadrille sets new state-of-the-art on three challenging datasets, including a real-world one.'}, {'id': 'arxiv_2412.13810', 'title': 'CAD-Assistant: Tool-Augmented VLLMs as Generic CAD Task Solvers', 'URL': 'http://arxiv.org/abs/2412.13810', 'extra_urls': ['http://arxiv.org/abs/2412.13810'], 'type': 'article', 'author': [{'family': 'Mallis', 'given': 'Dimitrios'}, {'family': 'Karadeniz', 'given': 'Ahmet Serdar'}, {'family': 'Cavada', 'given': 'Sebastian'}, {'family': 'Rukhovich', 'given': 'Danila'}, {'family': 'Foteinopoulou', 'given': 'Niki'}, {'family': 'Cherenkova', 'given': 'Kseniya'}, {'family': 'Kacem', 'given': 'Anis'}, {'family': 'Aouada', 'given': 'Djamila'}], 'publisher': 'arXiv', 'abstract': 'We propose CAD-Assistant, a general-purpose CAD agent for AI-assisted design. Our approach is based on a powerful Vision and Large Language Model (VLLM) as a planner and a tool-augmentation paradigm using CAD-specific tools. CAD-Assistant addresses multimodal user queries by generating actions that are iteratively executed on a Python interpreter equipped with the FreeCAD software, accessed via its Python API. Our framework is able to assess the impact of generated CAD commands on geometry and adapts subsequent actions based on the evolving state of the CAD design. We consider a wide range of CAD-specific tools including a sketch image parameterizer, rendering modules, a 2D cross-section generator, and other specialized routines. CAD-Assistant is evaluated on multiple CAD benchmarks, where it outperforms VLLM baselines and supervised task-specific methods. Beyond existing benchmarks, we qualitatively demonstrate the potential of tool-augmented VLLMs as general-purpose CAD solvers across diverse workflows.'}, {'id': 'grounded_question', 'title': 'QueryCAD: Grounded Question Answering for CAD Models', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11128709', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11128709'], 'type': 'article', 'author': [{'family': 'Kienle', 'given': 'Claudius'}, {'family': 'Alt', 'given': 'Benjamin'}, {'family': 'Katic', 'given': 'Darko'}, {'family': 'J\xe4kel', 'given': 'Rainer'}, {'family': 'Peters', 'given': 'Jan'}], 'abstract': 'CAD models are widely used in industry and are essential for robotic automation processes. However, these models are rarely considered in novel AI-based approaches, such as the automatic synthesis of robot programs, as there are no readily available methods that would allow CAD models to be incorporated for the analysis, interpretation, or extraction of information. To address these limitations, we propose QueryCAD, the first system designed for CAD question answering, enabling the extraction of precise information from CAD models using natural language queries. QueryCAD incorporates SegCAD, an open-vocabulary instance segmentation model we developed to identify and select specific parts of the CAD model based on part descriptions. We further propose a CAD question answering benchmark to evaluate QueryCAD and establish a foundation for future research. Lastly, we integrate QueryCAD within an automatic robot program synthesis framework, validating its ability to enhance deep-learning solutions for robotics by enabling them to process CAD models. https://claudius-kienle.github.com/querycad.'}, {'id': 'arxiv_2503.19990', 'title': 'LEGO-Puzzles: How Good Are MLLMs at Multi-Step Spatial Reasoning?', 'URL': 'http://arxiv.org/abs/2503.19990', 'extra_urls': ['http://arxiv.org/abs/2503.19990'], 'type': 'article', 'author': [{'family': 'Tang', 'given': 'Kexian'}, {'family': 'Gao', 'given': 'Junyao'}, {'family': 'Zeng', 'given': 'Yanhong'}, {'family': 'Duan', 'given': 'Haodong'}, {'family': 'Sun', 'given': 'Yanan'}, {'family': 'Xing', 'given': 'Zhening'}, {'family': 'Liu', 'given': 'Wenran'}, {'family': 'Lyu', 'given': 'Kaifeng'}, {'family': 'Chen', 'given': 'Kai'}], 'publisher': 'arXiv', 'abstract': &quot;Multi-step spatial reasoning entails understanding and reasoning about spatial relationships across multiple sequential steps, which is crucial for tackling complex real-world applications, such as robotic manipulation, autonomous navigation, and automated assembly. To assess how well current Multimodal Large Language Models (MLLMs) have acquired this fundamental capability, we introduce LEGO-Puzzles, a scalable benchmark designed to evaluate both spatial understanding and sequential reasoning in MLLMs through LEGO-based tasks. LEGO-Puzzles consists of 1,100 carefully curated visual question-answering (VQA) samples spanning 11 distinct tasks, ranging from basic spatial understanding to complex multi-step reasoning. Based on LEGO-Puzzles, we conduct a comprehensive evaluation of 20 state-of-the-art MLLMs and uncover significant limitations in their spatial reasoning capabilities: even the most powerful MLLMs can answer only about half of the test cases, whereas human participants achieve over 90% accuracy. Furthermore, based on LEGO-Puzzles, we design generation tasks to investigate whether MLLMs can transfer their spatial understanding and reasoning abilities to image generation. Our experiments show that only GPT-4o and Gemini-2.0-Flash exhibit a limited ability to follow these instructions, while other MLLMs either replicate the input image or generate completely irrelevant outputs. Overall, LEGO-Puzzles exposes critical deficiencies in existing MLLMs' spatial understanding and sequential reasoning capabilities, and underscores the need for further advancements in multimodal spatial reasoning.&quot;}, {'id': 'arxiv_2507.04293', 'title': 'AutoLayout: Closed-Loop Layout Synthesis via Slow-Fast Collaborative Reasoning', 'URL': 'http://arxiv.org/abs/2507.04293', 'extra_urls': ['http://arxiv.org/abs/2507.04293'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Weixing'}, {'family': 'Chi', 'given': 'Dafeng'}, {'family': 'Liu', 'given': 'Yang'}, {'family': 'Yang', 'given': 'Yuxi'}, {'family': 'Zhang', 'given': 'Yexin'}, {'family': 'Zhuang', 'given': 'Yuzheng'}, {'family': 'Quan', 'given': 'Xingyue'}, {'family': 'Hao', 'given': 'Jianye'}, {'family': 'Li', 'given': 'Guanbin'}, {'family': 'Lin', 'given': 'Liang'}], 'publisher': 'arXiv', 'abstract': 'The automated generation of layouts is vital for embodied intelligence and autonomous systems, supporting applications from virtual environment construction to home robot deployment. Current approaches, however, suffer from spatial hallucination and struggle with balancing semantic fidelity and physical plausibility, often producing layouts with deficits such as floating or overlapping objects and misaligned stacking relation. In this paper, we propose AutoLayout, a fully automated method that integrates a closed-loop self-validation process within a dual-system framework. Specifically, a slow system harnesses detailed reasoning with a Reasoning-Reflection-Generation (RRG) pipeline to extract object attributes and spatial constraints. Then, a fast system generates discrete coordinate sets and a topological relation set that are jointly validated. To mitigate the limitations of handcrafted rules, we further introduce an LLM-based Adaptive Relation Library (ARL) for generating and evaluating layouts. Through the implementation of Slow-Fast Collaborative Reasoning, the AutoLayout efficiently generates layouts after thorough deliberation, effectively mitigating spatial hallucination. Its self-validation mechanism establishes a closed-loop process that iteratively corrects potential errors, achieving a balance between physical stability and semantic consistency. The effectiveness of AutoLayout was validated across 8 distinct scenarios, where it demonstrated a significant 10.1% improvement over SOTA methods in terms of physical plausibility, semantic consistency, and functional completeness.'}, {'id': 'arxiv_2505.19713', 'title': 'CAD-Coder: Text-to-CAD Generation with Chain-of-Thought and Geometric Reward', 'URL': 'http://arxiv.org/abs/2505.19713', 'extra_urls': ['http://arxiv.org/abs/2505.19713'], 'type': 'article', 'author': [{'family': 'Guan', 'given': 'Yandong'}, {'family': 'Wang', 'given': 'Xilin'}, {'family': 'Ming', 'given': 'Xingxi'}, {'family': 'Zhang', 'given': 'Jing'}, {'family': 'Xu', 'given': 'Dong'}, {'family': 'Yu', 'given': 'Qian'}], 'publisher': 'arXiv', 'abstract': 'In this work, we introduce CAD-Coder, a novel framework that reformulates text-to-CAD as the generation of CadQuery scripts - a Python-based, parametric CAD language. This representation enables direct geometric validation, a richer modeling vocabulary, and seamless integration with existing LLMs. To further enhance code validity and geometric fidelity, we propose a two-stage learning pipeline: (1) supervised fine-tuning on paired text-CadQuery data, and (2) reinforcement learning with Group Reward Policy Optimization (GRPO), guided by a CAD-specific reward comprising both a geometric reward (Chamfer Distance) and a format reward. We also introduce a chain-of-thought (CoT) planning process to improve model reasoning, and construct a large-scale, high-quality dataset of 110K text-CadQuery-3D model triplets and 1.5K CoT samples via an automated pipeline. Extensive experiments demonstrate that CAD-Coder enables LLMs to generate diverse, valid, and complex CAD models directly from natural language, advancing the state of the art of text-to-CAD generation and geometric reasoning.'}, {'id': 'material_transfer', 'title': 'MTScan: Material Transfer from\xa0Partial Scans to\xa0CAD Models', 'URL': 'urn:isbn:978-981-96-5812-1', 'type': 'article', 'author': [{'family': 'Su', 'given': 'Xiangyu'}, {'family': 'Peng', 'given': 'Sida'}, {'family': 'van Kaick', 'given': 'Oliver'}, {'family': 'Huang', 'given': 'Hui'}, {'family': 'Hu', 'given': 'Ruizhen'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Springer Nature', 'abstract': 'We introduce a method for transferring material information from a partial scan to a CAD model by establishing a dense correspondence between the scan and the CAD model. Our method is enabled by a pipeline composed of a material decomposition network, a geometry mapping network, and material completion networks. Specifically, given a single RGB-D source image and a target CAD model aligned to the scan, we employ a material decomposition network to extract material and illumination parameters from the image. Next, we sample point clouds from the image and CAD model, and establish a dense correspondence between the two point clouds with a geometry mapping network, which maps the point clouds to a shared template space where correspondences can be derived from closest points and aligned UV maps can be obtained. Finally, based on the established correspondence, we transfer the decomposed material information from the source to the target, and further perform material completion via diffusion on the point clouds and in the UV space. We demonstrate with qualitative and quantitative evaluations that our method is able to obtain more accurate material transfers than previous work in challenging input cases with imperfect shape alignment, so that the shapes with transferred materials better resemble the scanned shapes.'}, {'id': 'generating', 'title': 'CADCrafter: Generating Computer-Aided Design Models from Unconstrained Images', 'URL': 'https://openaccess.thecvf.com/content/CVPR2025/html/Chen_CADCrafter_Generating_Computer-Aided_Design_Models_from_Unconstrained_Images_CVPR_2025_paper.html', 'extra_urls': ['https://openaccess.thecvf.com/content/CVPR2025/html/Chen_CADCrafter_Generating_Computer-Aided_Design_Models_from_Unconstrained_Images_CVPR_2025_paper.html'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Cheng'}, {'family': 'Wei', 'given': 'Jiacheng'}, {'family': 'Chen', 'given': 'Tianrun'}, {'family': 'Zhang', 'given': 'Chi'}, {'family': 'Yang', 'given': 'Xiaofeng'}, {'family': 'Zhang', 'given': 'Shangzhan'}, {'family': 'Yang', 'given': 'Bingchen'}, {'family': 'Foo', 'given': 'Chuan-Sheng'}, {'family': 'Lin', 'given': 'Guosheng'}, {'family': 'Huang', 'given': 'Qixing'}, {'family': 'Liu', 'given': 'Fayao'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'arxiv_2508.10118', 'title': 'From Intent to Execution: Multimodal Chain-of-Thought Reinforcement Learning for Precise CAD Code Generation', 'URL': 'http://arxiv.org/abs/2508.10118', 'extra_urls': ['http://arxiv.org/abs/2508.10118'], 'type': 'article', 'author': [{'family': 'Niu', 'given': 'Ke'}, {'family': 'Yu', 'given': 'Haiyang'}, {'family': 'Chen', 'given': 'Zhuofan'}, {'family': 'Zhao', 'given': 'Mengyang'}, {'family': 'Fu', 'given': 'Teng'}, {'family': 'Li', 'given': 'Bin'}, {'family': 'Xue', 'given': 'Xiangyang'}], 'publisher': 'arXiv', 'abstract': 'Computer-Aided Design (CAD) plays a vital role in engineering and manufacturing, yet current CAD workflows require extensive domain expertise and manual modeling effort. Recent advances in large language models (LLMs) have made it possible to generate code from natural language, opening new opportunities for automating parametric 3D modeling. However, directly translating human design intent into executable CAD code remains highly challenging, due to the need for logical reasoning, syntactic correctness, and numerical precision. In this work, we propose CAD-RL, a multimodal Chain-of-Thought (CoT) guided reinforcement learning post training framework for CAD modeling code generation. Our method combines CoT-based Cold Start with goal-driven reinforcement learning post training using three task-specific rewards: executability reward, geometric accuracy reward, and external evaluation reward. To ensure stable policy learning under sparse and high-variance reward conditions, we introduce three targeted optimization strategies: Trust Region Stretch for improved exploration, Precision Token Loss for enhanced dimensions parameter accuracy, and Overlong Filtering to reduce noisy supervision. To support training and benchmarking, we release ExeCAD, a noval dataset comprising 16,540 real-world CAD examples with paired natural language and structured design language descriptions, executable CADQuery scripts, and rendered 3D models. Experiments demonstrate that CAD-RL achieves significant improvements in reasoning quality, output precision, and code executability over existing VLMs.'}, {'id': 'arxiv_2505.14646', 'title': 'CAD-Coder: An Open-Source Vision-Language Model for Computer-Aided Design Code Generation', 'URL': 'http://arxiv.org/abs/2505.14646', 'extra_urls': ['http://arxiv.org/abs/2505.14646'], 'type': 'article', 'author': [{'family': 'Doris', 'given': 'Anna C.'}, {'family': 'Alam', 'given': 'Md Ferdous'}, {'family': 'Nobari', 'given': 'Amin Heyrani'}, {'family': 'Ahmed', 'given': 'Faez'}], 'publisher': 'arXiv', 'abstract': 'Efficient creation of accurate and editable 3D CAD models is critical in engineering design, significantly impacting cost and time-to-market in product innovation. Current manual workflows remain highly time-consuming and demand extensive user expertise. While recent developments in AI-driven CAD generation show promise, existing models are limited by incomplete representations of CAD operations, inability to generalize to real-world images, and low output accuracy. This paper introduces CAD-Coder, an open-source Vision-Language Model (VLM) explicitly fine-tuned to generate editable CAD code (CadQuery Python) directly from visual input. Leveraging a novel dataset that we created--GenCAD-Code, consisting of over 163k CAD-model image and code pairs--CAD-Coder outperforms state-of-the-art VLM baselines such as GPT-4.5 and Qwen2.5-VL-72B, achieving a 100% valid syntax rate and the highest accuracy in 3D solid similarity. Notably, our VLM demonstrates some signs of generalizability, successfully generating CAD code from real-world images and executing CAD operations unseen during fine-tuning. The performance and adaptability of CAD-Coder highlights the potential of VLMs fine-tuned on code to streamline CAD workflows for engineers and designers. CAD-Coder is publicly available at: https://github.com/anniedoris/CAD-Coder.'}, {'id': 'learning', 'title': 'Stitch-A-Shape: Bottom-up Learning for B-Rep Generation', 'URL': 'https://dl.acm.org/doi/10.1145/3721238.3730661', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3721238.3730661'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Pu'}, {'family': 'Zhang', 'given': 'Wenhao'}, {'family': 'Chen', 'given': 'Jinglu'}, {'family': 'Yan', 'given': 'Dongming'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Boundary representation (B-Rep) models serve as the primary representation format in modern CAD systems for describing 3D shapes. While deep learning has achieved success with various geometric representations, B-Reps remain challenging due to their hybrid nature of combining continuous geometry with discrete topological relationships. In this paper, we present Stitch-A-Shape, a B-Rep generation framework that directly models both topology and geometry. This strategy departs from prior work that focuses on either topology or geometry while recovering the other through post-processing. Our method consists of a geometry module that determines the spatial configuration of geometric elements (vertices, curves, and surface control points) and a topology module that establishes connectivity relationships and identifies boundary structures, including outer and inner loops. Our approach leverages a sequential &quot;stitching&quot; representation that mirrors the native data structure and inherent bottom-up organization of B-Rep, assembling geometric entities from vertices through curves to faces. We validate that our framework can handle topological and geometric ambiguities, as well as open surfaces and compound solids. Experiments show that Stitch-A-Shape achieves superior generation quality and computational efficiency compared to existing approaches in unconditional generation tasks, while exhibiting effective capabilities in class-conditional generation and B-Rep autocompletion applications.'}, {'id': 'arxiv_2504.04000', 'title': 'View2CAD: Reconstructing View-Centric CAD Models from Single RGB-D Scans', 'URL': 'http://arxiv.org/abs/2504.04000', 'extra_urls': ['http://arxiv.org/abs/2504.04000'], 'type': 'article', 'author': [{'family': 'Noeckel', 'given': 'James'}, {'family': 'Jones', 'given': 'Benjamin'}, {'family': 'Schulz', 'given': 'Adriana'}, {'family': 'Curless', 'given': 'Brian'}], 'publisher': 'arXiv', 'abstract': 'Parametric CAD models, represented as Boundary Representations (B-reps), are foundational to modern design and manufacturing workflows, offering the precision and topological breakdown required for downstream tasks such as analysis, editing, and fabrication. However, B-Reps are often inaccessible due to conversion to more standardized, less expressive geometry formats. Existing methods to recover B-Reps from measured data require complete, noise-free 3D data, which are laborious to obtain. We alleviate this difficulty by enabling the precise reconstruction of CAD shapes from a single RGB-D image. We propose a method that addresses the challenge of reconstructing only the observed geometry from a single view. To allow for these partial observations, and to avoid hallucinating incorrect geometry, we introduce a novel view-centric B-rep (VB-Rep) representation, which incorporates structures to handle visibility limits and encode geometric uncertainty. We combine panoptic image segmentation with iterative geometric optimization to refine and improve the reconstruction process. Our results demonstrate high-quality reconstruction on synthetic and real RGB-D data, showing that our method can bridge the reality gap.'}, {'id': 'arxiv_2505.06507', 'title': 'Text-to-CadQuery: A New Paradigm for CAD Generation with Scalable Large Model Capabilities', 'URL': 'http://arxiv.org/abs/2505.06507', 'extra_urls': ['http://arxiv.org/abs/2505.06507'], 'type': 'article', 'author': [{'family': 'Xie', 'given': 'Haoyang'}, {'family': 'Ju', 'given': 'Feng'}], 'publisher': 'arXiv', 'abstract': 'Computer-aided design (CAD) is fundamental to modern engineering and manufacturing, but creating CAD models still requires expert knowledge and specialized software. Recent advances in large language models (LLMs) open up the possibility of generative CAD, where natural language is directly translated into parametric 3D models. However, most existing methods generate task-specific command sequences that pretrained models cannot directly handle. These sequences must be converted into CAD representations such as CAD vectors before a 3D model can be produced, which requires training models from scratch and adds unnecessary complexity. To tackle this issue, we propose generating CadQuery code directly from text, leveraging the strengths of pretrained LLMs to produce 3D models without intermediate representations, using this Python-based scripting language. Since LLMs already excel at Python generation and spatial reasoning, fine-tuning them on Text-to-CadQuery data proves highly effective. Given that these capabilities typically improve with scale, we hypothesize that larger models will perform better after fine-tuning. To enable this, we augment the Text2CAD dataset with 170,000 CadQuery annotations. We fine-tune six open-source LLMs of varying sizes and observe consistent improvements. Our best model achieves a top-1 exact match of 69.3%, up from 58.8%, and reduces Chamfer Distance by 48.6%. Project page: https://github.com/Text-to-CadQuery/Text-to-CadQuery.'}, {'id': 'from_cad_data', 'title': 'From CAD Data to Semantic Graphs: A Framework for Classification', 'URL': 'https://www.computer.org/csdl/proceedings-article/icsc/2025/242600a144/27FQH13dPMI', 'type': 'article', 'author': [{'family': 'Taba', 'given': 'Robin'}, {'family': 'Schonlau', 'given': 'Anna Liza'}, {'family': 'Falkenhain', 'given': 'Joshua'}, {'family': 'Maas', 'given': 'Patrick'}, {'family': 'Koster', 'given': 'Frank'}], 'publisher': 'IEEE Computer Society', 'abstract': 'The growing complexity of digital assemblies presents significant challenges, particularly in understanding their characteristics and interdependencies. Traditional approaches, which focus largely on geometric properties, fall short in capturing the functional dependencies between components. This research introduces a novel approach using semantic enrichment of CAD components and Graph Neural Networks (GNNs) to classify mechanical parts and analyze their interconnections. By leveraging open-source gearbox designs which are based on native CAD data in addition to STEP data, the methodology showcases the ability of graph-based structures to account for both geometric and functional relationships, providing a more comprehensive digital understanding of assemblies.'}, {'id': 'arxiv_2411.10848', 'title': 'NeuroNURBS: Learning Efficient Surface Representations for 3D Solids', 'URL': 'http://arxiv.org/abs/2411.10848', 'extra_urls': ['http://arxiv.org/abs/2411.10848'], 'type': 'article', 'author': [{'family': 'Fan', 'given': 'Jiajie'}, {'family': 'Gholami', 'given': 'Babak'}, {'family': 'B\xe4ck', 'given': 'Thomas'}, {'family': 'Wang', 'given': 'Hao'}], 'publisher': 'arXiv', 'abstract': 'Boundary Representation (B-Rep) is the de facto representation of 3D solids in Computer-Aided Design (CAD). B-Rep solids are defined with a set of NURBS (Non-Uniform Rational B-Splines) surfaces forming a closed volume. To represent a surface, current works often employ the UV-grid approximation, i.e., sample points uniformly on the surface. However, the UV-grid method is not efficient in surface representation and sometimes lacks precision and regularity. In this work, we propose NeuroNURBS, a representation learning method to directly encode the parameters of NURBS surfaces. Our evaluation in solid generation and segmentation tasks indicates that the NeuroNURBS performs comparably and, in some cases, superior to UV-grids, but with a significantly improved efficiency: for training the surface autoencoder, GPU consumption is reduced by 86.7%; memory requirement drops by 79.9% for storing 3D solids. Moreover, adapting BrepGen for solid generation with our NeuroNURBS improves the FID from 30.04 to 27.24, and resolves the undulating issue in generated surfaces.'}, {'id': 'cad_object', 'title': 'CADDreamer: CAD Object Generation from Single-view Images', 'URL': 'https://openaccess.thecvf.com/content/CVPR2025/html/Li_CADDreamer_CAD_Object_Generation_from_Single-view_Images_CVPR_2025_paper.html', 'extra_urls': ['https://openaccess.thecvf.com/content/CVPR2025/html/Li_CADDreamer_CAD_Object_Generation_from_Single-view_Images_CVPR_2025_paper.html'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Yuan'}, {'family': 'Lin', 'given': 'Cheng'}, {'family': 'Liu', 'given': 'Yuan'}, {'family': 'Long', 'given': 'Xiaoxiao'}, {'family': 'Zhang', 'given': 'Chenxu'}, {'family': 'Wang', 'given': 'Ningna'}, {'family': 'Li', 'given': 'Xin'}, {'family': 'Wang', 'given': 'Wenping'}, {'family': 'Guo', 'given': 'Xiaohu'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'arxiv_2508.08821', 'title': '3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs', 'URL': 'http://arxiv.org/abs/2508.08821', 'extra_urls': ['http://arxiv.org/abs/2508.08821'], 'type': 'article', 'author': [{'family': 'Ahmed', 'given': 'Noor'}, {'family': 'Braunstein', 'given': 'Cameron'}, {'family': 'Eger', 'given': 'Steffen'}, {'family': 'Ilg', 'given': 'Eddy'}], 'publisher': 'arXiv', 'abstract': 'Recent Multi-Modal Large Language Models (MLLMs) have demonstrated strong capabilities in learning joint representations from text and images. However, their spatial reasoning remains limited. We introduce 3DFroMLLM, a novel framework that enables the generation of 3D object prototypes directly from MLLMs, including geometry and part labels. Our pipeline is agentic, comprising a designer, coder, and visual inspector operating in a refinement loop. Notably, our approach requires no additional training data or detailed user instructions. Building on prior work in 2D generation, we demonstrate that rendered images produced by our framework can be effectively used for image classification pretraining tasks and outperforms previous methods by 15%. As a compelling real-world use case, we show that the generated prototypes can be leveraged to improve fine-grained vision-language models by using the rendered, part-labeled prototypes to fine-tune CLIP for part segmentation and achieving a 55% accuracy improvement without relying on any additional human-labeled data.'}, {'id': 'arxiv_2505.19490', 'title': 'Automated CAD Modeling Sequence Generation from Text Descriptions via Transformer-Based Large Language Models', 'URL': 'http://arxiv.org/abs/2505.19490', 'extra_urls': ['http://arxiv.org/abs/2505.19490'], 'type': 'article', 'author': [{'family': 'Liao', 'given': 'Jianxing'}, {'family': 'Xu', 'given': 'Junyan'}, {'family': 'Sun', 'given': 'Yatao'}, {'family': 'Tang', 'given': 'Maowen'}, {'family': 'He', 'given': 'Sicheng'}, {'family': 'Liao', 'given': 'Jingxian'}, {'family': 'Yu', 'given': 'Shui'}, {'family': 'Li', 'given': 'Yun'}, {'family': 'Xiao', 'given': 'Hongguan'}], 'publisher': 'arXiv', 'abstract': 'Designing complex computer-aided design (CAD) models is often time-consuming due to challenges such as computational inefficiency and the difficulty of generating precise models. We propose a novel language-guided framework for industrial design automation to address these issues, integrating large language models (LLMs) with computer-automated design (CAutoD).Through this framework, CAD models are automatically generated from parameters and appearance descriptions, supporting the automation of design tasks during the detailed CAD design phase. Our approach introduces three key innovations: (1) a semi-automated data annotation pipeline that leverages LLMs and vision-language large models (VLLMs) to generate high-quality parameters and appearance descriptions; (2) a Transformer-based CAD generator (TCADGen) that predicts modeling sequences via dual-channel feature aggregation; (3) an enhanced CAD modeling generation model, called CADLLM, that is designed to refine the generated sequences by incorporating the confidence scores from TCADGen. Experimental results demonstrate that the proposed approach outperforms traditional methods in both accuracy and efficiency, providing a powerful tool for automating industrial workflows and generating complex CAD models from textual prompts. The code is available at https://jianxliao.github.io/cadllm-page/'}, {'id': 'arxiv_2506.10337', 'title': 'GeoCAD: Local Geometry-Controllable CAD Generation', 'URL': 'http://arxiv.org/abs/2506.10337', 'extra_urls': ['http://arxiv.org/abs/2506.10337'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Zhanwei'}, {'family': 'Liu', 'given': 'Kaiyuan'}, {'family': 'Liu', 'given': 'Junjie'}, {'family': 'Wang', 'given': 'Wenxiao'}, {'family': 'Lin', 'given': 'Binbin'}, {'family': 'Xie', 'given': 'Liang'}, {'family': 'Shen', 'given': 'Chen'}, {'family': 'Cai', 'given': 'Deng'}], 'publisher': 'arXiv', 'abstract': 'Local geometry-controllable computer-aided design (CAD) generation aims to modify local parts of CAD models automatically, enhancing design efficiency. It also ensures that the shapes of newly generated local parts follow user-specific geometric instructions (e.g., an isosceles right triangle or a rectangle with one corner cut off). However, existing methods encounter challenges in achieving this goal. Specifically, they either lack the ability to follow textual instructions or are unable to focus on the local parts. To address this limitation, we introduce GeoCAD, a user-friendly and local geometry-controllable CAD generation method. Specifically, we first propose a complementary captioning strategy to generate geometric instructions for local parts. This strategy involves vertex-based and VLLM-based captioning for systematically annotating simple and complex parts, respectively. In this way, we caption $\\sim$221k different local parts in total. In the training stage, given a CAD model, we randomly mask a local part. Then, using its geometric instruction and the remaining parts as input, we prompt large language models (LLMs) to predict the masked part. During inference, users can specify any local part for modification while adhering to a variety of predefined geometric instructions. Extensive experiments demonstrate the effectiveness of GeoCAD in generation quality, validity and text-to-CAD consistency. Code will be available at https://github.com/Zhanwei-Z/GeoCAD.'}, {'id': 'arxiv_2506.00568', 'title': 'CReFT-CAD: Boosting Orthographic Projection Reasoning for CAD via Reinforcement Fine-Tuning', 'URL': 'http://arxiv.org/abs/2506.00568', 'extra_urls': ['http://arxiv.org/abs/2506.00568'], 'type': 'article', 'author': [{'family': 'Niu', 'given': 'Ke'}, {'family': 'Chen', 'given': 'Zhuofan'}, {'family': 'Yu', 'given': 'Haiyang'}, {'family': 'Chen', 'given': 'Yuwen'}, {'family': 'Fu', 'given': 'Teng'}, {'family': 'Zhao', 'given': 'Mengyang'}, {'family': 'Li', 'given': 'Bin'}, {'family': 'Xue', 'given': 'Xiangyang'}], 'publisher': 'arXiv', 'abstract': 'Computer-Aided Design (CAD) plays a pivotal role in industrial manufacturing. Orthographic projection reasoning underpins the entire CAD workflow, encompassing design, manufacturing, and simulation. However, prevailing deep-learning approaches employ standard 3D reconstruction pipelines as an alternative, which often introduce imprecise dimensions and limit the parametric editability required for CAD workflows. Recently, some researchers adopt vision-language models (VLMs), particularly supervised fine-tuning (SFT), to tackle CAD-related challenges. SFT shows promise but often devolves into pattern memorization, yielding poor out-of-distribution performance on complex reasoning tasks. To address these gaps, we introduce CReFT-CAD, a two-stage fine-tuning paradigm that first employs a curriculum-driven reinforcement learning stage with difficulty-aware rewards to build reasoning ability steadily, and then applies supervised post-tuning to hone instruction following and semantic extraction. Complementing this, we release TriView2CAD, the first large-scale, open-source benchmark for orthographic projection reasoning, comprising 200,000 synthetic and 3,000 real-world orthographic projections with precise dimension annotations and six interoperable data modalities. We benchmark leading VLMs on orthographic projection reasoning and demonstrate that CReFT-CAD substantially improves reasoning accuracy and out-of-distribution generalizability in real-world scenarios, offering valuable insights for advancing CAD reasoning research.'}, {'id': 'arxiv_2503.06796', 'title': 'RoboDesign1M: A Large-scale Dataset for Robot Design Understanding', 'URL': 'http://arxiv.org/abs/2503.06796', 'extra_urls': ['http://arxiv.org/abs/2503.06796'], 'type': 'article', 'author': [{'family': 'Le', 'given': 'Tri'}, {'family': 'Nguyen', 'given': 'Toan'}, {'family': 'Tran', 'given': 'Quang'}, {'family': 'Nguyen', 'given': 'Quang'}, {'family': 'Huang', 'given': 'Baoru'}, {'family': 'Nguyen', 'given': 'Hoan'}, {'family': 'Vu', 'given': 'Minh Nhat'}, {'family': 'Ta', 'given': 'Tung D.'}, {'family': 'Nguyen', 'given': 'Anh'}], 'publisher': 'arXiv', 'abstract': 'Robot design is a complex and time-consuming process that requires specialized expertise. Gaining a deeper understanding of robot design data can enable various applications, including automated design generation, retrieving example designs from text, and developing AI-powered design assistants. While recent advancements in foundation models present promising approaches to addressing these challenges, progress in this field is hindered by the lack of large-scale design datasets. In this paper, we introduce RoboDesign1M, a large-scale dataset comprising 1 million samples. Our dataset features multimodal data collected from scientific literature, covering various robotics domains. We propose a semi-automated data collection pipeline, enabling efficient and diverse data acquisition. To assess the effectiveness of RoboDesign1M, we conduct extensive experiments across multiple tasks, including design image generation, visual question answering about designs, and design image retrieval. The results demonstrate that our dataset serves as a challenging new benchmark for design understanding tasks and has the potential to advance research in this field. RoboDesign1M will be released to support further developments in AI-driven robotic design automation.'}, {'id': 'arxiv_2508.17645', 'title': 'Generating Human-AI Collaborative Design Sequence for 3D Assets via Differentiable Operation Graph', 'URL': 'http://arxiv.org/abs/2508.17645', 'extra_urls': ['http://arxiv.org/abs/2508.17645'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Xiaoyang'}, {'family': 'Ni', 'given': 'Bingbing'}, {'family': 'Zhang', 'given': 'Wenjun'}], 'publisher': 'arXiv', 'abstract': &quot;The emergence of 3D artificial intelligence-generated content (3D-AIGC) has enabled rapid synthesis of intricate geometries. However, a fundamental disconnect persists between AI-generated content and human-centric design paradigms, rooted in representational incompatibilities: conventional AI frameworks predominantly manipulate meshes or neural representations (\\emph{e.g.}, NeRF, Gaussian Splatting), while designers operate within parametric modeling tools. This disconnection diminishes the practical value of AI for 3D industry, undermining the efficiency of human-AI collaboration. To resolve this disparity, we focus on generating design operation sequences, which are structured modeling histories that comprehensively capture the step-by-step construction process of 3D assets and align with designers' typical workflows in modern 3D software. We first reformulate fundamental modeling operations (\\emph{e.g.}, \\emph{Extrude}, \\emph{Boolean}) into differentiable units, enabling joint optimization of continuous (\\emph{e.g.}, \\emph{Extrude} height) and discrete (\\emph{e.g.}, \\emph{Boolean} type) parameters via gradient-based learning. Based on these differentiable operations, a hierarchical graph with gating mechanism is constructed and optimized end-to-end by minimizing Chamfer Distance to target geometries. Multi-stage sequence length constraint and domain rule penalties enable unsupervised learning of compact design sequences without ground-truth sequence supervision. Extensive validation demonstrates that the generated operation sequences achieve high geometric fidelity, smooth mesh wiring, rational step composition and flexible editing capacity, with full compatibility within design industry.&quot;}, {'id': 'arxiv_2508.10201', 'title': 'B-repLer: Semantic B-rep Latent Editor using Large Language Models', 'URL': 'http://arxiv.org/abs/2508.10201', 'extra_urls': ['http://arxiv.org/abs/2508.10201'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Yilin'}, {'family': 'Dutt', 'given': 'Niladri Shekhar'}, {'family': 'Li', 'given': 'Changjian'}, {'family': 'Mitra', 'given': 'Niloy J.'}], 'publisher': 'arXiv', 'abstract': &quot;Multimodal large language models (mLLMs), trained in a mixed modal setting as a universal model, have been shown to compete with or even outperform many specialized algorithms for imaging and graphics tasks. As demonstrated across many applications, mLLMs' ability to jointly process image and text data makes them suitable for zero-shot applications or efficient fine-tuning towards specialized tasks. However, they have had limited success in 3D analysis and editing tasks. This is due to both the lack of suitable (annotated) 3D data as well as the idiosyncrasies of 3D representations. In this paper, we investigate whether mLLMs can be adapted to support high-level editing of Boundary Representation (B-rep) CAD objects. B-reps remain the industry-standard for precisely encoding engineering objects, but are challenging as the representation is fragile (i.e. can easily lead to invalid CAD objects) and no publicly available data source exists with semantically-annotated B-reps or CAD construction history. We present B-repLer as a finetuned mLLM that can understand text prompts and make semantic edits on given B-Reps to produce valid outputs. We enable this via a novel multimodal architecture, specifically designed to handle B-rep models, and demonstrate how existing CAD tools, in conjunction with mLLMs, can be used to automatically generate the required reasoning dataset, without relying on external annotations. We extensively evaluate B-repLer and demonstrate several text-based B-rep edits of various complexity, which were not previously possible.&quot;}, {'id': 'arxiv_2507.09792', 'title': 'CADmium: Fine-Tuning Code Language Models for Text-Driven Sequential CAD Design', 'URL': 'http://arxiv.org/abs/2507.09792', 'extra_urls': ['http://arxiv.org/abs/2507.09792'], 'type': 'article', 'author': [{'family': 'Govindarajan', 'given': 'Prashant'}, {'family': 'Baldelli', 'given': 'Davide'}, {'family': 'Pathak', 'given': 'Jay'}, {'family': 'Fournier', 'given': 'Quentin'}, {'family': 'Chandar', 'given': 'Sarath'}], 'publisher': 'arXiv', 'abstract': 'Computer-aided design (CAD) is the digital construction of 2D and 3D objects, and is central to a wide range of engineering and manufacturing applications like automobile and aviation. Despite its importance, CAD modeling remains largely a time-intensive, manual task. Recent works have attempted to automate this process with small transformer-based models and handcrafted CAD sequence representations. However, there has been little effort to leverage the potential of large language models (LLMs) for sequential CAD design. In this work, we introduce a new large-scale dataset of more than 170k CAD models annotated with high-quality, human-like descriptions generated with our pipeline based on GPT-4.1. Using this dataset, we fine-tune powerful code-LLMs to generate CAD sequences represented in a JSON-based format from natural language descriptions, demonstrating the viability and effectiveness of this approach for text-conditioned CAD generation. Because simple metrics often fail to reflect the quality of generated objects, we introduce geometric and topological metrics based on sphericity, mean curvature, and Euler characteristic to provide richer structural insights. Our experiments and ablation studies on both synthetic and human-annotated data demonstrate that CADmium is able to automate CAD design, drastically speeding up the design of new objects. The dataset, code, and fine-tuned models are available online.'}, {'id': 'arxiv_2503.18549', 'title': 'RLCAD: Reinforcement Learning Training Gym for Revolution Involved CAD Command Sequence Generation', 'URL': 'http://arxiv.org/abs/2503.18549', 'extra_urls': ['http://arxiv.org/abs/2503.18549'], 'type': 'article', 'author': [{'family': 'Yin', 'given': 'Xiaolong'}, {'family': 'Lu', 'given': 'Xingyu'}, {'family': 'Shen', 'given': 'Jiahang'}, {'family': 'Ni', 'given': 'Jingzhe'}, {'family': 'Li', 'given': 'Hailong'}, {'family': 'Tong', 'given': 'Ruofeng'}, {'family': 'Tang', 'given': 'Min'}, {'family': 'Du', 'given': 'Peng'}], 'publisher': 'arXiv', 'abstract': 'A CAD command sequence is a typical parametric design paradigm in 3D CAD systems where a model is constructed by overlaying 2D sketches with operations such as extrusion, revolution, and Boolean operations. Although there is growing academic interest in the automatic generation of command sequences, existing methods and datasets only support operations such as 2D sketching, extrusion,and Boolean operations. This limitation makes it challenging to represent more complex geometries. In this paper, we present a reinforcement learning (RL) training environment (gym) built on a CAD geometric engine. Given an input boundary representation (B-Rep) geometry, the policy network in the RL algorithm generates an action. This action, along with previously generated actions, is processed within the gym to produce the corresponding CAD geometry, which is then fed back into the policy network. The rewards, determined by the difference between the generated and target geometries within the gym, are used to update the RL network. Our method supports operations beyond sketches, Boolean, and extrusion, including revolution operations. With this training gym, we achieve state-of-the-art (SOTA) quality in generating command sequences from B-Rep geometries.'}, {'id': 'arxiv_2509.11447', 'title': 'Large language model-empowered next-generation computer-aided engineering', 'URL': 'http://arxiv.org/abs/2509.11447', 'extra_urls': ['http://arxiv.org/abs/2509.11447'], 'type': 'article', 'author': [{'family': 'Guo', 'given': 'Jiachen'}, {'family': 'Park', 'given': 'Chanwook'}, {'family': 'Qian', 'given': 'Dong'}, {'family': 'Hughes', 'given': 'Thomas J. R.'}, {'family': 'Liu', 'given': 'Wing Kam'}], 'publisher': 'arXiv', 'abstract': 'Software development has entered a new era where large language models (LLMs) now serve as general-purpose reasoning engines, enabling natural language interaction and transformative applications across diverse domains. This paradigm is now extending into computer-aided engineering (CAE). Recent applications of LLMs in CAE have successfully automated routine tasks, including CAD model generation and FEM simulations. Nevertheless, these contributions, which primarily serve to reduce manual labor, are often insufficient for addressing the significant computational challenges posed by large-scale, high-dimensional systems. To this aim, we first introduce the concept of LLM-empowered CAE agent, where LLMs act as autonomous collaborators that plan, execute, and adapt CAE workflows. Then, we propose an LLM-empowered CAE agent for data-free model order reduction (MOR), a powerful yet underused approach for ultra-fast large-scale parametric analysis due to the intrusive nature and labor-intensive redevelopment of solvers. LLMs can alleviate this barrier by automating derivations, code restructuring, and implementation, making intrusive MOR both practical and broadly accessible. To demonstrate feasibility, we present an LLM-empowered CAE agent for solving ultra-large-scale space-parameter-time (S-P-T) physical problems using Tensor-decomposition-based A Priori Surrogates (TAPS). Our results show that natural language prompts describing parametric partial differential equations (PDEs) can be translated into efficient solver implementations, substantially reducing human effort while producing high-fidelity reduced-order models. Moreover, LLMs can synthesize novel MOR solvers for unseen cases such as nonlinear and high-dimensional parametric problems based on their internal knowledge base. This highlights the potential of LLMs to establish the foundation for next-generation CAE systems.'}, {'id': 'arxiv_2509.17283', 'title': 'Automated Facility Enumeration for Building Compliance Checking using Door Detection and Large Language Models', 'URL': 'http://arxiv.org/abs/2509.17283', 'extra_urls': ['http://arxiv.org/abs/2509.17283'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Licheng'}, {'family': 'Le', 'given': 'Bach'}, {'family': 'Akhtar', 'given': 'Naveed'}, {'family': 'Ngo', 'given': 'Tuan'}], 'publisher': 'arXiv', 'abstract': 'Building compliance checking (BCC) is a critical process for ensuring that constructed facilities meet regulatory standards. A core component of BCC is the accurate enumeration of facility types and their spatial distribution. Despite its importance, this problem has been largely overlooked in the literature, posing a significant challenge for BCC and leaving a critical gap in existing workflows. Performing this task manually is time-consuming and labor-intensive. Recent advances in large language models (LLMs) offer new opportunities to enhance automation by combining visual recognition with reasoning capabilities. In this paper, we introduce a new task for BCC: automated facility enumeration, which involves validating the quantity of each facility type against statutory requirements. To address it, we propose a novel method that integrates door detection with LLM-based reasoning. We are the first to apply LLMs to this task and further enhance their performance through a Chain-of-Thought (CoT) pipeline. Our approach generalizes well across diverse datasets and facility types. Experiments on both real-world and synthetic floor plan data demonstrate the effectiveness and robustness of our method.'}, {'id': 'an_approach', 'title': 'An Analytics-Driven Approach to Enhancing Supply Chain Visibility with   Graph Neural Networks and Federated Learning', 'URL': 'https://arxiv.org/html/2503.07231v1', 'extra_urls': ['https://arxiv.org/html/2503.07231v1'], 'type': 'article', 'author': [{'family': 'Zheng', 'given': 'Ge'}, {'family': 'Brintrup', 'given': 'Alexandra'}], 'publisher': 'arXiv', 'abstract': &quot;In today's globalised trade, supply chains form complex networks spanning\nmultiple organisations and even countries, making them highly vulnerable to\ndisruptions. These vulnerabilities, highlighted by recent global crises,\nunderscore the urgent need for improved visibility and resilience of the supply\nchain. However, data-sharing limitations often hinder the achievement of\ncomprehensive visibility between organisations or countries due to privacy,\nsecurity, and regulatory concerns. Moreover, most existing research studies\nfocused on individual firm- or product-level networks, overlooking the\nmultifaceted interactions among diverse entities that characterise real-world\nsupply chains, thus limiting a holistic understanding of supply chain dynamics.\nTo address these challenges, we propose a novel approach that integrates\nFederated Learning (FL) and Graph Convolutional Neural Networks (GCNs) to\nenhance supply chain visibility through relationship prediction in supply chain\nknowledge graphs. FL enables collaborative model training across countries by\nfacilitating information sharing without requiring raw data exchange, ensuring\ncompliance with privacy regulations and maintaining data security. GCNs empower\nthe framework to capture intricate relational patterns within knowledge graphs,\nenabling accurate link prediction to uncover hidden connections and provide\ncomprehensive insights into supply chain networks. Experimental results\nvalidate the effectiveness of the proposed approach, demonstrating its ability\nto accurately predict relationships within country-level supply chain knowledge\ngraphs. This enhanced visibility supports actionable insights, facilitates\nproactive risk management, and contributes to the development of resilient and\nadaptive supply chain strategies, ensuring that supply chains are better\nequipped to navigate the complexities of the global economy.&quot;}, {'id': 'arxiv_2505.11154', 'title': 'MPMA: Preference Manipulation Attack Against Model Context Protocol', 'URL': 'http://arxiv.org/abs/2505.11154', 'extra_urls': ['http://arxiv.org/abs/2505.11154'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Zihan'}, {'family': 'Li', 'given': 'Hongwei'}, {'family': 'Zhang', 'given': 'Rui'}, {'family': 'Liu', 'given': 'Yu'}, {'family': 'Jiang', 'given': 'Wenbo'}, {'family': 'Fan', 'given': 'Wenshu'}, {'family': 'Zhao', 'given': 'Qingchuan'}, {'family': 'Xu', 'given': 'Guowen'}], 'publisher': 'arXiv', 'abstract': 'Model Context Protocol (MCP) standardizes interface mapping for large language models (LLMs) to access external data and tools, which revolutionizes the paradigm of tool selection and facilitates the rapid expansion of the LLM agent tool ecosystem. However, as the MCP is increasingly adopted, third-party customized versions of the MCP server expose potential security vulnerabilities. In this paper, we first introduce a novel security threat, which we term the MCP Preference Manipulation Attack (MPMA). An attacker deploys a customized MCP server to manipulate LLMs, causing them to prioritize it over other competing MCP servers. This can result in economic benefits for attackers, such as revenue from paid MCP services or advertising income generated from free servers. To achieve MPMA, we first design a Direct Preference Manipulation Attack ($\\mathtt{DPMA}$) that achieves significant effectiveness by inserting the manipulative word and phrases into the tool name and description. However, such a direct modification is obvious to users and lacks stealthiness. To address these limitations, we further propose Genetic-based Advertising Preference Manipulation Attack ($\\mathtt{GAPMA}$). $\\mathtt{GAPMA}$ employs four commonly used strategies to initialize descriptions and integrates a Genetic Algorithm (GA) to enhance stealthiness. The experiment results demonstrate that $\\mathtt{GAPMA}$ balances high effectiveness and stealthiness. Our study reveals a critical vulnerability of the MCP in open ecosystems, highlighting an urgent need for robust defense mechanisms to ensure the fairness of the MCP ecosystem.'}, {'id': 'arxiv_2403.14442', 'title': 'RoDLA: Benchmarking the Robustness of Document Layout Analysis Models', 'URL': 'https://arxiv.org/abs/2403.14442', 'extra_urls': ['https://arxiv.org/abs/2403.14442'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Yufan'}, {'family': 'Zhang', 'given': 'Jiaming'}, {'family': 'Peng', 'given': 'Kunyu'}, {'family': 'Zheng', 'given': 'Junwei'}, {'family': 'Liu', 'given': 'Ruiping'}, {'family': 'Torr', 'given': 'Philip'}, {'family': 'Stiefelhagen', 'given': 'Rainer'}], 'publisher': 'arXiv', 'abstract': 'Before developing a Document Layout Analysis (DLA) model in real-world\napplications, conducting comprehensive robustness testing is essential.\nHowever, the robustness of DLA models remains underexplored in the literature.\nTo address this, we are the first to introduce a robustness benchmark for DLA\nmodels, which includes 450K document images of three datasets. To cover\nrealistic corruptions, we propose a perturbation taxonomy with 36 common\ndocument perturbations inspired by real-world document processing.\nAdditionally, to better understand document perturbation impacts, we propose\ntwo metrics, Mean Perturbation Effect (mPE) for perturbation assessment and\nMean Robustness Degradation (mRD) for robustness evaluation. Furthermore, we\nintroduce a self-titled model, i.e., Robust Document Layout Analyzer (RoDLA),\nwhich improves attention mechanisms to boost extraction of robust features.\nExperiments on the proposed benchmarks (PubLayNet-P, DocLayNet-P, and\nM$^6$Doc-P) demonstrate that RoDLA obtains state-of-the-art mRD scores of\n115.7, 135.4, and 150.4, respectively. Compared to previous methods, RoDLA\nachieves notable improvements in mAP of +3.8%, +7.1% and +12.1%, respectively.'}, {'id': 'arxiv_2505.10609', 'title': 'Agent Name Service (ANS): A Universal Directory for Secure AI Agent   Discovery and Interoperability', 'URL': 'https://arxiv.org/abs/2505.10609', 'extra_urls': ['https://arxiv.org/abs/2505.10609'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Ken'}, {'family': 'Narajala', 'given': 'Vineeth Sai'}, {'family': 'Habler', 'given': 'Idan'}, {'family': 'Sheriff', 'given': 'Akram'}], 'publisher': 'arXiv', 'abstract': 'The proliferation of AI agents requires robust mechanisms for secure\ndiscovery. This paper introduces the Agent Name Service (ANS), a novel\narchitecture based on DNS addressing the lack of a public agent discovery\nframework. ANS provides a protocol-agnostic registry infrastructure that\nleverages Public Key Infrastructure (PKI) certificates for verifiable agent\nidentity and trust. The architecture features several key innovations: a\nformalized agent registration and renewal mechanism for lifecycle management;\nDNS-inspired naming conventions with capability-aware resolution; a modular\nProtocol Adapter Layer supporting diverse communication standards (A2A, MCP,\nACP etc.); and precisely defined algorithms for secure resolution. We implement\nstructured communication using JSON Schema and conduct a comprehensive threat\nanalysis of our proposal. The result is a foundational directory service\naddressing the core challenges of secured discovery and interaction in\nmulti-agent systems, paving the way for future interoperable, trustworthy, and\nscalable agent ecosystems.'}, {'id': 'arxiv_2508.03858', 'title': 'MI9 -- Agent Intelligence Protocol: Runtime Governance for Agentic AI   Systems', 'URL': 'https://arxiv.org/abs/2508.03858', 'extra_urls': ['https://arxiv.org/abs/2508.03858'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Charles L.'}, {'family': 'Singhal', 'given': 'Trisha'}, {'family': 'Kelkar', 'given': 'Ameya'}, {'family': 'Tuo', 'given': 'Jason'}], 'publisher': 'arXiv', 'abstract': &quot;Agentic AI systems capable of reasoning, planning, and executing actions\npresent fundamentally distinct governance challenges compared to traditional AI\nmodels. Unlike conventional AI, these systems exhibit emergent and unexpected\nbehaviors during runtime, introducing novel agent-related risks that cannot be\nfully anticipated through pre-deployment governance alone. To address this\ncritical gap, we introduce MI9, the first fully integrated runtime governance\nframework designed specifically for safety and alignment of agentic AI systems.\nMI9 introduces real-time controls through six integrated components:\nagency-risk index, agent-semantic telemetry capture, continuous authorization\nmonitoring, Finite-State-Machine (FSM)-based conformance engines,\ngoal-conditioned drift detection, and graduated containment strategies.\nOperating transparently across heterogeneous agent architectures, MI9 enables\nthe systematic, safe, and responsible deployment of agentic systems in\nproduction environments where conventional governance approaches fall short,\nproviding the foundational infrastructure for safe agentic AI deployment at\nscale. Detailed analysis through a diverse set of scenarios demonstrates MI9's\nsystematic coverage of governance challenges that existing approaches fail to\naddress, establishing the technical foundation for comprehensive agentic AI\noversight.&quot;}, {'id': 'arxiv_2508.13220', 'title': 'MCPSecBench: A Systematic Security Benchmark and Playground for Testing   Model Context Protocols', 'URL': 'https://arxiv.org/abs/2508.13220', 'extra_urls': ['https://arxiv.org/abs/2508.13220'], 'type': 'article', 'author': [{'family': 'Yang', 'given': 'Yixuan'}, {'family': 'Wu', 'given': 'Daoyuan'}, {'family': 'Chen', 'given': 'Yufan'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) are increasingly integrated into real-world\napplications via the Model Context Protocol (MCP), a universal, open standard\nfor connecting AI agents with data sources and external tools. While MCP\nenhances the capabilities of LLM-based agents, it also introduces new security\nrisks and expands their attack surfaces. In this paper, we present the first\nsystematic taxonomy of MCP security, identifying 17 attack types across 4\nprimary attack surfaces. We introduce MCPSecBench, a comprehensive security\nbenchmark and playground that integrates prompt datasets, MCP servers, MCP\nclients, attack scripts, and protection mechanisms to evaluate these attacks\nacross three major MCP providers. Our benchmark is modular and extensible,\nallowing researchers to incorporate custom implementations of clients, servers,\nand transport protocols for systematic security assessment. Experimental\nresults show that over 85% of the identified attacks successfully compromise at\nleast one platform, with core vulnerabilities universally affecting Claude,\nOpenAI, and Cursor, while prompt-based and tool-centric attacks exhibit\nconsiderable variability across different hosts and models. In addition,\ncurrent protection mechanisms have little effect against these attacks.\nOverall, MCPSecBench standardizes the evaluation of MCP security and enables\nrigorous testing across all MCP layers.'}, {'id': 'arxiv_2508.12538', 'title': 'Systematic Analysis of MCP Security', 'URL': 'https://arxiv.org/abs/2508.12538', 'extra_urls': ['https://arxiv.org/abs/2508.12538'], 'type': 'article', 'author': [{'family': 'Guo', 'given': 'Yongjian'}, {'family': 'Liu', 'given': 'Puzhuo'}, {'family': 'Ma', 'given': 'Wanlun'}, {'family': 'Deng', 'given': 'Zehang'}, {'family': 'Zhu', 'given': 'Xiaogang'}, {'family': 'Di', 'given': 'Peng'}, {'family': 'Xiao', 'given': 'Xi'}, {'family': 'Wen', 'given': 'Sheng'}], 'publisher': 'arXiv', 'abstract': &quot;The Model Context Protocol (MCP) has emerged as a universal standard that\nenables AI agents to seamlessly connect with external tools, significantly\nenhancing their functionality. However, while MCP brings notable benefits, it\nalso introduces significant vulnerabilities, such as Tool Poisoning Attacks\n(TPA), where hidden malicious instructions exploit the sycophancy of large\nlanguage models (LLMs) to manipulate agent behavior. Despite these risks,\ncurrent academic research on MCP security remains limited, with most studies\nfocusing on narrow or qualitative analyses that fail to capture the diversity\nof real-world threats. To address this gap, we present the MCP Attack Library\n(MCPLIB), which categorizes and implements 31 distinct attack methods under\nfour key classifications: direct tool injection, indirect tool injection,\nmalicious user attacks, and LLM inherent attack. We further conduct a\nquantitative analysis of the efficacy of each attack. Our experiments reveal\nkey insights into MCP vulnerabilities, including agents' blind reliance on tool\ndescriptions, sensitivity to file-based attacks, chain attacks exploiting\nshared context, and difficulty distinguishing external data from executable\ncommands. These insights, validated through attack experiments, underscore the\nurgency for robust defense strategies and informed MCP design. Our\ncontributions include 1) constructing a comprehensive MCP attack taxonomy, 2)\nintroducing a unified attack framework MCPLIB, and 3) conducting empirical\nvulnerability analysis to enhance MCP security mechanisms. This work provides a\nfoundational framework, supporting the secure evolution of MCP ecosystems.&quot;}, {'id': 'arxiv_2506.13590', 'title': 'Agent Capability Negotiation and Binding Protocol (ACNBP)', 'URL': 'https://arxiv.org/abs/2506.13590', 'extra_urls': ['https://arxiv.org/abs/2506.13590'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Ken'}, {'family': 'Sheriff', 'given': 'Akram'}, {'family': 'Narajala', 'given': 'Vineeth Sai'}, {'family': 'Habler', 'given': 'Idan'}], 'publisher': 'arXiv', 'abstract': &quot;As multi-agent systems evolve to encompass increasingly diverse and\nspecialized agents, the challenge of enabling effective collaboration between\nheterogeneous agents has become paramount, with traditional agent communication\nprotocols often assuming homogeneous environments or predefined interaction\npatterns that limit their applicability in dynamic, open-world scenarios. This\npaper presents the Agent Capability Negotiation and Binding Protocol (ACNBP), a\nnovel framework designed to facilitate secure, efficient, and verifiable\ninteractions between agents in heterogeneous multi-agent systems through\nintegration with an Agent Name Service (ANS) infrastructure that provides\ncomprehensive discovery, negotiation, and binding mechanisms. The protocol\nintroduces a structured 10-step process encompassing capability discovery,\ncandidate pre-screening and selection, secure negotiation phases, and binding\ncommitment with built-in security measures including digital signatures,\ncapability attestation, and comprehensive threat mitigation strategies, while a\nkey innovation of ACNBP is its protocolExtension mechanism that enables\nbackward-compatible protocol evolution and supports diverse agent architectures\nwhile maintaining security and interoperability. We demonstrate ACNBP's\neffectiveness through a comprehensive security analysis using the MAESTRO\nthreat modeling framework, practical implementation considerations, and a\ndetailed example showcasing the protocol's application in a document\ntranslation scenario, with the protocol addressing critical challenges in agent\nautonomy, capability verification, secure communication, and scalable agent\necosystem management.&quot;}, {'id': 'arxiv_2210.03629', 'title': 'ReAct: Synergizing Reasoning and Acting in Language Models', 'URL': 'https://arxiv.org/abs/2210.03629', 'extra_urls': ['https://arxiv.org/abs/2210.03629'], 'type': 'article', 'author': [{'family': 'Yao', 'given': 'Shunyu'}, {'family': 'Zhao', 'given': 'Jeffrey'}, {'family': 'Yu', 'given': 'Dian'}, {'family': 'Du', 'given': 'Nan'}, {'family': 'Shafran', 'given': 'Izhak'}, {'family': 'Narasimhan', 'given': 'Karthik'}, {'family': 'Cao', 'given': 'Yuan'}], 'publisher': 'arXiv', 'abstract': 'While large language models (LLMs) have demonstrated impressive capabilities\nacross tasks in language understanding and interactive decision making, their\nabilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g.\naction plan generation) have primarily been studied as separate topics. In this\npaper, we explore the use of LLMs to generate both reasoning traces and\ntask-specific actions in an interleaved manner, allowing for greater synergy\nbetween the two: reasoning traces help the model induce, track, and update\naction plans as well as handle exceptions, while actions allow it to interface\nwith external sources, such as knowledge bases or environments, to gather\nadditional information. We apply our approach, named ReAct, to a diverse set of\nlanguage and decision making tasks and demonstrate its effectiveness over\nstate-of-the-art baselines, as well as improved human interpretability and\ntrustworthiness over methods without reasoning or acting components.\nConcretely, on question answering (HotpotQA) and fact verification (Fever),\nReAct overcomes issues of hallucination and error propagation prevalent in\nchain-of-thought reasoning by interacting with a simple Wikipedia API, and\ngenerates human-like task-solving trajectories that are more interpretable than\nbaselines without reasoning traces. On two interactive decision making\nbenchmarks (ALFWorld and WebShop), ReAct outperforms imitation and\nreinforcement learning methods by an absolute success rate of 34% and 10%\nrespectively, while being prompted with only one or two in-context examples.\nProject site with code: https://react-lm.github.io'}, {'id': 'arxiv_2504.16902', 'title': 'Building A Secure Agentic AI Application Leveraging A2A Protocol', 'URL': 'https://arxiv.org/abs/2504.16902', 'extra_urls': ['https://arxiv.org/abs/2504.16902'], 'type': 'article', 'author': [{'family': 'Habler', 'given': 'Idan'}, {'family': 'Huang', 'given': 'Ken'}, {'family': 'Narajala', 'given': 'Vineeth Sai'}, {'family': 'Kulkarni', 'given': 'Prashant'}], 'publisher': 'arXiv', 'abstract': &quot;As Agentic AI systems evolve from basic workflows to complex multi agent\ncollaboration, robust protocols such as Google's Agent2Agent (A2A) become\nessential enablers. To foster secure adoption and ensure the reliability of\nthese complex interactions, understanding the secure implementation of A2A is\nessential. This paper addresses this goal by providing a comprehensive security\nanalysis centered on the A2A protocol. We examine its fundamental elements and\noperational dynamics, situating it within the framework of agent communication\ndevelopment. Utilizing the MAESTRO framework, specifically designed for AI\nrisks, we apply proactive threat modeling to assess potential security issues\nin A2A deployments, focusing on aspects such as Agent Card management, task\nexecution integrity, and authentication methodologies.\n  Based on these insights, we recommend practical secure development\nmethodologies and architectural best practices designed to build resilient and\neffective A2A systems. Our analysis also explores how the synergy between A2A\nand the Model Context Protocol (MCP) can further enhance secure\ninteroperability. This paper equips developers and architects with the\nknowledge and practical guidance needed to confidently leverage the A2A\nprotocol for building robust and secure next generation agentic applications.&quot;}, {'id': 'arxiv_2507.06323', 'title': 'Bridging AI and Software Security: A Comparative Vulnerability   Assessment of LLM Agent Deployment Paradigms', 'URL': 'https://arxiv.org/abs/2507.06323', 'extra_urls': ['https://arxiv.org/abs/2507.06323'], 'type': 'article', 'author': [{'family': 'Gasmi', 'given': 'Tarek'}, {'family': 'Guesmi', 'given': 'Ramzi'}, {'family': 'Belhadj', 'given': 'Ines'}, {'family': 'Bennaceur', 'given': 'Jihene'}], 'publisher': 'arXiv', 'abstract': 'Large Language Model (LLM) agents face security vulnerabilities spanning\nAI-specific and traditional software domains, yet current research addresses\nthese separately. This study bridges this gap through comparative evaluation of\nFunction Calling architecture and Model Context Protocol (MCP) deployment\nparadigms using a unified threat classification framework. We tested 3,250\nattack scenarios across seven language models, evaluating simple, composed, and\nchained attacks targeting both AI-specific threats (prompt injection) and\nsoftware vulnerabilities (JSON injection, denial-of-service). Function Calling\nshowed higher overall attack success rates (73.5% vs 62.59% for MCP), with\ngreater system-centric vulnerability while MCP exhibited increased LLM-centric\nexposure. Attack complexity dramatically amplified effectiveness, with chained\nattacks achieving 91-96% success rates. Counterintuitively, advanced reasoning\nmodels demonstrated higher exploitability despite better threat detection.\nResults demonstrate that architectural choices fundamentally reshape threat\nlandscapes. This work establishes methodological foundations for cross-domain\nLLM agent security assessment and provides evidence-based guidance for secure\ndeployment. Code and experimental materials are available at https: // github.\ncom/ theconsciouslab-ai/llm-agent-security.'}, {'id': 'arxiv_2408.10434', 'title': 'Insights on Microservice Architecture Through the Eyes of Industry   Practitioners', 'URL': 'https://www.arxiv.org/abs/2408.10434', 'extra_urls': ['https://www.arxiv.org/abs/2408.10434'], 'type': 'article', 'author': [{'family': 'Nogueira', 'given': 'Vinicius L.'}, {'family': 'Felizardo', 'given': 'Fernando S.'}, {'family': 'Amaral', 'given': 'Aline M. M. M.'}, {'family': 'Assuncao', 'given': 'Wesley K. G.'}, {'family': 'Colanzi', 'given': 'Thelma E.'}], 'publisher': 'arXiv', 'abstract': &quot;The adoption of microservice architecture has seen a considerable upswing in\nrecent years, mainly driven by the need to modernize legacy systems and address\ntheir limitations. Legacy systems, typically designed as monolithic\napplications, often struggle with maintenance, scalability, and deployment\ninefficiencies. This study investigates the motivations, activities, and\nchallenges associated with migrating from monolithic legacy systems to\nmicroservices, aiming to shed light on common practices and challenges from a\npractitioner's point of view. We conducted a comprehensive study with 53\nsoftware practitioners who use microservices, expanding upon previous research\nby incorporating diverse international perspectives. Our mixed-methods approach\nincludes quantitative and qualitative analyses, focusing on four main aspects:\n(i) the driving forces behind migration, (ii) the activities to conduct the\nmigration, (iii) strategies for managing data consistency, and (iv) the\nprevalent challenges. Thus, our results reveal diverse practices and challenges\npractitioners face when migrating to microservices. Companies are interested in\ntechnical benefits, enhancing maintenance, scalability, and deployment\nprocesses. Testing in microservice environments remains complex, and extensive\nmonitoring is crucial to managing the dynamic nature of microservices. Database\nmanagement remains challenging. While most participants prefer decentralized\ndatabases for autonomy and scalability, challenges persist in ensuring data\nconsistency. Additionally, many companies leverage modern cloud technologies to\nmitigate network overhead, showcasing the importance of cloud infrastructure in\nfacilitating efficient microservice communication.&quot;}, {'id': 'arxiv_2508.17536', 'title': 'Debate or Vote: Which Yields Better Decisions in Multi-Agent Large   Language Models?', 'URL': 'https://arxiv.org/abs/2508.17536', 'extra_urls': ['https://arxiv.org/abs/2508.17536'], 'type': 'article', 'author': [{'family': 'Choi', 'given': 'Hyeong Kyu'}, {'family': 'Zhu', 'given': 'Xiaojin'}, {'family': 'Li', 'given': 'Sharon'}], 'publisher': 'arXiv', 'abstract': &quot;Multi-Agent Debate~(MAD) has emerged as a promising paradigm for improving\nthe performance of large language models through collaborative reasoning.\nDespite recent advances, the key factors driving MAD's effectiveness remain\nunclear. In this work, we disentangle MAD into two key components--Majority\nVoting and inter-agent Debate--and assess their respective contributions.\nThrough extensive experiments across seven NLP benchmarks, we find that\nMajority Voting alone accounts for most of the performance gains typically\nattributed to MAD. To explain this, we propose a theoretical framework that\nmodels debate as a stochastic process. We prove that it induces a martingale\nover agents' belief trajectories, implying that debate alone does not improve\nexpected correctness. Guided by these insights, we demonstrate that targeted\ninterventions, by biasing the belief update toward correction, can meaningfully\nenhance debate effectiveness. Overall, our findings suggest that while MAD has\npotential, simple ensembling methods remain strong and more reliable\nalternatives in many practical settings. Code is released in\nhttps://github.com/deeplearning-wisc/debate-or-vote.&quot;}, {'id': 'arxiv_2510.01619', 'title': 'MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust   Physics-Based Dynamics', 'URL': 'https://arxiv.org/abs/2510.01619', 'extra_urls': ['https://arxiv.org/abs/2510.01619'], 'type': 'article', 'author': [{'family': 'Changmin Lee'}, {'family': 'Jihyun Lee'}, {'family': 'Tae-Kyun Kim'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2312.09228', 'title': '3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting', 'URL': 'https://arxiv.org/abs/2312.09228', 'extra_urls': ['https://arxiv.org/abs/2312.09228'], 'type': 'article', 'author': [{'family': 'Zhiyin Qian'}, {'family': 'Shaofei Wang'}, {'family': 'Marko Mihajlovic'}, {'family': 'Andreas Geiger'}, {'family': 'Siyu Tang'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2311.08581', 'title': 'Drivable 3D Gaussian Avatars', 'URL': 'https://arxiv.org/abs/2311.08581', 'extra_urls': ['https://arxiv.org/abs/2311.08581'], 'type': 'article', 'author': [{'family': 'Wojciech Zielonka'}, {'family': 'Timur Bagautdinov'}, {'family': 'Shunsuke Saito'}, {'family': 'Michael Zollh\xf6fer'}, {'family': 'Justus Thies'}, {'family': 'Javier Romero'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2409.08189', 'title': 'Gaussian Garments: Reconstructing Simulation-Ready Clothing with   Photorealistic Appearance from Multi-View Video', 'URL': 'https://arxiv.org/abs/2409.08189', 'extra_urls': ['https://arxiv.org/abs/2409.08189'], 'type': 'article', 'author': [{'family': 'Boxiang Rong'}, {'family': 'Artur Grigorev'}, {'family': 'Wenbo Wang'}, {'family': 'Michael J. Black'}, {'family': 'Bernhard Thomaszewski'}, {'family': 'Christina Tsalicoglou'}, {'family': 'Otmar Hilliges'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2508.19504', 'title': 'Aegis: Taxonomy and Optimizations for Overcoming Agent-Environment Failures in LLM Agents', 'URL': 'http://arxiv.org/abs/2508.19504', 'extra_urls': ['http://arxiv.org/abs/2508.19504'], 'type': 'article', 'author': [{'family': 'Song', 'given': 'Kevin'}, {'family': 'Jayarajan', 'given': 'Anand'}, {'family': 'Ding', 'given': 'Yaoyao'}, {'family': 'Su', 'given': 'Qidong'}, {'family': 'Zhu', 'given': 'Zhanda'}, {'family': 'Liu', 'given': 'Sihang'}, {'family': 'Pekhimenko', 'given': 'Gennady'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) agents augmented with domain tools promise to autonomously execute complex tasks requiring human-level intelligence, such as customer service and digital assistance. However, their practical deployment is often limited by their low success rates under complex real-world environments. To tackle this, prior research has primarily focused on improving the agents themselves, such as developing strong agentic LLMs, while overlooking the role of the system environment in which the agent operates. In this paper, we study a complementary direction: improving agent success rates by optimizing the system environment in which the agent operates. We collect 142 agent traces (3,656 turns of agent-environment interactions) across 5 state-of-the-art agentic benchmarks. By analyzing these agent failures, we propose a taxonomy for agent-environment interaction failures that includes 6 failure modes. Guided by these findings, we design Aegis, a set of targeted environment optimizations: 1) environment observability enhancement, 2) common computation offloading, and 3) speculative agentic actions. These techniques improve agent success rates on average by 6.7-12.5%, without any modifications to the agent and underlying LLM.'}, {'id': 'arxiv_2509.25370', 'title': 'Where LLM Agents Fail and How They can Learn From Failures', 'URL': 'http://arxiv.org/abs/2509.25370', 'extra_urls': ['http://arxiv.org/abs/2509.25370'], 'type': 'article', 'author': [{'family': 'Zhu', 'given': 'Kunlun'}, {'family': 'Liu', 'given': 'Zijia'}, {'family': 'Li', 'given': 'Bingxuan'}, {'family': 'Tian', 'given': 'Muxin'}, {'family': 'Yang', 'given': 'Yingxuan'}, {'family': 'Zhang', 'given': 'Jiaxun'}, {'family': 'Han', 'given': 'Pengrui'}, {'family': 'Xie', 'given': 'Qipeng'}, {'family': 'Cui', 'given': 'Fuyang'}, {'family': 'Zhang', 'given': 'Weijia'}, {'family': 'Ma', 'given': 'Xiaoteng'}, {'family': 'Yu', 'given': 'Xiaodong'}, {'family': 'Ramesh', 'given': 'Gowtham'}, {'family': 'Wu', 'given': 'Jialian'}, {'family': 'Liu', 'given': 'Zicheng'}, {'family': 'Lu', 'given': 'Pan'}, {'family': 'Zou', 'given': 'James'}, {'family': 'You', 'given': 'Jiaxuan'}], 'publisher': 'arXiv', 'abstract': 'Large Language Model (LLM) agents, which integrate planning, memory, reflection, and tool-use modules, have shown promise in solving complex, multi-step tasks. Yet their sophisticated architectures amplify vulnerability to cascading failures, where a single root-cause error propagates through subsequent decisions, leading to task failure. Current systems lack a framework that can comprehensively understand agent error in a modular and systemic way, and therefore fail to detect these errors accordingly. We address this gap with three contributions. First, we introduce the AgentErrorTaxonomy, a modular classification of failure modes spanning memory, reflection, planning, action, and system-level operations. Second, we construct AgentErrorBench, the first dataset of systematically annotated failure trajectories from ALFWorld, GAIA, and WebShop, grounding error analysis in real-world agent rollouts. Third, we propose AgentDebug, a debugging framework that isolates root-cause failures and provides corrective feedback, enabling agents to recover and iteratively improve. Experiments on AgentErrorBench show that AgentDebug achieves 24% higher all-correct accuracy and 17% higher step accuracy compared to the strongest baseline. Beyond detection, the targeted feedback generated by AgentDebug enables LLM agents to iteratively recover from failures, yielding up to 26% relative improvements in task success across ALFWorld, GAIA, and WebShop. These results establish principled debugging as a pathway to more reliable and adaptive LLM agents. The code and data will be available at https://github.com/ulab-uiuc/AgentDebug'}, {'id': 'arxiv_2504.06418', 'title': 'Releasing Differentially Private Event Logs Using Generative Models', 'URL': 'https://arxiv.org/abs/2504.06418', 'extra_urls': ['https://arxiv.org/abs/2504.06418'], 'type': 'article', 'author': [{'family': 'Frederik Wangelik'}, {'family': 'Majid Rafiei'}, {'family': 'Mahsa Pourbafrani'}, {'family': 'Wil M. P. van der Aalst'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2507.19550', 'title': 'Towards Multi-Agent Economies: Enhancing the A2A Protocol with   Ledger-Anchored Identities and x402 Micropayments for AI Agents', 'URL': 'https://arxiv.org/abs/2507.19550', 'extra_urls': ['https://arxiv.org/abs/2507.19550'], 'type': 'article', 'author': [{'family': 'Awid Vaziry'}, {'family': 'Sandro Rodriguez Garzon'}, {'family': 'Axel K\xfcpper'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.21594', 'title': 'Fast and Cost-effective Speculative Edge-Cloud Decoding with Early Exits', 'URL': 'https://arxiv.org/abs/2505.21594', 'extra_urls': ['https://arxiv.org/abs/2505.21594'], 'type': 'article', 'author': [{'family': 'Yeshwanth Venkatesha'}, {'family': 'Souvik Kundu'}, {'family': 'Priyadarshini Panda'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.19591', 'title': 'Multi-Agent Collaboration via Evolving Orchestration', 'URL': 'https://arxiv.org/abs/2505.19591', 'extra_urls': ['https://arxiv.org/abs/2505.19591'], 'type': 'article', 'author': [{'family': 'Yufan Dang'}, {'family': 'Chen Qian'}, {'family': 'Xueheng Luo'}, {'family': 'Jingru Fan'}, {'family': 'Zihao Xie'}, {'family': 'Ruijie Shi'}, {'family': 'Weize Chen'}, {'family': 'Cheng Yang'}, {'family': 'Xiaoyin Che'}, {'family': 'Ye Tian'}, {'family': 'Xuantang Xiong'}, {'family': 'Lei Han'}, {'family': 'Zhiyuan Liu'}, {'family': 'Maosong Sun'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2507.12311', 'title': 'An Ecosystem for Ontology Interoperability', 'URL': 'https://arxiv.org/abs/2507.12311', 'extra_urls': ['https://arxiv.org/abs/2507.12311'], 'type': 'article', 'author': [{'family': 'Zhangcheng Qiang'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.02861', 'title': 'Neural Orchestration for Multi-Agent Systems: A Deep Learning Framework   for Optimal Agent Selection in Multi-Domain Task Environments', 'URL': 'https://arxiv.org/abs/2505.02861', 'extra_urls': ['https://arxiv.org/abs/2505.02861'], 'type': 'article', 'author': [{'family': 'Kushagra Agrawal'}, {'family': 'Nisharg Nargund'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.05428', 'title': 'Empowering Scientific Workflows with Federated Agents', 'URL': 'https://arxiv.org/abs/2505.05428', 'extra_urls': ['https://arxiv.org/abs/2505.05428'], 'type': 'article', 'author': [{'family': 'J. Gregory Pauloski'}, {'family': 'Yadu Babuji'}, {'family': 'Ryan Chard'}, {'family': 'Mansi Sakarvadia'}, {'family': 'Kyle Chard'}, {'family': 'Ian Foster'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2509.05985', 'title': 'Operationalising AI Regulatory Sandboxes under the EU AI Act: The Triple   Challenge of Capacity, Coordination and Attractiveness to Providers', 'URL': 'https://arxiv.org/abs/2509.05985', 'extra_urls': ['https://arxiv.org/abs/2509.05985'], 'type': 'article', 'author': [{'family': 'Deirdre Ahern'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2406.08695', 'title': 'Global AI Governance in Healthcare: A Cross-Jurisdictional Regulatory   Analysis', 'URL': 'https://arxiv.org/abs/2406.08695', 'extra_urls': ['https://arxiv.org/abs/2406.08695'], 'type': 'article', 'author': [{'family': 'Attrayee Chakraborty'}, {'family': 'Mandar Karhade'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2507.02648', 'title': 'Recourse, Repair, Reparation, &amp; Prevention: A Stakeholder Analysis of AI   Supply Chains', 'URL': 'https://arxiv.org/abs/2507.02648', 'extra_urls': ['https://arxiv.org/abs/2507.02648'], 'type': 'article', 'author': [{'family': 'Aspen K. Hopkins'}, {'family': 'Isabella Struckman'}, {'family': 'Kevin Klyman'}, {'family': 'Susan S. Silbey'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2508.06760', 'title': 'Understanding Privacy Norms Around LLM-Based Chatbots: A Contextual   Integrity Perspective', 'URL': 'https://arxiv.org/abs/2508.06760', 'extra_urls': ['https://arxiv.org/abs/2508.06760'], 'type': 'article', 'author': [{'family': 'Sarah Tran'}, {'family': 'Hongfan Lu'}, {'family': 'Isaac Slaughter'}, {'family': 'Bernease Herman'}, {'family': 'Aayushi Dangol'}, {'family': 'Yue Fu'}, {'family': 'Lufei Chen'}, {'family': 'Biniyam Gebreyohannes'}, {'family': 'Bill Howe'}, {'family': 'Alexis Hiniker'}, {'family': 'Nicholas Weber'}, {'family': 'Robert Wolfe'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2409.00088', 'title': 'On-Device Language Models: A Comprehensive Review', 'URL': 'https://arxiv.org/abs/2409.00088', 'extra_urls': ['https://arxiv.org/abs/2409.00088'], 'type': 'article', 'author': [{'family': 'Jiajun Xu'}, {'family': 'Zhiyuan Li'}, {'family': 'Wei Chen'}, {'family': 'Qun Wang'}, {'family': 'Xin Gao'}, {'family': 'Qi Cai'}, {'family': 'Ziyuan Ling'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2502.17125', 'title': 'LettuceDetect: A Hallucination Detection Framework for RAG Applications', 'URL': 'https://arxiv.org/abs/2502.17125', 'extra_urls': ['https://arxiv.org/abs/2502.17125'], 'type': 'article', 'author': [{'family': '\xc1d\xe1m Kov\xe1cs'}, {'family': 'G\xe1bor Recski'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2401.10895', 'title': 'AI in Supply Chain Risk Assessment: A Systematic Literature Review and   Bibliometric Analysis', 'URL': 'https://arxiv.org/abs/2401.10895', 'extra_urls': ['https://arxiv.org/abs/2401.10895'], 'type': 'article', 'author': [{'family': 'Md Abrar Jahin'}, {'family': 'Saleh Akram Naife'}, {'family': 'Anik Kumar Saha'}, {'family': 'M. F. Mridha'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.15799', 'title': 'The Agentic Economy', 'URL': 'https://arxiv.org/abs/2505.15799', 'extra_urls': ['https://arxiv.org/abs/2505.15799'], 'type': 'article', 'author': [{'family': 'David M. Rothschild'}, {'family': 'Markus Mobius'}, {'family': 'Jake M. Hofman'}, {'family': 'Eleanor W. Dillon'}, {'family': 'Daniel G. Goldstein'}, {'family': 'Nicole Immorlica'}, {'family': 'Sonia Jaffe'}, {'family': 'Brendan Lucier'}, {'family': 'Aleksandrs Slivkins'}, {'family': 'Matthew Vogel'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2501.07913', 'title': 'Governing AI Agents', 'URL': 'https://arxiv.org/abs/2501.07913', 'extra_urls': ['https://arxiv.org/abs/2501.07913'], 'type': 'article', 'author': [{'family': 'Noam Kolt'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2509.01063', 'title': 'An Economy of AI Agents', 'URL': 'https://arxiv.org/abs/2509.01063', 'extra_urls': ['https://arxiv.org/abs/2509.01063'], 'type': 'article', 'author': [{'family': 'Gillian K. Hadfield'}, {'family': 'Andrew Koh'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2509.15366', 'title': 'Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context', 'URL': 'http://arxiv.org/abs/2509.15366', 'extra_urls': ['http://arxiv.org/abs/2509.15366'], 'type': 'article', 'author': [{'family': 'Sorstkins', 'given': 'Andrejs'}, {'family': 'Bailey', 'given': 'Josh'}, {'family': 'Baron', 'given': 'Dr Alistair'}], 'publisher': 'arXiv', 'abstract': 'The rapid evolution of neural architectures - from multilayer perceptrons to large-scale Transformer-based models - has enabled language models (LLMs) to exhibit emergent agentic behaviours when equipped with memory, planning, and external tool use. However, their inherent stochasticity and multi-step decision processes render classical evaluation methods inadequate for diagnosing agentic performance. This work introduces a diagnostic framework for expert systems that not only evaluates but also facilitates the transfer of expert behaviour into LLM-powered agents. The framework integrates (i) curated golden datasets of expert annotations, (ii) silver datasets generated through controlled behavioural mutation, and (iii) an LLM-based Agent Judge that scores and prescribes targeted improvements. These prescriptions are embedded into a vectorized recommendation map, allowing expert interventions to propagate as reusable improvement trajectories across multiple system instances. We demonstrate the framework on a multi-agent recruiter-assistant system, showing that it uncovers latent cognitive failures - such as biased phrasing, extraction drift, and tool misrouting - while simultaneously steering agents toward expert-level reasoning and style. The results establish a foundation for standardized, reproducible expert behaviour transfer in stochastic, tool-augmented LLM agents, moving beyond static evaluation to active expert system refinement.'}, {'id': 'arxiv_2508.02150', 'title': &quot;Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models' Instruction Following&quot;, 'URL': 'http://arxiv.org/abs/2508.02150', 'extra_urls': ['http://arxiv.org/abs/2508.02150'], 'type': 'article', 'author': [{'family': 'Ren', 'given': 'Qingyu'}, {'family': 'He', 'given': 'Qianyu'}, {'family': 'Zhang', 'given': 'Bowei'}, {'family': 'Zeng', 'given': 'Jie'}, {'family': 'Liang', 'given': 'Jiaqing'}, {'family': 'Xiao', 'given': 'Yanghua'}, {'family': 'Zhou', 'given': 'Weikang'}, {'family': 'Sun', 'given': 'Zeye'}, {'family': 'Yu', 'given': 'Fei'}], 'publisher': 'arXiv', 'abstract': &quot;Reasoning models excel in complex problem solving but exhibit a concerning trade off between reasoning capabilities and instruction following abilities. Existing approaches for improving instruction following rely on stronger external models, creating methodological bottlenecks and practical limitations including increased costs and accessibility constraints. We propose a self-supervised RL framework that leverages reasoning models' own internal signals to improve instruction following capabilities without external supervision. Extensive experiments demonstrate that our framework significantly improves instruction following capabilities while maintaining reasoning performance, offering a scalable and cost-effective approach to enhance instruction following in reasoning models. The data and code are publicly available at https://github.com/Rainier-rq/verl-if.&quot;}, {'id': 'arxiv_2510.11588', 'title': 'Analyzing and Internalizing Complex Policy Documents for LLM Agents', 'URL': 'http://arxiv.org/abs/2510.11588', 'extra_urls': ['http://arxiv.org/abs/2510.11588'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Jiateng'}, {'family': 'Wang', 'given': 'Zhenhailong'}, {'family': 'Huang', 'given': 'Xiaojiang'}, {'family': 'Li', 'given': 'Yingjie'}, {'family': 'Fan', 'given': 'Xing'}, {'family': 'Li', 'given': 'Xiang'}, {'family': 'Guo', 'given': 'Chenlei'}, {'family': 'Sarikaya', 'given': 'Ruhi'}, {'family': 'Ji', 'given': 'Heng'}], 'publisher': 'arXiv', 'abstract': &quot;Large Language Model (LLM)-based agentic systems rely on in-context policy documents encoding diverse business rules. As requirements grow, these documents expand rapidly, causing high computational overhead. This motivates developing internalization methods that embed policy documents into model priors while preserving performance. Prior prompt compression work targets generic prompts, but agentic policy documents span multiple complexity levels and require deeper reasoning, making internalization harder. We introduce CC-Gen, an agentic benchmark generator with Controllable Complexity across four levels, enabling systematic evaluation of agents' ability to handle complexity and offering a unified framework for assessing policy internalization. Our analysis shows that complex policy specifications governing workflows pose major reasoning challenges. Supporting internalization with gold user agent interaction trajectories containing chain-of-thought (CoT) annotations via supervised fine-tuning (SFT) is data-intensive and degrades sharply as policy complexity increases. To mitigate data and reasoning burdens, we propose Category-Aware Policy Continued Pretraining (CAP-CPT). Our automated pipeline parses policy documents to extract key specifications, grouping them into factual, behavioral, and conditional categories, and isolating complex conditions that drive workflow complexity. This guides targeted data synthesis and enables agents to internalize policy information through an autoregressive pretraining loss. Experiments show CAP-CPT improves SFT baselines in all settings, with up to 41% and 22% gains on Qwen-3-32B, achieving 97.3% prompt length reduction on CC-Gen and further enhancing tau-Bench with minimal SFT data.&quot;}, {'id': 'arxiv_2510.14420', 'title': 'Instructions are all you need: Self-supervised Reinforcement Learning for Instruction Following', 'URL': 'http://arxiv.org/abs/2510.14420', 'extra_urls': ['http://arxiv.org/abs/2510.14420'], 'type': 'article', 'author': [{'family': 'Ren', 'given': 'Qingyu'}, {'family': 'He', 'given': 'Qianyu'}, {'family': 'Zhang', 'given': 'Bowei'}, {'family': 'Zeng', 'given': 'Jie'}, {'family': 'Liang', 'given': 'Jiaqing'}, {'family': 'Xiao', 'given': 'Yanghua'}, {'family': 'Zhou', 'given': 'Weikang'}, {'family': 'Sun', 'given': 'Zeye'}, {'family': 'Yu', 'given': 'Fei'}], 'publisher': 'arXiv', 'abstract': 'Language models often struggle to follow multi-constraint instructions that are crucial for real-world applications. Existing reinforcement learning (RL) approaches suffer from dependency on external supervision and sparse reward signals from multi-constraint tasks. We propose a label-free self-supervised RL framework that eliminates dependency on external supervision by deriving reward signals directly from instructions and generating pseudo-labels for reward model training. Our approach introduces constraint decomposition strategies and efficient constraint-wise binary classification to address sparse reward challenges while maintaining computational efficiency. Experiments show that our approach generalizes well, achieving strong improvements across 3 in-domain and 5 out-of-domain datasets, including challenging agentic and multi-turn instruction following. The data and code are publicly available at https://github.com/Rainier-rq/verl-if'}, {'id': 'arxiv_2505.16944', 'title': 'AGENTIF: Benchmarking Instruction Following of Large Language Models in Agentic Scenarios', 'URL': 'http://arxiv.org/abs/2505.16944', 'extra_urls': ['http://arxiv.org/abs/2505.16944'], 'type': 'article', 'author': [{'family': 'Qi', 'given': 'Yunjia'}, {'family': 'Peng', 'given': 'Hao'}, {'family': 'Wang', 'given': 'Xiaozhi'}, {'family': 'Xin', 'given': 'Amy'}, {'family': 'Liu', 'given': 'Youfeng'}, {'family': 'Xu', 'given': 'Bin'}, {'family': 'Hou', 'given': 'Lei'}, {'family': 'Li', 'given': 'Juanzi'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) have demonstrated advanced capabilities in real-world agentic applications. Growing research efforts aim to develop LLM-based agents to address practical demands, introducing a new challenge: agentic scenarios often involve lengthy instructions with complex constraints, such as extended system prompts and detailed tool specifications. While adherence to such instructions is crucial for agentic applications, whether LLMs can reliably follow them remains underexplored. In this paper, we introduce AgentIF, the first benchmark for systematically evaluating LLM instruction following ability in agentic scenarios. AgentIF features three key characteristics: (1) Realistic, constructed from 50 real-world agentic applications. (2) Long, averaging 1,723 words with a maximum of 15,630 words. (3) Complex, averaging 11.9 constraints per instruction, covering diverse constraint types, such as tool specifications and condition constraints. To construct AgentIF, we collect 707 human-annotated instructions across 50 agentic tasks from industrial application agents and open-source agentic systems. For each instruction, we annotate the associated constraints and corresponding evaluation metrics, including code-based evaluation, LLM-based evaluation, and hybrid code-LLM evaluation. We use AgentIF to systematically evaluate existing advanced LLMs. We observe that current models generally perform poorly, especially in handling complex constraint structures and tool specifications. We further conduct error analysis and analytical experiments on instruction length and meta constraints, providing some findings about the failure modes of existing LLMs. We have released the code and data to facilitate future research.'}, {'id': 'arxiv_2505.04260', 'title': 'Steerable Chatbots: Personalizing LLMs with Preference-Based Activation Steering', 'URL': 'http://arxiv.org/abs/2505.04260', 'extra_urls': ['http://arxiv.org/abs/2505.04260'], 'type': 'article', 'author': [{'family': 'Bo', 'given': 'Jessica Y.'}, {'family': 'Xu', 'given': 'Tianyu'}, {'family': 'Chatterjee', 'given': 'Ishan'}, {'family': 'Passarella-Ward', 'given': 'Katrina'}, {'family': 'Kulshrestha', 'given': 'Achin'}, {'family': 'Shin', 'given': 'D.'}], 'publisher': 'arXiv', 'abstract': 'As large language models (LLMs) improve in their capacity to serve as personal AI assistants, their ability to output uniquely tailored, personalized responses that align with the soft preferences of their users is essential for enhancing user satisfaction and retention. However, untrained lay users have poor prompt specification abilities and often struggle with conveying their latent preferences to AI assistants. To address this, we leverage activation steering to guide LLMs to align with interpretable preference dimensions during inference. In contrast to memory-based personalization methods that require longer user history, steering is extremely lightweight and can be easily controlled by the user via an linear strength factor. We embed steering into three different interactive chatbot interfaces and conduct a within-subjects user study (n=14) to investigate how end users prefer to personalize their conversations. The results demonstrate the effectiveness of preference-based steering for aligning real-world conversations with hidden user preferences, and highlight further insights on how diverse values around control, usability, and transparency lead users to prefer different interfaces.'}, {'id': 'arxiv_2505.16467', 'title': &quot;Reading Between the Prompts: How Stereotypes Shape LLM's Implicit Personalization&quot;, 'URL': 'http://arxiv.org/abs/2505.16467', 'extra_urls': ['http://arxiv.org/abs/2505.16467'], 'type': 'article', 'author': [{'family': 'Neplenbroek', 'given': 'Vera'}, {'family': 'Bisazza', 'given': 'Arianna'}, {'family': 'Fern\xe1ndez', 'given': 'Raquel'}], 'publisher': 'arXiv', 'abstract': &quot;Generative Large Language Models (LLMs) infer user's demographic information from subtle cues in the conversation -- a phenomenon called implicit personalization. Prior work has shown that such inferences can lead to lower quality responses for users assumed to be from minority groups, even when no demographic information is explicitly provided. In this work, we systematically explore how LLMs respond to stereotypical cues using controlled synthetic conversations, by analyzing the models' latent user representations through both model internals and generated answers to targeted user questions. Our findings reveal that LLMs do infer demographic attributes based on these stereotypical signals, which for a number of groups even persists when the user explicitly identifies with a different demographic group. Finally, we show that this form of stereotype-driven implicit personalization can be effectively mitigated by intervening on the model's internal representations using a trained linear probe to steer them toward the explicitly stated identity. Our results highlight the need for greater transparency and control in how LLMs represent user identity.&quot;}, {'id': 'arxiv_2509.19364', 'title': 'The Inadequacy of Offline LLM Evaluations: A Need to Account for Personalization in Model Behavior', 'URL': 'http://arxiv.org/abs/2509.19364', 'extra_urls': ['http://arxiv.org/abs/2509.19364'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Angelina'}, {'family': 'Ho', 'given': 'Daniel E.'}, {'family': 'Koyejo', 'given': 'Sanmi'}], 'publisher': 'arXiv', 'abstract': &quot;Standard offline evaluations for language models -- a series of independent, state-less inferences made by models -- fail to capture how language models actually behave in practice, where personalization fundamentally alters model behavior. For instance, identical benchmark questions to the same language model can produce markedly different responses when prompted to a state-less system, in one user's chat session, or in a different user's chat session. In this work, we provide empirical evidence showcasing this phenomenon by comparing offline evaluations to field evaluations conducted by having 800 real users of ChatGPT and Gemini pose benchmark and other provided questions to their chat interfaces.&quot;}, {'id': 'arxiv_2509.18052', 'title': 'The PIMMUR Principles: Ensuring Validity in Collective Behavior of LLM Societies', 'URL': 'http://arxiv.org/abs/2509.18052', 'extra_urls': ['http://arxiv.org/abs/2509.18052'], 'type': 'article', 'author': [{'family': 'Zhou', 'given': 'Jiaxu'}, {'family': 'Huang', 'given': 'Jen-tse'}, {'family': 'Zhou', 'given': 'Xuhui'}, {'family': 'Lam', 'given': 'Man Ho'}, {'family': 'Wang', 'given': 'Xintao'}, {'family': 'Zhu', 'given': 'Hao'}, {'family': 'Wang', 'given': 'Wenxuan'}, {'family': 'Sap', 'given': 'Maarten'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) are increasingly used for social simulation, where populations of agents are expected to reproduce human-like collective behavior. However, we find that many recent studies adopt experimental designs that systematically undermine the validity of their claims. From a survey of over 40 papers, we identify six recurring methodological flaws: agents are often homogeneous (Profile), interactions are absent or artificially imposed (Interaction), memory is discarded (Memory), prompts tightly control outcomes (Minimal-Control), agents can infer the experimental hypothesis (Unawareness), and validation relies on simplified theoretical models rather than real-world data (Realism). For instance, GPT-4o and Qwen-3 correctly infer the underlying social experiment in 53.1% of cases when given instructions from prior work-violating the Unawareness principle. We formalize these six requirements as the PIMMUR principles and argue they are necessary conditions for credible LLM-based social simulation. To demonstrate their impact, we re-run five representative studies using a framework that enforces PIMMUR and find that the reported social phenomena frequently fail to emerge under more rigorous conditions. Our work establishes methodological standards for LLM-based multi-agent research and provides a foundation for more reliable and reproducible claims about &quot;AI societies.&quot;'}, {'id': 'arxiv_2505.03961', 'title': 'The Power of Stories: Narrative Priming Shapes How LLM Agents Collaborate and Compete', 'URL': 'http://arxiv.org/abs/2505.03961', 'extra_urls': ['http://arxiv.org/abs/2505.03961'], 'type': 'article', 'author': [{'family': 'Gro\xdfmann', 'given': 'Gerrit'}, {'family': 'Ivanova', 'given': 'Larisa'}, {'family': 'Poduru', 'given': 'Sai Leela'}, {'family': 'Tabrizian', 'given': 'Mohaddeseh'}, {'family': 'Mesabah', 'given': 'Islam'}, {'family': 'Selby', 'given': 'David A.'}, {'family': 'Vollmer', 'given': 'Sebastian J.'}], 'publisher': 'arXiv', 'abstract': 'According to Yuval Noah Harari, large-scale human cooperation is driven by shared narratives that encode common beliefs and values. This study explores whether such narratives can similarly nudge LLM agents toward collaboration. We use a finitely repeated public goods game in which LLM agents choose either cooperative or egoistic spending strategies. We prime agents with stories highlighting teamwork to different degrees and test how this influences negotiation outcomes. Our experiments explore four questions:(1) How do narratives influence negotiation behavior? (2) What differs when agents share the same story versus different ones? (3) What happens when the agent numbers grow? (4) Are agents resilient against self-serving negotiators? We find that story-based priming significantly affects negotiation strategies and success rates. Common stories improve collaboration, benefiting each agent. By contrast, priming agents with different stories reverses this effect, and those agents primed toward self-interest prevail. We hypothesize that these results carry implications for multi-agent system design and AI alignment.'}, {'id': 'arxiv_2502.16320', 'title': 'Direct Alignment with Heterogeneous Preferences', 'URL': 'http://arxiv.org/abs/2502.16320', 'extra_urls': ['http://arxiv.org/abs/2502.16320'], 'type': 'article', 'author': [{'family': 'Shirali', 'given': 'Ali'}, {'family': 'Nasr-Esfahany', 'given': 'Arash'}, {'family': 'Alomar', 'given': 'Abdullah'}, {'family': 'Mirtaheri', 'given': 'Parsa'}, {'family': 'Abebe', 'given': 'Rediet'}, {'family': 'Procaccia', 'given': 'Ariel'}], 'publisher': 'arXiv', 'abstract': 'Alignment with human preferences is commonly framed using a universal reward function, even though human preferences are inherently heterogeneous. We formalize this heterogeneity by introducing user types and examine the limits of the homogeneity assumption. We show that aligning to heterogeneous preferences with a single policy is best achieved using the average reward across user types. However, this requires additional information about annotators. We examine improvements under different information settings, focusing on direct alignment methods. We find that minimal information can yield first-order improvements, while full feedback from each user type leads to consistent learning of the optimal policy. Surprisingly, however, no sample-efficient consistent direct loss exists in this latter setting. These results reveal a fundamental tension between consistency and sample efficiency in direct policy alignment.'}, {'id': 'arxiv_2501.11549', 'title': 'Whose Boat Does it Float? Improving Personalization in Preference Tuning via Inferred User Personas', 'URL': 'http://arxiv.org/abs/2501.11549', 'extra_urls': ['http://arxiv.org/abs/2501.11549'], 'type': 'article', 'author': [{'family': 'Balepur', 'given': 'Nishant'}, {'family': 'Padmakumar', 'given': 'Vishakh'}, {'family': 'Yang', 'given': 'Fumeng'}, {'family': 'Feng', 'given': 'Shi'}, {'family': 'Rudinger', 'given': 'Rachel'}, {'family': 'Boyd-Graber', 'given': 'Jordan Lee'}], 'publisher': 'arXiv', 'abstract': 'LLMs are aligned to follow input instructions by learning which of two responses users prefer for a prompt. However, such preference data do not convey why users prefer responses that are chosen or rejected, so LLMs trained on these datasets cannot tailor responses to varied user needs. To surface these parameters of personalization, we apply abductive reasoning to preference data, inferring needs and interests of users, i.e., personas, that may prefer either response. We test this idea in two steps: Persona Inference (PI), abductively inferring personas of users who prefer chosen or rejected outputs, and Persona Tailoring (PT), training models to tailor outputs to personas from PI. We show: 1) LLMs infer personas accurately explaining why different users may prefer both chosen or rejected outputs; 2) Training on preference data augmented with PI personas via PT boosts personalization and generalizes to supporting user-written personas; and 3) Rejected response personas form harder personalization evaluations, showing PT better aids users with uncommon preferences versus typical alignment methods. We argue for an abductive view of preferences for personalization, asking not only which response is better but when, why, and for whom.'}, {'id': 'arxiv_2410.05613', 'title': 'Stereotype or Personalization? User Identity Biases Chatbot Recommendations', 'URL': 'http://arxiv.org/abs/2410.05613', 'extra_urls': ['http://arxiv.org/abs/2410.05613'], 'type': 'article', 'author': [{'family': 'Kantharuban', 'given': 'Anjali'}, {'family': 'Milbauer', 'given': 'Jeremiah'}, {'family': 'Sap', 'given': 'Maarten'}, {'family': 'Strubell', 'given': 'Emma'}, {'family': 'Neubig', 'given': 'Graham'}], 'publisher': 'arXiv', 'abstract': &quot;While personalized recommendations are often desired by users, it can be difficult in practice to distinguish cases of bias from cases of personalization: we find that models generate racially stereotypical recommendations regardless of whether the user revealed their identity intentionally through explicit indications or unintentionally through implicit cues. We demonstrate that when people use large language models (LLMs) to generate recommendations, the LLMs produce responses that reflect both what the user wants and who the user is. We argue that chatbots ought to transparently indicate when recommendations are influenced by a user's revealed identity characteristics, but observe that they currently fail to do so. Our experiments show that even though a user's revealed identity significantly influences model recommendations (p &lt; 0.001), model responses obfuscate this fact in response to user queries. This bias and lack of transparency occurs consistently across multiple popular consumer LLMs and for four American racial groups.&quot;}, {'id': 'arxiv_2509.23767', 'title': 'From Personal to Collective: On the Role of Local and Global Memory in LLM Personalization', 'URL': 'http://arxiv.org/abs/2509.23767', 'extra_urls': ['http://arxiv.org/abs/2509.23767'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Zehong'}, {'family': 'Wu', 'given': 'Junlin'}, {'family': 'Tan', 'given': 'ZHaoxuan'}, {'family': 'Li', 'given': 'Bolian'}, {'family': 'Zhong', 'given': 'Xianrui'}, {'family': 'Liu', 'given': 'Zheli'}, {'family': 'Zeng', 'given': 'Qingkai'}], 'publisher': 'arXiv', 'abstract': 'Large language model (LLM) personalization aims to tailor model behavior to individual users based on their historical interactions. However, its effectiveness is often hindered by two key challenges: the \\textit{cold-start problem}, where users with limited history provide insufficient context for accurate personalization, and the \\textit{biasing problem}, where users with abundant but skewed history cause the model to overfit to narrow preferences. We identify both issues as symptoms of a common underlying limitation, i.e., the inability to model collective knowledge across users. To address this, we propose a local-global memory framework (LoGo) that combines the personalized local memory with a collective global memory that captures shared interests across the population. To reconcile discrepancies between these two memory sources, we introduce a mediator module designed to resolve conflicts between local and global signals. Extensive experiments on multiple benchmarks demonstrate that LoGo consistently improves personalization quality by both warming up cold-start users and mitigating biased predictions. These results highlight the importance of incorporating collective knowledge to enhance LLM personalization.'}, {'id': 'arxiv_2504.00338', 'title': 'Agentic Multimodal AI for Hyperpersonalized B2B and B2C Advertising in Competitive Markets: An AI-Driven Competitive Advertising Framework', 'URL': 'http://arxiv.org/abs/2504.00338', 'extra_urls': ['http://arxiv.org/abs/2504.00338'], 'type': 'article', 'author': [{'family': 'Srinivas', 'given': 'Sakhinana Sagar'}, {'family': 'Das', 'given': 'Akash'}, {'family': 'Gupta', 'given': 'Shivam'}, {'family': 'Runkana', 'given': 'Venkataramana'}], 'publisher': 'arXiv', 'abstract': 'The growing use of foundation models (FMs) in real-world applications demands adaptive, reliable, and efficient strategies for dynamic markets. In the chemical industry, AI-discovered materials drive innovation, but commercial success hinges on market adoption, requiring FM-driven advertising frameworks that operate in-the-wild. We present a multilingual, multimodal AI framework for autonomous, hyper-personalized advertising in B2B and B2C markets. By integrating retrieval-augmented generation (RAG), multimodal reasoning, and adaptive persona-based targeting, our system generates culturally relevant, market-aware ads tailored to shifting consumer behaviors and competition. Validation combines real-world product experiments with a Simulated Humanistic Colony of Agents to model consumer personas, optimize strategies at scale, and ensure privacy compliance. Synthetic experiments mirror real-world scenarios, enabling cost-effective testing of ad strategies without risky A/B tests. Combining structured retrieval-augmented reasoning with in-context learning (ICL), the framework boosts engagement, prevents market cannibalization, and maximizes ROAS. This work bridges AI-driven innovation and market adoption, advancing multimodal FM deployment for high-stakes decision-making in commercial marketing.'}, {'id': 'arxiv_2505.00038', 'title': 'HyPerAlign: Interpretable Personalized LLM Alignment via Hypothesis Generation', 'URL': 'http://arxiv.org/abs/2505.00038', 'extra_urls': ['http://arxiv.org/abs/2505.00038'], 'type': 'article', 'author': [{'family': 'Garbacea', 'given': 'Cristina'}, {'family': 'Tan', 'given': 'Chenhao'}], 'publisher': 'arXiv', 'abstract': &quot;Alignment algorithms are widely used to align large language models (LLMs) to human users based on preference annotations. Typically these (often divergent) preferences are aggregated over a diverse set of users, resulting in fine-tuned models that are aligned to the ``average-user'' preference. Nevertheless, current models are used by individual users in very specific contexts and situations, emphasizing the need for user-dependent preference control. In this work we address the problem of personalizing LLM outputs to their users. We aim to generate customized responses tailored to specific individuals instead of generic outputs that emulate the collective voices of diverse populations. We propose HyPerAlign, an interpretable and sample-efficient hypothesis-driven personalization approach for LLM models. Given few-shot examples written by a particular user, we first infer hypotheses about their communication strategies, personality, and writing style, then prompt LLM models with these hypotheses and user-specific attributes to generate customized outputs. We conduct experiments on two different personalization tasks, namely authorship attribution and deliberative alignment, with datasets from diverse domains (news articles, blog posts, emails, jailbreaking benchmarks). Results demonstrate the superiority of hypothesis-driven LLM personalization compared to preference-based fine-tuning methods. For authorship attribution, HyPerAlign generations have consistently high win-rates (commonly $&gt; 90\\%$) against state-of-the-art preference fine-tuning approaches across diverse user profiles and LLM models. For deliberative alignment, the helpfulness of LLM models is improved by up to $70\\%$ on average. Overall, HyPerAlign represents an interpretable and sample-efficient strategy for the personalization of LLM models to individual users.&quot;}, {'id': 'arxiv_2501.10685', 'title': 'Harnessing the Potential of Large Language Models in Modern Marketing Management: Applications, Future Directions, and Strategic Recommendations', 'URL': 'http://arxiv.org/abs/2501.10685', 'extra_urls': ['http://arxiv.org/abs/2501.10685'], 'type': 'article', 'author': [{'family': 'Aghaei', 'given': 'Raha'}, {'family': 'Kiaei', 'given': 'Ali A.'}, {'family': 'Boush', 'given': 'Mahnaz'}, {'family': 'Vahidi', 'given': 'Javad'}, {'family': 'Zavvar', 'given': 'Mohammad'}, {'family': 'Barzegar', 'given': 'Zeynab'}, {'family': 'Rofoosheh', 'given': 'Mahan'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) have revolutionized the process of customer engagement, campaign optimization, and content generation, in marketing management. In this paper, we explore the transformative potential of LLMs along with the current applications, future directions, and strategic recommendations for marketers. In particular, we focus on LLMs major business drivers such as personalization, real-time-interactive customer insights, and content automation, and how they enable customers and business outcomes. For instance, the ethical aspects of AI with respect to data privacy, transparency, and mitigation of bias are also covered, with the goal of promoting responsible use of the technology through best practices and the use of new technologies businesses can tap into the LLM potential, which help growth and stay one step ahead in the turmoil of digital marketing. This article is designed to give marketers the necessary guidance by using best industry practices to integrate these powerful LLMs into their marketing strategy and innovation without compromising on the ethos of their brand.'}, {'id': 'arxiv_2310.11689', 'title': 'Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs', 'URL': 'http://arxiv.org/abs/2310.11689', 'extra_urls': ['http://arxiv.org/abs/2310.11689'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Jiefeng'}, {'family': 'Yoon', 'given': 'Jinsung'}, {'family': 'Ebrahimi', 'given': 'Sayna'}, {'family': 'Arik', 'given': 'Sercan O.'}, {'family': 'Pfister', 'given': 'Tomas'}, {'family': 'Jha', 'given': 'Somesh'}], 'publisher': 'arXiv', 'abstract': 'Large language models (LLMs) have recently shown great advances in a variety of tasks, including natural language understanding and generation. However, their use in high-stakes decision-making scenarios is still limited due to the potential for errors. Selective prediction is a technique that can be used to improve the reliability of the LLMs by allowing them to abstain from making predictions when they are unsure of the answer. In this work, we propose a novel framework for adaptation with self-evaluation to improve the selective prediction performance of LLMs. Our framework is based on the idea of using parameter-efficient tuning to adapt the LLM to the specific task at hand while improving its ability to perform self-evaluation. We evaluate our method on a variety of question-answering (QA) datasets and show that it outperforms state-of-the-art selective prediction methods. For example, on the CoQA benchmark, our method improves the AUACC from 91.23% to 92.63% and improves the AUROC from 74.61% to 80.25%.'}, {'id': 'arxiv_2506.20178', 'title': 'COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees', 'URL': 'http://arxiv.org/abs/2506.20178', 'extra_urls': ['http://arxiv.org/abs/2506.20178'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Zhiyuan'}, {'family': 'Duan', 'given': 'Jinhao'}, {'family': 'Wang', 'given': 'Qingni'}, {'family': 'Zhu', 'given': 'Xiaofeng'}, {'family': 'Chen', 'given': 'Tianlong'}, {'family': 'Shi', 'given': 'Xiaoshuang'}, {'family': 'Xu', 'given': 'Kaidi'}], 'publisher': 'arXiv', 'abstract': &quot;Uncertainty quantification (UQ) for foundation models is essential to identify and mitigate potential hallucinations in automatically generated text. However, heuristic UQ approaches lack formal guarantees for key metrics such as the false discovery rate (FDR) in selective prediction. Previous work adopts the split conformal prediction (SCP) framework to ensure desired coverage of admissible answers by constructing prediction sets, but these sets often contain incorrect candidates, limiting their practical utility. To address this, we propose COIN, an uncertainty-guarding selection framework that calibrates statistically valid thresholds to filter a single generated answer per question under user-specified FDR constraints. COIN estimates the empirical error rate on a calibration set and applies confidence interval methods such as Clopper-Pearson to establish a high-probability upper bound on the true error rate (i.e., FDR). This enables the selection of the largest uncertainty threshold that ensures FDR control on test data while significantly increasing sample retention. We demonstrate COIN's robustness in risk control, strong test-time power in retaining admissible answers, and predictive efficiency under limited calibration data across both general and multimodal text generation tasks. Furthermore, we show that employing alternative upper bound constructions and UQ strategies can further boost COIN's power performance, which underscores its extensibility and adaptability to diverse application scenarios.&quot;}, {'id': 'arxiv_2409.18645', 'title': 'The Craft of Selective Prediction: Towards Reliable Case Outcome Classification -- An Empirical Study on European Court of Human Rights Cases', 'URL': 'http://arxiv.org/abs/2409.18645', 'extra_urls': ['http://arxiv.org/abs/2409.18645'], 'type': 'article', 'author': [{'family': 'Santosh', 'given': 'T. Y. S. S.'}, {'family': 'Chowdhury', 'given': 'Irtiza'}, {'family': 'Xu', 'given': 'Shanshan'}, {'family': 'Grabmair', 'given': 'Matthias'}], 'publisher': 'arXiv', 'abstract': &quot;In high-stakes decision-making tasks within legal NLP, such as Case Outcome Classification (COC), quantifying a model's predictive confidence is crucial. Confidence estimation enables humans to make more informed decisions, particularly when the model's certainty is low, or where the consequences of a mistake are significant. However, most existing COC works prioritize high task performance over model reliability. This paper conducts an empirical investigation into how various design choices including pre-training corpus, confidence estimator and fine-tuning loss affect the reliability of COC models within the framework of selective prediction. Our experiments on the multi-label COC task, focusing on European Court of Human Rights (ECtHR) cases, highlight the importance of a diverse yet domain-specific pre-training corpus for better calibration. Additionally, we demonstrate that larger models tend to exhibit overconfidence, Monte Carlo dropout methods produce reliable confidence estimates, and confident error regularization effectively mitigates overconfidence. To our knowledge, this is the first systematic exploration of selective prediction in legal NLP. Our findings underscore the need for further research on enhancing confidence measurement and improving the trustworthiness of models in the legal domain.&quot;}, {'id': 'arxiv_2506.23464', 'title': &quot;The Confidence Paradox: Can LLM Know When It's Wrong&quot;, 'URL': 'http://arxiv.org/abs/2506.23464', 'extra_urls': ['http://arxiv.org/abs/2506.23464'], 'type': 'article', 'author': [{'family': 'Tripathi', 'given': 'Sahil'}, {'family': 'Nafis', 'given': 'Md Tabrez'}, {'family': 'Hussain', 'given': 'Imran'}, {'family': 'Gao', 'given': 'Jiechao'}], 'publisher': 'arXiv', 'abstract': 'Document Visual Question Answering (DocVQA) systems are increasingly deployed in real world applications, yet they remain ethically opaque-often producing overconfident answers to ambiguous questions or failing to communicate uncertainty in a trustworthy manner. This misalignment between model confidence and actual knowledge poses significant risks, particularly in domains requiring ethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUT have advanced SOTA performance by focusing on architectural sophistication and accuracy; however, they fall short in ethical responsiveness. To address these limitations, we introduce HonestVQA, a self-supervised honesty calibration framework for ethically aligned DocVQA. Our model-agnostic method quantifies uncertainty to identify knowledge gaps, aligns model confidence with actual correctness using weighted loss functions, and enforces ethical response behavior via contrastive learning. We further introduce two principled evaluation metrics--Honesty Score (H-Score) and Ethical Confidence Index (ECI)--to benchmark alignment between confidence, accuracy, and ethical communication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3% and F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reduces overconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. In cross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score, demonstrating strong generalization. Ablation shows a 3.8% drop in accuracy without alignment or contrastive loss.'}, {'id': 'arxiv_2508.07407', 'title': 'A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems', 'URL': 'http://arxiv.org/abs/2508.07407', 'extra_urls': ['http://arxiv.org/abs/2508.07407'], 'type': 'article', 'author': [{'family': 'Fang', 'given': 'Jinyuan'}, {'family': 'Peng', 'given': 'Yanwen'}, {'family': 'Zhang', 'given': 'Xi'}, {'family': 'Wang', 'given': 'Yingxu'}, {'family': 'Yi', 'given': 'Xinhao'}, {'family': 'Zhang', 'given': 'Guibin'}, {'family': 'Xu', 'given': 'Yi'}, {'family': 'Wu', 'given': 'Bin'}, {'family': 'Liu', 'given': 'Siwei'}, {'family': 'Li', 'given': 'Zihao'}, {'family': 'Ren', 'given': 'Zhaochun'}, {'family': 'Aletras', 'given': 'Nikos'}, {'family': 'Wang', 'given': 'Xi'}, {'family': 'Zhou', 'given': 'Han'}, {'family': 'Meng', 'given': 'Zaiqiao'}], 'publisher': 'arXiv', 'abstract': 'Recent advances in large language models have sparked growing interest in AI agents capable of solving complex, real-world tasks. However, most existing agent systems rely on manually crafted configurations that remain static after deployment, limiting their ability to adapt to dynamic and evolving environments. To this end, recent research has explored agent evolution techniques that aim to automatically enhance agent systems based on interaction data and environmental feedback. This emerging direction lays the foundation for self-evolving AI agents, which bridge the static capabilities of foundation models with the continuous adaptability required by lifelong agentic systems. In this survey, we provide a comprehensive review of existing techniques for self-evolving agentic systems. Specifically, we first introduce a unified conceptual framework that abstracts the feedback loop underlying the design of self-evolving agentic systems. The framework highlights four key components: System Inputs, Agent System, Environment, and Optimisers, serving as a foundation for understanding and comparing different strategies. Based on this framework, we systematically review a wide range of self-evolving techniques that target different components of the agent system. We also investigate domain-specific evolution strategies developed for specialised fields such as biomedicine, programming, and finance, where optimisation objectives are tightly coupled with domain constraints. In addition, we provide a dedicated discussion on the evaluation, safety, and ethical considerations for self-evolving agentic systems, which are critical to ensuring their effectiveness and reliability. This survey aims to provide researchers and practitioners with a systematic understanding of self-evolving AI agents, laying the foundation for the development of more adaptive, autonomous, and lifelong agentic systems.'}, {'id': 'arxiv_2509.14284', 'title': 'The Sum Leaks More Than Its Parts: Compositional Privacy Risks and Mitigations in Multi-Agent Collaboration', 'URL': 'http://arxiv.org/abs/2509.14284', 'extra_urls': ['http://arxiv.org/abs/2509.14284'], 'type': 'article', 'author': [{'family': 'Patil', 'given': 'Vaidehi'}, {'family': 'Stengel-Eskin', 'given': 'Elias'}, {'family': 'Bansal', 'given': 'Mohit'}], 'publisher': 'arXiv', 'abstract': &quot;As large language models (LLMs) become integral to multi-agent systems, new privacy risks emerge that extend beyond memorization, direct inference, or single-turn evaluations. In particular, seemingly innocuous responses, when composed across interactions, can cumulatively enable adversaries to recover sensitive information, a phenomenon we term compositional privacy leakage. We present the first systematic study of such compositional privacy leaks and possible mitigation methods in multi-agent LLM systems. First, we develop a framework that models how auxiliary knowledge and agent interactions jointly amplify privacy risks, even when each response is benign in isolation. Next, to mitigate this, we propose and evaluate two defense strategies: (1) Theory-of-Mind defense (ToM), where defender agents infer a questioner's intent by anticipating how their outputs may be exploited by adversaries, and (2) Collaborative Consensus Defense (CoDef), where responder agents collaborate with peers who vote based on a shared aggregated state to restrict sensitive information spread. Crucially, we balance our evaluation across compositions that expose sensitive information and compositions that yield benign inferences. Our experiments quantify how these defense strategies differ in balancing the privacy-utility trade-off. We find that while chain-of-thought alone offers limited protection to leakage (~39% sensitive blocking rate), our ToM defense substantially improves sensitive query blocking (up to 97%) but can reduce benign task success. CoDef achieves the best balance, yielding the highest Balanced Outcome (79.8%), highlighting the benefit of combining explicit reasoning with defender collaboration. Together, our results expose a new class of risks in collaborative LLM deployments and provide actionable insights for designing safeguards against compositional, context-driven privacy leakage.&quot;}, {'id': 'arxiv_2508.06225', 'title': 'Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution', 'URL': 'http://arxiv.org/abs/2508.06225', 'extra_urls': ['http://arxiv.org/abs/2508.06225'], 'type': 'article', 'author': [{'family': 'Tian', 'given': 'Zailong'}, {'family': 'Han', 'given': 'Zhuoheng'}, {'family': 'Chen', 'given': 'Yanzhe'}, {'family': 'Xu', 'given': 'Haozhe'}, {'family': 'Yang', 'given': 'Xi'}, {'family': 'Xuan', 'given': 'Richeng'}, {'family': 'Wang', 'given': 'Houfeng'}, {'family': 'Liao', 'given': 'Lizi'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) are widely used as automated judges, where practical value depends on both accuracy and trustworthy, risk-aware judgments. Existing approaches predominantly focus on accuracy, overlooking the necessity of well-calibrated confidence, which is vital for adaptive and reliable evaluation pipelines. In this work, we advocate a shift from accuracy-centric evaluation to confidence-driven, risk-aware LLM-as-a-Judge systems, emphasizing the necessity of well-calibrated confidence for trustworthy and adaptive evaluation. We systematically identify the Overconfidence Phenomenon in current LLM-as-a-Judges, where predicted confidence significantly overstates actual correctness, undermining reliability in practical deployment. To quantify this phenomenon, we introduce TH-Score, a novel metric measuring confidence-accuracy alignment. Furthermore, we propose LLM-as-a-Fuser, an ensemble framework that transforms LLMs into reliable, risk-aware evaluators. Extensive experiments demonstrate that our approach substantially improves calibration and enables adaptive, confidence-driven evaluation pipelines, achieving superior reliability and accuracy compared to existing baselines.'}, {'id': 'arxiv_2501.10970', 'title': 'The Alternative Annotator Test for LLM-as-a-Judge: How to Statistically Justify Replacing Human Annotators with LLMs', 'URL': 'http://arxiv.org/abs/2501.10970', 'extra_urls': ['http://arxiv.org/abs/2501.10970'], 'type': 'article', 'author': [{'family': 'Calderon', 'given': 'Nitay'}, {'family': 'Reichart', 'given': 'Roi'}, {'family': 'Dror', 'given': 'Rotem'}], 'publisher': 'arXiv', 'abstract': 'The &quot;LLM-as-an-annotator&quot; and &quot;LLM-as-a-judge&quot; paradigms employ Large Language Models (LLMs) as annotators, judges, and evaluators in tasks traditionally performed by humans. LLM annotations are widely used, not only in NLP research but also in fields like medicine, psychology, and social science. Despite their role in shaping study results and insights, there is no standard or rigorous procedure to determine whether LLMs can replace human annotators. In this paper, we propose a novel statistical procedure, the Alternative Annotator Test (alt-test), that requires only a modest subset of annotated examples to justify using LLM annotations. Additionally, we introduce a versatile and interpretable measure for comparing LLM annotators and judges. To demonstrate our procedure, we curated a diverse collection of ten datasets, consisting of language and vision-language tasks, and conducted experiments with six LLMs and four prompting techniques. Our results show that LLMs can sometimes replace humans with closed-source LLMs (such as GPT-4o), outperforming the open-source LLMs we examine, and that prompting techniques yield judges of varying quality. We hope this study encourages more rigorous and reliable practices.'}, {'id': 'arxiv_2410.15393', 'title': 'CalibraEval: Calibrating Prediction Distribution to Mitigate Selection Bias in LLMs-as-Judges', 'URL': 'http://arxiv.org/abs/2410.15393', 'extra_urls': ['http://arxiv.org/abs/2410.15393'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Haitao'}, {'family': 'Chen', 'given': 'Junjie'}, {'family': 'Ai', 'given': 'Qingyao'}, {'family': 'Chu', 'given': 'Zhumin'}, {'family': 'Zhou', 'given': 'Yujia'}, {'family': 'Dong', 'given': 'Qian'}, {'family': 'Liu', 'given': 'Yiqun'}], 'publisher': 'arXiv', 'abstract': 'The use of large language models (LLMs) as automated evaluation tools to assess the quality of generated natural language, known as LLMs-as-Judges, has demonstrated promising capabilities and is rapidly gaining widespread attention. However, when applied to pairwise comparisons of candidate responses, LLM-based evaluators often exhibit selection bias. Specifically, their judgments may become inconsistent when the option positions or ID tokens are swapped, compromising the effectiveness and fairness of the evaluation result. To address this challenge, we introduce CalibraEval, a novel label-free method for mitigating selection bias during inference. Specifically, CalibraEval reformulates debiasing as an optimization task aimed at adjusting observed prediction distributions to align with unbiased prediction distributions. To solve this optimization problem, we propose a non-parametric order-preserving algorithm (NOA). This algorithm leverages the partial order relationships between model prediction distributions, thereby eliminating the need for explicit labels and precise mathematical function modeling.Empirical evaluations of LLMs in multiple representative benchmarks demonstrate that CalibraEval effectively mitigates selection bias and improves performance compared to existing debiasing methods. This work marks a step toward building more robust and unbiased automated evaluation frameworks, paving the way for improved reliability in AI-driven assessments'}, {'id': 'arxiv_2508.18725', 'title': 'Toward Edge General Intelligence with Agentic AI and Agentification: Concepts, Technologies, and Future Directions', 'URL': 'http://arxiv.org/abs/2508.18725', 'extra_urls': ['http://arxiv.org/abs/2508.18725'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Ruichen'}, {'family': 'Liu', 'given': 'Guangyuan'}, {'family': 'Liu', 'given': 'Yinqiu'}, {'family': 'Zhao', 'given': 'Changyuan'}, {'family': 'Wang', 'given': 'Jiacheng'}, {'family': 'Xu', 'given': 'Yunting'}, {'family': 'Niyato', 'given': 'Dusit'}, {'family': 'Kang', 'given': 'Jiawen'}, {'family': 'Li', 'given': 'Yonghui'}, {'family': 'Mao', 'given': 'Shiwen'}, {'family': 'Sun', 'given': 'Sumei'}, {'family': 'Shen', 'given': 'Xuemin'}, {'family': 'Kim', 'given': 'Dong In'}], 'publisher': 'arXiv', 'abstract': &quot;The rapid expansion of sixth-generation (6G) wireless networks and the Internet of Things (IoT) has catalyzed the evolution from centralized cloud intelligence towards decentralized edge general intelligence. However, traditional edge intelligence methods, characterized by static models and limited cognitive autonomy, fail to address the dynamic, heterogeneous, and resource-constrained scenarios inherent to emerging edge networks. Agentic artificial intelligence (Agentic AI) emerges as a transformative solution, enabling edge systems to autonomously perceive multimodal environments, reason contextually, and adapt proactively through continuous perception-reasoning-action loops. In this context, the agentification of edge intelligence serves as a key paradigm shift, where distributed entities evolve into autonomous agents capable of collaboration and continual adaptation. This paper presents a comprehensive survey dedicated to Agentic AI and agentification frameworks tailored explicitly for edge general intelligence. First, we systematically introduce foundational concepts and clarify distinctions from traditional edge intelligence paradigms. Second, we analyze important enabling technologies, including compact model compression, energy-aware computing strategies, robust connectivity frameworks, and advanced knowledge representation and reasoning mechanisms. Third, we provide representative case studies demonstrating Agentic AI's capabilities in low-altitude economy networks, intent-driven networking, vehicular networks, and human-centric service provisioning, supported by numerical evaluations. Furthermore, we identify current research challenges, review emerging open-source platforms, and highlight promising future research directions to guide robust, scalable, and trustworthy Agentic AI deployments for next-generation edge environments.&quot;}, {'id': 'arxiv_2510.08529', 'title': 'CoMAS: Co-Evolving Multi-Agent Systems via Interaction Rewards', 'URL': 'http://arxiv.org/abs/2510.08529', 'extra_urls': ['http://arxiv.org/abs/2510.08529'], 'type': 'article', 'author': [{'family': 'Xue', 'given': 'Xiangyuan'}, {'family': 'Zhou', 'given': 'Yifan'}, {'family': 'Zhang', 'given': 'Guibin'}, {'family': 'Zhang', 'given': 'Zaibin'}, {'family': 'Li', 'given': 'Yijiang'}, {'family': 'Zhang', 'given': 'Chen'}, {'family': 'Yin', 'given': 'Zhenfei'}, {'family': 'Torr', 'given': 'Philip'}, {'family': 'Ouyang', 'given': 'Wanli'}, {'family': 'Bai', 'given': 'Lei'}], 'publisher': 'arXiv', 'abstract': &quot;Self-evolution is a central research topic in enabling large language model (LLM)-based agents to continually improve their capabilities after pretraining. Recent research has witnessed a transition from reinforcement learning (RL)-free to RL-based methods. Current RL-based methods either rely on dense external reward signals or extract intrinsic reward signals from LLMs themselves. However, these approaches diverge from the self-evolution mechanisms observed in human intelligence, where individuals learn and improve through mutual discussion and collaboration. In this work, we introduce Co-Evolving Multi-Agent Systems (CoMAS), a novel framework that enables agents to improve autonomously by learning from inter-agent interactions without external supervision. CoMAS generates intrinsic rewards from rich discussion dynamics, employs an LLM-as-a-judge mechanism to formulate these rewards, and optimizes each agent's policy through RL, thereby enabling decentralized and scalable co-evolution. Experimental results demonstrate that CoMAS consistently outperforms untrained agents and achieves state-of-the-art performance across most evaluation settings. Ablation studies confirm the necessity of interaction-based reward signals and reveal promising scalability as the number and diversity of agents increase. These findings establish CoMAS as a novel and effective paradigm for self-evolution in LLM-based agents.&quot;}, {'id': 'arxiv_2509.15160', 'title': 'An Evaluation-Centric Paradigm for Scientific Visualization Agents', 'URL': 'http://arxiv.org/abs/2509.15160', 'extra_urls': ['http://arxiv.org/abs/2509.15160'], 'type': 'article', 'author': [{'family': 'Ai', 'given': 'Kuangshi'}, {'family': 'Miao', 'given': 'Haichao'}, {'family': 'Li', 'given': 'Zhimin'}, {'family': 'Wang', 'given': 'Chaoli'}, {'family': 'Liu', 'given': 'Shusen'}], 'publisher': 'arXiv', 'abstract': 'Recent advances in multi-modal large language models (MLLMs) have enabled increasingly sophisticated autonomous visualization agents capable of translating user intentions into data visualizations. However, measuring progress and comparing different agents remains challenging, particularly in scientific visualization (SciVis), due to the absence of comprehensive, large-scale benchmarks for evaluating real-world capabilities. This position paper examines the various types of evaluation required for SciVis agents, outlines the associated challenges, provides a simple proof-of-concept evaluation example, and discusses how evaluation benchmarks can facilitate agent self-improvement. We advocate for a broader collaboration to develop a SciVis agentic evaluation benchmark that would not only assess existing capabilities but also drive innovation and stimulate future development in the field.'}, {'id': 'arxiv_2508.21148', 'title': 'A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers', 'URL': 'http://arxiv.org/abs/2508.21148', 'extra_urls': ['http://arxiv.org/abs/2508.21148'], 'type': 'article', 'author': [{'family': 'Hu', 'given': 'Ming'}, {'family': 'Ma', 'given': 'Chenglong'}, {'family': 'Li', 'given': 'Wei'}, {'family': 'Xu', 'given': 'Wanghan'}, {'family': 'Wu', 'given': 'Jiamin'}, {'family': 'Hu', 'given': 'Jucheng'}, {'family': 'Li', 'given': 'Tianbin'}, {'family': 'Zhuang', 'given': 'Guohang'}, {'family': 'Liu', 'given': 'Jiaqi'}, {'family': 'Lu', 'given': 'Yingzhou'}, {'family': 'Chen', 'given': 'Ying'}, {'family': 'Zhang', 'given': 'Chaoyang'}, {'family': 'Tan', 'given': 'Cheng'}, {'family': 'Ying', 'given': 'Jie'}, {'family': 'Wu', 'given': 'Guocheng'}, {'family': 'Gao', 'given': 'Shujian'}, {'family': 'Chen', 'given': 'Pengcheng'}, {'family': 'Lin', 'given': 'Jiashi'}, {'family': 'Wu', 'given': 'Haitao'}, {'family': 'Chen', 'given': 'Lulu'}, {'family': 'Wang', 'given': 'Fengxiang'}, {'family': 'Zhang', 'given': 'Yuanyuan'}, {'family': 'Zhao', 'given': 'Xiangyu'}, {'family': 'Tang', 'given': 'Feilong'}, {'family': 'Su', 'given': 'Encheng'}, {'family': 'Ning', 'given': 'Junzhi'}, {'family': 'Liu', 'given': 'Xinyao'}, {'family': 'Du', 'given': 'Ye'}, {'family': 'Ji', 'given': 'Changkai'}, {'family': 'Jiang', 'given': 'Pengfei'}, {'family': 'Tang', 'given': 'Cheng'}, {'family': 'Huang', 'given': 'Ziyan'}, {'family': 'Liu', 'given': 'Jiyao'}, {'family': 'Wei', 'given': 'Jiaqi'}, {'family': 'Yang', 'given': 'Yuejin'}, {'family': 'Zhang', 'given': 'Xiang'}, {'family': 'Wang', 'given': 'Guangshuai'}, {'family': 'Yang', 'given': 'Yue'}, {'family': 'Xu', 'given': 'Huihui'}, {'family': 'Chen', 'given': 'Ziyang'}, {'family': 'Wang', 'given': 'Yizhou'}, {'family': 'Tang', 'given': 'Chen'}, {'family': 'Wu', 'given': 'Jianyu'}, {'family': 'Ren', 'given': 'Yuchen'}, {'family': 'Yan', 'given': 'Siyuan'}, {'family': 'Wang', 'given': 'Zhonghua'}, {'family': 'Xu', 'given': 'Zhongxing'}, {'family': 'Su', 'given': 'Shiyan'}, {'family': 'Sun', 'given': 'Shangquan'}, {'family': 'Zhao', 'given': 'Runkai'}, {'family': 'Zhang', 'given': 'Zhisheng'}, {'family': 'Yang', 'given': 'Dingkang'}, {'family': 'Wei', 'given': 'Jinjie'}, {'family': 'Wang', 'given': 'Jiaqi'}, {'family': 'Xu', 'given': 'Jiahao'}, {'family': 'Yan', 'given': 'Jiangtao'}, {'family': 'Tang', 'given': 'Wenhao'}, {'family': 'Zhu', 'given': 'Hongze'}, {'family': 'Liu', 'given': 'Yu'}, {'family': 'Wang', 'given': 'Fudi'}, {'family': 'Shen', 'given': 'Yiqing'}, {'family': 'Ji', 'given': 'Yuanfeng'}, {'family': 'Su', 'given': 'Yanzhou'}, {'family': 'Xie', 'given': 'Tong'}, {'family': 'Shan', 'given': 'Hongming'}, {'family': 'Feng', 'given': 'Chun-Mei'}, {'family': 'Hou', 'given': 'Zhi'}, {'family': 'Song', 'given': 'Diping'}, {'family': 'Liu', 'given': 'Lihao'}, {'family': 'Huang', 'given': 'Yanyan'}, {'family': 'Yu', 'given': 'Lequan'}, {'family': 'Fu', 'given': 'Bin'}, {'family': 'Wang', 'given': 'Shujun'}, {'family': 'Li', 'given': 'Xiaomeng'}, {'family': 'Hu', 'given': 'Xiaowei'}, {'family': 'Gu', 'given': 'Yun'}, {'family': 'Fei', 'given': 'Ben'}, {'family': 'Wang', 'given': 'Benyou'}, {'family': 'Cao', 'given': 'Yuewen'}, {'family': 'Shen', 'given': 'Minjie'}, {'family': 'Xu', 'given': 'Jie'}, {'family': 'Duan', 'given': 'Haodong'}, {'family': 'Yan', 'given': 'Fang'}, {'family': 'Hao', 'given': 'Hongxia'}, {'family': 'Li', 'given': 'Jielan'}, {'family': 'Du', 'given': 'Jiajun'}, {'family': 'Wang', 'given': 'Yanbo'}, {'family': 'Razzak', 'given': 'Imran'}, {'family': 'Deng', 'given': 'Zhongying'}, {'family': 'Zhang', 'given': 'Chi'}, {'family': 'Wu', 'given': 'Lijun'}, {'family': 'He', 'given': 'Conghui'}, {'family': 'Lu', 'given': 'Zhaohui'}, {'family': 'Huang', 'given': 'Jinhai'}, {'family': 'Shao', 'given': 'Wenqi'}, {'family': 'Liu', 'given': 'Yihao'}, {'family': 'Luo', 'given': 'Siqi'}, {'family': 'Xin', 'given': 'Yi'}, {'family': 'Liu', 'given': 'Xiaohong'}, {'family': 'Ling', 'given': 'Fenghua'}, {'family': 'Li', 'given': 'Yuqiang'}, {'family': 'Wang', 'given': 'Aoran'}, {'family': 'Sun', 'given': 'Siqi'}, {'family': 'Zheng', 'given': 'Qihao'}, {'family': 'Dong', 'given': 'Nanqing'}, {'family': 'Fu', 'given': 'Tianfan'}, {'family': 'Zhou', 'given': 'Dongzhan'}, {'family': 'Lu', 'given': 'Yan'}, {'family': 'Zhang', 'given': 'Wenlong'}, {'family': 'Ye', 'given': 'Jin'}, {'family': 'Cai', 'given': 'Jianfei'}, {'family': 'Chen', 'given': 'Yirong'}, {'family': 'Ouyang', 'given': 'Wanli'}, {'family': 'Qiao', 'given': 'Yu'}, {'family': 'Ge', 'given': 'Zongyuan'}, {'family': 'Tang', 'given': 'Shixiang'}, {'family': 'He', 'given': 'Junjun'}, {'family': 'Song', 'given': 'Chunfeng'}, {'family': 'Bai', 'given': 'Lei'}, {'family': 'Zhou', 'given': 'Bowen'}], 'publisher': 'arXiv', 'abstract': 'Scientific Large Language Models (Sci-LLMs) are transforming how knowledge is represented, integrated, and applied in scientific research, yet their progress is shaped by the complex nature of scientific data. This survey presents a comprehensive, data-centric synthesis that reframes the development of Sci-LLMs as a co-evolution between models and their underlying data substrate. We formulate a unified taxonomy of scientific data and a hierarchical model of scientific knowledge, emphasizing the multimodal, cross-scale, and domain-specific challenges that differentiate scientific corpora from general natural language processing datasets. We systematically review recent Sci-LLMs, from general-purpose foundations to specialized models across diverse scientific disciplines, alongside an extensive analysis of over 270 pre-/post-training datasets, showing why Sci-LLMs pose distinct demands -- heterogeneous, multi-scale, uncertainty-laden corpora that require representations preserving domain invariance and enabling cross-modal reasoning. On evaluation, we examine over 190 benchmark datasets and trace a shift from static exams toward process- and discovery-oriented assessments with advanced evaluation protocols. These data-centric analyses highlight persistent issues in scientific data development and discuss emerging solutions involving semi-automated annotation pipelines and expert validation. Finally, we outline a paradigm shift toward closed-loop systems where autonomous agents based on Sci-LLMs actively experiment, validate, and contribute to a living, evolving knowledge base. Collectively, this work provides a roadmap for building trustworthy, continually evolving artificial intelligence (AI) systems that function as a true partner in accelerating scientific discovery.'}, {'id': 'arxiv_2508.02994', 'title': 'When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs', 'URL': 'http://arxiv.org/abs/2508.02994', 'extra_urls': ['http://arxiv.org/abs/2508.02994'], 'type': 'article', 'author': [{'family': 'Yu', 'given': 'Fangyi'}], 'publisher': 'arXiv', 'abstract': 'As large language models (LLMs) grow in capability and autonomy, evaluating their outputs-especially in open-ended and complex tasks-has become a critical bottleneck. A new paradigm is emerging: using AI agents as the evaluators themselves. This &quot;agent-as-a-judge&quot; approach leverages the reasoning and perspective-taking abilities of LLMs to assess the quality and safety of other models, promising calable and nuanced alternatives to human evaluation. In this review, we define the agent-as-a-judge concept, trace its evolution from single-model judges to dynamic multi-agent debate frameworks, and critically examine their strengths and shortcomings. We compare these approaches across reliability, cost, and human alignment, and survey real-world deployments in domains such as medicine, law, finance, and education. Finally, we highlight pressing challenges-including bias, robustness, and meta evaluation-and outline future research directions. By bringing together these strands, our review demonstrates how agent-based judging can complement (but not replace) human oversight, marking a step toward trustworthy, scalable evaluation for next-generation LLMs.'}, {'id': 'arxiv_2510.15186', 'title': 'MAGPIE: A benchmark for Multi-AGent contextual PrIvacy Evaluation', 'URL': 'http://arxiv.org/abs/2510.15186', 'extra_urls': ['http://arxiv.org/abs/2510.15186'], 'type': 'article', 'author': [{'family': 'Juneja', 'given': 'Gurusha'}, {'family': 'Pasupulati', 'given': 'Jayanth Naga Sai'}, {'family': 'Albalak', 'given': 'Alon'}, {'family': 'Hua', 'given': 'Wenyue'}, {'family': 'Wang', 'given': 'William Yang'}], 'publisher': 'arXiv', 'abstract': 'A core challenge for autonomous LLM agents in collaborative settings is balancing robust privacy understanding and preservation alongside task efficacy. Existing privacy benchmarks only focus on simplistic, single-turn interactions where private information can be trivially omitted without affecting task outcomes. In this paper, we introduce MAGPIE (Multi-AGent contextual PrIvacy Evaluation), a novel benchmark of 200 high-stakes tasks designed to evaluate privacy understanding and preservation in multi-agent collaborative, non-adversarial scenarios. MAGPIE integrates private information as essential for task resolution, forcing agents to balance effective collaboration with strategic information control. Our evaluation reveals that state-of-the-art agents, including GPT-5 and Gemini 2.5-Pro, exhibit significant privacy leakage, with Gemini 2.5-Pro leaking up to 50.7% and GPT-5 up to 35.1% of the sensitive information even when explicitly instructed not to. Moreover, these agents struggle to achieve consensus or task completion and often resort to undesirable behaviors such as manipulation and power-seeking (e.g., Gemini 2.5-Pro demonstrating manipulation in 38.2% of the cases). These findings underscore that current LLM agents lack robust privacy understanding and are not yet adequately aligned to simultaneously preserve privacy and maintain effective collaboration in complex environments.'}, {'id': 'arxiv_2412.14461', 'title': 'To Err Is Human; To Annotate, SILICON? Reducing Measurement Error in LLM Annotation', 'URL': 'http://arxiv.org/abs/2412.14461', 'extra_urls': ['http://arxiv.org/abs/2412.14461'], 'type': 'article', 'author': [{'family': 'Cheng', 'given': 'Xiang'}, {'family': 'Mayya', 'given': 'Raveesh'}, {'family': 'Sedoc', 'given': 'Jo\xe3o'}], 'publisher': 'arXiv', 'abstract': 'Unstructured text data annotation is foundational to management research and Large Language Models (LLMs) promise a cost-effective and scalable alternative to human annotation. The validity of insights drawn from LLM annotated data critically depends on minimizing the discrepancy between LLM assigned labels and the unobserved ground truth, as well as ensuring long-term reproducibility of results. We address the gap in the literature on LLM annotation by decomposing measurement error in LLM-based text annotation into four distinct sources: (1) guideline-induced error from inconsistent annotation criteria, (2) baseline-induced error from unreliable human reference standards, (3) prompt-induced error from suboptimal meta-instruction formatting, and (4) model-induced error from architectural differences across LLMs. We develop the SILICON methodology to systematically reduce measurement error from LLM annotation in all four sources above. Empirical validation across seven management research cases shows iteratively refined guidelines substantially increases the LLM-human agreement compared to one-shot guidelines; expert-generated baselines exhibit higher inter-annotator agreement as well as are less prone to producing misleading LLM-human agreement estimates compared to crowdsourced baselines; placing content in the system prompt reduces prompt-induced error; and model performance varies substantially across tasks. To further reduce error, we introduce a cost-effective multi-LLM labeling method, where only low-confidence items receive additional labels from alternative models. Finally, in addressing closed source model retirement cycles, we introduce an intuitive regression-based methodology to establish robust reproducibility protocols. Our evidence indicates that reducing each error source is necessary, and that SILICON supports reproducible, rigorous annotation in management research.'}, {'id': 'arxiv_2504.10768', 'title': 'The Art of Audience Engagement: LLM-Based Thin-Slicing of Scientific Talks', 'URL': 'http://arxiv.org/abs/2504.10768', 'extra_urls': ['http://arxiv.org/abs/2504.10768'], 'type': 'article', 'author': [{'family': 'Schm\xe4lzle', 'given': 'Ralf'}, {'family': 'Lim', 'given': 'Sue'}, {'family': 'Du', 'given': 'Yuetong'}, {'family': 'Bente', 'given': 'Gary'}], 'publisher': 'arXiv', 'abstract': 'This paper examines the thin-slicing approach - the ability to make accurate judgments based on minimal information - in the context of scientific presentations. Drawing on research from nonverbal communication and personality psychology, we show that brief excerpts (thin slices) reliably predict overall presentation quality. Using a novel corpus of over one hundred real-life science talks, we employ Large Language Models (LLMs) to evaluate transcripts of full presentations and their thin slices. By correlating LLM-based evaluations of short excerpts with full-talk assessments, we determine how much information is needed for accurate predictions. Our results demonstrate that LLM-based evaluations align closely with human ratings, proving their validity, reliability, and efficiency. Critically, even very short excerpts (less than 10 percent of a talk) strongly predict overall evaluations. This suggests that the first moments of a presentation convey relevant information that is used in quality evaluations and can shape lasting impressions. The findings are robust across different LLMs and prompting strategies. This work extends thin-slicing research to public speaking and connects theories of impression formation to LLMs and current research on AI communication. We discuss implications for communication and social cognition research on message reception. Lastly, we suggest an LLM-based thin-slicing framework as a scalable feedback tool to enhance human communication.'}, {'id': 'llms_do', 'title': &quot;Can't LLMs do that? Supporting Third-Party Audits under the DSA: Exploring Large Language Models for Systemic Risk Evaluation of the Digital Services Act in an Interdisciplinary Setting&quot;, 'URL': 'https://dl.acm.org/doi/10.1145/3707640.3731929', 'type': 'article', 'author': [{'family': 'Sekwenz', 'given': 'Marie-Therese'}, {'family': 'Gsenger', 'given': 'Rita'}, {'family': 'Stocker', 'given': 'Volker'}, {'family': 'G\xf6rnemann', 'given': 'Esther'}, {'family': 'Talypova', 'given': 'Dinara'}, {'family': 'Parkin', 'given': 'Simon'}, {'family': 'Greminger', 'given': 'Lea'}, {'family': 'Smaragdakis', 'given': 'Georgios'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'This paper investigates the feasibility and potential role of using Large Language Models (LLMs) to support systemic risk audits under the European Union\u2019s Digital Services Act (DSA). It examines how automated tools can enhance the work of DSA auditors and other ecosystem actors by enabling scalable, explainable, and legally grounded content analysis. An interdisciplinary expert workshop with twelve participants from legal, technical, and social science backgrounds explored prompting strategies for LLM-assisted auditing. Thematic analysis of the sessions identified key challenges and design considerations, including prompt engineering, model interpretability, legal alignment, and user empowerment. Findings highlight the potential of LLMs to improve annotation workflows and expand audit scale, while underscoring the continued importance of human oversight, iterative testing, and cross-disciplinary collaboration. This study offers practical insights for integrating AI tools into auditing processes and contributes to emerging methodologies for operationalizing systemic risk evaluations under the DSA.'}, {'id': 'arxiv_2411.15594', 'title': 'A Survey on LLM-as-a-Judge', 'URL': 'http://arxiv.org/abs/2411.15594', 'extra_urls': ['http://arxiv.org/abs/2411.15594'], 'type': 'article', 'author': [{'family': 'Gu', 'given': 'Jiawei'}, {'family': 'Jiang', 'given': 'Xuhui'}, {'family': 'Shi', 'given': 'Zhichao'}, {'family': 'Tan', 'given': 'Hexiang'}, {'family': 'Zhai', 'given': 'Xuehao'}, {'family': 'Xu', 'given': 'Chengjin'}, {'family': 'Li', 'given': 'Wei'}, {'family': 'Shen', 'given': 'Yinghan'}, {'family': 'Ma', 'given': 'Shengjie'}, {'family': 'Liu', 'given': 'Honghao'}, {'family': 'Wang', 'given': 'Saizhuo'}, {'family': 'Zhang', 'given': 'Kun'}, {'family': 'Wang', 'given': 'Yuanzhuo'}, {'family': 'Gao', 'given': 'Wen'}, {'family': 'Ni', 'given': 'Lionel'}, {'family': 'Guo', 'given': 'Jian'}], 'publisher': 'arXiv', 'abstract': 'Accurate and consistent evaluation is crucial for decision-making across numerous fields, yet it remains a challenging task due to inherent subjectivity, variability, and scale. Large Language Models (LLMs) have achieved remarkable success across diverse domains, leading to the emergence of &quot;LLM-as-a-Judge,&quot; where LLMs are employed as evaluators for complex tasks. With their ability to process diverse data types and provide scalable, cost-effective, and consistent assessments, LLMs present a compelling alternative to traditional expert-driven evaluations. However, ensuring the reliability of LLM-as-a-Judge systems remains a significant challenge that requires careful design and standardization. This paper provides a comprehensive survey of LLM-as-a-Judge, addressing the core question: How can reliable LLM-as-a-Judge systems be built? We explore strategies to enhance reliability, including improving consistency, mitigating biases, and adapting to diverse assessment scenarios. Additionally, we propose methodologies for evaluating the reliability of LLM-as-a-Judge systems, supported by a novel benchmark designed for this purpose. To advance the development and real-world deployment of LLM-as-a-Judge systems, we also discussed practical applications, challenges, and future directions. This survey serves as a foundational reference for researchers and practitioners in this rapidly evolving field.'}, {'id': 'a_system', 'title': 'Plurals: A System for Guiding LLMs via Simulated Social Ensembles', 'URL': 'https://dl.acm.org/doi/10.1145/3706598.3713675', 'type': 'article', 'author': [{'family': 'Ashkinaze', 'given': 'Joshua'}, {'family': 'Fry', 'given': 'Emily'}, {'family': 'Edara', 'given': 'Narendra'}, {'family': 'Gilbert', 'given': 'Eric'}, {'family': 'Budak', 'given': 'Ceren'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Recent debates raised concerns that language models may favor certain viewpoints. But what if the solution is not to aim for a \u201cview from nowhere\u201d but rather to leverage different viewpoints? We introduce Plurals, a system and Python library for pluralistic AI deliberation. Plurals consists of Agents (LLMs, optionally with personas) which deliberate within customizable Structures, with Moderators overseeing deliberation. Plurals is a generator of simulated social ensembles. Plurals integrates with government datasets to create nationally representative personas, includes deliberation templates inspired by deliberative democracy, and allows users to customize both information-sharing structures and deliberation behavior within Structures. Six case studies demonstrate fidelity to theoretical constructs and efficacy. Three randomized experiments show simulated focus groups produced output resonant with an online sample of the relevant audiences (chosen over zero-shot generation in 75% of trials). Plurals is both a paradigm and a concrete system for pluralistic AI.'}, {'id': 'can_video_llms', 'title': 'Can Video LLMs Refuse to Answer? Alignment for Answerability in Video Large Language Models', 'URL': 'https://openreview.net/forum?id=P9VdRQOyqu', 'extra_urls': ['https://openreview.net/forum?id=P9VdRQOyqu'], 'type': 'article', 'author': [{'family': 'Yoon', 'given': 'Eunseop'}, {'family': 'Yoon', 'given': 'Hee Suk'}, {'family': 'Hasegawa-Johnson', 'given': 'Mark A.'}, {'family': 'Yoo', 'given': 'Chang D.'}], 'abstract': 'In the broader context of deep learning, Multimodal Large Language Models have achieved significant breakthroughs by leveraging powerful Large Language Models as a backbone to align different modalities into the language space. A prime exemplification is the development of Video Large Language Models (Video-LLMs). While numerous advancements have been proposed to enhance the video understanding capabilities of these models, they are predominantly trained on questions generated directly from video content. However, in real-world scenarios, users often pose questions that extend beyond the informational scope of the video, highlighting the need for Video-LLMs to assess the relevance of the question. We demonstrate that even the best-performing Video-LLMs fail to reject unfit questions-not necessarily due to a lack of video understanding, but because they have not been trained to identify and refuse such questions. To address this limitation, we propose alignment for answerability, a framework that equips Video-LLMs with the ability to evaluate the relevance of a question based on the input video and appropriately decline to answer when the question exceeds the scope of the video, as well as an evaluation framework with a comprehensive set of metrics designed to measure model behavior before and after alignment. Furthermore, we present a pipeline for creating a dataset specifically tailored for alignment for answerability, leveraging existing video-description paired datasets.'}, {'id': 'arxiv_2502.12964', 'title': &quot;Trust Me, I'm Wrong: LLMs Hallucinate with Certainty Despite Knowing the Answer&quot;, 'URL': 'http://arxiv.org/abs/2502.12964', 'extra_urls': ['http://arxiv.org/abs/2502.12964'], 'type': 'article', 'author': [{'family': 'Simhi', 'given': 'Adi'}, {'family': 'Itzhak', 'given': 'Itay'}, {'family': 'Barez', 'given': 'Fazl'}, {'family': 'Stanovsky', 'given': 'Gabriel'}, {'family': 'Belinkov', 'given': 'Yonatan'}], 'publisher': 'arXiv', 'abstract': 'Prior work on large language model (LLM) hallucinations has associated them with model uncertainty or inaccurate knowledge. In this work, we define and investigate a distinct type of hallucination, where a model can consistently answer a question correctly, but a seemingly trivial perturbation, which can happen in real-world settings, causes it to produce a hallucinated response with high certainty. This phenomenon, which we dub CHOKE (Certain Hallucinations Overriding Known Evidence), is particularly concerning in high-stakes domains such as medicine or law, where model certainty is often used as a proxy for reliability. We show that CHOKE examples are consistent across prompts, occur in different models and datasets, and are fundamentally distinct from other hallucinations. This difference leads existing mitigation methods to perform worse on CHOKE examples than on general hallucinations. Finally, we introduce a probing-based mitigation that outperforms existing methods on CHOKE hallucinations. These findings reveal an overlooked aspect of hallucinations, emphasizing the need to understand their origins and improve mitigation strategies to enhance LLM safety. The code is available at https://github.com/technion-cs-nlp/Trust_me_Im_wrong .'}, {'id': 'arxiv_2506.09038', 'title': 'AbstentionBench: Reasoning LLMs Fail on Unanswerable Questions', 'URL': 'http://arxiv.org/abs/2506.09038', 'extra_urls': ['http://arxiv.org/abs/2506.09038'], 'type': 'article', 'author': [{'family': 'Kirichenko', 'given': 'Polina'}, {'family': 'Ibrahim', 'given': 'Mark'}, {'family': 'Chaudhuri', 'given': 'Kamalika'}, {'family': 'Bell', 'given': 'Samuel J.'}], 'publisher': 'arXiv', 'abstract': &quot;For Large Language Models (LLMs) to be reliably deployed in both everyday and high-stakes domains, knowing when not to answer is equally critical as answering correctly. Real-world user queries, which can be underspecified, ill-posed, or fundamentally unanswerable, require LLMs to reason about uncertainty and selectively abstain -- i.e., refuse to answer definitively. However, abstention remains understudied, without a systematic evaluation framework for modern LLMs. In this work, we introduce AbstentionBench, a large-scale benchmark for holistically evaluating abstention across 20 diverse datasets, including questions with unknown answers, underspecification, false premises, subjective interpretations, and outdated information. Evaluating 20 frontier LLMs reveals abstention is an unsolved problem, and one where scaling models is of little use. While recent reasoning LLMs have shown impressive results in complex problem solving, surprisingly, we find that reasoning fine-tuning degrades abstention (by $24\\%$ on average), even for math and science domains on which reasoning models are explicitly trained. We find that while a carefully crafted system prompt can boost abstention in practice, it does not resolve models' fundamental inability to reason about uncertainty. We release AbstentionBench to foster research into advancing LLM reliability.&quot;}, {'id': 'arxiv_2510.10390', 'title': 'RefusalBench: Generative Evaluation of Selective Refusal in Grounded Language Models', 'URL': 'http://arxiv.org/abs/2510.10390', 'extra_urls': ['http://arxiv.org/abs/2510.10390'], 'type': 'article', 'author': [{'family': 'Muhamed', 'given': 'Aashiq'}, {'family': 'Ribeiro', 'given': 'Leonardo F. R.'}, {'family': 'Dreyer', 'given': 'Markus'}, {'family': 'Smith', 'given': 'Virginia'}, {'family': 'Diab', 'given': 'Mona T.'}], 'publisher': 'arXiv', 'abstract': 'The ability of language models in RAG systems to selectively refuse to answer based on flawed context is critical for safety, yet remains a significant failure point. Our large-scale study reveals that even frontier models struggle in this setting, with refusal accuracy dropping below 50% on multi-document tasks, while exhibiting either dangerous overconfidence or overcaution. Static benchmarks fail to reliably evaluate this capability, as models exploit dataset-specific artifacts and memorize test instances. We introduce RefusalBench, a generative methodology that programmatically creates diagnostic test cases through controlled linguistic perturbation. Our framework employs 176 distinct perturbation strategies across six categories of informational uncertainty and three intensity levels. Evaluation of over 30 models uncovers systematic failure patterns: refusal comprises separable detection and categorization skills, and neither scale nor extended reasoning improves performance. We find that selective refusal is a trainable, alignment-sensitive capability, offering a clear path for improvement. We release two benchmarks -- RefusalBench-NQ (single document) and RefusalBench-GaRAGe (multi-document) -- and our complete generation framework to enable continued, dynamic evaluation of this critical capability.'}, {'id': 'arxiv_2510.14591', 'title': 'Just-In-Time Objectives: A General Approach for Specialized AI Interactions', 'URL': 'http://arxiv.org/abs/2510.14591', 'extra_urls': ['http://arxiv.org/abs/2510.14591'], 'type': 'article', 'author': [{'family': 'Lam', 'given': 'Michelle S.'}, {'family': 'Shaikh', 'given': 'Omar'}, {'family': 'Xu', 'given': 'Hallie'}, {'family': 'Guo', 'given': 'Alice'}, {'family': 'Yang', 'given': 'Diyi'}, {'family': 'Heer', 'given': 'Jeffrey'}, {'family': 'Landay', 'given': 'James A.'}, {'family': 'Bernstein', 'given': 'Michael S.'}], 'publisher': 'arXiv', 'abstract': 'Large language models promise a broad set of functions, but when not given a specific objective, they default to milquetoast results such as drafting emails littered with cliches. We demonstrate that inferring the user\'s in-the-moment objective, then rapidly optimizing for that singular objective, enables LLMs to produce tools, interfaces, and responses that are more responsive and desired. We contribute an architecture for automatically inducing just-in-time objectives by passively observing user behavior, then steering downstream AI systems through generation and evaluation against this objective. Inducing just-in-time objectives (e.g., &quot;Clarify the abstract\'s research contribution&quot;) enables automatic generation of tools, e.g., those that critique a draft based on relevant HCI methodologies, anticipate related researchers\' reactions, or surface ambiguous terminology. In a series of experiments (N=14, N=205) on participants\' own tasks, JIT objectives enable LLM outputs that achieve 66-86% win rates over typical LLMs, and in-person use sessions (N=17) confirm that JIT objectives produce specialized tools unique to each participant.'}, {'id': 'uncovering_confident', 'title': 'Uncovering Confident Failures: The Complementary Roles of Aleatoric and Epistemic Uncertainty in LLMs', 'URL': 'https://openreview.net/forum?id=9Jq7wNrpUI#discussion', 'extra_urls': ['https://openreview.net/forum?id=9Jq7wNrpUI#discussion'], 'type': 'article', 'author': [{'family': 'Hamidieh', 'given': 'Kimia'}, {'family': 'Thost', 'given': 'Veronika'}, {'family': 'Gerych', 'given': 'Walter'}, {'family': 'Yurochkin', 'given': 'Mikhail'}, {'family': 'Ghassemi', 'given': 'Marzyeh'}], 'abstract': 'Large language models (LLMs) often produce confident yet incorrect responses, and uncertainty quantification in LLMs is one potential solution to more robust usage. Recent works routinely rely on self-consistency to estimate aleatoric uncertainty (AU), yet this proxy collapses precisely when models are overconfident, and produce the same incorrect answer across samples. We address this failure mode by introducing an epistemic term that measures semantic disagreement across a small ensemble of scale-matched LLMs. Specifically, we operationalize epistemic uncertainty (EU) as the gap between inter-model and intra-model response similarity, and define total uncertainty (TU) as the sum of AU and EU. The estimator is training-free and uses only black-box outputs: a few responses per model suffice. Across a range of LLMs, and long-form generation tasks, we compare TU to AU and measure uncertainty calibration by AUROC with respect to correctness and selective abstention via uncertainty thresholding. We find that TU consistently achieves higher AUROC in predicting correctness and improves selective abstention compared to AU alone. EU further exposes confident errors that AU misses, especially on tasks with near-unique correct answers, and improves the reliability of LLM uncertainty estimates.'}, {'id': 'arxiv_2508.01208', 'title': 'Calibrated Prediction Set in Fault Detection with Risk Guarantees via Significance Tests', 'URL': 'http://arxiv.org/abs/2508.01208', 'extra_urls': ['http://arxiv.org/abs/2508.01208'], 'type': 'article', 'author': [{'family': 'Mei', 'given': 'Mingchen'}, {'family': 'Li', 'given': 'Yi'}, {'family': 'Qian', 'given': 'YiYao'}, {'family': 'Jia', 'given': 'Zijun'}], 'publisher': 'arXiv', 'abstract': 'Fault detection is crucial for ensuring the safety and reliability of modern industrial systems. However, a significant scientific challenge is the lack of rigorous risk control and reliable uncertainty quantification in existing diagnostic models, particularly when facing complex scenarios such as distributional shifts. To address this issue, this paper proposes a novel fault detection method that integrates significance testing with the conformal prediction framework to provide formal risk guarantees. The method transforms fault detection into a hypothesis testing task by defining a nonconformity measure based on model residuals. It then leverages a calibration dataset to compute p-values for new samples, which are used to construct prediction sets mathematically guaranteed to contain the true label with a user-specified probability, $1-\\alpha$. Fault classification is subsequently performed by analyzing the intersection of the constructed prediction set with predefined normal and fault label sets. Experimental results on cross-domain fault diagnosis tasks validate the theoretical properties of our approach. The proposed method consistently achieves an empirical coverage rate at or above the nominal level ($1-\\alpha$), demonstrating robustness even when the underlying point-prediction models perform poorly. Furthermore, the results reveal a controllable trade-off between the user-defined risk level ($\\alpha$) and efficiency, where higher risk tolerance leads to smaller average prediction set sizes. This research contributes a theoretically grounded framework for fault detection that enables explicit risk control, enhancing the trustworthiness of diagnostic systems in safety-critical applications and advancing the field from simple point predictions to informative, uncertainty-aware outputs.'}, {'id': 'arxiv_2509.24202', 'title': 'Can Large Language Models Express Uncertainty Like Human?', 'URL': 'http://arxiv.org/abs/2509.24202', 'extra_urls': ['http://arxiv.org/abs/2509.24202'], 'type': 'article', 'author': [{'family': 'Tao', 'given': 'Linwei'}, {'family': 'Yeh', 'given': 'Yi-Fan'}, {'family': 'Kai', 'given': 'Bo'}, {'family': 'Dong', 'given': 'Minjing'}, {'family': 'Huang', 'given': 'Tao'}, {'family': 'Lamb', 'given': 'Tom A.'}, {'family': 'Yu', 'given': 'Jialin'}, {'family': 'Torr', 'given': 'Philip H. S.'}, {'family': 'Xu', 'given': 'Chang'}], 'publisher': 'arXiv', 'abstract': 'Large language models (LLMs) are increasingly used in high-stakes settings, where overconfident responses can mislead users. Reliable confidence estimation has been shown to enhance trust and task accuracy. Yet existing methods face practical barriers: logits are often hidden, multi-sampling is computationally expensive, and verbalized numerical uncertainty (e.g., giving a 0-100 score) deviates from natural communication. We revisit linguistic confidence (LC), where models express uncertainty through hedging language (e.g., probably, might), offering a lightweight and human-centered alternative. To advance this direction, we (1) release the first diverse, large-scale dataset of hedging expressions with human-annotated confidence scores, and (2) propose a lightweight mapper that converts hedges into confidence scores at near-zero cost. Building on these resources, we (3) conduct the first systematic study of LC across modern LLMs and QA benchmarks, revealing that while most LLMs underperform in expressing reliable LC, carefully designed prompting achieves competitive calibration and discriminability. Finally, we (4) introduce a fine-tuning framework that further improves LC reliability. Taken together, our work positions linguistic confidence as a scalable, efficient, and human-aligned approach to LLM uncertainty estimation, and calls for deeper exploration of this promising yet underexplored direction.'}, {'id': 'federated_learning', 'title': 'Confusion-Resistant Federated Learning via Diffusion-Based Data Harmonization on Non-IID Data', 'URL': 'https://openreview.net/forum?id=G89r8Mgi5r', 'extra_urls': ['https://openreview.net/forum?id=G89r8Mgi5r'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Xiaohong'}, {'family': 'Xiao', 'given': 'Canran'}, {'family': 'Liu', 'given': 'Yongmei'}], 'abstract': 'Federated learning has become a pivotal distributed learning paradigm, involving collaborative model updates across multiple nodes with private data. However, handling non-i.i.d. (not identically and independently distributed) data and ensuring model consistency across heterogeneous environments present significant challenges. These challenges often lead to model performance degradation and increased difficulty in achieving effective communication among participant models. In this work, we propose Confusion-Resistant Federated Learning via Consistent Diffusion (CRFed), a novel framework designed to address these issues. Our approach introduces a new diffusion-based data harmonization mechanism that includes data augmentation, noise injection, and iterative denoising to ensure consistent model updates across non-i.i.d. data distributions. This mechanism aims to reduce data distribution disparities among participating nodes, enhancing the coordination and consistency of model updates. Moreover, we design a confusion-resistant strategy leveraging an indicator function and adaptive learning rate adjustment to mitigate the adverse effects of data heterogeneity and model inconsistency. Specifically, we calculate importance sampling weights based on the optimal sampling probability, which guides the selection of clients and the sampling of their data, ensuring that model updates are robust and aligned across different nodes. Extensive experiments on benchmark datasets, including MNIST, FashionMNIST, CIFAR-10, CIFAR-100, and NIPD, demonstrate the effectiveness of CRFed in improving accuracy, convergence speed, and overall robustness in federated learning scenarios with severe data heterogeneity.'}, {'id': 'integrating_graceful_degradation', 'title': 'Integrating Graceful Degradation and Recovery through Requirement-driven Adaptation', 'URL': 'https://dl.acm.org/doi/10.1145/3643915.3644090', 'type': 'article', 'author': [{'family': 'Chu', 'given': 'Simon'}, {'family': 'Koe', 'given': 'Justin'}, {'family': 'Garlan', 'given': 'David'}, {'family': 'Kang', 'given': 'Eunsuk'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Cyber-physical systems (CPS) are subject to environmental uncertainties such as adverse operating conditions, malicious attacks, and hardware degradation. These uncertainties may lead to failures that put the system in a sub-optimal or unsafe state. Systems that are resilient to such uncertainties rely on two types of operations: (1) graceful degradation, for ensuring that the system maintains an acceptable level of safety during unexpected environmental conditions and (2) recovery, to facilitate the resumption of normal system functions. Typically, mechanisms for degradation and recovery are developed independently from each other, and later integrated into a system, requiring the designer to develop an additional, ad-hoc logic for activating and coordinating between the two operations.In this paper, we propose a self-adaptation approach for improving system resiliency through automated triggering and coordination of graceful degradation and recovery. The key idea behind our approach is to treat degradation and recovery as requirement-driven adaptation tasks: Degradation can be thought of as temporarily weakening original (i.e., ideal) system requirements to be achieved by the system, and recovery as strengthening the weakened requirements when the environment returns within an expected operating boundary. Furthermore, by treating weakening and strengthening as dual operations, we argue that a single requirement-based adaptation method is sufficient to enable coordination between degradation and recovery. Given system requirements specified in signal temporal logic (STL), we propose a run-time adaptation framework that performs degradation and recovery in response to environmental changes. We describe a prototype implementation of our framework and demonstrate the feasibility of the proposed approach using a case study in unmanned underwater vehicles.'}, {'id': 'arxiv_2502.14743', 'title': 'Multi-Agent Coordination across Diverse Applications: A Survey', 'URL': 'http://arxiv.org/abs/2502.14743', 'extra_urls': ['http://arxiv.org/abs/2502.14743'], 'type': 'article', 'author': [{'family': 'Sun', 'given': 'Lijun'}, {'family': 'Yang', 'given': 'Yijun'}, {'family': 'Duan', 'given': 'Qiqi'}, {'family': 'Shi', 'given': 'Yuhui'}, {'family': 'Lyu', 'given': 'Chao'}, {'family': 'Chang', 'given': 'Yu-Cheng'}, {'family': 'Lin', 'given': 'Chin-Teng'}, {'family': 'Shen', 'given': 'Yang'}], 'publisher': 'arXiv', 'abstract': 'Multi-agent coordination studies the underlying mechanism enabling the trending spread of diverse multi-agent systems (MAS) and has received increasing attention, driven by the expansion of emerging applications and rapid AI advances. This survey outlines the current state of coordination research across applications through a unified understanding that answers four fundamental coordination questions: (1) what is coordination; (2) why coordination; (3) who to coordinate with; and (4) how to coordinate. Our purpose is to explore existing ideas and expertise in coordination and their connections across diverse applications, while identifying and highlighting emerging and promising research directions. First, general coordination problems that are essential to varied applications are identified and analyzed. Second, a number of MAS applications are surveyed, ranging from widely studied domains, e.g., search and rescue, warehouse automation and logistics, and transportation systems, to emerging fields including humanoid and anthropomorphic robots, satellite systems, and large language models (LLMs). Finally, open challenges about the scalability, heterogeneity, and learning mechanisms of MAS are analyzed and discussed. In particular, we identify the hybridization of hierarchical and decentralized coordination, human-MAS coordination, and LLM-based MAS as promising future directions.'}, {'id': 'arxiv_2504.00587', 'title': 'AgentNet: Decentralized Evolutionary Coordination for LLM-based Multi-Agent Systems', 'URL': 'http://arxiv.org/abs/2504.00587', 'extra_urls': ['http://arxiv.org/abs/2504.00587'], 'type': 'article', 'author': [{'family': 'Yang', 'given': 'Yingxuan'}, {'family': 'Chai', 'given': 'Huacan'}, {'family': 'Shao', 'given': 'Shuai'}, {'family': 'Song', 'given': 'Yuanyi'}, {'family': 'Qi', 'given': 'Siyuan'}, {'family': 'Rui', 'given': 'Renting'}, {'family': 'Zhang', 'given': 'Weinan'}], 'publisher': 'arXiv', 'abstract': 'The rapid advancement of large language models (LLMs) has enabled the development of multi-agent systems where multiple LLM-based agents collaborate on complex tasks. However, existing systems often rely on centralized coordination, leading to scalability bottlenecks, reduced adaptability, and single points of failure. Privacy and proprietary knowledge concerns further hinder cross-organizational collaboration, resulting in siloed expertise. We propose AgentNet, a decentralized, Retrieval-Augmented Generation (RAG)-based framework that enables LLM-based agents to specialize, evolve, and collaborate autonomously in a dynamically structured Directed Acyclic Graph (DAG). Unlike prior approaches with static roles or centralized control, AgentNet allows agents to adjust connectivity and route tasks based on local expertise and context. AgentNet introduces three key innovations: (1) a fully decentralized coordination mechanism that eliminates the need for a central orchestrator, enhancing robustness and emergent intelligence; (2) dynamic agent graph topology that adapts in real time to task demands, ensuring scalability and resilience; and (3) a retrieval-based memory system for agents that supports continual skill refinement and specialization. By minimizing centralized control and data exchange, AgentNet enables fault-tolerant, privacy-preserving collaboration across organizations. Experiments show that AgentNet achieves higher task accuracy than both single-agent and centralized multi-agent baselines.'}, {'id': 'arxiv_2311.05304', 'title': 'Data Valuation and Detections in Federated Learning', 'URL': 'http://arxiv.org/abs/2311.05304', 'extra_urls': ['http://arxiv.org/abs/2311.05304'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Wenqian'}, {'family': 'Fu', 'given': 'Shuran'}, {'family': 'Zhang', 'given': 'Fengrui'}, {'family': 'Pang', 'given': 'Yan'}], 'publisher': 'arXiv', 'abstract': 'Federated Learning (FL) enables collaborative model training while preserving the privacy of raw data. A challenge in this framework is the fair and efficient valuation of data, which is crucial for incentivizing clients to contribute high-quality data in the FL task. In scenarios involving numerous data clients within FL, it is often the case that only a subset of clients and datasets are pertinent to a specific learning task, while others might have either a negative or negligible impact on the model training process. This paper introduces a novel privacy-preserving method for evaluating client contributions and selecting relevant datasets without a pre-specified training algorithm in an FL task. Our proposed approach FedBary, utilizes Wasserstein distance within the federated context, offering a new solution for data valuation in the FL framework. This method ensures transparent data valuation and efficient computation of the Wasserstein barycenter and reduces the dependence on validation datasets. Through extensive empirical experiments and theoretical analyses, we demonstrate the potential of this data valuation method as a promising avenue for FL research.'}, {'id': 'fair_and_efficient', 'title': 'Fair and Efficient Contribution Valuation for Vertical Federated Learning', 'URL': 'https://openreview.net/forum?id=sLQb8q0sUi', 'extra_urls': ['https://openreview.net/forum?id=sLQb8q0sUi'], 'type': 'article', 'author': [{'family': 'Fan', 'given': 'Zhenan'}, {'family': 'Fang', 'given': 'Huang'}, {'family': 'Wang', 'given': 'Xinglu'}, {'family': 'Zhou', 'given': 'Zirui'}, {'family': 'Pei', 'given': 'Jian'}, {'family': 'Friedlander', 'given': 'Michael'}, {'family': 'Zhang', 'given': 'Yong'}], 'abstract': 'Federated learning is an emerging technology for training machine learning models across decentralized data sources without sharing data. Vertical federated learning, also known as feature-based federated learning, applies to scenarios where data sources have the same sample IDs but different feature sets. To ensure fairness among data owners, it is critical to objectively assess the contributions from different data sources and compensate the corresponding data owners accordingly. The Shapley value is a provably fair contribution valuation metric originating from cooperative game theory. However, its straight-forward computation requires extensively retraining a model on each potential combination of data sources, leading to prohibitively high communication and computation overheads due to multiple rounds of federated learning. To tackle this challenge, we propose a contribution valuation metric called vertical federated Shapley value (VerFedSV) based on the classic Shapley value. We show that VerFedSV not only satisfies many desirable properties of fairness but is also efficient to compute. Moreover, VerFedSV can be adapted to both synchronous and asynchronous vertical federated learning algorithms. Both theoretical analysis and extensive experimental results demonstrate the fairness, efficiency, adaptability, and effectiveness of VerFedSV.'}, {'id': 'arxiv_2506.17419', 'title': 'UProp: Investigating the Uncertainty Propagation of LLMs in Multi-Step Agentic Decision-Making', 'URL': 'http://arxiv.org/abs/2506.17419', 'extra_urls': ['http://arxiv.org/abs/2506.17419'], 'type': 'article', 'author': [{'family': 'Duan', 'given': 'Jinhao'}, {'family': 'Diffenderfer', 'given': 'James'}, {'family': 'Madireddy', 'given': 'Sandeep'}, {'family': 'Chen', 'given': 'Tianlong'}, {'family': 'Kailkhura', 'given': 'Bhavya'}, {'family': 'Xu', 'given': 'Kaidi'}], 'publisher': 'arXiv', 'abstract': 'As Large Language Models (LLMs) are integrated into safety-critical applications involving sequential decision-making in the real world, it is essential to know when to trust LLM decisions. Existing LLM Uncertainty Quantification (UQ) methods are primarily designed for single-turn question-answering formats, resulting in multi-step decision-making scenarios, e.g., LLM agentic system, being underexplored. In this paper, we introduce a principled, information-theoretic framework that decomposes LLM sequential decision uncertainty into two parts: (i) internal uncertainty intrinsic to the current decision, which is focused on existing UQ methods, and (ii) extrinsic uncertainty, a Mutual-Information (MI) quantity describing how much uncertainty should be inherited from preceding decisions. We then propose UProp, an efficient and effective extrinsic uncertainty estimator that converts the direct estimation of MI to the estimation of Pointwise Mutual Information (PMI) over multiple Trajectory-Dependent Decision Processes (TDPs). UProp is evaluated over extensive multi-step decision-making benchmarks, e.g., AgentBench and HotpotQA, with state-of-the-art LLMs, e.g., GPT-4.1 and DeepSeek-V3. Experimental results demonstrate that UProp significantly outperforms existing single-turn UQ baselines equipped with thoughtful aggregation strategies. Moreover, we provide a comprehensive analysis of UProp, including sampling efficiency, potential applications, and intermediate uncertainty propagation, to demonstrate its effectiveness. Codes will be available at https://github.com/jinhaoduan/UProp.'}, {'id': 'arxiv_2509.02401', 'title': &quot;Towards Agents That Know When They Don't Know: Uncertainty as a Control Signal for Structured Reasoning&quot;, 'URL': 'http://arxiv.org/abs/2509.02401', 'extra_urls': ['http://arxiv.org/abs/2509.02401'], 'type': 'article', 'author': [{'family': 'Stoisser', 'given': 'Josefa Lia'}, {'family': 'Martell', 'given': 'Marc Boubnovski'}, {'family': 'Phillips', 'given': 'Lawrence'}, {'family': 'Mazzoni', 'given': 'Gianluca'}, {'family': 'Harder', 'given': 'Lea M\xf8rch'}, {'family': 'Torr', 'given': 'Philip'}, {'family': 'Ferkinghoff-Borg', 'given': 'Jesper'}, {'family': 'Martens', 'given': 'Kaspar'}, {'family': 'Fauqueur', 'given': 'Julien'}], 'publisher': 'arXiv', 'abstract': 'Large language model (LLM) agents are increasingly deployed in structured biomedical data environments, yet they often produce fluent but overconfident outputs when reasoning over complex multi-table data. We introduce an uncertainty-aware agent for query-conditioned multi-table summarization that leverages two complementary signals: (i) retrieval uncertainty--entropy over multiple table-selection rollouts--and (ii) summary uncertainty--combining self-consistency and perplexity. Summary uncertainty is incorporated into reinforcement learning (RL) with Group Relative Policy Optimization (GRPO), while both retrieval and summary uncertainty guide inference-time filtering and support the construction of higher-quality synthetic datasets. On multi-omics benchmarks, our approach improves factuality and calibration, nearly tripling correct and useful claims per summary (3.0\\(\\rightarrow\\)8.4 internal; 3.6\\(\\rightarrow\\)9.9 cancer multi-omics) and substantially improving downstream survival prediction (C-index 0.32\\(\\rightarrow\\)0.63). These results demonstrate that uncertainty can serve as a control signal--enabling agents to abstain, communicate confidence, and become more reliable tools for complex structured-data environments.'}, {'id': 'arxiv_2510.11414', 'title': 'Uncertainty-Aware, Risk-Adaptive Access Control for Agentic Systems using an LLM-Judged TBAC Model', 'URL': 'http://arxiv.org/abs/2510.11414', 'extra_urls': ['http://arxiv.org/abs/2510.11414'], 'type': 'article', 'author': [{'family': 'Fleming', 'given': 'Charles'}, {'family': 'Kundu', 'given': 'Ashish'}, {'family': 'Kompella', 'given': 'Ramana'}], 'publisher': 'arXiv', 'abstract': &quot;The proliferation of autonomous AI agents within enterprise environments introduces a critical security challenge: managing access control for emergent, novel tasks for which no predefined policies exist. This paper introduces an advanced security framework that extends the Task-Based Access Control (TBAC) model by using a Large Language Model (LLM) as an autonomous, risk-aware judge. This model makes access control decisions not only based on an agent's intent but also by explicitly considering the inherent \\textbf{risk associated with target resources} and the LLM's own \\textbf{model uncertainty} in its decision-making process. When an agent proposes a novel task, the LLM judge synthesizes a just-in-time policy while also computing a composite risk score for the task and an uncertainty estimate for its own reasoning. High-risk or high-uncertainty requests trigger more stringent controls, such as requiring human approval. This dual consideration of external risk and internal confidence allows the model to enforce a more robust and adaptive version of the principle of least privilege, paving the way for safer and more trustworthy autonomous systems.&quot;}, {'id': 'arxiv_2504.15722', 'title': 'From predictions to confidence intervals: an empirical study of conformal prediction methods for in-context learning', 'URL': 'http://arxiv.org/abs/2504.15722', 'extra_urls': ['http://arxiv.org/abs/2504.15722'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Zhe'}, {'family': 'Rossi', 'given': 'Simone'}, {'family': 'Yuan', 'given': 'Rui'}, {'family': 'Hannagan', 'given': 'Thomas'}], 'publisher': 'arXiv', 'abstract': 'Transformers have become a standard architecture in machine learning, demonstrating strong in-context learning (ICL) abilities that allow them to learn from the prompt at inference time. However, uncertainty quantification for ICL remains an open challenge, particularly in noisy regression tasks. This paper investigates whether ICL can be leveraged for distribution-free uncertainty estimation, proposing a method based on conformal prediction to construct prediction intervals with guaranteed coverage. While traditional conformal methods are computationally expensive due to repeated model fitting, we exploit ICL to efficiently generate confidence intervals in a single forward pass. Our empirical analysis compares this approach against ridge regression-based conformal methods, showing that conformal prediction with in-context learning (CP with ICL) achieves robust and scalable uncertainty estimates. Additionally, we evaluate its performance under distribution shifts and establish scaling laws to guide model training. These findings bridge ICL and conformal prediction, providing a theoretically grounded and new framework for uncertainty quantification in transformer-based models.'}, {'id': 'arxiv_2508.07556', 'title': 'Uncertainty-Driven Reliability: Selective Prediction and Trustworthy Deployment in Modern Machine Learning', 'URL': 'http://arxiv.org/abs/2508.07556', 'extra_urls': ['http://arxiv.org/abs/2508.07556'], 'type': 'article', 'author': [{'family': 'Rabanser', 'given': 'Stephan'}], 'publisher': 'arXiv', 'abstract': 'Machine learning (ML) systems are increasingly deployed in high-stakes domains where reliability is paramount. This thesis investigates how uncertainty estimation can enhance the safety and trustworthiness of ML, focusing on selective prediction -- where models abstain when confidence is low. We first show that a model\'s training trajectory contains rich uncertainty signals that can be exploited without altering its architecture or loss. By ensembling predictions from intermediate checkpoints, we propose a lightweight, post-hoc abstention method that works across tasks, avoids the cost of deep ensembles, and achieves state-of-the-art selective prediction performance. Crucially, this approach is fully compatible with differential privacy (DP), allowing us to study how privacy noise affects uncertainty quality. We find that while many methods degrade under DP, our trajectory-based approach remains robust, and we introduce a framework for isolating the privacy-uncertainty trade-off. Next, we then develop a finite-sample decomposition of the selective classification gap -- the deviation from the oracle accuracy-coverage curve -- identifying five interpretable error sources and clarifying which interventions can close the gap. This explains why calibration alone cannot fix ranking errors, motivating methods that improve uncertainty ordering. Finally, we show that uncertainty signals can be adversarially manipulated to hide errors or deny service while maintaining high accuracy, and we design defenses combining calibration audits with verifiable inference. Together, these contributions advance reliable ML by improving, evaluating, and safeguarding uncertainty estimation, enabling models that not only make accurate predictions -- but also know when to say &quot;I do not know&quot;.'}, {'id': 'arxiv_2510.13297', 'title': 'Federated Conditional Conformal Prediction via Generative Models', 'URL': 'http://arxiv.org/abs/2510.13297', 'extra_urls': ['http://arxiv.org/abs/2510.13297'], 'type': 'article', 'author': [{'family': 'Xu', 'given': 'Rui'}, {'family': 'Chen', 'given': 'Xingyuan'}, {'family': 'Huang', 'given': 'Wenxing'}, {'family': 'Huang', 'given': 'Minxuan'}, {'family': 'Xie', 'given': 'Yun'}, {'family': 'Chen', 'given': 'Weiyan'}, {'family': 'Xie', 'given': 'Sihong'}], 'publisher': 'arXiv', 'abstract': 'Conformal Prediction (CP) provides distribution-free uncertainty quantification by constructing prediction sets that guarantee coverage of the true labels. This reliability makes CP valuable for high-stakes federated learning scenarios such as multi-center healthcare. However, standard CP assumes i.i.d. data, which is violated in federated settings where client distributions differ substantially. Existing federated CP methods address this by maintaining marginal coverage on each client, but such guarantees often fail to reflect input-conditional uncertainty. In this work, we propose Federated Conditional Conformal Prediction (Fed-CCP) via generative models, which aims for conditional coverage that adapts to local data heterogeneity. Fed-CCP leverages generative models, such as normalizing flows or diffusion models, to approximate conditional data distributions without requiring the sharing of raw data. This enables each client to locally calibrate conformal scores that reflect its unique uncertainty, while preserving global consistency through federated aggregation. Experiments on real datasets demonstrate that Fed-CCP achieves more adaptive prediction sets.'}, {'id': 'arxiv_2510.15233', 'title': 'Adaptive Individual Uncertainty under Out-Of-Distribution Shift with Expert-Routed Conformal Prediction', 'URL': 'http://arxiv.org/abs/2510.15233', 'extra_urls': ['http://arxiv.org/abs/2510.15233'], 'type': 'article', 'author': [{'family': 'Badkul', 'given': 'Amitesh'}, {'family': 'Xie', 'given': 'Lei'}], 'publisher': 'arXiv', 'abstract': 'Reliable, informative, and individual uncertainty quantification (UQ) remains missing in current ML community. This hinders the effective application of AI/ML to risk-sensitive domains. Most methods either fail to provide coverage on new data, inflate intervals so broadly that they are not actionable, or assign uncertainties that do not track actual error, especially under a distribution shift. In high-stakes drug discovery, protein-ligand affinity (PLI) prediction is especially challenging as assay noise is heterogeneous, chemical space is imbalanced and large, and practical evaluations routinely involve distribution shift. In this work, we introduce a novel uncertainty quantification method, Trustworthy Expert Split-conformal with Scaled Estimation for Efficient Reliable Adaptive intervals (TESSERA), that provides per-sample uncertainty with reliable coverage guarantee, informative and adaptive prediction interval widths that track the absolute error. We evaluate on protein-ligand binding affinity prediction under both independent and identically distributed (i.i.d.) and scaffold-based out-of-distribution (OOD) splits, comparing against strong UQ baselines. TESSERA attains near-nominal coverage and the best coverage-width trade-off as measured by the Coverage-Width Criterion (CWC), while maintaining competitive adaptivity (lowest Area Under the Sparsification Error (AUSE)). Size-Stratified Coverage (SSC) further confirms that intervals are right-sized, indicating width increases when data are scarce or noisy, and remain tight when predictions are reliable. By unifying Mixture of Expert (MoE) diversity with conformal calibration, TESSERA delivers trustworthy, tight, and adaptive uncertainties that are well-suited to selective prediction and downstream decision-making in the drug-discovery pipeline and other applications.'}, {'id': 'arxiv_2509.13717', 'title': 'A Conformal Prediction Framework for Uncertainty Quantification in Physics-Informed Neural Networks', 'URL': 'http://arxiv.org/abs/2509.13717', 'extra_urls': ['http://arxiv.org/abs/2509.13717'], 'type': 'article', 'author': [{'family': 'Yu', 'given': 'Yifan'}, {'family': 'Ho', 'given': 'Cheuk Hin'}, {'family': 'Wang', 'given': 'Yangshuai'}], 'publisher': 'arXiv', 'abstract': 'Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving PDEs, yet existing uncertainty quantification (UQ) approaches for PINNs generally lack rigorous statistical guarantees. In this work, we bridge this gap by introducing a distribution-free conformal prediction (CP) framework for UQ in PINNs. This framework calibrates prediction intervals by constructing nonconformity scores on a calibration set, thereby yielding distribution-free uncertainty estimates with rigorous finite-sample coverage guarantees for PINNs. To handle spatial heteroskedasticity, we further introduce local conformal quantile estimation, enabling spatially adaptive uncertainty bands while preserving theoretical guarantee. Through systematic evaluations on typical PDEs (damped harmonic oscillator, Poisson, Allen-Cahn, and Helmholtz equations) and comprehensive testing across multiple uncertainty metrics, our results demonstrate that the proposed framework achieves reliable calibration and locally adaptive uncertainty intervals, consistently outperforming heuristic UQ approaches. By bridging PINNs with distribution-free UQ, this work introduces a general framework that not only enhances calibration and reliability, but also opens new avenues for uncertainty-aware modeling of complex PDE systems.'}, {'id': 'arxiv_2410.01767', 'title': 'Utility-Directed Conformal Prediction: A Decision-Aware Framework for Actionable Uncertainty Quantification', 'URL': 'http://arxiv.org/abs/2410.01767', 'extra_urls': ['http://arxiv.org/abs/2410.01767'], 'type': 'article', 'author': [{'family': 'Cortes-Gomez', 'given': 'Santiago'}, {'family': 'Pati\xf1o', 'given': 'Carlos'}, {'family': 'Byun', 'given': 'Yewon'}, {'family': 'Wu', 'given': 'Steven'}, {'family': 'Horvitz', 'given': 'Eric'}, {'family': 'Wilder', 'given': 'Bryan'}], 'publisher': 'arXiv', 'abstract': 'Interest has been growing in decision-focused machine learning methods which train models to account for how their predictions are used in downstream optimization problems. Doing so can often improve performance on subsequent decision problems. However, current methods for uncertainty quantification do not incorporate any information about downstream decisions. We develop a methodology based on conformal prediction to identify prediction sets that account for a downstream cost function, making them more appropriate to inform high-stakes decision-making. Our approach harnesses the strengths of conformal methods -- modularity, model-agnosticism, and statistical coverage guarantees -- while incorporating downstream decisions and user-specified utility functions. We prove that our methods retain standard coverage guarantees. Empirical evaluation across a range of datasets and utility metrics demonstrates that our methods achieve significantly lower costs than standard conformal methods. We present a real-world use case in healthcare diagnosis, where our method effectively incorporates the hierarchical structure of dermatological diseases. The method successfully generates sets with coherent diagnostic meaning, potentially aiding triage for dermatology diagnosis and illustrating how our method can ground high-stakes decision-making employing domain knowledge.'}, {'id': 'arxiv_2510.15103', 'title': 'Continual Learning via Sparse Memory Finetuning', 'URL': 'http://arxiv.org/abs/2510.15103', 'extra_urls': ['http://arxiv.org/abs/2510.15103'], 'type': 'article', 'author': [{'family': 'Lin', 'given': 'Jessy'}, {'family': 'Zettlemoyer', 'given': 'Luke'}, {'family': 'Ghosh', 'given': 'Gargi'}, {'family': 'Yih', 'given': 'Wen-Tau'}, {'family': 'Markosyan', 'given': 'Aram'}, {'family': 'Berges', 'given': 'Vincent-Pierre'}, {'family': 'O\u011fuz', 'given': 'Barlas'}], 'publisher': 'arXiv', 'abstract': &quot;Modern language models are powerful, but typically static after deployment. A major obstacle to building models that continually learn over time is catastrophic forgetting, where updating on new data erases previously acquired capabilities. Motivated by the intuition that mitigating forgetting is challenging because trainable parameters are shared across all tasks, we investigate whether sparse parameter updates can enable learning without catastrophic forgetting. We introduce sparse memory finetuning, leveraging memory layer models (Berges et al., 2024), which are sparsely updated by design. By updating only the memory slots that are highly activated by a new piece of knowledge relative to usage on pretraining data, we reduce interference between new knowledge and the model's existing capabilities. We evaluate learning and forgetting compared to full finetuning and parameter-efficient finetuning with LoRA on two question answering tasks. We find that sparse memory finetuning learns new knowledge while exhibiting substantially less forgetting: while NaturalQuestions F1 drops by 89% after full finetuning on new facts and 71% with LoRA, sparse memory finetuning yields only an 11% drop with the same level of new knowledge acquisition. Our results suggest sparsity in memory layers offers a promising path toward continual learning in large language models.&quot;}, {'id': 'arxiv_2506.04133', 'title': 'TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems', 'URL': 'http://arxiv.org/abs/2506.04133', 'extra_urls': ['http://arxiv.org/abs/2506.04133'], 'type': 'article', 'author': [{'family': 'Raza', 'given': 'Shaina'}, {'family': 'Sapkota', 'given': 'Ranjan'}, {'family': 'Karkee', 'given': 'Manoj'}, {'family': 'Emmanouilidis', 'given': 'Christos'}], 'publisher': 'arXiv', 'abstract': 'Agentic AI systems, built upon large language models (LLMs) and deployed in multi-agent configurations, are redefining intelligence, autonomy, collaboration, and decision-making across enterprise and societal domains. This review presents a structured analysis of Trust, Risk, and Security Management (TRiSM) in the context of LLM-based Agentic Multi-Agent Systems (AMAS). We begin by examining the conceptual foundations of Agentic AI and highlight its architectural distinctions from traditional AI agents. We then adapt and extend the AI TRiSM framework for Agentic AI, structured around key pillars: \\textit{ Explainability, ModelOps, Security, Privacy} and \\textit{their Lifecycle Governance}, each contextualized to the challenges of AMAS. A risk taxonomy is proposed to capture the unique threats and vulnerabilities of Agentic AI, ranging from coordination failures to prompt-based adversarial manipulation. To support practical assessment in Agentic AI works, we introduce two novel metrics: the Component Synergy Score (CSS), which quantifies the quality of inter-agent collaboration, and the Tool Utilization Efficacy (TUE), which evaluates the efficiency of tool use within agent workflows. We further discuss strategies for improving explainability in Agentic AI, as well as approaches to enhancing security and privacy through encryption, adversarial robustness, and regulatory compliance. The review concludes with a research roadmap for the responsible development and deployment of Agentic AI, highlighting key directions to align emerging systems with TRiSM principles-ensuring safety, transparency, and accountability in their operation.'}, {'id': 'arxiv_2508.08997', 'title': 'Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory', 'URL': 'http://arxiv.org/abs/2508.08997', 'extra_urls': ['http://arxiv.org/abs/2508.08997'], 'type': 'article', 'author': [{'family': 'Yuen', 'given': 'Sizhe'}, {'family': 'Medina', 'given': 'Francisco Gomez'}, {'family': 'Su', 'given': 'Ting'}, {'family': 'Du', 'given': 'Yali'}, {'family': 'Sobey', 'given': 'Adam J.'}], 'publisher': 'arXiv', 'abstract': 'Multi-agent systems built on Large Language Models (LLMs) show exceptional promise for complex collaborative problem-solving, yet they face fundamental challenges stemming from context window limitations that impair memory consistency, role adherence, and procedural integrity. This paper introduces Intrinsic Memory Agents, a novel framework that addresses these limitations through structured agent-specific memories that evolve intrinsically with agent outputs. Specifically, our method maintains role-aligned memory templates that preserve specialized perspectives while focusing on task-relevant information. We benchmark our approach on the PDDL dataset, comparing its performance to existing state-of-the-art multi-agentic memory approaches and showing an improvement of 38.6\\% with the highest token efficiency. An additional evaluation is performed on a complex data pipeline design task, we demonstrate that our approach produces higher quality designs when comparing 5 metrics: scalability, reliability, usability, cost-effectiveness and documentation with additional qualitative evidence of the improvements. Our findings suggest that addressing memory limitations through structured, intrinsic approaches can improve the capabilities of multi-agent LLM systems on structured planning tasks.'}, {'id': 'arxiv_2508.18765', 'title': 'Governance-as-a-Service: A Multi-Agent Framework for AI System Compliance and Policy Enforcement', 'URL': 'http://arxiv.org/abs/2508.18765', 'extra_urls': ['http://arxiv.org/abs/2508.18765'], 'type': 'article', 'author': [{'family': 'Gaurav', 'given': 'Suyash'}, {'family': 'Heikkonen', 'given': 'Jukka'}, {'family': 'Chaudhary', 'given': 'Jatin'}], 'publisher': 'arXiv', 'abstract': 'As AI systems evolve into distributed ecosystems with autonomous execution, asynchronous reasoning, and multi-agent coordination, the absence of scalable, decoupled governance poses a structural risk. Existing oversight mechanisms are reactive, brittle, and embedded within agent architectures, making them non-auditable and hard to generalize across heterogeneous deployments. We introduce Governance-as-a-Service (GaaS): a modular, policy-driven enforcement layer that regulates agent outputs at runtime without altering model internals or requiring agent cooperation. GaaS employs declarative rules and a Trust Factor mechanism that scores agents based on compliance and severity-weighted violations. It enables coercive, normative, and adaptive interventions, supporting graduated enforcement and dynamic trust modulation. To evaluate GaaS, we conduct three simulation regimes with open-source models (LLaMA3, Qwen3, DeepSeek-R1) across content generation and financial decision-making. In the baseline, agents act without governance; in the second, GaaS enforces policies; in the third, adversarial agents probe robustness. All actions are intercepted, evaluated, and logged for analysis. Results show that GaaS reliably blocks or redirects high-risk behaviors while preserving throughput. Trust scores track rule adherence, isolating and penalizing untrustworthy components in multi-agent systems. By positioning governance as a runtime service akin to compute or storage, GaaS establishes infrastructure-level alignment for interoperable agent ecosystems. It does not teach agents ethics; it enforces them.'}, {'id': 'arxiv_2404.10142', 'title': 'Shaping Realities: Enhancing 3D Generative AI with Fabrication Constraints', 'URL': 'http://arxiv.org/abs/2404.10142', 'extra_urls': ['http://arxiv.org/abs/2404.10142'], 'type': 'article', 'author': [{'family': 'Faruqi', 'given': 'Faraz'}, {'family': 'Tian', 'given': 'Yingtao'}, {'family': 'Phadnis', 'given': 'Vrushank'}, {'family': 'Jampani', 'given': 'Varun'}, {'family': 'Mueller', 'given': 'Stefanie'}], 'publisher': 'arXiv', 'abstract': 'Generative AI tools are becoming more prevalent in 3D modeling, enabling users to manipulate or create new models with text or images as inputs. This makes it easier for users to rapidly customize and iterate on their 3D designs and explore new creative ideas. These methods focus on the aesthetic quality of the 3D models, refining them to look similar to the prompts provided by the user. However, when creating 3D models intended for fabrication, designers need to trade-off the aesthetic qualities of a 3D model with their intended physical properties. To be functional post-fabrication, 3D models have to satisfy structural constraints informed by physical principles. Currently, such requirements are not enforced by generative AI tools. This leads to the development of aesthetically appealing, but potentially non-functional 3D geometry, that would be hard to fabricate and use in the real world. This workshop paper highlights the limitations of generative AI tools in translating digital creations into the physical world and proposes new augmentations to generative AI tools for creating physically viable 3D models. We advocate for the development of tools that manipulate or generate 3D models by considering not only the aesthetic appearance but also using physical properties as constraints. This exploration seeks to bridge the gap between digital creativity and real-world applicability, extending the creative potential of generative AI into the tangible domain.'}, {'id': 'accumulative_fidelity_maximization', 'title': 'Accumulative Fidelity Maximization of Inference Services in DT-Assisted Edge Computing', 'URL': 'https://ieeexplore.ieee.org/document/11062774', 'extra_urls': ['https://ieeexplore.ieee.org/document/11062774'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Jing'}, {'family': 'Liang', 'given': 'Weifa'}, {'family': 'Wang', 'given': 'Jianping'}, {'family': 'Jia', 'given': 'Xiaohua'}], 'abstract': 'Digital twin (DT) technology illuminates the smooth integration of cyber and physical worlds in alignment with the Industry 4.0 initiative. Through synchronizations with physical objects, DTs of objects can reflect the states of the objects with high fidelity. Machine learning-based service models through continual training by the DT update data can provide users with accurate inference services. Orthogonal to the DT technology, mobile edge computing (MEC) is a promising computing paradigm that shifts computing power to the edge network, which is particularly appropriate for delay-sensitive intelligent services. In this paper, we study the fidelity enhancement of service models in a DT-assisted edge computing environment empowered by 6G communication, through continuously training service models, using DT update data obtained from their mobile \\mathbfIoT devices (objects) in a real-time manner. To this end, we first formulate an accumulative fidelity maximization problem that jointly considers the placement of DTs and models, with the aim to maximize the accumulative fidelity gain of all models while minimizing the total cost of resource consumed due to DT updating and service model training. We then develop an efficient algorithm for a sub-optimization problem - the placement problem of DTs and models, under the assumption that the mobility profile of each mobile object is given. When both DTs and models have already been placed, we devise an algorithm for the accumulative fidelity maximization problem that schedules each object to choose an access point (AP) to upload its update data at each time slot for a given time horizon to maximize the accumulative fidelity of all service models while minimizing the total cost of various resources consumed. We finally evaluate the performance of the proposed algorithms through simulations. Simulation results indicate that the proposed algorithms are promising, and outperform their baselines nearly by 20%.'}, {'id': 'regtech_and', 'title': 'FinTech, RegTech and the Reconceptualization of Financial Regulation', 'URL': 'https://papers.ssrn.com/abstract=2847806', 'extra_urls': ['https://papers.ssrn.com/abstract=2847806'], 'type': 'article', 'author': [{'family': 'Arner', 'given': 'Douglas W.'}, {'family': 'Barberis', 'given': 'Janos Nathan'}, {'family': 'Buckley', 'given': 'Ross P.'}], 'publisher': 'Social Science Research Network', 'abstract': 'The regulatory changes and technological developments following the 2008 Global Financial Crisis are fundamentally changing the nature of financial markets, services and institutions. At the juncture of these two phenomena lies regulatory technology or \u2018RegTech\u2019 \u2013 the use of technology, particularly information technology, in the context of regulatory monitoring, reporting and compliance.'}, {'id': 'arxiv_2407.18418', 'title': 'Know Your Limits: A Survey of Abstention in Large Language Models', 'URL': 'https://arxiv.org/abs/2407.18418', 'extra_urls': ['https://arxiv.org/abs/2407.18418'], 'type': 'article', 'author': [{'family': 'Bingbing Wen'}, {'family': 'Jihan Yao'}, {'family': 'Shangbin Feng'}, {'family': 'Chenjun Xu'}, {'family': 'Yulia Tsvetkov'}, {'family': 'Bill Howe'}, {'family': 'Lucy Lu Wang'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2507.15439', 'title': 'Human vs. Algorithmic Auditors: The Impact of Entity Type and Ambiguity   on Human Dishonesty', 'URL': 'https://arxiv.org/abs/2507.15439', 'extra_urls': ['https://arxiv.org/abs/2507.15439'], 'type': 'article', 'author': [{'family': 'Marius Protte'}, {'family': 'Behnud Mir Djawadi'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.15918', 'title': 'Extracting Probabilistic Knowledge from Large Language Models for   Bayesian Network Parameterization', 'URL': 'https://arxiv.org/abs/2505.15918', 'extra_urls': ['https://arxiv.org/abs/2505.15918'], 'type': 'article', 'author': [{'family': 'Aliakbar Nafar'}, {'family': 'Kristen Brent Venable'}, {'family': 'Zijun Cui'}, {'family': 'Parisa Kordjamshidi'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2405.06258', 'title': 'Automatic Generation of Model and Data Cards: A Step Towards Responsible   AI', 'URL': 'https://arxiv.org/abs/2405.06258', 'extra_urls': ['https://arxiv.org/abs/2405.06258'], 'type': 'article', 'author': [{'family': 'Jiarui Liu'}, {'family': 'Wenkai Li'}, {'family': 'Zhijing Jin'}, {'family': 'Mona Diab'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2307.15475', 'title': 'FeedbackLogs: Recording and Incorporating Stakeholder Feedback into   Machine Learning Pipelines', 'URL': 'https://arxiv.org/abs/2307.15475', 'extra_urls': ['https://arxiv.org/abs/2307.15475'], 'type': 'article', 'author': [{'family': 'Matthew Barker'}, {'family': 'Emma Kallina'}, {'family': 'Dhananjay Ashok'}, {'family': 'Katherine M. Collins'}, {'family': 'Ashley Casovan'}, {'family': 'Adrian Weller'}, {'family': 'Ameet Talwalkar'}, {'family': 'Valerie Chen'}, {'family': 'Umang Bhatt'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2303.08774', 'title': 'GPT-4 Technical Report', 'URL': 'https://arxiv.org/abs/2303.08774', 'extra_urls': ['https://arxiv.org/abs/2303.08774'], 'type': 'article', 'author': [{'family': 'OpenAI'}, {'family': 'Josh Achiam'}, {'family': 'Steven Adler'}, {'family': 'Sandhini Agarwal'}, {'family': 'Lama Ahmad'}, {'family': 'Ilge Akkaya'}, {'family': 'Florencia Leoni Aleman'}, {'family': 'Diogo Almeida'}, {'family': 'Janko Altenschmidt'}, {'family': 'Sam Altman'}, {'family': 'Shyamal Anadkat'}, {'family': 'Red Avila'}, {'family': 'Igor Babuschkin'}, {'family': 'Suchir Balaji'}, {'family': 'Valerie Balcom'}, {'family': 'Paul Baltescu'}, {'family': 'Haiming Bao'}, {'family': 'Mohammad Bavarian'}, {'family': 'Jeff Belgum'}, {'family': 'Irwan Bello'}, {'family': 'Jake Berdine'}, {'family': 'Gabriel Bernadett-Shapiro'}, {'family': 'Christopher Berner'}, {'family': 'Lenny Bogdonoff'}, {'family': 'Oleg Boiko'}, {'family': 'Madelaine Boyd'}, {'family': 'Anna-Luisa Brakman'}, {'family': 'Greg Brockman'}, {'family': 'Tim Brooks'}, {'family': 'Miles Brundage'}, {'family': 'Kevin Button'}, {'family': 'Trevor Cai'}, {'family': 'Rosie Campbell'}, {'family': 'Andrew Cann'}, {'family': 'Brittany Carey'}, {'family': 'Chelsea Carlson'}, {'family': 'Rory Carmichael'}, {'family': 'Brooke Chan'}, {'family': 'Che Chang'}, {'family': 'Fotis Chantzis'}, {'family': 'Derek Chen'}, {'family': 'Sully Chen'}, {'family': 'Ruby Chen'}, {'family': 'Jason Chen'}, {'family': 'Mark Chen'}, {'family': 'Ben Chess'}, {'family': 'Chester Cho'}, {'family': 'Casey Chu'}, {'family': 'Hyung Won Chung'}, {'family': 'Dave Cummings'}, {'family': 'Jeremiah Currier'}, {'family': 'Yunxing Dai'}, {'family': 'Cory Decareaux'}, {'family': 'Thomas Degry'}, {'family': 'Noah Deutsch'}, {'family': 'Damien Deville'}, {'family': 'Arka Dhar'}, {'family': 'David Dohan'}, {'family': 'Steve Dowling'}, {'family': 'Sheila Dunning'}, {'family': 'Adrien Ecoffet'}, {'family': 'Atty Eleti'}, {'family': 'Tyna Eloundou'}, {'family': 'David Farhi'}, {'family': 'Liam Fedus'}, {'family': 'Niko Felix'}, {'family': 'Sim\xf3n Posada Fishman'}, {'family': 'Juston Forte'}, {'family': 'Isabella Fulford'}, {'family': 'Leo Gao'}, {'family': 'Elie Georges'}, {'family': 'Christian Gibson'}, {'family': 'Vik Goel'}, {'family': 'Tarun Gogineni'}, {'family': 'Gabriel Goh'}, {'family': 'Rapha Gontijo-Lopes'}, {'family': 'Jonathan Gordon'}, {'family': 'Morgan Grafstein'}, {'family': 'Scott Gray'}, {'family': 'Ryan Greene'}, {'family': 'Joshua Gross'}, {'family': 'Shixiang Shane Gu'}, {'family': 'Yufei Guo'}, {'family': 'Chris Hallacy'}, {'family': 'Jesse Han'}, {'family': 'Jeff Harris'}, {'family': 'Yuchen He'}, {'family': 'Mike Heaton'}, {'family': 'Johannes Heidecke'}, {'family': 'Chris Hesse'}, {'family': 'Alan Hickey'}, {'family': 'Wade Hickey'}, {'family': 'Peter Hoeschele'}, {'family': 'Brandon Houghton'}, {'family': 'Kenny Hsu'}, {'family': 'Shengli Hu'}, {'family': 'Xin Hu'}, {'family': 'Joost Huizinga'}, {'family': 'Shantanu Jain'}, {'family': 'Shawn Jain'}, {'family': 'Joanne Jang'}, {'family': 'Angela Jiang'}, {'family': 'Roger Jiang'}, {'family': 'Haozhun Jin'}, {'family': 'Denny Jin'}, {'family': 'Shino Jomoto'}, {'family': 'Billie Jonn'}, {'family': 'Heewoo Jun'}, {'family': 'Tomer Kaftan'}, {'family': '\u0141ukasz Kaiser'}, {'family': 'Ali Kamali'}, {'family': 'Ingmar Kanitscheider'}, {'family': 'Nitish Shirish Keskar'}, {'family': 'Tabarak Khan'}, {'family': 'Logan Kilpatrick'}, {'family': 'Jong Wook Kim'}, {'family': 'Christina Kim'}, {'family': 'Yongjik Kim'}, {'family': 'Jan Hendrik Kirchner'}, {'family': 'Jamie Kiros'}, {'family': 'Matt Knight'}, {'family': 'Daniel Kokotajlo'}, {'family': '\u0141ukasz Kondraciuk'}, {'family': 'Andrew Kondrich'}, {'family': 'Aris Konstantinidis'}, {'family': 'Kyle Kosic'}, {'family': 'Gretchen Krueger'}, {'family': 'Vishal Kuo'}, {'family': 'Michael Lampe'}, {'family': 'Ikai Lan'}, {'family': 'Teddy Lee'}, {'family': 'Jan Leike'}, {'family': 'Jade Leung'}, {'family': 'Daniel Levy'}, {'family': 'Chak Ming Li'}, {'family': 'Rachel Lim'}, {'family': 'Molly Lin'}, {'family': 'Stephanie Lin'}, {'family': 'Mateusz Litwin'}, {'family': 'Theresa Lopez'}, {'family': 'Ryan Lowe'}, {'family': 'Patricia Lue'}, {'family': 'Anna Makanju'}, {'family': 'Kim Malfacini'}, {'family': 'Sam Manning'}, {'family': 'Todor Markov'}, {'family': 'Yaniv Markovski'}, {'family': 'Bianca Martin'}, {'family': 'Katie Mayer'}, {'family': 'Andrew Mayne'}, {'family': 'Bob McGrew'}, {'family': 'Scott Mayer McKinney'}, {'family': 'Christine McLeavey'}, {'family': 'Paul McMillan'}, {'family': 'Jake McNeil'}, {'family': 'David Medina'}, {'family': 'Aalok Mehta'}, {'family': 'Jacob Menick'}, {'family': 'Luke Metz'}, {'family': 'Andrey Mishchenko'}, {'family': 'Pamela Mishkin'}, {'family': 'Vinnie Monaco'}, {'family': 'Evan Morikawa'}, {'family': 'Daniel Mossing'}, {'family': 'Tong Mu'}, {'family': 'Mira Murati'}, {'family': 'Oleg Murk'}, {'family': 'David M\xe9ly'}, {'family': 'Ashvin Nair'}, {'family': 'Reiichiro Nakano'}, {'family': 'Rajeev Nayak'}, {'family': 'Arvind Neelakantan'}, {'family': 'Richard Ngo'}, {'family': 'Hyeonwoo Noh'}, {'family': 'Long Ouyang'}, {'family': &quot;Cullen O'Keefe&quot;}, {'family': 'Jakub Pachocki'}, {'family': 'Alex Paino'}, {'family': 'Joe Palermo'}, {'family': 'Ashley Pantuliano'}, {'family': 'Giambattista Parascandolo'}, {'family': 'Joel Parish'}, {'family': 'Emy Parparita'}, {'family': 'Alex Passos'}, {'family': 'Mikhail Pavlov'}, {'family': 'Andrew Peng'}, {'family': 'Adam Perelman'}, {'family': 'Filipe de Avila Belbute Peres'}, {'family': 'Michael Petrov'}, {'family': 'Henrique Ponde de Oliveira Pinto'}, {'family': 'Michael'}, {'family': 'Pokorny'}, {'family': 'Michelle Pokrass'}, {'family': 'Vitchyr H. Pong'}, {'family': 'Tolly Powell'}, {'family': 'Alethea Power'}, {'family': 'Boris Power'}, {'family': 'Elizabeth Proehl'}, {'family': 'Raul Puri'}, {'family': 'Alec Radford'}, {'family': 'Jack Rae'}, {'family': 'Aditya Ramesh'}, {'family': 'Cameron Raymond'}, {'family': 'Francis Real'}, {'family': 'Kendra Rimbach'}, {'family': 'Carl Ross'}, {'family': 'Bob Rotsted'}, {'family': 'Henri Roussez'}, {'family': 'Nick Ryder'}, {'family': 'Mario Saltarelli'}, {'family': 'Ted Sanders'}, {'family': 'Shibani Santurkar'}, {'family': 'Girish Sastry'}, {'family': 'Heather Schmidt'}, {'family': 'David Schnurr'}, {'family': 'John Schulman'}, {'family': 'Daniel Selsam'}, {'family': 'Kyla Sheppard'}, {'family': 'Toki Sherbakov'}, {'family': 'Jessica Shieh'}, {'family': 'Sarah Shoker'}, {'family': 'Pranav Shyam'}, {'family': 'Szymon Sidor'}, {'family': 'Eric Sigler'}, {'family': 'Maddie Simens'}, {'family': 'Jordan Sitkin'}, {'family': 'Katarina Slama'}, {'family': 'Ian Sohl'}, {'family': 'Benjamin Sokolowsky'}, {'family': 'Yang Song'}, {'family': 'Natalie Staudacher'}, {'family': 'Felipe Petroski Such'}, {'family': 'Natalie Summers'}, {'family': 'Ilya Sutskever'}, {'family': 'Jie Tang'}, {'family': 'Nikolas Tezak'}, {'family': 'Madeleine B. Thompson'}, {'family': 'Phil Tillet'}, {'family': 'Amin Tootoonchian'}, {'family': 'Elizabeth Tseng'}, {'family': 'Preston Tuggle'}, {'family': 'Nick Turley'}, {'family': 'Jerry Tworek'}, {'family': 'Juan Felipe Cer\xf3n Uribe'}, {'family': 'Andrea Vallone'}, {'family': 'Arun Vijayvergiya'}, {'family': 'Chelsea Voss'}, {'family': 'Carroll Wainwright'}, {'family': 'Justin Jay Wang'}, {'family': 'Alvin Wang'}, {'family': 'Ben Wang'}, {'family': 'Jonathan Ward'}, {'family': 'Jason Wei'}, {'family': 'CJ Weinmann'}, {'family': 'Akila Welihinda'}, {'family': 'Peter Welinder'}, {'family': 'Jiayi Weng'}, {'family': 'Lilian Weng'}, {'family': 'Matt Wiethoff'}, {'family': 'Dave Willner'}, {'family': 'Clemens Winter'}, {'family': 'Samuel Wolrich'}, {'family': 'Hannah Wong'}, {'family': 'Lauren Workman'}, {'family': 'Sherwin Wu'}, {'family': 'Jeff Wu'}, {'family': 'Michael Wu'}, {'family': 'Kai Xiao'}, {'family': 'Tao Xu'}, {'family': 'Sarah Yoo'}, {'family': 'Kevin Yu'}, {'family': 'Qiming Yuan'}, {'family': 'Wojciech Zaremba'}, {'family': 'Rowan Zellers'}, {'family': 'Chong Zhang'}, {'family': 'Marvin Zhang'}, {'family': 'Shengjia Zhao'}, {'family': 'Tianhao Zheng'}, {'family': 'Juntang Zhuang'}, {'family': 'William Zhuk'}, {'family': 'Barret Zoph'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_1803.09010', 'title': 'Datasheets for Datasets', 'URL': 'https://arxiv.org/abs/1803.09010', 'extra_urls': ['https://arxiv.org/abs/1803.09010'], 'type': 'article', 'author': [{'family': 'Timnit Gebru'}, {'family': 'Jamie Morgenstern'}, {'family': 'Briana Vecchione'}, {'family': 'Jennifer Wortman Vaughan'}, {'family': 'Hanna Wallach'}, {'family': 'Hal Daum\xe9 III'}, {'family': 'Kate Crawford'}], 'issued': {'date-parts': [[2018]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.20295', 'title': 'SelfReflect: Can LLMs Communicate Their Internal Answer Distribution?', 'URL': 'https://arxiv.org/abs/2505.20295', 'extra_urls': ['https://arxiv.org/abs/2505.20295'], 'type': 'article', 'author': [{'family': 'Michael Kirchhof'}, {'family': 'Luca F\xfcger'}, {'family': 'Adam Goli\u0144ski'}, {'family': 'Eeshan Gunesh Dhekane'}, {'family': 'Arno Blaas'}, {'family': 'Seong Joon Oh'}, {'family': 'Sinead Williamson'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2412.20892', 'title': 'Rethinking Aleatoric and Epistemic Uncertainty', 'URL': 'https://arxiv.org/abs/2412.20892', 'extra_urls': ['https://arxiv.org/abs/2412.20892'], 'type': 'article', 'author': [{'family': 'Freddie Bickford Smith'}, {'family': 'Jannik Kossen'}, {'family': 'Eleanor Trollope'}, {'family': 'Mark van der Wilk'}, {'family': 'Adam Foster'}, {'family': 'Tom Rainforth'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2402.10189', 'title': 'Uncertainty Quantification for In-Context Learning of Large Language   Models', 'URL': 'https://arxiv.org/abs/2402.10189', 'extra_urls': ['https://arxiv.org/abs/2402.10189'], 'type': 'article', 'author': [{'family': 'Chen Ling'}, {'family': 'Xujiang Zhao'}, {'family': 'Xuchao Zhang'}, {'family': 'Wei Cheng'}, {'family': 'Yanchi Liu'}, {'family': 'Yiyou Sun'}, {'family': 'Mika Oishi'}, {'family': 'Takao Osaki'}, {'family': 'Katsushi Matsuda'}, {'family': 'Jie Ji'}, {'family': 'Guangji Bai'}, {'family': 'Liang Zhao'}, {'family': 'Haifeng Chen'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2311.08718', 'title': 'Decomposing Uncertainty for Large Language Models through Input   Clarification Ensembling', 'URL': 'https://arxiv.org/abs/2311.08718', 'extra_urls': ['https://arxiv.org/abs/2311.08718'], 'type': 'article', 'author': [{'family': 'Bairu Hou'}, {'family': 'Yujian Liu'}, {'family': 'Kaizhi Qian'}, {'family': 'Jacob Andreas'}, {'family': 'Shiyu Chang'}, {'family': 'Yang Zhang'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_1703.04977', 'title': 'What Uncertainties Do We Need in Bayesian Deep Learning for Computer   Vision?', 'URL': 'https://arxiv.org/abs/1703.04977', 'extra_urls': ['https://arxiv.org/abs/1703.04977'], 'type': 'article', 'author': [{'family': 'Kendall', 'given': 'Alex'}, {'family': 'Gal', 'given': 'Yarin'}], 'issued': {'date-parts': [[2017]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2412.02646', 'title': 'Interpretable Generalized Additive Models for Datasets with Missing   Values', 'URL': 'https://arxiv.org/abs/2412.02646', 'extra_urls': ['https://arxiv.org/abs/2412.02646'], 'type': 'article', 'author': [{'family': 'Hayden McTavish'}, {'family': 'Jon Donnelly'}, {'family': 'Margo Seltzer'}, {'family': 'Cynthia Rudin'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2004.13912', 'title': 'Neural Additive Models: Interpretable Machine Learning with Neural Nets', 'URL': 'https://arxiv.org/abs/2004.13912', 'extra_urls': ['https://arxiv.org/abs/2004.13912'], 'type': 'article', 'author': [{'family': 'Rishabh Agarwal'}, {'family': 'Levi Melnick'}, {'family': 'Nicholas Frosst'}, {'family': 'Xuezhou Zhang'}, {'family': 'Ben Lengerich'}, {'family': 'Rich Caruana'}, {'family': 'Geoffrey Hinton'}], 'issued': {'date-parts': [[2020]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2509.12527', 'title': 'Selective Risk Certification for LLM Outputs via Information-Lift   Statistics: PAC-Bayes, Robustness, and Skeleton Design', 'URL': 'https://arxiv.org/abs/2509.12527', 'extra_urls': ['https://arxiv.org/abs/2509.12527'], 'type': 'article', 'author': [{'family': 'Sanjeda Akter'}, {'family': 'Ibne Farabi Shihab'}, {'family': 'Anuj Sharma'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2402.15610', 'title': 'Selective &quot;Selective Prediction&quot;: Reducing Unnecessary Abstention in   Vision-Language Reasoning', 'URL': 'https://arxiv.org/abs/2402.15610', 'extra_urls': ['https://arxiv.org/abs/2402.15610'], 'type': 'article', 'author': [{'family': 'Tejas Srinivasan'}, {'family': 'Jack Hessel'}, {'family': 'Tanmay Gupta'}, {'family': 'Bill Yuchen Lin'}, {'family': 'Yejin Choi'}, {'family': 'Jesse Thomason'}, {'family': 'Khyathi Raghavi Chandu'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2502.06884', 'title': 'Learning Conformal Abstention Policies for Adaptive Risk Management in   Large Language and Vision-Language Models', 'URL': 'https://arxiv.org/abs/2502.06884', 'extra_urls': ['https://arxiv.org/abs/2502.06884'], 'type': 'article', 'author': [{'family': 'Sina Tayebati'}, {'family': 'Divake Kumar'}, {'family': 'Nastaran Darabi'}, {'family': 'Dinithi Jayasuriya'}, {'family': 'Ranganath Krishnan'}, {'family': 'Amit Ranjan Trivedi'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_1705.08500', 'title': 'Selective Classification for Deep Neural Networks', 'URL': 'https://arxiv.org/abs/1705.08500', 'extra_urls': ['https://arxiv.org/abs/1705.08500'], 'type': 'article', 'author': [{'family': 'Yonatan Geifman'}, {'family': 'Ran El-Yaniv'}], 'issued': {'date-parts': [[2017]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2305.18404', 'title': 'Conformal Prediction with Large Language Models for Multi-Choice   Question Answering', 'URL': 'https://arxiv.org/abs/2305.18404', 'extra_urls': ['https://arxiv.org/abs/2305.18404'], 'type': 'article', 'author': [{'family': 'Bhawesh Kumar'}, {'family': 'Charlie Lu'}, {'family': 'Gauri Gupta'}, {'family': 'Anil Palepu'}, {'family': 'David Bellamy'}, {'family': 'Ramesh Raskar'}, {'family': 'Andrew Beam'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_1904.06019', 'title': 'Conformal Prediction Under Covariate Shift', 'URL': 'https://arxiv.org/abs/1904.06019', 'extra_urls': ['https://arxiv.org/abs/1904.06019'], 'type': 'article', 'author': [{'family': 'Ryan J. Tibshirani'}, {'family': 'Rina Foygel Barber'}, {'family': 'Emmanuel J. Candes'}, {'family': 'Aaditya Ramdas'}], 'issued': {'date-parts': [[2019]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_1905.03222', 'title': 'Conformalized Quantile Regression', 'URL': 'https://arxiv.org/abs/1905.03222', 'extra_urls': ['https://arxiv.org/abs/1905.03222'], 'type': 'article', 'author': [{'family': 'Yaniv Romano'}, {'family': 'Evan Patterson'}, {'family': 'Emmanuel J. Cand\xe8s'}], 'issued': {'date-parts': [[2019]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2009.14193', 'title': 'Uncertainty Sets for Image Classifiers using Conformal Prediction', 'URL': 'https://arxiv.org/abs/2009.14193', 'extra_urls': ['https://arxiv.org/abs/2009.14193'], 'type': 'article', 'author': [{'family': 'Anastasios Angelopoulos'}, {'family': 'Stephen Bates'}, {'family': 'Jitendra Malik'}, {'family': 'Michael I. Jordan'}], 'issued': {'date-parts': [[2020]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2412.05563', 'title': 'A Survey on Uncertainty Quantification of Large Language Models:   Taxonomy, Open Research Challenges, and Future Directions', 'URL': 'https://arxiv.org/abs/2412.05563', 'extra_urls': ['https://arxiv.org/abs/2412.05563'], 'type': 'article', 'author': [{'family': 'Ola Shorinwa'}, {'family': 'Zhiting Mei'}, {'family': 'Justin Lidard'}, {'family': 'Allen Z. Ren'}, {'family': 'Anirudha Majumdar'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2506.01333', 'title': 'ETDI: Mitigating Tool Squatting and Rug Pull Attacks in Model Context   Protocol (MCP) by using OAuth-Enhanced Tool Definitions and Policy-Based   Access Control', 'URL': 'https://arxiv.org/abs/2506.01333', 'extra_urls': ['https://arxiv.org/abs/2506.01333'], 'type': 'article', 'author': [{'family': 'Manish Bhatt'}, {'family': 'Vineeth Sai Narajala'}, {'family': 'Idan Habler'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.20020', 'title': 'Ontology- and LLM-based Data Harmonization for Federated Learning in   Healthcare', 'URL': 'https://arxiv.org/abs/2505.20020', 'extra_urls': ['https://arxiv.org/abs/2505.20020'], 'type': 'article', 'author': [{'family': 'Natallia Kokash'}, {'family': 'Lei Wang'}, {'family': 'Thomas H. Gillespie'}, {'family': 'Adam Belloum'}, {'family': 'Paola Grosso'}, {'family': 'Sara Quinney'}, {'family': 'Lang Li'}, {'family': 'Bernard de Bono'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2402.08088', 'title': 'Out-of-Distribution Detection and Data Drift Monitoring using   Statistical Process Control', 'URL': 'https://arxiv.org/abs/2402.08088', 'extra_urls': ['https://arxiv.org/abs/2402.08088'], 'type': 'article', 'author': [{'family': 'Ghada Zamzmi'}, {'family': 'Kesavan Venkatesh'}, {'family': 'Brandon Nelson'}, {'family': 'Smriti Prathapan'}, {'family': 'Paul H. Yi'}, {'family': 'Berkman Sahiner'}, {'family': 'Jana G. Delfino'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2410.24105', 'title': 'Matchmaker: Self-Improving Large Language Model Programs for Schema   Matching', 'URL': 'https://arxiv.org/abs/2410.24105', 'extra_urls': ['https://arxiv.org/abs/2410.24105'], 'type': 'article', 'author': [{'family': 'Nabeel Seedat'}, {'family': 'Mihaela van der Schaar'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2509.10691', 'title': 'Privacy-Preserving Decentralized Federated Learning via Explainable   Adaptive Differential Privacy', 'URL': 'https://arxiv.org/abs/2509.10691', 'extra_urls': ['https://arxiv.org/abs/2509.10691'], 'type': 'article', 'author': [{'family': 'Fardin Jalil Piran'}, {'family': 'Zhiling Chen'}, {'family': 'Yang Zhang'}, {'family': 'Qianyu Zhou'}, {'family': 'Jiong Tang'}, {'family': 'Farhad Imani'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2309.07864', 'title': 'The Rise and Potential of Large Language Model Based Agents: A Survey', 'URL': 'https://arxiv.org/abs/2309.07864', 'extra_urls': ['https://arxiv.org/abs/2309.07864'], 'type': 'article', 'author': [{'family': 'Zhiheng Xi'}, {'family': 'Wenxiang Chen'}, {'family': 'Xin Guo'}, {'family': 'Wei He'}, {'family': 'Yiwen Ding'}, {'family': 'Boyang Hong'}, {'family': 'Ming Zhang'}, {'family': 'Junzhe Wang'}, {'family': 'Senjie Jin'}, {'family': 'Enyu Zhou'}, {'family': 'Rui Zheng'}, {'family': 'Xiaoran Fan'}, {'family': 'Xiao Wang'}, {'family': 'Limao Xiong'}, {'family': 'Yuhao Zhou'}, {'family': 'Weiran Wang'}, {'family': 'Changhao Jiang'}, {'family': 'Yicheng Zou'}, {'family': 'Xiangyang Liu'}, {'family': 'Zhangyue Yin'}, {'family': 'Shihan Dou'}, {'family': 'Rongxiang Weng'}, {'family': 'Wensen Cheng'}, {'family': 'Qi Zhang'}, {'family': 'Wenjuan Qin'}, {'family': 'Yongyan Zheng'}, {'family': 'Xipeng Qiu'}, {'family': 'Xuanjing Huang'}, {'family': 'Tao Gui'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2107.07511', 'title': 'A Gentle Introduction to Conformal Prediction and Distribution-Free   Uncertainty Quantification', 'URL': 'https://arxiv.org/abs/2107.07511', 'extra_urls': ['https://arxiv.org/abs/2107.07511'], 'type': 'article', 'author': [{'family': 'Anastasios N. Angelopoulos'}, {'family': 'Stephen Bates'}], 'issued': {'date-parts': [[2021]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.22852', 'title': 'Operationalizing CaMeL: Strengthening LLM Defenses for Enterprise   Deployment', 'URL': 'https://arxiv.org/abs/2505.22852', 'extra_urls': ['https://arxiv.org/abs/2505.22852'], 'type': 'article', 'author': [{'family': 'Krti Tallam'}, {'family': 'Emma Miller'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2508.10991', 'title': 'MCP-Guard: A Defense Framework for Model Context Protocol Integrity in   Large Language Model Applications', 'URL': 'https://arxiv.org/abs/2508.10991', 'extra_urls': ['https://arxiv.org/abs/2508.10991'], 'type': 'article', 'author': [{'family': 'Wenpeng Xing'}, {'family': 'Zhonghao Qi'}, {'family': 'Yupeng Qin'}, {'family': 'Yilin Li'}, {'family': 'Caini Chang'}, {'family': 'Jiahui Yu'}, {'family': 'Changting Lin'}, {'family': 'Zhenzhen Xie'}, {'family': 'Meng Han'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2401.13178', 'title': 'AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents', 'URL': 'https://arxiv.org/abs/2401.13178', 'extra_urls': ['https://arxiv.org/abs/2401.13178'], 'type': 'article', 'author': [{'family': 'Chang Ma'}, {'family': 'Junlei Zhang'}, {'family': 'Zhihao Zhu'}, {'family': 'Cheng Yang'}, {'family': 'Yujiu Yang'}, {'family': 'Yaohui Jin'}, {'family': 'Zhenzhong Lan'}, {'family': 'Lingpeng Kong'}, {'family': 'Junxian He'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'using_of_digital', 'title': 'Using of Digital Twin Technology on the Stages of Implementation of ERP Systems', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10705183', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10705183'], 'type': 'article', 'author': [{'family': 'Hrischev', 'given': 'Radoslav'}, {'family': 'Shakev', 'given': 'Nikola'}], 'abstract': 'The globalization is challenging for the business and the companies must adapt quickly to changing market conditions, customer demands, rising resource costs and political uncertainties using new effective management systems, based on the digitalization of the economy in all its aspects. The concept Digital Twin appeared and in recent years, Digital Twin has evolved from an outcome to a driver of Industry 4.0. This paper discusses the conceptual framework and potential applications of advanced software tools for modeling and simulation as base of Digital Twin of business process and manufacturing systems. The relationship between the application of Digital Twin technology and modern Enterprise Resource Planning (ERP) systems in the phases of deployment is presented.'}, {'id': 'arxiv_2504.03692', 'title': 'A Theoretical Framework for Graph-based Digital Twins for Supply Chain Management and Optimization', 'URL': 'http://arxiv.org/abs/2504.03692', 'extra_urls': ['http://arxiv.org/abs/2504.03692'], 'type': 'article', 'author': [{'family': 'Wasi', 'given': 'Azmine Toushik'}, {'family': 'Anik', 'given': 'Mahfuz Ahmed'}, {'family': 'Rahman', 'given': 'Abdur'}, {'family': 'Hoque', 'given': 'Md Iqramul'}, {'family': 'Islam', 'given': 'MD Shafikul'}, {'family': 'Ahsan', 'given': 'Md Manjurul'}], 'publisher': 'arXiv', 'abstract': 'Supply chain management is growing increasingly complex due to globalization, evolving market demands, and sustainability pressures, yet traditional systems struggle with fragmented data and limited analytical capabilities. Graph-based modeling offers a powerful way to capture the intricate relationships within supply chains, while Digital Twins (DTs) enable real-time monitoring and dynamic simulations. However, current implementations often face challenges related to scalability, data integration, and the lack of sustainability-focused metrics. To address these gaps, we propose a Graph-Based Digital Twin Framework for Supply Chain Optimization, which combines graph modeling with DT architecture to create a dynamic, real-time representation of supply networks. Our framework integrates a Data Integration Layer to harmonize disparate sources, a Graph Construction Module to model complex dependencies, and a Simulation and Analysis Engine for scalable optimization. Importantly, we embed sustainability metrics - such as carbon footprints and resource utilization - into operational dashboards to drive eco-efficiency. By leveraging the synergy between graph-based modeling and DTs, our approach enhances scalability, improves decision-making, and enables organizations to proactively manage disruptions, cut costs, and transition toward greener, more resilient supply chains.'}, {'id': 'arxiv_2204.06972', 'title': 'The multi-modal universe of fast-fashion: the Visuelle 2.0 benchmark', 'URL': 'http://arxiv.org/abs/2204.06972', 'extra_urls': ['http://arxiv.org/abs/2204.06972'], 'type': 'article', 'author': [{'family': 'Skenderi', 'given': 'Geri'}, {'family': 'Joppi', 'given': 'Christian'}, {'family': 'Denitto', 'given': 'Matteo'}, {'family': 'Scarpa', 'given': 'Berniero'}, {'family': 'Cristani', 'given': 'Marco'}], 'publisher': 'arXiv', 'abstract': 'We present Visuelle 2.0, the first dataset useful for facing diverse prediction problems that a fast-fashion company has to manage routinely. Furthermore, we demonstrate how the use of computer vision is substantial in this scenario. Visuelle 2.0 contains data for 6 seasons / 5355 clothing products of Nuna Lie, a famous Italian company with hundreds of shops located in different areas within the country. In particular, we focus on a specific prediction problem, namely short-observation new product sale forecasting (SO-fore). SO-fore assumes that the season has started and a set of new products is on the shelves of the different stores. The goal is to forecast the sales for a particular horizon, given a short, available past (few weeks), since no earlier statistics are available. To be successful, SO-fore approaches should capture this short past and exploit other modalities or exogenous data. To these aims, Visuelle 2.0 is equipped with disaggregated data at the item-shop level and multi-modal information for each clothing item, allowing computer vision approaches to come into play. The main message that we deliver is that the use of image data with deep networks boosts performances obtained when using the time series in long-term forecasting scenarios, ameliorating the WAPE and MAE by up to 5.48% and 7% respectively compared to competitive baseline methods. The dataset is available at https://humaticslab.github.io/forecasting/visuelle'}, {'id': 'arxiv_2501.15411', 'title': 'The Potential of Large Language Models in Supply Chain Management: Advancing Decision-Making, Efficiency, and Innovation', 'URL': 'http://arxiv.org/abs/2501.15411', 'extra_urls': ['http://arxiv.org/abs/2501.15411'], 'type': 'article', 'author': [{'family': 'Aghaei', 'given': 'Raha'}, {'family': 'Kiaei', 'given': 'Ali A.'}, {'family': 'Boush', 'given': 'Mahnaz'}, {'family': 'Vahidi', 'given': 'Javad'}, {'family': 'Barzegar', 'given': 'Zeynab'}, {'family': 'Rofoosheh', 'given': 'Mahan'}], 'publisher': 'arXiv', 'abstract': 'The integration of large language models (LLMs) into supply chain management (SCM) is revolutionizing the industry by improving decision-making, predictive analytics, and operational efficiency. This white paper explores the transformative impact of LLMs on various SCM functions, including demand forecasting, inventory management, supplier relationship management, and logistics optimization. By leveraging advanced data analytics and real-time insights, LLMs enable organizations to optimize resources, reduce costs, and improve responsiveness to market changes. Key findings highlight the benefits of integrating LLMs with emerging technologies such as IoT, blockchain, and robotics, which together create smarter and more autonomous supply chains. Ethical considerations, including bias mitigation and data protection, are taken into account to ensure fair and transparent AI practices. In addition, the paper discusses the need to educate the workforce on how to manage new AI-driven processes and the long-term strategic benefits of adopting LLMs. Strategic recommendations for SCM professionals include investing in high-quality data management, promoting cross-functional collaboration, and aligning LLM initiatives with overall business goals. The findings highlight the potential of LLMs to drive innovation, sustainability, and competitive advantage in the ever-changing supply chain management landscape.'}, {'id': 'arxiv_2509.03811', 'title': 'Leveraging LLM-Based Agents for Intelligent Supply Chain Planning', 'URL': 'http://arxiv.org/abs/2509.03811', 'extra_urls': ['http://arxiv.org/abs/2509.03811'], 'type': 'article', 'author': [{'family': 'Qi', 'given': 'Yongzhi'}, {'family': 'Yin', 'given': 'Jiaheng'}, {'family': 'Zhang', 'given': 'Jianshen'}, {'family': 'Geng', 'given': 'Dongyang'}, {'family': 'Chen', 'given': 'Zhengyu'}, {'family': 'Hu', 'given': 'Hao'}, {'family': 'Qi', 'given': 'Wei'}, {'family': 'Shen', 'given': 'Zuo-Jun Max'}], 'publisher': 'arXiv', 'abstract': &quot;In supply chain management, planning is a critical concept. The movement of physical products across different categories, from suppliers to warehouse management, to sales, and logistics transporting them to customers, entails the involvement of many entities. It covers various aspects such as demand forecasting, inventory management, sales operations, and replenishment. How to collect relevant data from an e-commerce platform's perspective, formulate long-term plans, and dynamically adjust them based on environmental changes, while ensuring interpretability, efficiency, and reliability, is a practical and challenging problem. In recent years, the development of AI technologies, especially the rapid progress of large language models, has provided new tools to address real-world issues. In this work, we construct a Supply Chain Planning Agent (SCPA) framework that can understand domain knowledge, comprehend the operator's needs, decompose tasks, leverage or create new tools, and return evidence-based planning reports. We deploy this framework in JD.com's real-world scenario, demonstrating the feasibility of LLM-agent applications in the supply chain. It effectively reduced labor and improved accuracy, stock availability, and other key metrics.&quot;}, {'id': 'the', 'title': &quot;Position: What's the next frontier for Data-centric AI? Data Savvy Agents!&quot;, 'URL': 'https://openreview.net/forum?id=2GEipEDZB0', 'extra_urls': ['https://openreview.net/forum?id=2GEipEDZB0'], 'type': 'article', 'author': [{'family': 'Seedat', 'given': 'Nabeel'}, {'family': 'Liu', 'given': 'Jiashuo'}, {'family': 'Schaar', 'given': 'Mihaela van der'}], 'abstract': 'The recent surge in AI agents that autonomously communicate, collaborate with humans and use diverse tools has unlocked promising opportunities in various real-world settings. However, a vital aspect remains underexplored: how agents handle data. Agents cannot achieve scalable autonomy without the ability to dynamically acquire, process, and continually evolve their data ecosystems to navigate complex and changing environments. In this position paper, we argue that data-savvy capabilities should be a top priority in the design of agentic systems to ensure reliable real-world deployment. Specifically, we propose four key capabilities to realize this vision: (1) Proactive data acquisition: enabling agents to autonomously gather task-critical knowledge or solicit human input to address data gaps; (2) Sophisticated data processing: requiring context-aware and flexible handling of diverse data challenges and inputs; (3) Interactive test data synthesis: shifting from static benchmarks to dynamically generated interactive test data for agent evaluation; and (4) Continual adaptation: empowering agents to iteratively refine their data and background knowledge to adapt to shifting environments. While current agent research predominantly emphasizes reasoning, we hope this work inspires a broader reflection on the role of data-savvy agents as the next frontier in data-centric AI.'}, {'id': 'arxiv_2406.14758', 'title': 'Compliance Cards: Automated EU AI Act Compliance Analyses amidst a Complex AI Supply Chain', 'URL': 'http://arxiv.org/abs/2406.14758', 'extra_urls': ['http://arxiv.org/abs/2406.14758'], 'type': 'article', 'author': [{'family': 'Marino', 'given': 'Bill'}, {'family': 'Chaudhary', 'given': 'Yaqub'}, {'family': 'Pi', 'given': 'Yulu'}, {'family': 'Yew', 'given': 'Rui-Jie'}, {'family': 'Aleksandrov', 'given': 'Preslav'}, {'family': 'Rahman', 'given': 'Carwyn'}, {'family': 'Shen', 'given': 'William F.'}, {'family': 'Robinson', 'given': 'Isaac'}, {'family': 'Lane', 'given': 'Nicholas D.'}], 'publisher': 'arXiv', 'abstract': &quot;As the AI supply chain grows more complex, AI systems and models are increasingly likely to incorporate multiple internally- or externally-sourced components such as datasets and (pre-trained) models. In such cases, determining whether or not the aggregate AI system or model complies with the EU AI Act (AIA) requires a multi-step process in which compliance-related information about both the AI system or model and all its component parts is: (1) gathered, potentially from multiple arms-length sources; (2) harmonized, if necessary; (3) inputted into an analysis that looks across all of it to render a compliance prediction. Because this process is so complex and time-consuming, it threatens to overburden the limited compliance resources of the AI providers (i.e., developers) who bear much of the responsibility for complying with the AIA. It also renders rapid or real-time compliance analyses infeasible in many AI development scenarios where they would be beneficial to providers. To address these shortcomings, we introduce a complete system for automating provider-side AIA compliance analyses amidst a complex AI supply chain. This system has two key elements. First is an interlocking set of computational, multi-stakeholder transparency artifacts that capture AIA-specific metadata about both: (1) the provider's overall AI system or model; and (2) the datasets and pre-trained models it incorporates as components. Second is an algorithm that operates across all those artifacts to render a real-time prediction about whether or not the aggregate AI system or model complies with the AIA. All told, this system promises to dramatically facilitate and democratize provider-side AIA compliance analyses (and, perhaps by extension, provider-side AIA compliance).&quot;}, {'id': 'arxiv_2509.13813', 'title': 'Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs', 'URL': 'http://arxiv.org/abs/2509.13813', 'extra_urls': ['http://arxiv.org/abs/2509.13813'], 'type': 'article', 'author': [{'family': 'Phillips', 'given': 'Edward'}, {'family': 'Wu', 'given': 'Sean'}, {'family': 'Molaei', 'given': 'Soheila'}, {'family': 'Belgrave', 'given': 'Danielle'}, {'family': 'Thakur', 'given': 'Anshul'}, {'family': 'Clifton', 'given': 'David'}], 'publisher': 'arXiv', 'abstract': 'Large language models demonstrate impressive results across diverse tasks but are still known to hallucinate, generating linguistically plausible but incorrect answers to questions. Uncertainty quantification has been proposed as a strategy for hallucination detection, but no existing black-box approach provides estimates for both global and local uncertainty. The former attributes uncertainty to a batch of responses, while the latter attributes uncertainty to individual responses. Current local methods typically rely on white-box access to internal model states, whilst black-box methods only provide global uncertainty estimates. We introduce a geometric framework to address this, based on archetypal analysis of batches of responses sampled with only black-box model access. At the global level, we propose Geometric Volume, which measures the convex hull volume of archetypes derived from response embeddings. At the local level, we propose Geometric Suspicion, which ranks responses by reliability and enables hallucination reduction through preferential response selection. Unlike prior dispersion methods which yield only a single global score, our approach provides semantic boundary points which have utility for attributing reliability to individual responses. Experiments show that our framework performs comparably to or better than prior methods on short form question-answering datasets, and achieves superior results on medical datasets where hallucinations carry particularly critical risks. We also provide theoretical justification by proving a link between convex hull volume and entropy.'}, {'id': 'arxiv_2503.00172', 'title': 'A Survey of Uncertainty Estimation Methods on Large Language Models', 'URL': 'http://arxiv.org/abs/2503.00172', 'extra_urls': ['http://arxiv.org/abs/2503.00172'], 'type': 'article', 'author': [{'family': 'Xia', 'given': 'Zhiqiu'}, {'family': 'Xu', 'given': 'Jinxuan'}, {'family': 'Zhang', 'given': 'Yuqian'}, {'family': 'Liu', 'given': 'Hang'}], 'publisher': 'arXiv', 'abstract': 'Large language models (LLMs) have demonstrated remarkable capabilities across various tasks. However, these models could offer biased, hallucinated, or non-factual responses camouflaged by their fluency and realistic appearance. Uncertainty estimation is the key method to address this challenge. While research efforts in uncertainty estimation are ramping up, there is a lack of comprehensive and dedicated surveys on LLM uncertainty estimation. This survey presents four major avenues of LLM uncertainty estimation. Furthermore, we perform extensive experimental evaluations across multiple methods and datasets. At last, we provide critical and promising future directions for LLM uncertainty estimation.'}, {'id': 'a_dataset', 'title': 'GarmentCodeData: A Dataset of\xa03D Made-to-Measure Garments with Sewing Patterns', 'URL': 'urn:isbn:978-3-031-73027-6', 'type': 'article', 'author': [{'family': 'Korosteleva', 'given': 'Maria'}, {'family': 'Kesdogan', 'given': 'Timur Levent'}, {'family': 'Kemper', 'given': 'Fabian'}, {'family': 'Wenninger', 'given': 'Stephan'}, {'family': 'Koller', 'given': 'Jasmin'}, {'family': 'Zhang', 'given': 'Yuhan'}, {'family': 'Botsch', 'given': 'Mario'}, {'family': 'Sorkine-Hornung', 'given': 'Olga'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Springer Nature Switzerland', 'abstract': 'Recent research interest in learning-based processing of garments, from virtual fitting to generation and reconstruction, stumbles on a scarcity of high-quality public data in the domain. We contribute to resolving this need by presenting the first large-scale synthetic dataset of 3D made-to-measure garments with sewing patterns, as well as its generation pipeline. GarmentCodeData contains 115,000 data points that cover a variety of designs in many common garment categories: tops, shirts, dresses, jumpsuits, skirts, pants, etc., fitted to a variety of body shapes sampled from a custom statistical body model based on CAESAR\xa0[28], as well as a standard reference body shape, applying three different textile materials. To enable the creation of datasets of such complexity, we introduce a set of algorithms for automatically taking tailor\u2019s measures on sampled body shapes, sampling strategies for sewing pattern design, and propose an automatic, open-source 3D garment draping pipeline based on a fast XPBD simulator\xa0[22], while contributing several solutions for collision resolution and drape correctness to enable scalability.'}, {'id': 'generation', 'title': 'WordRobe: Text-Guided Generation of\xa0Textured 3D Garments', 'URL': 'urn:isbn:978-3-031-73232-4', 'type': 'article', 'author': [{'family': 'Srivastava', 'given': 'Astitva'}, {'family': 'Manu', 'given': 'Pranav'}, {'family': 'Raj', 'given': 'Amit'}, {'family': 'Jampani', 'given': 'Varun'}, {'family': 'Sharma', 'given': 'Avinash'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Springer Nature Switzerland', 'abstract': 'In this paper, we tackle a new and challenging problem of text-driven generation of 3D garments with high-quality textures. We propose, WordRobe, a novel framework for the generation of unposed &amp; textured 3D garment meshes from user-friendly text prompts. We achieve this by first learning a latent representation of 3D garments using a novel coarse-to-fine training strategy and a loss for latent disentanglement, promoting better latent interpolation. Subsequently, we align the garment latent space to the CLIP embedding space in a weakly supervised manner, enabling text-driven 3D garment generation and editing. For appearance modeling, we leverage the zero-shot generation capability of ControlNet to synthesize view-consistent texture maps in a single feed-forward inference step, thereby drastically decreasing the generation time as compared to existing methods. We demonstrate superior performance over current SOTAs for learning 3D garment latent space, garment interpolation, and text-driven texture synthesis, supported by quantitative evaluation and qualitative user study. The unposed 3D garment meshes generated using WordRobe can be directly fed to standard cloth simulation &amp; animation pipelines without any post-processing.'}, {'id': 'designing_creative', 'title': 'CRAFT: Designing Creative and Functional 3D Objects', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10944124', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10944124'], 'type': 'article', 'author': [{'family': 'Guo', 'given': 'Michelle'}, {'family': 'Tang', 'given': 'Mia'}, {'family': 'Cha', 'given': 'Hannah'}, {'family': 'Zhang', 'given': 'Ruohan'}, {'family': 'Liu', 'given': 'C. Karen'}, {'family': 'Wu', 'given': 'Jiajun'}], 'abstract': 'For designing a wide range of everyday objects, the design process should be aware of both the human body and the underlying semantics of the design specification. However, these two objectives present significant challenges to the current AI-based designing tools. In this work, we present a method to synthesize body-aware 3D objects from a base mesh given an input body geometry and either text or image as guidance. The generated objects can be simulated on virtual characters, or fabricated for real-world use. We propose to use a mesh deformation procedure that optimizes for both semantic alignment as well as contact and penetration losses. Using our method, users can generate both virtual or real-world objects from text, image, or sketch, without the need for manual artist intervention. We present both qualitative and quantitative results on various object categories, demonstrating the effectiveness of our approach.'}, {'id': 'arxiv_2508.17712', 'title': 'NGD: Neural Gradient Based Deformation for Monocular Garment Reconstruction', 'URL': 'http://arxiv.org/abs/2508.17712', 'extra_urls': ['http://arxiv.org/abs/2508.17712'], 'type': 'article', 'author': [{'family': 'Dasgupta', 'given': 'Soham'}, {'family': 'Naik', 'given': 'Shanthika'}, {'family': 'Savalia', 'given': 'Preet'}, {'family': 'Ingle', 'given': 'Sujay Kumar'}, {'family': 'Sharma', 'given': 'Avinash'}], 'publisher': 'arXiv', 'abstract': 'Dynamic garment reconstruction from monocular video is an important yet challenging task due to the complex dynamics and unconstrained nature of the garments. Recent advancements in neural rendering have enabled high-quality geometric reconstruction with image/video supervision. However, implicit representation methods that use volume rendering often provide smooth geometry and fail to model high-frequency details. While template reconstruction methods model explicit geometry, they use vertex displacement for deformation, which results in artifacts. Addressing these limitations, we propose NGD, a Neural Gradient-based Deformation method to reconstruct dynamically evolving textured garments from monocular videos. Additionally, we propose a novel adaptive remeshing strategy for modelling dynamically evolving surfaces like wrinkles and pleats of the skirt, leading to high-quality reconstruction. Finally, we learn dynamic texture maps to capture per-frame lighting and shadow effects. We provide extensive qualitative and quantitative evaluations to demonstrate significant improvements over existing SOTA methods and provide high-quality garment reconstructions.'}, {'id': 'arxiv_2507.21288', 'title': 'Learning Simulatable Models of Cloth with Spatially-varying Constitutive Properties', 'URL': 'http://arxiv.org/abs/2507.21288', 'extra_urls': ['http://arxiv.org/abs/2507.21288'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Guanxiong'}, {'family': 'Suri', 'given': 'Shashwat'}, {'family': 'Wu', 'given': 'Yuhao'}, {'family': 'Voulga', 'given': 'Etienne'}, {'family': 'Levin', 'given': 'David I. W.'}, {'family': 'Pai', 'given': 'Dinesh K.'}], 'publisher': 'arXiv', 'abstract': &quot;Materials used in real clothing exhibit remarkable complexity and spatial variation due to common processes such as stitching, hemming, dyeing, printing, padding, and bonding. Simulating these materials, for instance using finite element methods, is often computationally demanding and slow. Worse, such methods can suffer from numerical artifacts called ``membrane locking'' that makes cloth appear artificially stiff. Here we propose a general framework, called Mass-Spring Net, for learning a simple yet efficient surrogate model that captures the effects of these complex materials using only motion observations. The cloth is discretized into a mass-spring network with unknown material parameters that are learned directly from the motion data, using a novel force-and-impulse loss function. Our approach demonstrates the ability to accurately model spatially varying material properties from a variety of data sources, and immunity to membrane locking which plagues FEM-based simulations. Compared to graph-based networks and neural ODE-based architectures, our method achieves significantly faster training times, higher reconstruction accuracy, and improved generalization to novel dynamic scenarios.&quot;}, {'id': 'arxiv_2509.08828', 'title': 'SAFT: Shape and Appearance of Fabrics from Template via Differentiable Physical Simulations from Monocular Video', 'URL': 'http://arxiv.org/abs/2509.08828', 'extra_urls': ['http://arxiv.org/abs/2509.08828'], 'type': 'article', 'author': [{'family': 'Stotko', 'given': 'David'}, {'family': 'Klein', 'given': 'Reinhard'}], 'publisher': 'arXiv', 'abstract': 'The reconstruction of three-dimensional dynamic scenes is a well-established yet challenging task within the domain of computer vision. In this paper, we propose a novel approach that combines the domains of 3D geometry reconstruction and appearance estimation for physically based rendering and present a system that is able to perform both tasks for fabrics, utilizing only a single monocular RGB video sequence as input. In order to obtain realistic and high-quality deformations and renderings, a physical simulation of the cloth geometry and differentiable rendering are employed. In this paper, we introduce two novel regularization terms for the 3D reconstruction task that improve the plausibility of the reconstruction by addressing the depth ambiguity problem in monocular video. In comparison with the most recent methods in the field, we have reduced the error in the 3D reconstruction by a factor of 2.64 while requiring a medium runtime of 30 min per scene. Furthermore, the optimized motion achieves sufficient quality to perform an appearance estimation of the deforming object, recovering sharp details from this single monocular RGB video.'}, {'id': 'arxiv_2503.08678', 'title': 'GarmentCrafter: Progressive Novel View Synthesis for Single-View 3D Garment Reconstruction and Editing', 'URL': 'http://arxiv.org/abs/2503.08678', 'extra_urls': ['http://arxiv.org/abs/2503.08678'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Yuanhao'}, {'family': 'Zhang', 'given': 'Cheng'}, {'family': 'Fraz\xe3o', 'given': 'Gon\xe7alo'}, {'family': 'Yang', 'given': 'Jinlong'}, {'family': 'Ichim', 'given': 'Alexandru-Eugen'}, {'family': 'Beeler', 'given': 'Thabo'}, {'family': 'Torre', 'given': 'Fernando De la'}], 'publisher': 'arXiv', 'abstract': 'We introduce GarmentCrafter, a new approach that enables non-professional users to create and modify 3D garments from a single-view image. While recent advances in image generation have facilitated 2D garment design, creating and editing 3D garments remains challenging for non-professional users. Existing methods for single-view 3D reconstruction often rely on pre-trained generative models to synthesize novel views conditioning on the reference image and camera pose, yet they lack cross-view consistency, failing to capture the internal relationships across different views. In this paper, we tackle this challenge through progressive depth prediction and image warping to approximate novel views. Subsequently, we train a multi-view diffusion model to complete occluded and unknown clothing regions, informed by the evolving camera pose. By jointly inferring RGB and depth, GarmentCrafter enforces inter-view coherence and reconstructs precise geometries and fine details. Extensive experiments demonstrate that our method achieves superior visual fidelity and inter-view coherence compared to state-of-the-art single-view 3D garment reconstruction methods.'}, {'id': 'arxiv_2508.09977', 'title': 'A Survey on 3D Gaussian Splatting Applications: Segmentation, Editing, and Generation', 'URL': 'http://arxiv.org/abs/2508.09977', 'extra_urls': ['http://arxiv.org/abs/2508.09977'], 'type': 'article', 'author': [{'family': 'He', 'given': 'Shuting'}, {'family': 'Ji', 'given': 'Peilin'}, {'family': 'Yang', 'given': 'Yitong'}, {'family': 'Wang', 'given': 'Changshuo'}, {'family': 'Ji', 'given': 'Jiayi'}, {'family': 'Wang', 'given': 'Yinglin'}, {'family': 'Ding', 'given': 'Henghui'}], 'publisher': 'arXiv', 'abstract': '3D Gaussian Splatting (3DGS) has recently emerged as a powerful alternative to Neural Radiance Fields (NeRF) for 3D scene representation, offering high-fidelity photorealistic rendering with real-time performance. Beyond novel view synthesis, the explicit and compact nature of 3DGS enables a wide range of downstream applications that require geometric and semantic understanding. This survey provides a comprehensive overview of recent progress in 3DGS applications. It first introduces 2D foundation models that support semantic understanding and control in 3DGS applications, followed by a review of NeRF-based methods that inform their 3DGS counterparts. We then categorize 3DGS applications into segmentation, editing, generation, and other functional tasks. For each, we summarize representative methods, supervision strategies, and learning paradigms, highlighting shared design principles and emerging trends. Commonly used datasets and evaluation protocols are also summarized, along with comparative analyses of recent methods across public benchmarks. To support ongoing research and development, a continually updated repository of papers, code, and resources is maintained at https://github.com/heshuting555/Awesome-3DGS-Applications.'}, {'id': 'arxiv_2506.12348', 'title': 'Real-Time Per-Garment Virtual Try-On with Temporal Consistency for Loose-Fitting Garments', 'URL': 'http://arxiv.org/abs/2506.12348', 'extra_urls': ['http://arxiv.org/abs/2506.12348'], 'type': 'article', 'author': [{'family': 'Wu', 'given': 'Zaiqiang'}, {'family': 'Shen', 'given': 'I.-Chao'}, {'family': 'Igarashi', 'given': 'Takeo'}], 'abstract': 'Per-garment virtual try-on methods collect garment-specific datasets and train networks tailored to each garment to achieve superior results. However, these approaches often struggle with loose-fitting garments due to two key limitations: (1) They rely on human body semantic maps to align garments with the body, but these maps become unreliable when body contours are obscured by loose-fitting garments, resulting in degraded outcomes; (2) They train garment synthesis networks on a per-frame basis without utilizing temporal information, leading to noticeable jittering artifacts. To address the first limitation, we propose a two-stage approach for robust semantic map estimation. First, we extract a garment-invariant representation from the raw input image. This representation is then passed through an auxiliary network to estimate the semantic map. This enhances the robustness of semantic map estimation under loose-fitting garments during garment-specific dataset generation. To address the second limitation, we introduce a recurrent garment synthesis framework that incorporates temporal dependencies to improve frame-to-frame coherence while maintaining real-time performance. We conducted qualitative and quantitative evaluations to demonstrate that our method outperforms existing approaches in both image quality and temporal coherence. Ablation studies further validate the effectiveness of the garment-invariant representation and the recurrent synthesis framework.'}, {'id': 'gaussian_reconstructing', 'title': 'Gaussian Garments: Reconstructing Simulation-Ready Clothing with Photorealistic Appearance from Multi-View Video', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11125573', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11125573'], 'type': 'article', 'author': [{'family': 'Rong', 'given': 'Boxiang'}, {'family': 'Grigorev', 'given': 'Artur'}, {'family': 'Wang', 'given': 'Wenbo'}, {'family': 'Black', 'given': 'Michael J.'}, {'family': 'Thomaszewski', 'given': 'Bernhard'}, {'family': 'Tsalicoglou', 'given': 'Christina'}, {'family': 'Hilliges', 'given': 'Otmar'}], 'abstract': 'We introduce Gaussian Garments, a novel approach for reconstructing realistic simulation-ready garment assets from multi-view videos. Our method represents garments with a combination of a 3D mesh and a Gaussian texture that encodes both the color and high-frequency surface details. This representation enables accurate registration of garment geometries to multi-view videos and helps disentangle albedo textures from lighting effects. Furthermore, we demonstrate how a pretrained graph neural network (GNN) can be fine-tuned to replicate the real behavior of each garment. The reconstructed Gaussian Garments can be automatically combined into multi-garment outfits and animated with the fine-tuned GNN.'}, {'id': 'arxiv_2501.10455', 'title': 'PhyDeformer: High-Quality Non-Rigid Garment Registration with Physics-Awareness', 'URL': 'http://arxiv.org/abs/2501.10455', 'extra_urls': ['http://arxiv.org/abs/2501.10455'], 'type': 'article', 'author': [{'family': 'Yu', 'given': 'Boyang'}, {'family': 'Cordier', 'given': 'Frederic'}, {'family': 'Seo', 'given': 'Hyewon'}], 'publisher': 'arXiv', 'abstract': 'We present PhyDeformer, a new deformation method for high-quality garment mesh registration. It operates in two phases: In the first phase, a garment grading is performed to achieve a coarse 3D alignment between the mesh template and the target mesh, accounting for proportional scaling and fit (e.g. length, size). Then, the graded mesh is refined to align with the fine-grained details of the 3D target through an optimization coupled with the Jacobian-based deformation framework. Both quantitative and qualitative evaluations on synthetic and real garments highlight the effectiveness of our method.'}, {'id': 'arxiv_2311.12194', 'title': 'DiffAvatar: Simulation-Ready Garment Optimization with Differentiable Simulation', 'URL': 'http://arxiv.org/abs/2311.12194', 'extra_urls': ['http://arxiv.org/abs/2311.12194'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Yifei'}, {'family': 'Chen', 'given': 'Hsiao-yu'}, {'family': 'Larionov', 'given': 'Egor'}, {'family': 'Sarafianos', 'given': 'Nikolaos'}, {'family': 'Matusik', 'given': 'Wojciech'}, {'family': 'Stuyck', 'given': 'Tuur'}], 'publisher': 'arXiv', 'abstract': &quot;The realism of digital avatars is crucial in enabling telepresence applications with self-expression and customization. While physical simulations can produce realistic motions for clothed humans, they require high-quality garment assets with associated physical parameters for cloth simulations. However, manually creating these assets and calibrating their parameters is labor-intensive and requires specialized expertise. Current methods focus on reconstructing geometry, but don't generate complete assets for physics-based applications. To address this gap, we propose \\papername,~a novel approach that performs body and garment co-optimization using differentiable simulation. By integrating physical simulation into the optimization loop and accounting for the complex nonlinear behavior of cloth and its intricate interaction with the body, our framework recovers body and garment geometry and extracts important material parameters in a physically plausible way. Our experiments demonstrate that our approach generates realistic clothing and body shape suitable for downstream applications. We provide additional insights and results on our webpage: https://people.csail.mit.edu/liyifei/publication/diffavatar/&quot;}, {'id': 'arxiv_2503.12052', 'title': 'Tailor: An Integrated Text-Driven CG-Ready Human and Garment Generation System', 'URL': 'http://arxiv.org/abs/2503.12052', 'extra_urls': ['http://arxiv.org/abs/2503.12052'], 'type': 'article', 'author': [{'family': 'Sun', 'given': 'Zhiyao'}, {'family': 'Wen', 'given': 'Yu-Hui'}, {'family': 'Lin', 'given': 'Matthieu'}, {'family': 'Fang', 'given': 'Ho-Jui'}, {'family': 'Ye', 'given': 'Sheng'}, {'family': 'Lv', 'given': 'Tian'}, {'family': 'Liu', 'given': 'Yong-Jin'}], 'publisher': 'arXiv', 'abstract': 'Creating detailed 3D human avatars with garments typically requires specialized expertise and labor-intensive processes. Although recent advances in generative AI have enabled text-to-3D human/clothing generation, current methods fall short in offering accessible, integrated pipelines for producing ready-to-use clothed avatars. To solve this, we introduce Tailor, an integrated text-to-avatar system that generates high-fidelity, customizable 3D humans with simulation-ready garments. Our system includes a three-stage pipeline. We first employ a large language model to interpret textual descriptions into parameterized body shapes and semantically matched garment templates. Next, we develop topology-preserving deformation with novel geometric losses to adapt garments precisely to body geometries. Furthermore, an enhanced texture diffusion module with a symmetric local attention mechanism ensures both view consistency and photorealistic details. Quantitative and qualitative evaluations demonstrate that Tailor outperforms existing SoTA methods in terms of fidelity, usability, and diversity. Code will be available for academic use.'}, {'id': 'arxiv_2504.03468', 'title': 'D-Garment: Physics-Conditioned Latent Diffusion for Dynamic Garment Deformations', 'URL': 'http://arxiv.org/abs/2504.03468', 'extra_urls': ['http://arxiv.org/abs/2504.03468'], 'type': 'article', 'author': [{'family': 'Dumoulin', 'given': 'Antoine'}, {'family': 'Boukhayma', 'given': 'Adnane'}, {'family': 'Boissieux', 'given': 'Laurence'}, {'family': 'Damodaran', 'given': 'Bharath Bhushan'}, {'family': 'Hellier', 'given': 'Pierre'}, {'family': 'Wuhrer', 'given': 'Stefanie'}], 'publisher': 'arXiv', 'abstract': &quot;Adjusting and deforming 3D garments to body shapes, body motion, and cloth material is an important problem in virtual and augmented reality. Applications are numerous, ranging from virtual change rooms to the entertainment and gaming industry. This problem is challenging as garment dynamics influence geometric details such as wrinkling patterns, which depend on physical input including the wearer's body shape and motion, as well as cloth material features. Existing work studies learning-based modeling techniques to generate garment deformations from example data, and physics-inspired simulators to generate realistic garment dynamics. We propose here a learning-based approach trained on data generated with a physics-based simulator. Compared to prior work, our 3D generative model learns garment deformations for loose cloth geometry, especially for large deformations and dynamic wrinkles driven by body motion and cloth material. Furthermore, the model can be efficiently fitted to observations captured using vision sensors. We propose to leverage the capability of diffusion models to learn fine-scale detail: we model the 3D garment in a 2D parameter space, and learn a latent diffusion model using this representation independent from the mesh resolution. This allows to condition global and local geometric information with body and material information. We quantitatively and qualitatively evaluate our method on both simulated data and data captured with a multi-view acquisition platform. Compared to strong baselines, our method is more accurate in terms of Chamfer distance.&quot;}, {'id': 'guided', 'title': 'GarmentGS: Point-Cloud Guided Gaussian Splatting for High-Fidelity Non-Watertight 3D Garment Reconstruction', 'URL': 'https://dl.acm.org/doi/10.1145/3731715.3733478', 'type': 'article', 'author': [{'family': 'Tang', 'given': 'Zhihao'}, {'family': 'Yang', 'given': 'Shenghao'}, {'family': 'Zhang', 'given': 'Hongtao'}, {'family': 'Zhao', 'given': 'Mingbo'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Traditional 3D garment creation requires extensive manual operations, resulting in time and labor costs. Recently, 3D Gaussian Splatting has achieved breakthrough progress in 3D scene reconstruction and rendering, attracting widespread attention and opening new pathways for 3D garment reconstruction. However, due to the unstructured and irregular nature of Gaussian primitives, it is difficult to reconstruct high-fidelity, non-watertight 3D garments. In this paper, we present GarmentGS, a dense point cloud-guided method that can reconstruct high-fidelity garment surfaces with high geometric accuracy and generate non-watertight, single-layer meshes. Our method introduces a fast dense point cloud reconstruction module that can complete garment point cloud reconstruction in 10 minutes, compared to traditional methods that require several hours. Furthermore, we use dense point clouds to guide the movement, flattening, and rotation of Gaussian primitives, enabling better distribution on the garment surface to achieve superior rendering effects and geometric accuracy. Through numerical and visual comparisons, our method achieves fast training and real-time rendering while maintaining competitive quality.'}, {'id': 'arxiv_2504.21476', 'title': 'GarmentDiffusion: 3D Garment Sewing Pattern Generation with Multimodal Diffusion Transformers', 'URL': 'http://arxiv.org/abs/2504.21476', 'extra_urls': ['http://arxiv.org/abs/2504.21476'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Xinyu'}, {'family': 'Yao', 'given': 'Qi'}, {'family': 'Wang', 'given': 'Yuanda'}], 'abstract': 'Garment sewing patterns are fundamental design elements that bridge the gap between design concepts and practical manufacturing. The generative modeling of sewing patterns is crucial for creating diversified garments. However, existing approaches are limited either by reliance on a single input modality or by suboptimal generation efficiency. In this work, we present GarmentDiffusion, a new generative model capable of producing centimeter-precise, vectorized 3D sewing patterns from multimodal inputs (text, image, and incomplete sewing pattern). Our method efficiently encodes 3D sewing pattern parameters into compact edge token representations, achieving a sequence length that is 10 times shorter than that of the autoregressive SewingGPT in DressCode. By employing a diffusion transformer, we simultaneously denoise all edge tokens along the temporal axis, while maintaining a constant number of denoising steps regardless of dataset-specific edge and panel statistics. With all combination of designs of our model, the sewing pattern generation speed is accelerated by 100 times compared to SewingGPT. We achieve new state-of-the-art results on DressCodeData, as well as on the largest sewing pattern dataset, namely GarmentCodeData. The project website is available at https://shenfu-research.github.io/Garment-Diffusion/.'}, {'id': 'arxiv_2501.13692', 'title': 'Training-Free Consistency Pipeline for Fashion Repose', 'URL': 'http://arxiv.org/abs/2501.13692', 'extra_urls': ['http://arxiv.org/abs/2501.13692'], 'type': 'article', 'author': [{'family': 'Aghilar', 'given': 'Potito'}, {'family': 'Anelli', 'given': 'Vito Walter'}, {'family': 'Trizio', 'given': 'Michelantonio'}, {'family': 'Noia', 'given': 'Tommaso Di'}], 'publisher': 'arXiv', 'abstract': 'Recent advancements in diffusion models have significantly broadened the possibilities for editing images of real-world objects. However, performing non-rigid transformations, such as changing the pose of objects or image-based conditioning, remains challenging. Maintaining object identity during these edits is difficult, and current methods often fall short of the precision needed for industrial applications, where consistency is critical. Additionally, fine-tuning diffusion models requires custom training data, which is not always accessible in real-world scenarios. This work introduces FashionRepose, a training-free pipeline for non-rigid pose editing specifically designed for the fashion industry. The approach integrates off-the-shelf models to adjust poses of long-sleeve garments, maintaining identity and branding attributes. FashionRepose uses a zero-shot approach to perform these edits in near real-time, eliminating the need for specialized training. consistent image editing. The solution holds potential for applications in the fashion industry and other fields demanding identity preservation in image editing.'}, {'id': 'arxiv_2510.04822', 'title': 'AvatarVTON: 4D Virtual Try-On for Animatable Avatars', 'URL': 'http://arxiv.org/abs/2510.04822', 'extra_urls': ['http://arxiv.org/abs/2510.04822'], 'type': 'article', 'author': [{'family': 'Jiang', 'given': 'Zicheng'}, {'family': 'Gao', 'given': 'Jixin'}, {'family': 'He', 'given': 'Shengfeng'}, {'family': 'Li', 'given': 'Xinzhe'}, {'family': 'Zheng', 'given': 'Yulong'}, {'family': 'Yang', 'given': 'Zhaotong'}, {'family': 'Dong', 'given': 'Junyu'}, {'family': 'Du', 'given': 'Yong'}], 'publisher': 'arXiv', 'abstract': 'We propose AvatarVTON, the first 4D virtual try-on framework that generates realistic try-on results from a single in-shop garment image, enabling free pose control, novel-view rendering, and diverse garment choices. Unlike existing methods, AvatarVTON supports dynamic garment interactions under single-view supervision, without relying on multi-view garment captures or physics priors. The framework consists of two key modules: (1) a Reciprocal Flow Rectifier, a prior-free optical-flow correction strategy that stabilizes avatar fitting and ensures temporal coherence; and (2) a Non-Linear Deformer, which decomposes Gaussian maps into view-pose-invariant and view-pose-specific components, enabling adaptive, non-linear garment deformations. To establish a benchmark for 4D virtual try-on, we extend existing baselines with unified modules for fair qualitative and quantitative comparisons. Extensive experiments show that AvatarVTON achieves high fidelity, diversity, and dynamic garment realism, making it well-suited for AR/VR, gaming, and digital-human applications.'}, {'id': 'arxiv_2509.16960', 'title': 'SemanticGarment: Semantic-Controlled Generation and Editing of 3D Gaussian Garments', 'URL': 'http://arxiv.org/abs/2509.16960', 'extra_urls': ['http://arxiv.org/abs/2509.16960'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Ruiyan'}, {'family': 'Cheng', 'given': 'Zhengxue'}, {'family': 'Lin', 'given': 'Zonghao'}, {'family': 'Ling', 'given': 'Jun'}, {'family': 'Liu', 'given': 'Yuzhou'}, {'family': 'An', 'given': 'Yanru'}, {'family': 'Xie', 'given': 'Rong'}, {'family': 'Song', 'given': 'Li'}], 'abstract': '3D digital garment generation and editing play a pivotal role in fashion design, virtual try-on, and gaming. Traditional methods struggle to meet the growing demand due to technical complexity and high resource costs. Learning-based approaches offer faster, more diverse garment synthesis based on specific requirements and reduce human efforts and time costs. However, they still face challenges such as inconsistent multi-view geometry or textures and heavy reliance on detailed garment topology and manual rigging. We propose SemanticGarment, a 3D Gaussian-based method that realizes high-fidelity 3D garment generation from text or image prompts and supports semantic-based interactive editing for flexible user customization. To ensure multi-view consistency and garment fitting, we propose to leverage structural human priors for the generative model by introducing a 3D semantic clothing model, which initializes the geometry structure and lays the groundwork for view-consistent garment generation and editing. Without the need to regenerate or rely on existing mesh templates, our approach allows for rapid and diverse modifications to existing Gaussians, either globally or within a local region. To address the artifacts caused by self-occlusion for garment reconstruction based on single image, we develop a self-occlusion optimization strategy to mitigate holes and artifacts that arise when directly animating self-occluded garments. Extensive experiments are conducted to demonstrate our superior performance in 3D garment generation and editing.'}, {'id': 'arxiv_2408.09126', 'title': 'Barbie: Text to Barbie-Style 3D Avatars', 'URL': 'http://arxiv.org/abs/2408.09126', 'extra_urls': ['http://arxiv.org/abs/2408.09126'], 'type': 'article', 'author': [{'family': 'Sun', 'given': 'Xiaokun'}, {'family': 'Zhang', 'given': 'Zhenyu'}, {'family': 'Tai', 'given': 'Ying'}, {'family': 'Tang', 'given': 'Hao'}, {'family': 'Yi', 'given': 'Zili'}, {'family': 'Yang', 'given': 'Jian'}], 'publisher': 'arXiv', 'abstract': &quot;To integrate digital humans into everyday life, there is a strong demand for generating high-quality, fine-grained disentangled 3D avatars that support expressive animation and simulation capabilities, ideally from low-cost textual inputs. Although text-driven 3D avatar generation has made significant progress by leveraging 2D generative priors, existing methods still struggle to fulfill all these requirements simultaneously. To address this challenge, we propose Barbie, a novel text-driven framework for generating animatable 3D avatars with separable shoes, accessories, and simulation-ready garments, truly capturing the iconic ``Barbie doll'' aesthetic. The core of our framework lies in an expressive 3D representation combined with appropriate modeling constraints. Unlike previous methods, we innovatively employ G-Shell to uniformly model both watertight components (e.g., bodies, shoes, and accessories) and non-watertight garments compatible with simulation. Furthermore, we introduce a well-designed initialization and a hole regularization loss to ensure clean open surface modeling. These disentangled 3D representations are then optimized by specialized expert diffusion models tailored to each domain, ensuring high-fidelity outputs. To mitigate geometric artifacts and texture conflicts when combining different expert models, we further propose several effective geometric losses and strategies. Extensive experiments demonstrate that Barbie outperforms existing methods in both dressed human and outfit generation. Our framework further enables diverse applications, including apparel combination, editing, expressive animation, and physical simulation. Our project page is: https://xiaokunsun.github.io/Barbie.github.io&quot;}, {'id': 'arxiv_2411.19528', 'title': 'RAGDiffusion: Faithful Cloth Generation via External Knowledge Assimilation', 'URL': 'http://arxiv.org/abs/2411.19528', 'extra_urls': ['http://arxiv.org/abs/2411.19528'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Yuhan'}, {'family': 'Tan', 'given': 'Xianfeng'}, {'family': 'Shang', 'given': 'Wenxiang'}, {'family': 'Wu', 'given': 'Yubo'}, {'family': 'Wang', 'given': 'Jian'}, {'family': 'Chen', 'given': 'Xuanhong'}, {'family': 'Zhang', 'given': 'Yi'}, {'family': 'Lin', 'given': 'Ran'}, {'family': 'Ni', 'given': 'Bingbing'}], 'publisher': 'arXiv', 'abstract': 'Standard clothing asset generation involves restoring forward-facing flat-lay garment images displayed on a clear background by extracting clothing information from diverse real-world contexts, which presents significant challenges due to highly standardized structure sampling distributions and clothing semantic absence in complex scenarios. Existing models have limited spatial perception, often exhibiting structural hallucinations and texture distortion in this high-specification generative task. To address this issue, we propose a novel Retrieval-Augmented Generation (RAG) framework, termed RAGDiffusion, to enhance structure determinacy and mitigate hallucinations by assimilating knowledge from language models and external databases. RAGDiffusion consists of two processes: (1) Retrieval-based structure aggregation, which employs contrastive learning and a Structure Locally Linear Embedding (SLLE) to derive global structure and spatial landmarks, providing both soft and hard guidance to counteract structural ambiguities; and (2) Omni-level faithful garment generation, which introduces a coarse-to-fine texture alignment that ensures fidelity in pattern and detail components within the diffusing. Extensive experiments on challenging real-world datasets demonstrate that RAGDiffusion synthesizes structurally and texture-faithful clothing assets with significant performance improvements, representing a pioneering effort in high-specification faithful generation with RAG to confront intrinsic hallucinations and enhance fidelity.'}, {'id': 'realistic', 'title': 'GaussianIP: Identity-Preserving Realistic 3D Human Generation via Human-Centric Diffusion Prior', 'URL': 'https://openaccess.thecvf.com/content/CVPR2025/html/Tang_GaussianIP_Identity-Preserving_Realistic_3D_Human_Generation_via_Human-Centric_Diffusion_Prior_CVPR_2025_paper.html', 'extra_urls': ['https://openaccess.thecvf.com/content/CVPR2025/html/Tang_GaussianIP_Identity-Preserving_Realistic_3D_Human_Generation_via_Human-Centric_Diffusion_Prior_CVPR_2025_paper.html'], 'type': 'article', 'author': [{'family': 'Tang', 'given': 'Zichen'}, {'family': 'Yao', 'given': 'Yuan'}, {'family': 'Cui', 'given': 'Miaomiao'}, {'family': 'Bo', 'given': 'Liefeng'}, {'family': 'Yang', 'given': 'Hongyu'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'arxiv_2501.04631', 'title': 'Disentangled Clothed Avatar Generation with Layered Representation', 'URL': 'http://arxiv.org/abs/2501.04631', 'extra_urls': ['http://arxiv.org/abs/2501.04631'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Weitian'}, {'family': 'Yan', 'given': 'Yichao'}, {'family': 'Wu', 'given': 'Sijing'}, {'family': 'Liao', 'given': 'Manwen'}, {'family': 'Yang', 'given': 'Xiaokang'}], 'publisher': 'arXiv', 'abstract': 'Clothed avatar generation has wide applications in virtual and augmented reality, filmmaking, and more. Previous methods have achieved success in generating diverse digital avatars, however, generating avatars with disentangled components (\\eg, body, hair, and clothes) has long been a challenge. In this paper, we propose LayerAvatar, the first feed-forward diffusion-based method for generating component-disentangled clothed avatars. To achieve this, we first propose a layered UV feature plane representation, where components are distributed in different layers of the Gaussian-based UV feature plane with corresponding semantic labels. This representation supports high-resolution and real-time rendering, as well as expressive animation including controllable gestures and facial expressions. Based on the well-designed representation, we train a single-stage diffusion model and introduce constrain terms to address the severe occlusion problem of the innermost human body layer. Extensive experiments demonstrate the impressive performances of our method in generating disentangled clothed avatars, and we further explore its applications in component transfer. The project page is available at: https://olivia23333.github.io/LayerAvatar/'}, {'id': '3d_garment', 'title': 'Garment3DGen: 3D Garment Stylization and Texture Generation', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11125610', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11125610'], 'type': 'article', 'author': [{'family': 'Sarafianos', 'given': 'Nikolaos'}, {'family': 'Stuyck', 'given': 'Tuur'}, {'family': 'Xiang', 'given': 'Xiaoyu'}, {'family': 'Li', 'given': 'Yilei'}, {'family': 'Popovic', 'given': 'Jovan'}, {'family': 'Ranjan', 'given': 'Rakesh'}], 'abstract': 'We introduce Garment3DGen a new method to synthesize 3D garment assets from a base mesh given a single input image as guidance. Our proposed approach allows users to generate 3D textured clothes based on both real and synthetic images, such as those generated by text prompts. The generated assets can be directly draped and simulated on human bodies. We leverage the recent progress of image-to-3D diffusion methods to generate 3D garment geometries. However, since these geometries cannot be utilized directly for downstream tasks, we propose to use them as pseudo ground-truth and set up a mesh deformation optimization procedure that deforms a base template mesh to match the generated 3D target. Carefully designed losses allow the base mesh to freely deform towards the desired target, yet preserve mesh quality and topology such that they can be simulated. Finally, we generate high-fidelity texture maps that are globally and locally consistent and faithfully capture the input guidance, allowing us to render the generated 3D assets. With Garment3DGen users can generate the simulation-ready 3D garment of their choice without the need of artist intervention. We present a plethora of quantitative and qualitative'}, {'id': 'arxiv_2412.14453', 'title': 'Multimodal Latent Diffusion Model for Complex Sewing Pattern Generation', 'URL': 'http://arxiv.org/abs/2412.14453', 'extra_urls': ['http://arxiv.org/abs/2412.14453'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Shengqi'}, {'family': 'Cheng', 'given': 'Yuhao'}, {'family': 'Chen', 'given': 'Zhuo'}, {'family': 'Ren', 'given': 'Xingyu'}, {'family': 'Zhu', 'given': 'Wenhan'}, {'family': 'Li', 'given': 'Lincheng'}, {'family': 'Bi', 'given': 'Mengxiao'}, {'family': 'Yang', 'given': 'Xiaokang'}, {'family': 'Yan', 'given': 'Yichao'}], 'publisher': 'arXiv', 'abstract': 'Generating sewing patterns in garment design is receiving increasing attention due to its CG-friendly and flexible-editing nature. Previous sewing pattern generation methods have been able to produce exquisite clothing, but struggle to design complex garments with detailed control. To address these issues, we propose SewingLDM, a multi-modal generative model that generates sewing patterns controlled by text prompts, body shapes, and garment sketches. Initially, we extend the original vector of sewing patterns into a more comprehensive representation to cover more intricate details and then compress them into a compact latent space. To learn the sewing pattern distribution in the latent space, we design a two-step training strategy to inject the multi-modal conditions, \\ie, body shapes, text prompts, and garment sketches, into a diffusion model, ensuring the generated garments are body-suited and detail-controlled. Comprehensive qualitative and quantitative experiments show the effectiveness of our proposed method, significantly surpassing previous approaches in terms of complex garment design and various body adaptability. Our project page: https://shengqiliu1.github.io/SewingLDM.'}, {'id': 'a_multimodal', 'title': 'AIpparel: A Multimodal Foundation Model for Digital Garments', 'URL': 'https://openaccess.thecvf.com/content/CVPR2025/html/Nakayama_AIpparel_A_Multimodal_Foundation_Model_for_Digital_Garments_CVPR_2025_paper.html', 'extra_urls': ['https://openaccess.thecvf.com/content/CVPR2025/html/Nakayama_AIpparel_A_Multimodal_Foundation_Model_for_Digital_Garments_CVPR_2025_paper.html'], 'type': 'article', 'author': [{'family': 'Nakayama', 'given': 'Kiyohiro'}, {'family': 'Ackermann', 'given': 'Jan'}, {'family': 'Kesdogan', 'given': 'Timur Levent'}, {'family': 'Zheng', 'given': 'Yang'}, {'family': 'Korosteleva', 'given': 'Maria'}, {'family': 'Sorkine-Hornung', 'given': 'Olga'}, {'family': 'Guibas', 'given': 'Leonidas J.'}, {'family': 'Yang', 'given': 'Guandao'}, {'family': 'Wetzstein', 'given': 'Gordon'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'arxiv_2509.09324', 'title': 'Fine-Grained Customized Fashion Design with Image-into-Prompt benchmark and dataset from LMM', 'URL': 'http://arxiv.org/abs/2509.09324', 'extra_urls': ['http://arxiv.org/abs/2509.09324'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Hui'}, {'family': 'You', 'given': 'Yi'}, {'family': 'Chen', 'given': 'Qiqi'}, {'family': 'Zhang', 'given': 'Bingfeng'}, {'family': 'Huang', 'given': 'George Q.'}], 'publisher': 'arXiv', 'abstract': &quot;Generative AI evolves the execution of complex workflows in industry, where the large multimodal model empowers fashion design in the garment industry. Current generation AI models magically transform brainstorming into fancy designs easily, but the fine-grained customization still suffers from text uncertainty without professional background knowledge from end-users. Thus, we propose the Better Understanding Generation (BUG) workflow with LMM to automatically create and fine-grain customize the cloth designs from chat with image-into-prompt. Our framework unleashes users' creative potential beyond words and also lowers the barriers of clothing design/editing without further human involvement. To prove the effectiveness of our model, we propose a new FashionEdit dataset that simulates the real-world clothing design workflow, evaluated from generation similarity, user satisfaction, and quality. The code and dataset: https://github.com/detectiveli/FashionEdit.&quot;}, {'id': 'texture', 'title': 'FabricDiffusion: High-Fidelity Texture Transfer for 3D Garments Generation from In-The-Wild Images', 'URL': 'https://dl.acm.org/doi/10.1145/3680528.3687637', 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Cheng'}, {'family': 'Wang', 'given': 'Yuanhao'}, {'family': 'Vicente', 'given': 'Francisco'}, {'family': 'Wu', 'given': 'Chenglei'}, {'family': 'Yang', 'given': 'Jinlong'}, {'family': 'Beeler', 'given': 'Thabo'}, {'family': 'De la Torre', 'given': 'Fernando'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'We introduce FabricDiffusion, a method for transferring fabric textures from a single clothing image to 3D garments of arbitrary shapes. Existing approaches typically synthesize textures on the garment surface through 2D-to-3D texture mapping or depth-aware inpainting via generative models. Unfortunately, these methods often struggle to capture and preserve texture details, particularly due to challenging occlusions, distortions, or poses in the input image. Inspired by the observation that in the fashion industry, most garments are constructed by stitching sewing patterns with flat, repeatable textures, we cast the task of clothing texture transfer as extracting distortion-free, tileable texture materials that are subsequently mapped onto the UV space of the garment. Building upon this insight, we train a denoising diffusion model with a large-scale synthetic dataset to rectify distortions in the input texture image. This process yields a flat texture map that enables a tight coupling with existing Physically-Based Rendering (PBR) material generation pipelines, allowing for realistic relighting of the garment under various lighting conditions. We show that FabricDiffusion can transfer various features from a single clothing image including texture patterns, material properties, and detailed prints and logos. Extensive experiments demonstrate that our model significantly outperforms state-to-the-art methods on both synthetic data and real-world, in-the-wild clothing images while generalizing to unseen textures and garment shapes.'}, {'id': '3dgs_guided', 'title': 'GarmentDreamer: 3DGS Guided Garment Synthesis with Diverse Geometry and Texture Details', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11125627', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11125627'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Boqian'}, {'family': 'Li', 'given': 'Xuan'}, {'family': 'Jiang', 'given': 'Ying'}, {'family': 'Xie', 'given': 'Tianyi'}, {'family': 'Gao', 'given': 'Feng'}, {'family': 'Wang', 'given': 'Huamin'}, {'family': 'Yang', 'given': 'Yin'}, {'family': 'Jiang', 'given': 'Chenfanfu'}], 'abstract': 'Traditional 3D garment creation is labor-intensive, involving sketching, modeling, UV mapping, and texturing, which are time-consuming and costly. Recent advances in diffusion-based generative models have enabled new possibilities for 3D garment generation from text prompts, images, and videos. However, existing methods either suffer from inconsistencies among multi-view images or require additional processes to separate cloth from the underlying human model. In this paper, we propose GarmentDreamer, a novel method that leverages 3D Gaussian Splatting (GS) as guidance to generate wearable, simulation-ready 3D garment meshes from text prompts. In contrast to using multi-view images directly predicted by generative models as guidance, our 3DGS guidance ensures consistent optimization in both garment deformation and texture synthesis. Our method introduces a novel garment augmentation module, guided by normal and RGBA information, and employs implicit Neural Texture Fields (NeTF) combined with Variational Score Distillation (VSD) to generate diverse geometric and texture details. We validate the effectiveness of our approach through comprehensive qualitative and quantitative experiments, showcasing the superior performance of GarmentDreamer over state-of-the-art alternatives11Demos and codes are available at https://xuan-li.github.io/GarmentDreamerDemo/.'}, {'id': 'arxiv_2504.20409', 'title': 'GarmentX: Autoregressive Parametric Representations for High-Fidelity 3D Garment Generation', 'URL': 'http://arxiv.org/abs/2504.20409', 'extra_urls': ['http://arxiv.org/abs/2504.20409'], 'type': 'article', 'author': [{'family': 'Guo', 'given': 'Jingfeng'}, {'family': 'Chen', 'given': 'Jinnan'}, {'family': 'Chen', 'given': 'Weikai'}, {'family': 'Sun', 'given': 'Zhenyu'}, {'family': 'Li', 'given': 'Lanjiong'}, {'family': 'Zhao', 'given': 'Baozhu'}, {'family': 'Zhu', 'given': 'Lingting'}, {'family': 'Wang', 'given': 'Xin'}, {'family': 'Liu', 'given': 'Qi'}], 'publisher': 'arXiv', 'abstract': 'This work presents GarmentX, a novel framework for generating diverse, high-fidelity, and wearable 3D garments from a single input image. Traditional garment reconstruction methods directly predict 2D pattern edges and their connectivity, an overly unconstrained approach that often leads to severe self-intersections and physically implausible garment structures. In contrast, GarmentX introduces a structured and editable parametric representation compatible with GarmentCode, ensuring that the decoded sewing patterns always form valid, simulation-ready 3D garments while allowing for intuitive modifications of garment shape and style. To achieve this, we employ a masked autoregressive model that sequentially predicts garment parameters, leveraging autoregressive modeling for structured generation while mitigating inconsistencies in direct pattern prediction. Additionally, we introduce GarmentX dataset, a large-scale dataset of 378,682 garment parameter-image pairs, constructed through an automatic data generation pipeline that synthesizes diverse and high-quality garment images conditioned on parametric garment representations. Through integrating our method with GarmentX dataset, we achieve state-of-the-art performance in geometric fidelity and input image alignment, significantly outperforming prior approaches. We will release GarmentX dataset upon publication.'}, {'id': 'arxiv_2412.17811', 'title': 'ChatGarment: Garment Estimation, Generation and Editing via Large Language Models', 'URL': 'http://arxiv.org/abs/2412.17811', 'extra_urls': ['http://arxiv.org/abs/2412.17811'], 'type': 'article', 'author': [{'family': 'Bian', 'given': 'Siyuan'}, {'family': 'Xu', 'given': 'Chenghao'}, {'family': 'Xiu', 'given': 'Yuliang'}, {'family': 'Grigorev', 'given': 'Artur'}, {'family': 'Liu', 'given': 'Zhen'}, {'family': 'Lu', 'given': 'Cewu'}, {'family': 'Black', 'given': 'Michael J.'}, {'family': 'Feng', 'given': 'Yao'}], 'publisher': 'arXiv', 'abstract': &quot;We introduce ChatGarment, a novel approach that leverages large vision-language models (VLMs) to automate the estimation, generation, and editing of 3D garments from images or text descriptions. Unlike previous methods that struggle in real-world scenarios or lack interactive editing capabilities, ChatGarment can estimate sewing patterns from in-the-wild images or sketches, generate them from text descriptions, and edit garments based on user instructions, all within an interactive dialogue. These sewing patterns can then be draped on a 3D body and animated. This is achieved by finetuning a VLM to directly generate a JSON file that includes both textual descriptions of garment types and styles, as well as continuous numerical attributes. This JSON file is then used to create sewing patterns through a programming parametric model. To support this, we refine the existing programming model, GarmentCode, by expanding its garment type coverage and simplifying its structure for efficient VLM fine-tuning. Additionally, we construct a large-scale dataset of image-to-sewing-pattern and text-to-sewing-pattern pairs through an automated data pipeline. Extensive evaluations demonstrate ChatGarment's ability to accurately reconstruct, generate, and edit garments from multimodal inputs, highlighting its potential to simplify workflows in fashion and gaming applications. Code and data are available at https://chatgarment.github.io/ .&quot;}, {'id': 'arxiv_2305.06131', 'title': 'Generative AI meets 3D: A Survey on Text-to-3D in AIGC Era', 'URL': 'http://arxiv.org/abs/2305.06131', 'extra_urls': ['http://arxiv.org/abs/2305.06131'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Chenghao'}, {'family': 'Zhang', 'given': 'Chaoning'}, {'family': 'Cho', 'given': 'Joseph'}, {'family': 'Waghwase', 'given': 'Atish'}, {'family': 'Lee', 'given': 'Lik-Hang'}, {'family': 'Rameau', 'given': 'Francois'}, {'family': 'Yang', 'given': 'Yang'}, {'family': 'Bae', 'given': 'Sung-Ho'}, {'family': 'Hong', 'given': 'Choong Seon'}], 'publisher': 'arXiv', 'abstract': 'Generative AI has made significant progress in recent years, with text-guided content generation being the most practical as it facilitates interaction between human instructions and AI-generated content (AIGC). Thanks to advancements in text-to-image and 3D modeling technologies, like neural radiance field (NeRF), text-to-3D has emerged as a nascent yet highly active research field. Our work conducts a comprehensive survey on this topic and follows up on subsequent research progress in the overall field, aiming to help readers interested in this direction quickly catch up with its rapid development. First, we introduce 3D data representations, including both Structured and non-Structured data. Building on this pre-requisite, we introduce various core technologies to achieve satisfactory text-to-3D results. Additionally, we present mainstream baselines and research directions in recent text-to-3D technology, including fidelity, efficiency, consistency, controllability, diversity, and applicability. Furthermore, we summarize the usage of text-to-3D technology in various applications, including avatar generation, texture generation, scene generation and 3D editing. Finally, we discuss the agenda for the future development of text-to-3D.'}, {'id': 'towards_intelligent', 'title': 'StyleMe: Towards Intelligent Fashion Generation with Designer Style', 'URL': 'https://dl.acm.org/doi/10.1145/3544548.3581377', 'type': 'article', 'author': [{'family': 'Wu', 'given': 'Di'}, {'family': 'Yu', 'given': 'Zhiwang'}, {'family': 'Ma', 'given': 'Nan'}, {'family': 'Jiang', 'given': 'Jianan'}, {'family': 'Wang', 'given': 'Yuetian'}, {'family': 'Zhou', 'given': 'Guixiang'}, {'family': 'Deng', 'given': 'Hanhui'}, {'family': 'Li', 'given': 'Yi'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Hand-drawn sketches and sketch colourization are the most laborious but necessary steps for fashion designers to design exquisite clothes, especially when the fashion design requires distinctive and personal characteristics from designer style. This paper presents an artificial intelligent aided fashion design system, namely StyleMe, to support the automatic generation of clothing sketches with designer style. Given the clothing pictures specified by the designer, StyleMe can use deep learning based generative model to generate clothing sketches that are consistent with the designer style. The system also supports intelligent colourization on clothing sketch by style transfer, according to specified styles from the real fashion images. Through a series of performance evaluations and user studies, we found that our system can generate effective clothing sketches as good as fashion designers\u2019 human work, and significantly improve the efficiency of fashion design with its sketch colourization method.'}, {'id': 'a_scriptable', 'title': 'PM4Furniture: A Scriptable Parametric Modeling Interface for Conceptual Furniture Design Using PM4VR', 'URL': 'https://dl.acm.org/doi/10.1145/3703619.3706030', 'type': 'article', 'author': [{'family': 'Li', 'given': 'Wanwan'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'In the field of furniture design, Virtual Reality (VR) has shown potential in enabling immersive prototyping and visualization. However, current VR design tools are often limited by a lack of parametrization, making it challenging for designers to iterate complex furniture forms quickly. This paper presents PM4Furniture, a scriptable parametric modeling interface tailored for VR-based conceptual furniture design. The proposed system leverages a scripting interface of PM4VR framework with a low learning curve that allows designers to adjust the parameters of 3D furniture models in real time. By integrating a VR environment, PM4Furniture enhances user\u2019s interaction and intuitive adjustments of design parameters with immediate visual feedback. We evaluate this novel interface through a preliminary user study with designers interacting with furniture design in an immersive VR environment, revealing PM4Furniture\u2019s design efficiency and creativity in VR furniture prototyping.'}, {'id': 'a_scriptable', 'title': 'PM4Bag: A Scriptable Parametric Modeling Interface for Conceptual Bag Design Using PM4VR', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10677763', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10677763'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Wanwan'}], 'abstract': 'This paper introduces PM4Bag, a novel scriptable parametric modeling interface tailored for conceptual bag design. Leveraging the power of PM4VR, a cutting-edge Parametric Modeling (PM) interface for the Virtual Reality (VR) platform, PM4Bag offers designers a seamless and intuitive toolset to create and customize bag designs in a virtual environment. This paper presents the design and implementation of PM4Bag, highlighting its key features, such as script-based design automation, real-time visualization, and interactive parameter adjustment. A preliminary user study demonstrates the effectiveness and efficiency of PM4Bag in designing a range of diverse bag concepts in virtual reality. The results indicate that PM4Bag facilitates and enhances the creativity and productivity of bag designers, offering a promising avenue for future research in the field of parametric modeling for the conceptual bag design industry.'}, {'id': 'a_scriptable', 'title': 'PM4Fashion: A Scriptable Parametric Modeling Interface for Conceptual Fashion Design Using PM4VR', 'URL': 'https://dl.acm.org/doi/10.1145/3670105.3670159', 'type': 'article', 'author': [{'family': 'Li', 'given': 'Wanwan'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'In the dynamic realm of fashion design, integrating emerging technologies of computational intelligence is essential to enhance creative activities and bring forth novel design concepts. This paper introduces PM4Fashion, a cutting-edge scriptable parametric modeling interface for conceptual fashion design. Leveraging the capabilities of PM4VR (Parametric Modeling for Virtual Reality), PM4Fashion provides designers with a novel interactive toolset to ideate and iterate conceptual fashion design in a virtual environment through diverse design possibilities of advanced parametric modeling technology via virtual reality-enabled platforms.'}, {'id': 'empowering_users', 'title': 'Empowering Non-Expert Users in Fashion Remanufacturing: Enhancing Human-Multi-Robot Interaction through Real-Time Visualization', 'URL': 'https://dl.acm.org/doi/10.1145/3706599.3716232', 'type': 'article', 'author': [{'family': 'Gollob', 'given': 'Emanuel'}, {'family': 'Bastan', 'given': 'Amir'}, {'family': 'Braumann', 'given': 'Johannes'}, {'family': 'Luible-Baer', 'given': 'Christiane'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Automating textile repair and remanufacturing can significantly improve the ecological and societal impact of textiles. However, the complex behavior of textiles poses challenges for integrating robotics into fashion. This research addresses these challenges by developing a platform that empowers non-experts to define complex multi-robot tasks through visualization-enhanced hand guiding. By leveraging collaborative automation, our approach facilitates intuitive human-multi-robot interaction without extensive technical knowledge. Our approach employs flexible, parametric systems and a dual-robot setup to achieve high precision and operational flexibility in remanufacturing processes. Utilizing Grasshopper for path planning and VVVV for real-time interaction, we create a user-friendly interface allowing non-experts to interact intuitively with robots. This work demonstrates how real-time visualization can make advanced robotic capabilities accessible to non-expert users in the fashion industry. By enabling non-experts to leverage these technologies, we aim to transform remanufacturing processes and foster innovation in human-robot collaboration in the fashion and textiles sector.'}, {'id': 'supporting_modular', 'title': 'QUILT: Supporting Modular Design of Machine-Knitting Programs', 'URL': 'https://dl.acm.org/doi/10.1145/3746059.3747608', 'type': 'article', 'author': [{'family': 'Hester', 'given': 'Jack'}, {'family': 'Law', 'given': 'Sebastian'}, {'family': 'Hofmann', 'given': 'Megan'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Knitting machines can manufacture complex layered, textured, and multi-material fabrics and garments. With new programming languages and interfaces there is greater access to the machine\u2019s capabilities. Developers can now create machine instructions that produce a fabric sample or garment. Such files can be easily shared with others, but modifying and combining these samples requires extensive expertise in knitting-specific programming languages, substantial effort, and time. Knit programming offers little support for modular design. We take a step towards modular knitting-machine programming and present QUILT: Quality Unification Infrastructure for Loop-based Textiles. QUILT enables knit programmers to create swatches from knitting programs and lay these swatches out spatially on a 2-dimensional grid. We use three novel knit-program merging algorithms to merge the connected swatches into a quilt program. The knitted structures of each swatch remain unchanged, and our algorithms ensure that the swatches are joined by a seamless boundary that maintains the constraints of knitting-machine programming and knitted-structure construction.'}, {'id': 'making_and', 'title': 'texTile: Making and Re-making Crochet Granny Square Garments Through Computational Design and 3D-printed Connectors', 'URL': 'https://dl.acm.org/doi/10.1145/3715336.3735819', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3715336.3735819'], 'type': 'article', 'author': [{'family': 'Del Valle', 'given': 'Ashley'}, {'family': 'Jacobs', 'given': 'Jennifer'}, {'family': 'Yu', 'given': 'Emilie'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'The rapid turnover of clothing contributes significantly to textile waste. Modular garment-making offers a potential solution by extending garment lifetimes through repair, resizing, and re-purposing, but producing modular garments introduces challenges not supported by existing design approaches or fabrication techniques. We explore the integration of computational design and digital fabrication to propose an alternative path for fashion, where making and re-making become integral to our relationship with garments. We present texTile, a modular fashion workflow that enables designers to assemble reusable crochet tiles into garments. To support our workflow, we developed digitally fabricated connectors for easy assembly and disassembly, a custom pattern solver and user interface to guide garment design, and a visualization tool to help plan manual assembly and reassembly. We conducted a user study with four experienced crocheters. Our results show that texTile can support the construction of tailored garments that integrate re-use as a core principle.'}, {'id': 'curl_quantization_for', 'title': 'Curl Quantization for Automatic Placement of Knit Singularities', 'URL': 'https://dl.acm.org/doi/10.1145/3721238.3730715', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3721238.3730715'], 'type': 'article', 'author': [{'family': 'Mitra', 'given': 'Rahul'}, {'family': 'Couplet', 'given': 'Matt\xe9o'}, {'family': 'Wang', 'given': 'Tongtong'}, {'family': 'Hoffman', 'given': 'Megan'}, {'family': 'Wu', 'given': 'Kui'}, {'family': 'Chien', 'given': 'Edward'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'We develop a method for automatic placement of knit singularities based on curl quantization, extending the knit-planning frameworks of Mitra et&amp;nbsp;al. [2024; 2023]. Stripe patterns are generated that closely follow the isolines of an underlying knitting time function, and has course and wale singularities in regions of high curl for the normalized time function gradient and its 90\xb0 rotated field, respectively. Singularities are placed in an iterative fashion, and we show that this strategy allows us to easily maintain the structural constraints necessary for machine-knitting, e.g., the helix-free constraint, and to satisfy user constraints such as stripe alignment and singularity placement. Our more performant approach obviates the need for a mixed-integer solve [Mitra et&amp;nbsp;al. 2023], manual fixing of singularity positions, or the running of a singularity matching procedure in post-processing [Mitra et&amp;nbsp;al. 2024]. Our global optimization also produces smooth knit graphs that provide quick simulation-free previews of rendered knits without the surface artifacts of competing methods. Furthermore, we extend our method to the popular cut-and-sew garment design paradigm. We validate our method by machine-knitting and rendering yarn-based visualizations of prototypical models in the 3D and cut-and-sew settings.'}, {'id': 'fabricating_accessible', 'title': 'KnitA11y: Fabricating Accessible Designs with Machine Knitting', 'URL': 'https://dl.acm.org/doi/10.1145/3706599.3719709', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3706599.3719709'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Tongyan'}, {'family': 'Zhao', 'given': 'Hanwen'}, {'family': 'Shahpurwala', 'given': 'Yusuf'}, {'family': 'Hofmann', 'given': 'Megan'}, {'family': 'Mankoff', 'given': 'Jennifer'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Digital knitting machines provide a fast and efficient way to create garments, but commercial knitting tools are limited to predefined templates. While many knitting design tools help users create patterns from scratch, modifying existing patterns remains challenging. This paper introduces KnitA11y, a digital machine knitting pipeline that enables users to import hand-knitting patterns, add accessibility features, and fabricate them using machine knitting. We support modifications such as holes, pockets, and straps/handles, based on common accessible functional modifications identified in a survey of Ravelry.com. KnitA11y offers an interactive design interface that allows users to visualize patterns and customize the position and shape of modifications. We demonstrate KnitA11y\u2019s capabilities through diverse examples, including a sensory-friendly scarf with a pocket, a hat with a hole for assistive devices, a sock with a pull handle, and a mitten with a pocket for heating pads to alleviate Raynaud\u2019s symptoms.'}, {'id': 'arxiv_2306.15166', 'title': 'Constraining Generative Models for Engineering Design with Negative Data', 'URL': 'http://arxiv.org/abs/2306.15166', 'extra_urls': ['http://arxiv.org/abs/2306.15166'], 'type': 'article', 'author': [{'family': 'Regenwetter', 'given': 'Lyle'}, {'family': 'Giannone', 'given': 'Giorgio'}, {'family': 'Srivastava', 'given': 'Akash'}, {'family': 'Gutfreund', 'given': 'Dan'}, {'family': 'Ahmed', 'given': 'Faez'}], 'publisher': 'arXiv', 'abstract': &quot;Generative models have recently achieved remarkable success and widespread adoption in society, yet they often struggle to generate realistic and accurate outputs. This challenge extends beyond language and vision into fields like engineering design, where safety-critical engineering standards and non-negotiable physical laws tightly constrain what outputs are considered acceptable. In this work, we introduce a novel training method to guide a generative model toward constraint-satisfying outputs using `negative data' -- examples of what to avoid. Our negative-data generative model (NDGM) formulation easily outperforms classic models, generating 1/6 as many constraint-violating samples using 1/8 as much data in certain problems. It also consistently outperforms other baselines, achieving a balance between constraint satisfaction and distributional similarity that is unsurpassed by any other model in 12 of the 14 problems tested. This widespread superiority is rigorously demonstrated across numerous synthetic tests and real engineering problems, such as ship hull synthesis with hydrodynamic constraints and vehicle design with impact safety constraints. Our benchmarks showcase both the best-in-class performance of our new NDGM formulation and the overall dominance of NDGMs versus classic generative models. We publicly release the code and benchmarks at https://github.com/Lyleregenwetter/NDGMs.&quot;}, {'id': 'arxiv_2405.12420', 'title': 'GarmentDreamer: 3DGS Guided Garment Synthesis with Diverse Geometry and Texture Details', 'URL': 'http://arxiv.org/abs/2405.12420', 'extra_urls': ['http://arxiv.org/abs/2405.12420'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Boqian'}, {'family': 'Li', 'given': 'Xuan'}, {'family': 'Jiang', 'given': 'Ying'}, {'family': 'Xie', 'given': 'Tianyi'}, {'family': 'Gao', 'given': 'Feng'}, {'family': 'Wang', 'given': 'Huamin'}, {'family': 'Yang', 'given': 'Yin'}, {'family': 'Jiang', 'given': 'Chenfanfu'}], 'publisher': 'arXiv', 'abstract': 'Traditional 3D garment creation is labor-intensive, involving sketching, modeling, UV mapping, and texturing, which are time-consuming and costly. Recent advances in diffusion-based generative models have enabled new possibilities for 3D garment generation from text prompts, images, and videos. However, existing methods either suffer from inconsistencies among multi-view images or require additional processes to separate cloth from the underlying human model. In this paper, we propose GarmentDreamer, a novel method that leverages 3D Gaussian Splatting (GS) as guidance to generate wearable, simulation-ready 3D garment meshes from text prompts. In contrast to using multi-view images directly predicted by generative models as guidance, our 3DGS guidance ensures consistent optimization in both garment deformation and texture synthesis. Our method introduces a novel garment augmentation module, guided by normal and RGBA information, and employs implicit Neural Texture Fields (NeTF) combined with Score Distillation Sampling (SDS) to generate diverse geometric and texture details. We validate the effectiveness of our approach through comprehensive qualitative and quantitative experiments, showcasing the superior performance of GarmentDreamer over state-of-the-art alternatives. Our project page is available at: https://xuan-li.github.io/GarmentDreamerDemo/.'}, {'id': 'arxiv_2302.02913', 'title': 'Beyond Statistical Similarity: Rethinking Metrics for Deep Generative Models in Engineering Design', 'URL': 'http://arxiv.org/abs/2302.02913', 'extra_urls': ['http://arxiv.org/abs/2302.02913'], 'type': 'article', 'author': [{'family': 'Regenwetter', 'given': 'Lyle'}, {'family': 'Srivastava', 'given': 'Akash'}, {'family': 'Gutfreund', 'given': 'Dan'}, {'family': 'Ahmed', 'given': 'Faez'}], 'publisher': 'arXiv', 'abstract': &quot;Deep generative models such as Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), Diffusion Models, and Transformers, have shown great promise in a variety of applications, including image and speech synthesis, natural language processing, and drug discovery. However, when applied to engineering design problems, evaluating the performance of these models can be challenging, as traditional statistical metrics based on likelihood may not fully capture the requirements of engineering applications. This paper doubles as a review and practical guide to evaluation metrics for deep generative models (DGMs) in engineering design. We first summarize the well-accepted `classic' evaluation metrics for deep generative models grounded in machine learning theory. Using case studies, we then highlight why these metrics seldom translate well to design problems but see frequent use due to the lack of established alternatives. Next, we curate a set of design-specific metrics which have been proposed across different research communities and can be used for evaluating deep generative models. These metrics focus on unique requirements in design and engineering, such as constraint satisfaction, functional performance, novelty, and conditioning. Throughout our discussion, we apply the metrics to models trained on simple-to-visualize 2-dimensional example problems. Finally, we evaluate four deep generative models on a bicycle frame design problem and structural topology generation problem. In particular, we showcase the use of proposed metrics to quantify performance target achievement, design novelty, and geometric constraints. We publicly release the code for the datasets, models, and metrics used throughout the paper at https://decode.mit.edu/projects/metrics/.&quot;}, {'id': 'arxiv_2112.01988', 'title': 'ROCA: Robust CAD Model Retrieval and Alignment from a Single Image', 'URL': 'http://arxiv.org/abs/2112.01988', 'extra_urls': ['http://arxiv.org/abs/2112.01988'], 'type': 'article', 'author': [{'family': 'G\xfcmeli', 'given': 'Can'}, {'family': 'Dai', 'given': 'Angela'}, {'family': 'Nie\xdfner', 'given': 'Matthias'}], 'abstract': 'We present ROCA, a novel end-to-end approach that retrieves and aligns 3D CAD models from a shape database to a single input image. This enables 3D perception of an observed scene from a 2D RGB observation, characterized as a lightweight, compact, clean CAD representation. Core to our approach is our differentiable alignment optimization based on dense 2D-3D object correspondences and Procrustes alignment. ROCA can thus provide a robust CAD alignment while simultaneously informing CAD retrieval by leveraging the 2D-3D correspondences to learn geometrically similar CAD models. Experiments on challenging, real-world imagery from ScanNet show that ROCA significantly improves on state of the art, from 9.5% to 17.6% in retrieval-aware CAD alignment accuracy.'}, {'id': 'arxiv_2412.08603', 'title': 'Design2GarmentCode: Turning Design Concepts to Tangible Garments Through Program Synthesis', 'URL': 'http://arxiv.org/abs/2412.08603', 'extra_urls': ['http://arxiv.org/abs/2412.08603'], 'type': 'article', 'author': [{'family': 'Zhou', 'given': 'Feng'}, {'family': 'Liu', 'given': 'Ruiyang'}, {'family': 'Liu', 'given': 'Chen'}, {'family': 'He', 'given': 'Gaofeng'}, {'family': 'Li', 'given': 'Yong-Lu'}, {'family': 'Jin', 'given': 'Xiaogang'}, {'family': 'Wang', 'given': 'Huamin'}], 'publisher': 'arXiv', 'abstract': 'Sewing patterns, the essential blueprints for fabric cutting and tailoring, act as a crucial bridge between design concepts and producible garments. However, existing uni-modal sewing pattern generation models struggle to effectively encode complex design concepts with a multi-modal nature and correlate them with vectorized sewing patterns that possess precise geometric structures and intricate sewing relations. In this work, we propose a novel sewing pattern generation approach \\textbf{Design2GarmentCode} based on Large Multimodal Models (LMMs), to generate parametric pattern-making programs from multi-modal design concepts. LMM offers an intuitive interface for interpreting diverse design inputs, while pattern-making programs could serve as well-structured and semantically meaningful representations of sewing patterns, and act as a robust bridge connecting the cross-domain pattern-making knowledge embedded in LMMs with vectorized sewing patterns. Experimental results demonstrate that our method can flexibly handle various complex design expressions such as images, textual descriptions, designer sketches, or their combinations, and convert them into size-precise sewing patterns with correct stitches. Compared to previous methods, our approach significantly enhances training efficiency, generation quality, and authoring flexibility.'}, {'id': 'arxiv_2304.03442', 'title': 'Generative Agents: Interactive Simulacra of Human Behavior', 'URL': 'https://arxiv.org/abs/2304.03442', 'extra_urls': ['https://arxiv.org/abs/2304.03442'], 'type': 'article', 'author': [{'family': 'Park', 'given': 'Joon Sung'}, {'family': &quot;O'Brien&quot;, 'given': 'Joseph C.'}, {'family': 'Cai', 'given': 'Carrie J.'}, {'family': 'Morris', 'given': 'Meredith Ringel'}, {'family': 'Liang', 'given': 'Percy'}, {'family': 'Bernstein', 'given': 'Michael S.'}], 'publisher': 'arXiv', 'abstract': &quot;Believable proxies of human behavior can empower interactive applications\nranging from immersive environments to rehearsal spaces for interpersonal\ncommunication to prototyping tools. In this paper, we introduce generative\nagents--computational software agents that simulate believable human behavior.\nGenerative agents wake up, cook breakfast, and head to work; artists paint,\nwhile authors write; they form opinions, notice each other, and initiate\nconversations; they remember and reflect on days past as they plan the next\nday. To enable generative agents, we describe an architecture that extends a\nlarge language model to store a complete record of the agent's experiences\nusing natural language, synthesize those memories over time into higher-level\nreflections, and retrieve them dynamically to plan behavior. We instantiate\ngenerative agents to populate an interactive sandbox environment inspired by\nThe Sims, where end users can interact with a small town of twenty five agents\nusing natural language. In an evaluation, these generative agents produce\nbelievable individual and emergent social behaviors: for example, starting with\nonly a single user-specified notion that one agent wants to throw a Valentine's\nDay party, the agents autonomously spread invitations to the party over the\nnext two days, make new acquaintances, ask each other out on dates to the\nparty, and coordinate to show up for the party together at the right time. We\ndemonstrate through ablation that the components of our agent\narchitecture--observation, planning, and reflection--each contribute critically\nto the believability of agent behavior. By fusing large language models with\ncomputational, interactive agents, this work introduces architectural and\ninteraction patterns for enabling believable simulations of human behavior.&quot;}, {'id': 'arxiv_2410.10762', 'title': 'AFlow: Automating Agentic Workflow Generation', 'URL': 'http://arxiv.org/abs/2410.10762', 'extra_urls': ['http://arxiv.org/abs/2410.10762'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Jiayi'}, {'family': 'Xiang', 'given': 'Jinyu'}, {'family': 'Yu', 'given': 'Zhaoyang'}, {'family': 'Teng', 'given': 'Fengwei'}, {'family': 'Chen', 'given': 'Xionghui'}, {'family': 'Chen', 'given': 'Jiaqi'}, {'family': 'Zhuge', 'given': 'Mingchen'}, {'family': 'Cheng', 'given': 'Xin'}, {'family': 'Hong', 'given': 'Sirui'}, {'family': 'Wang', 'given': 'Jinlin'}, {'family': 'Zheng', 'given': 'Bingnan'}, {'family': 'Liu', 'given': 'Bang'}, {'family': 'Luo', 'given': 'Yuyu'}, {'family': 'Wu', 'given': 'Chenglin'}], 'publisher': 'arXiv', 'abstract': &quot;Large language models (LLMs) have demonstrated remarkable potential in solving complex tasks across diverse domains, typically by employing agentic workflows that follow detailed instructions and operational sequences. However, constructing these workflows requires significant human effort, limiting scalability and generalizability. Recent research has sought to automate the generation and optimization of these workflows, but existing methods still rely on initial manual setup and fall short of achieving fully automated and effective workflow generation. To address this challenge, we reformulate workflow optimization as a search problem over code-represented workflows, where LLM-invoking nodes are connected by edges. We introduce AFlow, an automated framework that efficiently explores this space using Monte Carlo Tree Search, iteratively refining workflows through code modification, tree-structured experience, and execution feedback. Empirical evaluations across six benchmark datasets demonstrate AFlow's efficacy, yielding a 5.7% average improvement over state-of-the-art baselines. Furthermore, AFlow enables smaller models to outperform GPT-4o on specific tasks at 4.55% of its inference cost in dollars. The code is available at https://github.com/FoundationAgents/AFlow.&quot;}, {'id': 'arxiv_2507.06250', 'title': 'We Urgently Need Privilege Management in MCP: A Measurement of API Usage in MCP Ecosystems', 'URL': 'http://arxiv.org/abs/2507.06250', 'extra_urls': ['http://arxiv.org/abs/2507.06250'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Zhihao'}, {'family': 'Li', 'given': 'Kun'}, {'family': 'Ma', 'given': 'Boyang'}, {'family': 'Xu', 'given': 'Minghui'}, {'family': 'Zhang', 'given': 'Yue'}, {'family': 'Cheng', 'given': 'Xiuzhen'}], 'publisher': 'arXiv', 'abstract': 'The Model Context Protocol (MCP) has emerged as a widely adopted mechanism for connecting large language models to external tools and resources. While MCP promises seamless extensibility and rich integrations, it also introduces a substantially expanded attack surface: any plugin can inherit broad system privileges with minimal isolation or oversight. In this work, we conduct the first large-scale empirical analysis of MCP security risks. We develop an automated static analysis framework and systematically examine 2,562 real-world MCP applications spanning 23 functional categories. Our measurements reveal that network and system resource APIs dominate usage patterns, affecting 1,438 and 1,237 servers respectively, while file and memory resources are less frequent but still significant. We find that Developer Tools and API Development plugins are the most API-intensive, and that less popular plugins often contain disproportionately high-risk operations. Through concrete case studies, we demonstrate how insufficient privilege separation enables privilege escalation, misinformation propagation, and data tampering. Based on these findings, we propose a detailed taxonomy of MCP resource access, quantify security-relevant API usage, and identify open challenges for building safer MCP ecosystems, including dynamic permission models and automated trust assessment.'}, {'id': 'arxiv_2509.24272', 'title': 'When MCP Servers Attack: Taxonomy, Feasibility, and Mitigation', 'URL': 'http://arxiv.org/abs/2509.24272', 'extra_urls': ['http://arxiv.org/abs/2509.24272'], 'type': 'article', 'author': [{'family': 'Zhao', 'given': 'Weibo'}, {'family': 'Liu', 'given': 'Jiahao'}, {'family': 'Ruan', 'given': 'Bonan'}, {'family': 'Li', 'given': 'Shaofei'}, {'family': 'Liang', 'given': 'Zhenkai'}], 'publisher': 'arXiv', 'abstract': 'Model Context Protocol (MCP) servers enable AI applications to connect to external systems in a plug-and-play manner, but their rapid proliferation also introduces severe security risks. Unlike mature software ecosystems with rigorous vetting, MCP servers still lack standardized review mechanisms, giving adversaries opportunities to distribute malicious implementations. Despite this pressing risk, the security implications of MCP servers remain underexplored. To address this gap, we present the first systematic study that treats MCP servers as active threat actors and decomposes them into core components to examine how adversarial developers can implant malicious intent. Specifically, we investigate three research questions: (i) what types of attacks malicious MCP servers can launch, (ii) how vulnerable MCP hosts and Large Language Models (LLMs) are to these attacks, and (iii) how feasible it is to carry out MCP server attacks in practice. Our study proposes a component-based taxonomy comprising twelve attack categories. For each category, we develop Proof-of-Concept (PoC) servers and demonstrate their effectiveness across diverse real-world host-LLM settings. We further show that attackers can generate large numbers of malicious servers at virtually no cost. We then test state-of-the-art scanners on the generated servers and found that existing detection approaches are insufficient. These findings highlight that malicious MCP servers are easy to implement, difficult to detect with current tools, and capable of causing concrete damage to AI agent systems. Addressing this threat requires coordinated efforts among protocol designers, host developers, LLM providers, and end users to build a more secure and resilient MCP ecosystem.'}, {'id': 'arxiv_2503.13657', 'title': 'Why Do Multi-Agent LLM Systems Fail?', 'URL': 'http://arxiv.org/abs/2503.13657', 'extra_urls': ['http://arxiv.org/abs/2503.13657'], 'type': 'article', 'author': [{'family': 'Cemri', 'given': 'Mert'}, {'family': 'Pan', 'given': 'Melissa Z.'}, {'family': 'Yang', 'given': 'Shuyi'}, {'family': 'Agrawal', 'given': 'Lakshya A.'}, {'family': 'Chopra', 'given': 'Bhavya'}, {'family': 'Tiwari', 'given': 'Rishabh'}, {'family': 'Keutzer', 'given': 'Kurt'}, {'family': 'Parameswaran', 'given': 'Aditya'}, {'family': 'Klein', 'given': 'Dan'}, {'family': 'Ramchandran', 'given': 'Kannan'}, {'family': 'Zaharia', 'given': 'Matei'}, {'family': 'Gonzalez', 'given': 'Joseph E.'}, {'family': 'Stoica', 'given': 'Ion'}], 'publisher': 'arXiv', 'abstract': &quot;Despite growing enthusiasm for Multi-Agent LLM Systems (MAS), their performance gains on popular benchmarks often remain minimal compared with single-agent frameworks. This gap highlights the need to systematically analyze the challenges hindering MAS effectiveness. We present MAST (Multi-Agent System Failure Taxonomy), the first empirically grounded taxonomy designed to understand MAS failures. We analyze seven popular MAS frameworks across over 200 tasks, involving six expert human annotators. Through this process, we identify 14 unique failure modes, organized into 3 overarching categories, (i) specification issues, (ii) inter-agent misalignment, and (iii) task verification. MAST emerges iteratively from rigorous inter-annotator agreement studies, achieving a Cohen's Kappa score of 0.88. To support scalable evaluation, we develop a validated LLM-as-a-Judge pipeline integrated with MAST. We leverage two case studies to demonstrate MAST's practical utility in analyzing failures and guiding MAS development. Our findings reveal that identified failures require more complex solutions, highlighting a clear roadmap for future research. We open source our comprehensive dataset and LLM annotator to facilitate further development of MAS.&quot;}, {'id': 'doi_10_1109_BIGCOMP_2016_7425981', 'title': 'A runtime verification framework for dynamically adaptive multi-agent systems', 'URL': 'https://doi.org/10.1109/BIGCOMP.2016.7425981', 'extra_urls': ['https://doi.org/10.1109/BIGCOMP.2016.7425981'], 'type': 'article', 'author': [{'family': 'Lim', 'given': 'Yoo Jin'}, {'family': 'Hong', 'given': 'Gwangui'}, {'family': 'Shin', 'given': 'Donghwan'}, {'family': 'Jee', 'given': 'Eunkyoung'}, {'family': 'Bae', 'given': 'Doo-Hwan'}], 'abstract': 'Dynamically adaptive multi-agent systems (DAMS) consist of multiple agents that adapt to changing system and environmental conditions in order to achieve collaborative goals. As DAMS are found in applications across various domains, ensuring the correct and safe adaptations of DAMS has become more important. Formal verification techniques such as model checking present a promising approach to guaranteeing the correctness of a software system with respect to certain system requirements. Previous works on formal verification for dynamically adaptive system or multi-agent system, however, have not addressed the runtime and collaborative nature inherent to DAMS operations. This work proposes a runtime verification framework for DAMS (DAMS-RV) based on an adaptive feedback loop, which is activated for each adaptation that system makes after a change in the system or environment. The proposed framework is described using a collaborative nurse agent system as a running example. A case study with an application scenario provides insights into how DAMS-RV can serve as a feasible and effective framework for DAMS verification.', 'DOI': '10.1109/BIGCOMP.2016.7425981'}, {'id': 'billion', 'title': &quot;H&amp;M's $4.3 billion problem: A bundle of unsold clothes&quot;, 'URL': 'https://www.bloomberg.com/news/articles/2018-03-27/h-m-s-4-3-billion-problem-is-a-bunch-of-clothes-nobody-wants', 'extra_urls': ['https://www.bloomberg.com/news/articles/2018-03-27/h-m-s-4-3-billion-problem-is-a-bunch-of-clothes-nobody-wants'], 'type': 'article', 'author': [{'family': 'Bloomberg News'}], 'issued': {'date-parts': [[2018]]}}, {'id': 'the_resale', 'title': 'The resale effect: Impact of authentication on luxury resale values', 'URL': '#item_20342', 'type': 'article', 'author': [{'family': 'Vestiaire Collective'}], 'issued': {'date-parts': [[2022]]}}, {'id': 'arxiv_2510.00229', 'title': 'DualTune: Decoupled Fine-Tuning for On-Device Agentic Systems', 'URL': 'http://arxiv.org/abs/2510.00229', 'extra_urls': ['http://arxiv.org/abs/2510.00229'], 'type': 'article', 'author': [{'family': 'Kadekodi', 'given': 'Rohan'}, {'family': 'Jin', 'given': 'Zhan'}, {'family': 'Kamahori', 'given': 'Keisuke'}, {'family': 'Gu', 'given': 'Yile'}, {'family': 'Khatiri', 'given': 'Sean'}, {'family': 'Bayindirli', 'given': 'Noah H.'}, {'family': 'Gorbunov', 'given': 'Sergey'}, {'family': 'Kasikci', 'given': 'Baris'}], 'publisher': 'arXiv', 'abstract': 'The deployment of Large Language Models (LLMs) as agentic orchestrators has revolutionized task automation, but the need for privacy-preserving, cost-effective solutions demands on-device inference capabilities. However, local LLMs consistently underperform compared to frontier models in tool calling scenarios, struggling with both tool selection from large tool sets and accurate argument generation for complex parameter structures. We introduce a methodology that disaggregates a tool-calling task into two distinct subtasks: tool selection and argument generation. We propose &quot;decoupled fine-tuning&quot;, a novel post-training approach that employs LoRA fine-tuning to create dedicated LoRA adapters for tool selection and tool-specific argument generation using separate loss masking for each of the subtasks. Furthermore, we present DualTune, an inference framework that leverages the LoRA adapters created using decoupled fine-tuning to perform efficient agent orchestration with the help of local models on end-user devices. DualTune decomposes the tool-call generation step into tool selection and argument generation, and dynamically loads the corresponding LoRA adapters to generate tool calls. Additionally, DualTune implements hierarchical orchestration to restrict the number of tools required for tool selection. Our experiments on the MCP-Bench benchmark demonstrate that the Qwen-2.5-7B model trained using decoupled fine-tuning improves the tool calling accuracy of the base model by 46%, and outperforms other local reasoning, non-reasoning and fine-tuned models of similar size in all cases, and models that are 2x larger, in most cases.'}, {'id': 'arxiv_2510.15994', 'title': 'MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents', 'URL': 'http://arxiv.org/abs/2510.15994', 'extra_urls': ['http://arxiv.org/abs/2510.15994'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Dongsen'}, {'family': 'Li', 'given': 'Zekun'}, {'family': 'Luo', 'given': 'Xu'}, {'family': 'Liu', 'given': 'Xuannan'}, {'family': 'Li', 'given': 'Peipei'}, {'family': 'Xu', 'given': 'Wenjun'}], 'publisher': 'arXiv', 'abstract': 'The Model Context Protocol (MCP) standardizes how large language model (LLM) agents discover, describe, and call external tools. While MCP unlocks broad interoperability, it also enlarges the attack surface by making tools first-class, composable objects with natural-language metadata, and standardized I/O. We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling. MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed attacks; (2) an evaluation harness that executes attacks by running real tools (both benign and malicious) via MCP rather than simulation; and (3) a robustness metric that quantifies the trade-off between security and performance: Net Resilient Performance (NRP). We evaluate nine popular LLM agents across 10 domains and 400+ tools, producing 2,000 attack instances. Results reveal the effectiveness of attacks against each stage of MCP. Models with stronger performance are more vulnerable to attacks due to their outstanding tool calling and instruction following capabilities. MSB provides a practical baseline for researchers and practitioners to study, compare, and harden MCP agents.'}, {'id': 'arxiv_2505.12490', 'title': 'Improving Google A2A Protocol: Protecting Sensitive Data and Mitigating Unintended Harms in Multi-Agent Systems', 'URL': 'http://arxiv.org/abs/2505.12490', 'extra_urls': ['http://arxiv.org/abs/2505.12490'], 'type': 'article', 'author': [{'family': 'Louck', 'given': 'Yedidel'}, {'family': 'Stulman', 'given': 'Ariel'}, {'family': 'Dvir', 'given': 'Amit'}], 'publisher': 'arXiv', 'abstract': 'Googles A2A protocol provides a secure communication framework for AI agents but demonstrates critical limitations when handling highly sensitive information such as payment credentials and identity documents. These gaps increase the risk of unintended harms, including unauthorized disclosure, privilege escalation, and misuse of private data in generative multi-agent environments. In this paper, we identify key weaknesses of A2A: insufficient token lifetime control, lack of strong customer authentication, overbroad access scopes, and missing consent flows. We propose protocol-level enhancements grounded in a structured threat model for semi-trusted multi-agent systems. Our refinements introduce explicit consent orchestration, ephemeral scoped tokens, and direct user-to-service data channels to minimize exposure across time, context, and topology. Empirical evaluation using adversarial prompt injection tests shows that the enhanced protocol substantially reduces sensitive data leakage while maintaining low communication latency. Comparative analysis highlights the advantages of our approach over both the original A2A specification and related academic proposals. These contributions establish a practical path for evolving A2A into a privacy-preserving framework that mitigates unintended harms in multi-agent generative AI systems.'}, {'id': 'doi_10_1038_s41746-024-01085-w', 'title': 'Distribution shift detection for the postmarket surveillance of medical AI algorithms: a retrospective simulation study', 'URL': 'https://doi.org/10.1038/s41746-024-01085-w', 'extra_urls': ['https://doi.org/10.1038/s41746-024-01085-w'], 'type': 'article', 'author': [{'family': 'Koch', 'given': 'Lisa M.'}, {'family': 'Baumgartner', 'given': 'Christian F.'}, {'family': 'Berens', 'given': 'Philipp'}], 'abstract': 'Distribution shifts remain a problem for the safe application of regulated medical AI systems, and may impact their real-world performance if undetected. Postmarket shifts can occur for example if algorithms developed on data from various acquisition settings and a heterogeneous population are predominantly applied in hospitals with lower quality data acquisition or other centre-specific acquisition factors, or where some ethnicities are over-represented. Therefore, distribution shift detection could be important for monitoring AI-based medical products during postmarket surveillance. We implemented and evaluated three deep-learning based shift detection techniques (classifier-based, deep kernel, and multiple univariate kolmogorov-smirnov tests) on simulated shifts in a dataset of 130\u2019486 retinal images. We trained a deep learning classifier for diabetic retinopathy grading. We then simulated population shifts by changing the prevalence of patients\u2019 sex, ethnicity, and co-morbidities, and example acquisition shifts by changes in image quality. We observed classification subgroup performance disparities w.r.t. image quality, patient sex, ethnicity and co-morbidity presence. The sensitivity at detecting referable diabetic retinopathy ranged from 0.50 to 0.79 for different ethnicities. This motivates the need for detecting shifts after deployment. Classifier-based tests performed best overall, with perfect detection rates for quality and co-morbidity subgroup shifts at a sample size of 1000. It was the only method to detect shifts in patient sex, but required large sample sizes ($$&gt; 30^{\\prime} 000$$). All methods identified easier-to-detect out-of-distribution shifts with small (\u2264300) sample sizes. We conclude that effective tools exist for detecting clinically relevant distribution shifts. In particular classifier-based tests can be easily implemented components in the post-market surveillance strategy of medical device manufacturers.', 'DOI': '10.1038/s41746-024-01085-w'}, {'id': 'doi_10_1038_s42256-024-00857-z', 'title': 'Systematic analysis of 32,111 AI model cards characterizes documentation practice in AI', 'URL': 'https://doi.org/10.1038/s42256-024-00857-z', 'extra_urls': ['https://doi.org/10.1038/s42256-024-00857-z'], 'type': 'article', 'author': [{'family': 'Liang', 'given': 'Weixin'}, {'family': 'Rajani', 'given': 'Nazneen'}, {'family': 'Yang', 'given': 'Xinyu'}, {'family': 'Ozoani', 'given': 'Ezinwanne'}, {'family': 'Wu', 'given': 'Eric'}, {'family': 'Chen', 'given': 'Yiqun'}, {'family': 'Smith', 'given': 'Daniel Scott'}, {'family': 'Zou', 'given': 'James'}], 'abstract': 'The rapid proliferation of AI models has underscored the importance of thorough documentation, which enables users to understand, trust and effectively use these models in various applications. Although developers are encouraged to produce model cards, it\u2019s not clear how much or what information these cards contain. In this study we conduct a comprehensive analysis of 32,111 AI model documentations on Hugging Face, a leading platform for distributing and deploying AI models. Our investigation sheds light on the prevailing model card documentation practices. Most AI models with a substantial number of downloads provide model cards, although with uneven informativeness. We find that sections addressing environmental impact, limitations and evaluation exhibit the lowest filled-out rates, whereas the training section is the one most consistently filled-out. We analyse the content of each section to characterize practitioners\u2019 priorities. Interestingly, there are considerable discussions of data, sometimes with equal or even greater emphasis than the model itself. Our study provides a systematic assessment of community norms and practices surroinding model documentation through large-scale data science and linguistic analysis.', 'DOI': '10.1038/s42256-024-00857-z'}, {'id': 'doi_10_1007_s10676-024-09757-7', 'title': 'Use case cards: a use case reporting framework inspired by the European AI Act', 'URL': 'https://doi.org/10.1007/s10676-024-09757-7', 'extra_urls': ['https://doi.org/10.1007/s10676-024-09757-7'], 'type': 'article', 'author': [{'family': 'Hupont', 'given': 'Isabelle'}, {'family': 'Fern\xe1ndez-Llorca', 'given': 'David'}, {'family': 'Baldassarri', 'given': 'Sandra'}, {'family': 'G\xf3mez', 'given': 'Emilia'}], 'abstract': 'Despite recent efforts by the Artificial Intelligence (AI) community to move towards standardised procedures for documenting models, methods, systems or datasets, there is currently no methodology focused on use cases aligned with the risk-based approach of the European AI Act (AI Act). In this paper, we propose a new framework for the documentation of use cases that we call use case cards, based on the use case modelling included in the Unified Markup Language (UML) standard. Unlike other documentation methodologies, we focus on the intended purpose and operational use of an AI system. It consists of two main parts: firstly, a UML-based template, tailored to allow implicitly assessing the risk level of the AI system and defining relevant requirements, and secondly, a supporting UML diagram designed to provide information about the system-user interactions and relationships. The proposed framework is the result of a co-design process involving a relevant team of EU policy experts and scientists. We have validated our proposal with 11 experts with different backgrounds and a reasonable knowledge of the AI Act as a prerequisite. We provide the 5 use case cards used in the co-design and validation process. Use case cards allows framing and contextualising use cases in an effective way, and we hope this methodology can be a useful tool for policy makers and providers for documenting use cases, assessing the risk level, adapting the different requirements and building a catalogue of existing usages of AI.', 'DOI': '10.1007/s10676-024-09757-7'}, {'id': 'doi_10_1108_IMDS-08-2022-0468', 'title': 'Using deep learning to interpolate the missing data in time-series for\xa0credit risks along supply chain', 'URL': 'https://doi.org/10.1108/IMDS-08-2022-0468', 'extra_urls': ['https://doi.org/10.1108/IMDS-08-2022-0468'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Wenfeng'}, {'family': 'Lim', 'given': 'Ming K.'}, {'family': 'Yang', 'given': 'Mei'}, {'family': 'Li', 'given': 'Xingzhi'}, {'family': 'Ni', 'given': 'Du'}], 'abstract': 'As the supply chain is a highly integrated infrastructure in modern business, the risks in supply chain are also becoming highly contagious among the target company. This motivates researchers to continuously add new features to the datasets for the credit risk prediction (CRP). However, adding new features can easily lead to missing of the data.Based on the gaps summarized from the literature in CRP, this study first introduces the approaches to the building of datasets and the framing of the algorithmic models. Then, this study tests the interpolation effects of the algorithmic model in three artificial datasets with different missing rates and compares its predictability before and after the interpolation in a real dataset with the missing data in irregular time-series.The algorithmic model of the time-decayed long short-term memory (TD-LSTM) proposed in this study can monitor the missing data in irregular time-series by capturing more and better time-series information, and interpolating the missing data efficiently. Moreover, the algorithmic model of Deep Neural Network can be used in the CRP for the datasets with the missing data in irregular time-series after the interpolation by the TD-LSTM.This study fully validates the TD-LSTM interpolation effects and demonstrates that the predictability of the dataset after interpolation is improved. Accurate and timely CRP can undoubtedly assist a target company in avoiding losses. Identifying credit risks and taking preventive measures ahead of time, especially in the case of public emergencies, can help the company minimize losses.', 'DOI': '10.1108/IMDS-08-2022-0468'}, {'id': 'missing_data_assumptions', 'title': 'Missing Data Assumptions', 'URL': 'https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-040720-031104', 'extra_urls': ['https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-040720-031104'], 'type': 'article', 'author': [{'family': 'Little', 'given': 'Roderick J.'}], 'abstract': 'I review assumptions about the missing-data mechanisms that underlie methods for the statistical analysis of data with missing values. I describe Rubin&amp;apos;s original definition of missing at random (MAR), its motivation and criticisms, and his sufficient conditions for ignoring the missingness mechanism for likelihood-based, Bayesian, and frequentist inference. Related definitions, including missing completely at random, always MAR, always missing completely at random, and partially MAR, are also covered. I present a formal argument for weakening Rubin&amp;apos;s sufficient conditions for frequentist maximum likelihood inference with precision based on the observed information. Some simple examples of MAR are described, together with an example where the missingness mechanism can be ignored even though MAR does not hold. Alternative approaches to statistical inference based on the likelihood function are reviewed, along with non-likelihood frequentist approaches, including weighted generalized estimating equations. Connections with the causal inference literature are also discussed. Finally, alternatives to Rubin&amp;apos;s MAR definition are discussed, including informative missingness, informative censoring, and coarsening at random. The intent is to provide a relatively nontechnical discussion, although some of the underlying issues are challenging and touch on fundamental questions of statistical inference.'}, {'id': 'future_images_of', 'title': 'Future images of data in circular economy for textiles', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0040162522003833', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0040162522003833'], 'type': 'article', 'author': [{'family': 'Luoma', 'given': 'P\xe4ivi'}, {'family': 'Penttinen', 'given': 'Esko'}, {'family': 'Tapio', 'given': 'Petri'}, {'family': 'Toppinen', 'given': 'Anne'}], 'abstract': &quot;Rapid expansion of digitalization and in the volume of data available constitutes a major driver toward circular economy. In the textile industry, with its vast quantities of waste and huge environmental impact, transformation toward such circularity is necessary but challenging. To explore how the use of data could support building sustainability-aligned pathways to circular economy of textiles, a study employing a two-round disaggregative Delphi approach (engaging 33 experts in the first round, in May 2021, and 26 in the second, in June 2021) articulated alternative images of the future. The three images, dubbed Transparency, Conflicting Interests, and Sustainable Textiles, imply that the role for data is intertwined with sustainability aspirations. The results highlight that exploiting data in pursuit of circular economy is a collaborative effort involving business value networks that include consumers and regulators. Availability and sharing of accountability-affording, meaningful data on textiles' life cycle and value network function as a key enabler. By working with the images developed, actors can better assess their circular-economy commitments, planned actions, and the consequences of these. Furthermore, the images provide a tool for mutual discussion of the development desired and of related responsibilities and uncertainties.&quot;}, {'id': 'a_comprehensive_review', 'title': 'A comprehensive review of circular economy research in the textile and clothing industry', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0959652624006991', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0959652624006991'], 'type': 'article', 'author': [{'family': 'Saha', 'given': 'Krishnendu'}, {'family': 'Dey', 'given': 'Prasanta Kumar'}, {'family': 'Kumar', 'given': 'Vikas'}], 'abstract': 'The textile and clothing industry is a significant global sector due to its economic and social contributions. However, it is one of the most polluting industries. There has been a significant uptake of research on circular economy implementation to reduce its environmental impacts. Nevertheless, there is a critical gap in reviewing how the research field is evolving and what the core focus and underlying assumptions of the existing research are. This paper utilises bibliometrics, content analysis, and problematisation to comprehensively examine the state of research. Analysing 132 primary documents dating from January 2014 to April 2023, this study reveals that sustainability-oriented innovation and transition challenges are the core focus of existing research. Technology-oriented circularity and its positive impact on sustainability is the in-house assumption that almost all studies are founded on. Besides unpacking the risk of such assumptions, this study provides tangible suggestions for future research on circular economy disruption, its rebound effect, and sustainability-oriented innovation. Although the time lag and language biases may have impacted the representation of current research trends, findings from this study can facilitate academic research and industry practice in implementing circular economy practices for a more sustainable future.'}, {'id': 'supply_chain_traceability', 'title': 'Supply chain traceability and transparency: How do fashion companies perform and evaluate?', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1002/fcsr.70024', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1002/fcsr.70024'], 'type': 'article', 'author': [{'family': 'Bari', 'given': 'Md Sadaqul'}, {'family': 'Jin', 'given': 'Byoungho Ellie'}, {'family': 'Min', 'given': 'Yoo-Won'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'This study explores how companies practice and assess their traceability and transparency efforts, offering an initial comparison of their approaches. Qualitative research methodology and inductive theorizing approaches were utilized. One-on-one in-depth interviews with 11 apparel industry professionals and thematic analysis via NVivo 12 revealed that companies use advanced tools like Oritain technology and certifications for traceability but simpler methods for transparency. While internal traceability evaluation systems exist, none are in place for transparency. The findings highlight the need for affordable solutions for smaller companies with financial constraints and standardized indicators for a holistic assessment of traceability initiatives.'}, {'id': 'doi_10_1007_978-981-95-0469-5_14', 'title': 'Regulatory Standards and Certifications for Sustainable Textiles', 'URL': 'https://doi.org/10.1007/978-981-95-0469-5_14', 'type': 'article', 'author': [{'family': 'Walter', 'given': 'Chipambwa'}, {'family': 'Pethile', 'given': 'Dzingai'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Springer Nature', 'abstract': 'Globally, the textile industry is encountering increased scrutiny as it has a significant environmental impact, as it contributes to water pollution, excessive waste production, widespread use of hazardous chemicals, and elevated energy consumption during manufacturing. In recent years, sustainability has become crucial in the textile industry, motivated by eco-conscious customers, environmental concerns, and evolving legal demands. To support this shift, a variety of standards and certifications have been introduced by regulatory bodies and organizations worldwide. This chapter takes a closer look at key global sustainability standards and the specific certifications designed to help the textile sector operate more responsibly. This chapter also looks at how textile certifications are being put into practice, using a range of case studies to highlight key takeaways and real-world insights. It explores how different levels of regulation, regional, national, and international, interact to shape sustainability standards and ensure industry-wide compliance. The chapter also focuses on the role of technology in the certification process, including a review of current tools and emerging trends. The chapter concludes by addressing some of the major challenges, such as aligning various standards, compliance verification, and cost implications for manufacturers. At the same time, it also highlights how these standards and regulations create opportunities for innovation and boost competitiveness in the market.', 'DOI': '10.1007/978-981-95-0469-5_14'}, {'id': 'doi_10_1007_s13280-023-01865-w', 'title': 'Paradoxical tensions in exploiting data to implement circular economy in the textile industry', 'URL': 'https://doi.org/10.1007/s13280-023-01865-w', 'extra_urls': ['https://doi.org/10.1007/s13280-023-01865-w'], 'type': 'article', 'author': [{'family': 'Luoma', 'given': 'P\xe4ivi'}, {'family': 'Penttinen', 'given': 'Esko'}, {'family': 'Tapio', 'given': 'Petri'}, {'family': 'Toppinen', 'given': 'Anne'}], 'abstract': 'Increasing utilization of data, enabled by digitalization, constitutes a major driver toward circular economy but is not without potential paradoxical tensions. A two-round disaggregative Delphi study and analysis of the qualitative material generated in it explored these tensions. They were found to cohere around three themes: consumer concurrence, business transparency, and technology relevance. The first theme is connected with consumers\u2019 behavior and their perceptions as to data\u2019s value, the transparency one involves alignment of business interests and practices with data-driven developments, and the third pertains to the actual environmental impact of digital technologies used to initiate data-driven circular economy. Business decision-making should address both the positive and the negative effects, in both the short and long term. Insight as to these tensions supports discovering how businesses can successfully utilize data in their efforts promoting circular economy within the complex reality of dynamically changing business environments.', 'DOI': '10.1007/s13280-023-01865-w'}, {'id': 'consumer_behavioral_intention', 'title': 'Consumer behavioral intention for sustainable garments: do materials used and the level of garment\u2019s visibility and skin contact matter?', 'URL': 'https://www.sciencedirect.com/science/article/pii/S2444569X2500109X', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S2444569X2500109X'], 'type': 'article', 'author': [{'family': 'Schiaroli', 'given': 'Valerio'}, {'family': 'Dangelico', 'given': 'Rosa Maria'}, {'family': 'Fraccascia', 'given': 'Luca'}], 'abstract': 'Sustainable fashion consumption can be promoted only by understanding the motivation behind consumers\u2019 decision to purchase sustainable clothing. This study explores the determinants of consumers\u2019 purchasing intentions for two clothing items with different functions, characterized by different levels of visibility and skin contact (underwear and jacket) made with two sustainable materials (biobased and recycled). A conceptual framework was tested using the SEM technique on data collected through a questionnaire administered to 768 Italian consumers. Sustainable fashion knowledge, availability of sustainable garments, influence of celebrities and influencers, and environmental concerns significantly affected purchase intentions for the four product categories investigated. Moreover, gender and age significantly influenced purchase intention. The findings highlighted that purchase intentions and their determinants vary based on the levels of visibility and skin contact associated with the products and the type of sustainable materials used. Several contributions to the theory and managerial implications are provided.'}, {'id': 'doi_10_1080_08911762_2025_2472776', 'title': 'The Role of Environmental Concerns and Self-Expression in Ethical Fashion Consumption: A Mediated Model of Consumer Values', 'URL': 'https://doi.org/10.1080/08911762.2025.2472776', 'extra_urls': ['https://doi.org/10.1080/08911762.2025.2472776'], 'type': 'article', 'author': [{'family': 'Upadhyay', 'given': 'Nitin'}, {'family': 'Kamble', 'given': 'Aakash'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'The global fashion industry faces growing scrutiny for its significant environmental and social impacts, prompting an urgent need to understand consumer motivations for ethical fashion consumption. This study addresses the gap in knowledge regarding how environmental concerns and self-expressive benefits influence consumer intentions to purchase ethical fashion products. Drawing on Symbolic Self-Completion Theory and the Theory of Consumption Values, the research explores the mediating role of functional, social, and emotional values in these relationships. Data were collected from a survey of 422 consumers in India, a rapidly growing yet underexplored ethical fashion market. The findings reveal that environmental concerns and self-expressive benefits positively influence functional, social, and emotional consumption values. These values, in turn, significantly mediate the relationship between the antecedents and purchase intentions. These findings offer valuable insights to promote sustainable consumption practices while contributing to the theoretical understanding of ethical consumerism.', 'DOI': '10.1080/08911762.2025.2472776'}, {'id': 'strategic_marketing_of', 'title': 'Strategic marketing of sustainable fashion: Exploring approaches and contradictions in the positioning of fashion rental', 'URL': 'https://www.sciencedirect.com/science/article/pii/S2666791624000216', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S2666791624000216'], 'type': 'article', 'author': [{'family': 'Pet\xe4nen', 'given': 'P\xe4ivi'}, {'family': 'Tuovila', 'given': 'Hannamaija'}, {'family': 'Heikkil\xe4', 'given': 'Pirjo'}], 'abstract': 'Despite the potential of sustainable fashion alternatives such as fashion rental, the market share of these business models is low, and they are considered niche offerings in the fashion market dominated by unsustainable options. However, limited research exists on the strategic marketing efforts required to position and scale these models. The aim of this study was to explore the strategic marketing of sustainable fashion by identifying approaches and contradictions in the positioning of fashion rental as a sustainable alternative. A qualitative multiple-case study was conducted involving five fashion rental companies in Finland. The findings were interpreted using Customer Value Propositions (CVPs) as a conceptual framework for exploring the economic, functional, emotional, and symbolic dimensions of proposed customer value as indicators for positioning. The study identified two approaches for positioning fashion rental: 1) in relation to ownership and 2) in relation to consumerism. These approaches revealed contradictions between detaching from and encouraging product ownership and balancing between maintaining and reducing consumerism. The results suggest that fashion rental companies navigate between niche and mainstream audiences by applying plasticity in their strategic marketing and that these activities occur within a highly complex environment. This article provides insights into the intermediate position of sustainable fashion alternatives, and expands the understanding of the gap between the acknowledged need to move to sustainable fashion and the minor share of these options on the market.'}, {'id': 'long_live_the', 'title': 'Long Live the Future: Exploring Sustainable Consumption Frames in the Swedish Second-Hand Fashion Market', 'URL': 'http://lup.lub.lu.se/student-papers/record/9211650', 'extra_urls': ['http://lup.lub.lu.se/student-papers/record/9211650'], 'type': 'article', 'author': [{'family': 'Krakhmaleva', 'given': 'Olga'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'This thesis focuses on the concept \u201csustainable consumption\u201d and how it is conceptually constructed by Swedish secondhand actors, specifically non-profit actors who actively engage in the resale of clothing. Our current excessive overconsumption of fashion and pressing need to shift to a more sustainable mode of consumption requires us to critically assess the definition of our sustainability ideals and examine the actors who are tasked with implementing them. To carry out this study, Collective Action Frames and Master Frames theories are applied to sustainability reports by Swedish non-profit actors: Erikshj\xe4lpen, Myrorna, and Artikel2, covering the time period 2018 to 2024. The methodology is based on the framing method and qualitative content analysis. The findings identify eight collective action frames which inform the findings of three master frames: \u201cCircular Economy\u201d, \u201cSaving the Environment\u201d, and \u201cEthical Consumption\u201d. The study concludes that the actors conceptualize sustainable consumption as the collection of circular strategies with messages of reducing emissions, producing positive environmental impact, empowerment, accessibility, and motive guided both by an altruistic and self-fulfilling purpose.'}, {'id': 'research_opportunities_in', 'title': 'Research Opportunities in Supply Chain Transparency', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1111/poms.13115', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1111/poms.13115'], 'type': 'article', 'author': [{'family': 'Sodhi', 'given': 'ManMohan S.'}, {'family': 'Tang', 'given': 'Christopher S.'}], 'issued': {'date-parts': [[2019]]}, 'abstract': 'More firms than ever before are disclosing the provenance of their products, results of product testing, and suppliers\u2019 compliance with labor-practice norms in their annual reports, sustainability reports, and press releases, besides making such information available on third-party websites. However, collecting and disclosing such information is not only costly but also does not provide clear benefits. While the terminology is not yet standard in the literature, this study distinguishes supply chain transparency from visibility. Here, visibility refers to managers\u2019 efforts to learn more about operations upstream in their supply chains. In contrast, by transparency, we mean a company disclosing information to consumers, investors, and other stakeholders about compliance with consumer-expected norms in its supply chain operations and products. To motivate further research on supply chain transparency, we first report recent examples of companies providing supply chain transparency. Then we present potential benefits of supply chain visibility and supply chain transparency, respectively, for the company. Finally, we propose topics for research on supply chain transparency arranged by stakeholder.'}, {'id': 'international_spillover_effects', 'title': &quot;International spillover effects in the EU's textile supply chains: A global SDG assessment&quot;, 'URL': 'https://www.sciencedirect.com/science/article/pii/S0301479721010999', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0301479721010999'], 'type': 'article', 'author': [{'family': 'Malik', 'given': 'Arunima'}, {'family': 'Lafortune', 'given': 'Guillaume'}, {'family': 'Carter', 'given': 'Sarah'}, {'family': 'Li', 'given': 'Mengyu'}, {'family': 'Lenzen', 'given': 'Manfred'}, {'family': 'Kroll', 'given': 'Christian'}], 'abstract': &quot;Successful implementation of the Sustainable Development Goals (SDGs) requires world countries to account for actions that inadvertently generate negative impacts on other countries. These actions/effects are called \u2018spillovers\u2019, and can hinder a country's SDG progress. In this work, we analyse negative social spillover effects, focussing specifically on the occupational health and safety aspects of workers in textile supply chains. We select two indicators: fatal accidents and non-fatal accidents that take place in global supply chains for satisfying consumption of textile products (such as clothing, leather products) by European Union (EU) countries. Specifically, we scan global supply chains originating in countries outside of EU for meeting the demands of its citizens. To this end, we employ a well-established technique of multi-regional input-output analysis, featuring information on 15,000 sectors for 189 countries, to scan international supply chain routes that are linked to consumption of textile products by EU countries. Our findings suggest that Italy, Germany, France, Spain, Poland, Belgium and Portugal are collectively responsible for about 80% of both fatal- and non-fatal accidents that are attributed to the EU's consumption-based footprint. These findings not only call for a need for coherent SDG policies that consider spillover effects, but also the need for these effects to be included in EU's strategic instruments and policy-related tools.&quot;}, {'id': 'doi_10_1038_s41561-018-0113-9', 'title': 'Environmental and social footprints of international trade', 'URL': 'https://doi.org/10.1038/s41561-018-0113-9', 'extra_urls': ['https://doi.org/10.1038/s41561-018-0113-9'], 'type': 'article', 'author': [{'family': 'Wiedmann', 'given': 'Thomas'}, {'family': 'Lenzen', 'given': 'Manfred'}], 'abstract': 'Globalization has led to an increasing geospatial separation of production and consumption, and, as a consequence, to an unprecedented displacement of environmental and social impacts through international trade. A large proportion of total global impacts can be associated with trade, and the trend is rising. Advances in global multi-region input-output models have allowed researchers to draw detailed, international supply-chain connections between harmful production in social and environmental hotspots and affluent consumption in global centres of wealth. The general direction of impact displacement is from developed to developing countries\u2014an increase of health impacts in China from air pollution linked to export production for the United States being one prominent example. The relocation of production across countries counteracts national mitigation policies and may negate ostensible achievements in decoupling impacts from economic growth. A comprehensive implementation of the United Nations Sustainable Development Goals therefore requires the inclusion of footprint indicators to avoid loopholes in national sustainability assessments.', 'DOI': '10.1038/s41561-018-0113-9'}, {'id': 'doi_10_1016_j_jclepro_2016_05_144', 'title': 'Review on life cycle inventory: methods, examples and applications', 'URL': 'https://doi.org/10.1016/j.jclepro.2016.05.144', 'extra_urls': ['https://doi.org/10.1016/j.jclepro.2016.05.144'], 'type': 'article', 'author': [{'family': 'Islam', 'given': 'Samantha'}, {'family': 'Ponnambalam', 'given': 'S. G.'}, {'family': 'Lam', 'given': 'Hon Loong'}], 'abstract': 'Life cycle inventory (LCI) is the crucial phase of Life cycle assessment (LCA) which deals with the quantification and accumulation of a system inputs and outputs data. The three main currently available LCI methods are: Process based modeling, Input output (IO) LCI and Hybrid method. Different studies in literature adopt different methods of LCI. In contrast, different methods may provide different environmental impact results for the same product. Therefore, which LCI method should be chosen is highly important during conducting LCA studies. In order to choose a particular LCI method, one should know the calculation technique, relative advantages and limitations for the intended purpose. However, the knowledge about these methods and their application is split over various studies in literature. In this paper, a review on LCI evolution and their various methodological developments are presented along with numerical examples, advantages, disadvantages and application. This study is useful for choosing and applying an appropriate LCI method. It enables further exploration of advanced topic such as LCA software and extended LCA application like: Life cycle costing, Sustainability assessment, Green supply chain, Green product design and so on.', 'DOI': '10.1016/j.jclepro.2016.05.144'}, {'id': 'improving_matching_models', 'title': 'Improving Matching Models With Contextual Attention for Multi-Turn Response Selection in Retrieval-Based Chatbots', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10886991', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10886991'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Jingyu'}, {'family': 'Ma', 'given': 'Bing'}, {'family': 'Nan', 'given': 'Yafeng'}, {'family': 'He', 'given': 'Yixiao'}, {'family': 'Sun', 'given': 'Haifeng'}, {'family': 'Liu', 'given': 'Cong'}, {'family': 'Tao', 'given': 'Shimin'}, {'family': 'Qi', 'given': 'Qi'}, {'family': 'Liao', 'given': 'Jianxin'}], 'abstract': 'Multi-turn response selection is an important task in artificial intelligence. Early methods match each utterance with a response to obtain the matching information between utterance and response, then aggregate the matching vectors in chronological order. They are lightweight but ignore the dependencies between utterances, which is very important for mining useful matching information in utterance-response pair. Recently, some PLM-based methods can consider both relations between utterance and response and relations within utterances. However, they cost huge computational resource and suffer from loss of information due to the maximum length limit. In this research, we propose a lightweight, effective and low-loss method, CSMN. We initially expand the traditional attention to context-aware attention, making the model to dynamically learn complete matching information from response, utterance and context during the utterance-response matching. A hierarchical context-aware aggregation network is then applied for the further improvement of the proposed model. Experimental results on three large-scale dialogue datasets collected from social networks demonstrate the effectiveness of our proposed model. CSMN outperforms all traditional methods and is comparable to existing PLM-based methods with a extremely low cost of computational resource, which improves the response quality and user experience in multi-turn dialogue systems, and has important practical applications in resource-constrained environments.'}, {'id': 'doi_10_1080_10447318_2025_2495118', 'title': 'Designing Authentic Customer-Chatbot Interactions: A Necessary Condition Analysis of Emotional Intelligence and Anthropomorphic Features in Human-Computer Interaction', 'URL': 'https://doi.org/10.1080/10447318.2025.2495118', 'extra_urls': ['https://doi.org/10.1080/10447318.2025.2495118'], 'type': 'article', 'author': [{'family': 'Khan', 'given': 'Md Irfanuzzaman'}, {'family': 'Tarofder', 'given': 'Arun Kumar'}, {'family': 'Gopinathan', 'given': 'Sharmini'}, {'family': 'Haque', 'given': 'Ahasanul'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'This study offers a novel framework of perceived authenticity (PA) in chatbot-mediated service interactions by drawing on insights from Mind Perception Theory, Theory of Mind, the Authenticity Model of Computer-Mediated Communication, and Uncanny Valley Theory. The model integrates emotional and anthropomorphic cues by including perceived humanness, empathy, warmth, and humor. Survey data from 396 participants were analyzed using Partial Least Squares Structural Equation Modeling. The results indicate that empathy exerts the strongest influence on perceived authenticity, followed by perceived humanness and warmth, while humor plays a complementary role. PA significantly enhances trust, rapport, and satisfaction but has limited effect on frustration. Necessary Condition Analysis identifies minimum thresholds of key predictors needed to achieve high PA. Moderation analysis reveals that empathy and humanness are more effective for male-presenting chatbots, while humor enhances authenticity for female-presenting ones. The findings offer significant theoretical and practical implications in the domain of human -chatbot interaction.', 'DOI': '10.1080/10447318.2025.2495118'}, {'id': 'empathic_a', 'title': 'Empathic chatbots: A double-edged sword in customer experiences', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0148296324005782', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0148296324005782'], 'type': 'article', 'author': [{'family': 'Juquelier', 'given': 'Antoine'}, {'family': 'Poncin', 'given': 'Ingrid'}, {'family': 'Haz\xe9e', 'given': 'Simon'}], 'abstract': 'Recent breakthroughs in affective computing have enabled the shift from mechanical to empathic chatbots, now capable of detecting, decoding, and mimicking customers\u2019 thoughts and feelings to respond appropriately. While artificial empathy is believed to potentially bridge the human-artificial intelligence gap in customer experience, recent studies offer mixed support for its effectiveness in improving customer outcomes, leaving managers perplexed about the added value of empathic chatbots. Building on social presence theory, this paper investigates whether, how, and when empathic chatbot-led services enhance customer experience. Results from three experiments show that empathic chatbots trigger perceptions of social presence and information quality, which positively influence customer satisfaction. The findings further reveal that empathic chatbots can harm customer experience under certain conditions, particularly when customers feel time pressure. This paper provides insights into how and when to implement empathy in chatbots to enhance customer experience and boost customer satisfaction.'}, {'id': 'doi_10_1108_APJML-10-2024-1464', 'title': 'When empathy is enhanced by human\u2013AI interaction: an\xa0investigation of anthropomorphism and responsiveness on customer experience with AI chatbots', 'URL': 'https://doi.org/10.1108/APJML-10-2024-1464', 'extra_urls': ['https://doi.org/10.1108/APJML-10-2024-1464'], 'type': 'article', 'author': [{'family': 'Truong', 'given': 'Thi Thu Ha'}, {'family': 'Chen', 'given': 'Ja Shen'}], 'abstract': 'Artificial intelligence chatbots are increasingly employed as substitutes for human service agents in customer service. This study investigates how two key chatbot features, anthropomorphism and responsiveness, enhance the customer experience by fostering social presence and empathy, which in turn influence continuance intention. The moderating roles of privacy concerns and the need for human interaction (NFHI) are also examined.Data were collected from 461 respondents through an online survey on the Amazon Mechanical Turk platform, and partial least squares structural equation modeling was used to analyze the relationships.Both anthropomorphism and responsiveness significantly enhance social presence and empathy in chatbot interactions. Social presence mediates the relationship between chatbot features and empathy, which positively impacts continuance intention. Privacy concerns negatively moderate the relationship between empathy and continuance intention, whereas NFHI positively moderates it.Businesses should design chatbots with human-like behaviors and responsive features to create more engaging and empathetic interactions. Addressing privacy concerns and catering to users with high NFHI can further boost continued chatbot use.This study extends the stimuli-organism-response framework and social presence theory to chatbot interactions and provides insights into how psychological barriers influence user experience and continuance intention.', 'DOI': '10.1108/APJML-10-2024-1464'}, {'id': 'the_illusion_of', 'title': 'The Illusion of Empathy: How AI Chatbots Shape Conversation Perception', 'URL': 'https://ojs.aaai.org/index.php/AAAI/article/view/33569', 'extra_urls': ['https://ojs.aaai.org/index.php/AAAI/article/view/33569'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Tingting'}, {'family': 'Giorgi', 'given': 'Salvatore'}, {'family': 'Aich', 'given': 'Ankit'}, {'family': 'Lahnala', 'given': 'Allison'}, {'family': 'Curtis', 'given': 'Brenda'}, {'family': 'Ungar', 'given': 'Lyle'}, {'family': 'Sedoc', 'given': 'Jo\xe3o'}], 'abstract': &quot;As AI chatbots increasingly incorporate empathy, understanding user-centered perceptions of chatbot empathy and its impact on conversation quality remains essential yet under-explored. This study examines how chatbot identity and perceived empathy influence users' overall conversation experience. Analyzing 155 conversations from two datasets, we found that while GPT-based chatbots were rated significantly higher in conversational quality, they were consistently perceived as less empathetic than human conversational partners. Empathy ratings from GPT-4o annotations aligned with user ratings, reinforcing the perception of lower empathy in chatbots compared to humans. Our findings underscore the critical role of perceived empathy in shaping conversation quality, revealing that achieving high-quality human-AI interactions requires more than simply embedding empathetic language; it necessitates addressing the nuanced ways users interpret and experience empathy in conversations with chatbots.&quot;}, {'id': 'the_power_of', 'title': 'The power of emojis: Enhancing the willingness to adopt chatbot recommendations', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0969698925001675', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0969698925001675'], 'type': 'article', 'author': [{'family': 'Yan', 'given': 'Huili'}, {'family': 'Tian', 'given': 'Tian'}, {'family': 'Xiong', 'given': 'Hao'}], 'abstract': 'Chatbots have become an integral component of online services in the tourism industry. Emojis, which act as crucial nonverbal cues, have gained widespread attention because of their unique role in enhancing the emotional expression of chatbots. However, the impact of emoji use by chatbots on consumers\u2019 willingness to adopt recommendations has yet to receive sufficient scholarly attention. On the basis of the emotion as social information (EASI) model, this study conducts three online experiments to explore the mechanisms by which emoji use by chatbots influences the willingness to adopt recommendations within the context of tourism services. The findings from the three studies indicate that (1) compared with chatbots that do not use emojis, those that incorporate emojis significantly enhance consumers\u2019 willingness to adopt recommendations; (2) empathy and trust serve as mediators in this relationship; and (3) relationship norm orientation and identity disclosure moderate both the main effect and the mediating effects. This study contributes to the literature on emoji use in chatbots and provides practical insights for tourism companies in the design and deployment of chatbots.'}, {'id': 'amazon_0137670109', 'title': 'Patterns for API Design: Simplifying Integration with Loosely Coupled Message Exchanges', 'URL': 'https://www.amazon.com/Patterns-API-Design-Simplifying-Addison-Wesley/dp/0137670109', 'type': 'book', 'author': [{'family': 'Zimmermann', 'given': 'Olaf'}, {'family': 'Stocker', 'given': 'Mirko'}, {'family': 'Lubke', 'given': 'Daniel'}, {'family': 'Zdun', 'given': 'Uwe'}, {'family': 'Pautasso', 'given': 'Cesare'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'Addison-Wesley Professional', 'abstract': 'Proven Patterns for Designing Evolvable High-Quality APIs--For Any Domain, Technology, or PlatformAPIs enable breakthrough innovation and digital transformation in organizations and ecosystems of all kinds. To create user-friendly, reliable and well-performing APIs, architects, designers, and developers need expert design guidance. This practical guide cuts through the complexity of API conversations and their message contents, introducing comprehensive guidelines and heuristics for designing APIs sustainably and specifying them clearly, for whatever technologies or platforms you use.In Patterns for API Design: Simplifying Integration with Loosely Coupled Message Exchanges, five expert architects and developers cover the entire API lifecycle, from launching projects and establishing goals through defining requirements, elaborating designs, planning evolution, and creating useful documentation. They crystallize the collective knowledge of many practitioners into 44 API design patterns, consistently explained with context, pros and cons, conceptual solutions, and concrete examples. To make their pattern language accessible, they present a domain model, a running case study, decision narratives with pattern selection options and criteria, and walkthroughs of real-world projects applying the patterns in two different industries.Identify and overcome API design challenges with patternsSize your endpoint types and operations adequatelyDesign request and response messages and their representationsRefine your message design for qualityPlan to evolve your APIsDocument and communicate your API contractsCombine patterns to solve real-world problems and make the right tradeoffs&quot;This book provides a healthy mix of theory and practice, containing numerous nuggets of deep advice but never losing the big picture . . . grounded in real-world experience and documented with academic rigor applied and practitioner community feedback incorporated. I am confident that [it] will serve the community well, today and tomorrow.&quot;--Prof. Dr. Dr. h. c. Frank Leymann, Managing Director, Institute of Architecture of Application Systems, University of Stuttgart'}, {'id': 'information_systems_in', 'title': 'Information systems in supply chain integration and management', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0377221703005186', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0377221703005186'], 'type': 'article', 'author': [{'family': 'Gunasekaran', 'given': 'A'}, {'family': 'Ngai', 'given': 'E. W. T'}], 'abstract': 'Supply chain management (SCM) is the 21st century global operations strategy for achieving organizational competitiveness. Companies are attempting to find ways to improve their flexibility and responsiveness and in turn competitiveness by changing their operations strategy, methods and technologies that include the implementation of SCM paradigm and information technology (IT). However, a thorough and critical review of literature is yet to be carried out with the objective of bringing out pertinent factors and useful insights into the role and implications of IT in SCM. In this paper, the literature available on IT in SCM have been classified using suitable criteria and then critically reviewed to develop a framework for studying the applications of IT in SCM. Based on this review and analysis, recommendations have been made regarding the application of IT in SCM and some future research directions are indicated.'}, {'id': 'preparing_in_the', 'title': 'Preparing in the Light of Uncertainty: How Textile Companies respond to New Regulations on the Digital Product Passport', 'URL': 'https://studenttheses.uu.nl/handle/20.500.12932/48177', 'extra_urls': ['https://studenttheses.uu.nl/handle/20.500.12932/48177'], 'type': 'thesis', 'author': [{'family': 'Quick', 'given': 'Lea'}], 'issued': {'date-parts': [[2024]]}, 'abstract': &quot;European regulations are pushing for the implementation of a Digital Product Passport (DPP) to enhance transparency, circularity, and sustainability in different sectors, including the textile industry. This mandated information disclosure is a response to the textile industry's complex supply chains and should help mitigate its growing negative environmental and social impact. The DPP provides comprehensive data on products\u2019 origins, composition, and impact. This study aims to investigate how companies in the European textile sector perceive and respond to the upcoming DPP regulations characterised by regulatory uncertainty. The qualitative study of 16 semi-structured interviews with industry stakeholders revealed four different archetypes of companies, namely Enthusiastic Pioneers, Proactive Planners, Cautious Strategists, and Confident Procrastinators. Those types demonstrate different strategic responses and adoption strategies to the DPP. The findings illustrate that while some companies perceive the DPP as an opportunity to innovate and strengthen sustainability efforts, others remain hesitant, referring to challenges concerning data management and resource requirements. Some companies have started actively engaging with the DPP, either positioning themselves as pioneers in its implementation or taking precautionary steps to ensure they are fully prepared to comply with the upcoming regulations. In contrast, other companies apply a wait-and-see approach, confident in their ability to react when necessary. While the studied sample generally shows a positive and proactive attitude towards the DPP, the research indicates that many companies outside the sample investigated are rather sceptical and passive in their behaviour. Regulatory uncertainty builds a major challenge, affecting companies\u2019 strategies and planning. Policymakers are advised to provide clear guidelines while offering supporting resources and information. Companies are encouraged to engage proactively in industry collaborations and early compliance efforts. Future research should focus on broader cross-industry comparisons and longitudinal studies to analyse the adoption process and potential shifts in the four archetypes resulting from the final regulatory enforcement. This thesis contributes to the literature on regulatory uncertainty and innovation adoption, offering recommendations for companies and policymakers to navigate the transition to the DPP effectively.&quot;}, {'id': 'doi_10_1186_s13677-024-00618-8', 'title': 'Privacy-preserving federated learning based on partial low-quality data', 'URL': 'https://doi.org/10.1186/s13677-024-00618-8', 'extra_urls': ['https://doi.org/10.1186/s13677-024-00618-8'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Huiyong'}, {'family': 'Wang', 'given': 'Qi'}, {'family': 'Ding', 'given': 'Yong'}, {'family': 'Tang', 'given': 'Shijie'}, {'family': 'Wang', 'given': 'Yujue'}], 'abstract': 'Traditional machine learning requires collecting data from participants for training, which may lead to malicious acquisition of privacy in participants\u2019 data. Federated learning provides a method to protect participants\u2019 data privacy by transferring the training process from a centralized server to terminal devices. However, the server may still obtain participants\u2019 privacy through inference attacks and other methods. In addition, the data provided by participants varies in quality, and the excessive involvement of low-quality data in the training process can render the model unusable, which is an important issue in current mainstream federated learning. To address the aforementioned issues, this paper proposes a Privacy Preserving Federated Learning Scheme with Partial Low-Quality Data (PPFL-LQDP). It can achieve good training results while allowing participants to utilize partial low-quality data, thereby enhancing the privacy and security of the federated learning scheme. Specifically, we use a distributed Paillier cryptographic mechanism to protect the privacy and security of participants\u2019 data during the Federated training process. Additionally, we construct composite evaluation values for the data held by participants to reduce the involvement of low-quality data, thereby minimizing the negative impact of such data on the model. Through experiments on the MNIST dataset, we demonstrate that this scheme can complete the model training of federated learning with the participation of partial low-quality data, while effectively protecting the security and privacy of participants\u2019 data. Comparisons with related schemes also show that our scheme has good overall performance.', 'DOI': '10.1186/s13677-024-00618-8'}, {'id': 'doi_10_1080_00207543_2024_2432469', 'title': 'An adaptive federated learning system for information sharing in supply chains', 'URL': 'https://doi.org/10.1080/00207543.2024.2432469', 'extra_urls': ['https://doi.org/10.1080/00207543.2024.2432469'], 'type': 'article', 'author': [{'family': 'Zheng', 'given': 'Ge'}, {'family': 'Ivanov', 'given': 'Dmitry'}, {'family': 'Brintrup', 'given': 'Alexandra'}], 'abstract': &quot;Information sharing in supply chains can be challenged by privacy concerns. Equating data and information, the existing literature primarily focuses on the incentivisation behind information sharing between firms. The field of AI may bring a new way of looking at this problem by asking the following question: what if we do not share raw data but share learned information from it instead? This raises the next question, with whom and when should supply chain members share information, which we address in this paper. We develop a novel adaptive federated learning approach for the generation and usage of collective knowledge without direct data exchange and test the approach with a use case for collectively predicting supply risk. We propose a privacy-preserving network formation and clustering algorithm, which enables supply chain members to decide when to enter a collective information-sharing network, and how they should form information-sharing teams. Using data from an e-commerce platform, we illustrate how our approach outperforms the suppliers' own prediction models. We further show that clustering suppliers in teams achieves the best performance and converges faster compared to two benchmarks. The heterogeneity of information contribution by firms and those who benefit from collective information also raises important research questions on the role of cooperation in supply chains.&quot;, 'DOI': '10.1080/00207543.2024.2432469'}, {'id': 'doi_10_1007_978-3-030-63076-8_11', 'title': 'A Principled Approach to Data Valuation for Federated Learning', 'URL': 'https://doi.org/10.1007/978-3-030-63076-8_11', 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Tianhao'}, {'family': 'Rausch', 'given': 'Johannes'}, {'family': 'Zhang', 'given': 'Ce'}, {'family': 'Jia', 'given': 'Ruoxi'}, {'family': 'Song', 'given': 'Dawn'}], 'issued': {'date-parts': [[2020]]}, 'publisher': 'Springer International Publishing', 'abstract': 'Federated learning (FL) is a popular technique to train machine learning (ML) models on decentralized data sources. In order to sustain long-term participation of data owners, it is important to fairly appraise each data source and compensate data owners for their contribution to the training process. The Shapley value (SV) defines a unique payoff scheme that satisfies many desiderata for a data value notion. It has been increasingly used for valuing training data in centralized learning. However, computing the SV requires exhaustively evaluating the model performance on every subset of data sources, which incurs prohibitive communication cost in the federated setting. Besides, the canonical SV ignores the order of data sources during training, which conflicts with the sequential nature of FL. This chapter proposes a variant of the SV amenable to FL, which we call the federated Shapley value. The federated SV preserves the desirable properties of the canonical SV while it can be calculated without incurring extra communication cost and is also able to capture the effect of participation order on data value. We conduct a thorough empirical study of the federated SV on a range of tasks, including noisy label detection, adversarial participant detection, and data summarization on different benchmark datasets, and demonstrate that it can reflect the real utility of data sources for FL and has the potential to enhance system robustness, security, and efficiency. We also report and analyze \u201cfailure cases\u201d and hope to stimulate future research.', 'DOI': '10.1007/978-3-030-63076-8_11'}, {'id': 'doi_10_1007_s12599-024-00893-4', 'title': 'Data Sovereignty in Inter-organizational Information Systems', 'URL': 'https://doi.org/10.1007/s12599-024-00893-4', 'extra_urls': ['https://doi.org/10.1007/s12599-024-00893-4'], 'type': 'article', 'author': [{'family': 'Opriel', 'given': 'Sebastian'}, {'family': 'M\xf6ller', 'given': 'Frederik'}, {'family': 'Strobel', 'given': 'Gero'}, {'family': 'Otto', 'given': 'Boris'}], 'abstract': &quot;Car manufacturers and suppliers in the Automotive industry increasingly face the issue of optimization of highly complex supply chains that need to accommodate each customer's precise demands, requiring a vast array of parts and information to be available at the right place and at the right time. This involves data sharing between organizations, which is hindered by various issues, such as fear of data misappropriation by the data receiver or the involuntary disclosure of business secrets. The paper proposes design principles for a novel type of Inter-Organizational Information System, which addresses these challenges through the technical implementation of data sovereignty. The study reports on an Action Design Research study in the Automotive industry between a car manufacturer and a 1st-tier supplier. It contributes (a) design requirements, (b) design features, (c) an instantiation, and (d) design principles for this type of data sovereign inter-organizational information system.&quot;, 'DOI': '10.1007/s12599-024-00893-4'}, {'id': 'smart_conceptual', 'title': 'Smart Products: Conceptual Review, Synthesis, and Research Directions', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1111/jpim.12544', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1111/jpim.12544'], 'type': 'article', 'author': [{'family': 'Raff', 'given': 'Stefan'}, {'family': 'Wentzel', 'given': 'Daniel'}, {'family': 'Obwegeser', 'given': 'Nikolaus'}], 'issued': {'date-parts': [[2020]]}, 'abstract': 'Smart products have received increasing attention from researchers and practitioners alike. One limitation of the existing literature, however, is that the term is often used as a blanket term and that there is no consensus on what a smart product actually is. Because different studies rely on differing conceptualizations, the current body of knowledge is scattered and lacks a uniform language and conceptual boundaries. Specifically, existing research has subsumed inherently different products under one collective term, has relied on a multitude of ad hoc criteria to define smart products or has conflated smart products with the services they render and/or the wider ecosystem, in which they operate. These developments limit the systematic advancement of the field and impede the integration of the smart product concept into related concepts such as the Internet of Things. To address these issues, this article provides an extensive analysis of the status quo of the field, with the goal of developing a common language and comprehensive conceptualization of smart products. First, existing studies on smart products were systematically reviewed across contributing disciplines and supplemented with a bibliometric analysis that allowed for a deeper understanding of the smart product concept within and across disciplines. This analysis revealed an initial set of 16 capability-based criteria that are currently applied to conceptualize smart products. Second, based on a systematic coding procedure, these criteria were synthesized and organized within a comprehensive framework delineating four distinct product archetypes for the digital age: (1) Digital, (2) Connected, (3) Responsive, and (4) Intelligent. Third, three major conceptual themes that arise from this framework are identified and possibilities for future research are pointed out. In sum, this work contributes to the literature by improving the understanding of smart products as an epistemic object and by laying the ground for more cumulative research endeavors.'}, {'id': 'doi_10_1007_s11747-018-0608-3', 'title': 'Relationship journeys in the internet of things: a new framework for understanding interactions between consumers and smart objects', 'URL': 'https://doi.org/10.1007/s11747-018-0608-3', 'extra_urls': ['https://doi.org/10.1007/s11747-018-0608-3'], 'type': 'article', 'author': [{'family': 'Novak', 'given': 'Thomas P.'}, {'family': 'Hoffman', 'given': 'Donna L.'}], 'abstract': 'Consumers\u2019 interactions with smart objects have a relational nature, and extensive research has supported the \u201crelationship metaphor\u201d as a fruitful way to understand consumer responses to consumption objects. But, smart objects pose unique challenges for considering the emergence of consumer\u2013object relationships, because their degrees of agency, autonomy, and authority lend them their own unique capacities for interaction. We present a new framework for consumer\u2013object relationships based on the circumplex model of interpersonal complementarity and situated in assemblage theory and object-oriented ontology. Consumer\u2013object relationship styles are defined in terms of two foundational dimensions of behavior, agency, and communion, based on the expressive roles played by consumer and object. The overlay of assemblage theory provides a conceptually rich understanding of the space of master\u2013servant, partner, and unstable relationship styles, along with their concomitant positive (enabling) versus negative (constraining) consumer experiences. The model\u2019s underlying geometry supports extensive empirical work and provides a powerful managerial framework for measuring and tracking consumer\u2013object relationships and the journeys they take over time.', 'DOI': '10.1007/s11747-018-0608-3'}, {'id': 'towards_a_framework', 'title': 'Towards a framework of smart-circular systems: An integrative literature review', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0959652619304743', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0959652619304743'], 'type': 'article', 'author': [{'family': 'Alcayaga', 'given': 'Andres'}, {'family': 'Wiener', 'given': 'Melanie'}, {'family': 'Hansen', 'given': 'Erik G.'}], 'abstract': 'Profiting from the benefits of smart products connected through the Internet of Things (IoT) could disrupt business models and has the potential to foster a circular economy by embracing a performance economy. Extant literature has offered insights into circular strategies, smart products and product-service systems (PSS) in isolated ways or by considering partial overlaps, but lacks a holistic account of their interplay. By means of an integrated review, this paper synthesises literatures from various domains to describe interrelationships among these three concepts and propose a conceptual framework of smart-circular systems. This paper thereby advances research by providing a description of three binary interrelationships: smart circularity, smart PSS and circular PSS. Moreover, the review elaborates a new understanding of smart-circular (product-service) systems by articulating the base strategy smart use and extending the following circular strategies (or technical loops): maintenance, reuse, remanufacturing and recycling. Finally, the review outlines a critique of the state of the literature on this phenomenon and offers suggestions to guide future empirical and theoretical research in the domains of circular strategies, services and business models.'}, {'id': 'doi_10_1007_s12351-023-00810-9', 'title': 'The value of secondary markets when consumers are socially conscious', 'URL': 'https://doi.org/10.1007/s12351-023-00810-9', 'extra_urls': ['https://doi.org/10.1007/s12351-023-00810-9'], 'type': 'article', 'author': [{'family': 'Zhao', 'given': 'You'}, {'family': 'Hou', 'given': 'Rui'}, {'family': 'Ding', 'given': 'Zhonghui'}], 'abstract': 'This study examines the effect of a secondary market with socially conscious consumers on a brand firm\u2019s profitability. The existing literature on the introduction of a secondary market usually assumes a channel setting. In practice, however, brand firms begin introducing physical products to secondary markets with a consumer-to-consumer setting, which is not considered in existing theories. Therefore, we develop a two-period pricing model to investigate the effect of secondary markets with socially conscious consumers and conduct a sensitivity analysis to examine the impact of the main parameters on the equilibrium outcomes. Conventional wisdom suggests that the introduction of the consumer-to-consumer secondary market is always detrimental to suppliers of durable physical goods. However, we demonstrate that a brand firm may benefit from introducing the physical product secondary market if the consumers are socially conscious under certain conditions, which stands in contrast to the existing literature. Moreover, consumers always prefer the introduction of a secondary market; that is, a \u201cwin\u2013win\u201d outcome may be achieved. In summary, our findings provide useful implications regarding when managers should introduce a secondary market in case consumers are socially conscious.', 'DOI': '10.1007/s12351-023-00810-9'}, {'id': 'doi_10_1007_s43615-024-00351-z', 'title': 'Deconstructing Customer Value Propositions for the Circular Product-as-a-Service Business Model: A Case Study from the Textile Industry', 'URL': 'https://doi.org/10.1007/s43615-024-00351-z', 'extra_urls': ['https://doi.org/10.1007/s43615-024-00351-z'], 'type': 'article', 'author': [{'family': 'Pet\xe4nen', 'given': 'P\xe4ivi'}, {'family': 'Sundqvist', 'given': 'Henna'}, {'family': 'Antikainen', 'given': 'Maria'}], 'abstract': 'Offering products as a service is a way to implement circular economy principles in business models and promote sustainability. However, in many markets, the model is still in its infancy in terms of market maturity and lacks customer acceptance. More understanding is needed of how product-as-a-service companies can enhance and reconfigure their competitive position by proposing meaningful customer value. For this purpose, this study focuses on customer value propositions (CVPs) as a strategic management concept in the circular economy. The aim of the study is to outline a deconstruction framework for systematically identifying the strategically manageable components of CVPs in circular product-as-a-service business models. The framework establishes a link between the elements of circular product-as-a-service business models and competitive CVPs. The framework is developed and validated with seven product-as-a-service business cases in the textile and clothing industry context. The results of the study provide insights into how product-as-a-service companies in the textile field aim to differentiate, how they structure customer value by identifying customer benefits and sacrifices, and what kind of resources and capabilities are needed for competing in the circular economy context.', 'DOI': '10.1007/s43615-024-00351-z'}, {'id': 'doi_10_1108_QMR-05-2023-0069', 'title': 'When the secondhand economy is not as good as it seems: understanding conflicts and their (ir)resolutions between users on secondhand resale platforms', 'URL': 'https://doi.org/10.1108/QMR-05-2023-0069', 'extra_urls': ['https://doi.org/10.1108/QMR-05-2023-0069'], 'type': 'article', 'author': [{'family': 'Cerio', 'given': 'Eva'}, {'family': 'Debenedetti', 'given': 'Alain'}, {'family': 'Sophie', 'given': 'Rieunier'}], 'abstract': 'Peer-to-peer (P2P) secondhand resale platforms (SRP) are competitive places where different value systems beyond market values interact. This study aims to investigate the conflicts that may arise in interactions between users on SRP and the extent to which these conflicts are (ir)resolved, by drawing on economies of worth theory.The study takes a qualitative and interpretative approach to examine 22 active users on P2P resales platforms such as Vinted, including in-depth interviews. Following the Straussian view of grounded theory, the study uses constant comparison (open, axial and selective coding) to analyze data on SRP users\u2019 experiences.Drawing on the economies of worth theory, the study shows that SRP users rely on four different value systems or \u201cworlds\u201d when using the platforms (market, domestic, green and civic worlds) that come into conflict, at either an interactional (three conflicts identified) or an individual (two conflicts identified) level. The findings reveal that these conflicts are temporarily resolved at the interactional level and in a sustainable way at the individual level.This study sheds further light on the relationship between consumers on SRP by offering a more nuanced perspective on these exchanges than market-oriented exchanges. It also analyzes the data through the economies of worth theory, which is an appropriate lens to better understand social interactions and conventions. Finally, the study offers recommendations on how managers can improve buyers\u2019 and sellers\u2019 experiences on these platforms and, thus, foster their satisfaction.', 'DOI': '10.1108/QMR-05-2023-0069'}, {'id': 'doi_10_1007_s11356-022-19255-2', 'title': 'Towards the circular economy in the fashion industry: the second-hand market as a best practice of sustainable responsibility for businesses and consumers', 'URL': 'https://doi.org/10.1007/s11356-022-19255-2', 'extra_urls': ['https://doi.org/10.1007/s11356-022-19255-2'], 'type': 'article', 'author': [{'family': 'D\u2019Adamo', 'given': 'Idiano'}, {'family': 'Lupi', 'given': 'Gianluca'}, {'family': 'Morone', 'given': 'Piergiuseppe'}, {'family': 'Settembre-Blundo', 'given': 'Davide'}], 'abstract': 'The transition to a circular economy is a key concern for the fashion industry. The emerging second-hand market is a practice that could enable the circular economy in the fashion industry. As this is an emerging trend, the literature has not yet sufficiently explored how it is possible to simultaneously meet consumer and industry expectations in the management of second-hand garments within the value chain. This article aimed to fill that gap with the analytic hierarchy process, which demonstrated that garment collection and recycling are not necessarily best practices for the circular economy. For this to happen, close collaboration between manufacturers and retailers in the value chain is needed to move the industry towards responsibly sustainable production and consumption models. The results emphasise that harvesting management and internal competition on low-cost collection are critical business drivers, while responsible consumption and benefits are opportunities for consumers.', 'DOI': '10.1007/s11356-022-19255-2'}, {'id': 'doi_10_1080_00207543_2025_2456991', 'title': 'The optimality of second-hand business decisions in the presence of consumer valuation uncertainty', 'URL': 'https://doi.org/10.1080/00207543.2025.2456991', 'extra_urls': ['https://doi.org/10.1080/00207543.2025.2456991'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Mengdan'}, {'family': 'Wang', 'given': 'Nengmin'}, {'family': 'Han', 'given': 'Zheng'}, {'family': 'Jiang', 'given': 'Bin'}], 'abstract': 'Valuation uncertainty of new products may expose consumers to undesirable trial-and-error costs and thus deter them from making a purchase. To mitigate such costs, manufacturers can incentivize consumers to recycle their products or offer second-hand products at lower prices. However, second-hand products may cannibalise new products, raising questions about the feasibility of adopting such a business model. Inspired by this observation, we build a game theoretic model where a manufacturer can develop two types of second-hand businesses (recycling-only or refurbishing-and-resale). We find that when consumers\u2019 trial-and-error costs on new products are low (high), the recycling-only (refurbishing-and-resale) model can be optimal for the manufacturer. In the former case, the recycling-only model converts a portion of non-buyers into buyers and thus improves profitability. In the latter case, the refurbishing-and-resale model induces consumers with high valuations to initially purchase second-hand products and later switch to new products. Interestingly, we also identify scenarios where the manufacturer benefits from not developing any second-hand business. Our findings are validated with real-world examples. Our results provide an explanation for the diversified choices regarding whether and how to implement second-hand business in practice.', 'DOI': '10.1080/00207543.2025.2456991'}, {'id': 'doi_10_1007_s11747-012-0308-3', 'title': 'Critical service logic: making sense of value creation and co-creation', 'URL': 'https://doi.org/10.1007/s11747-012-0308-3', 'extra_urls': ['https://doi.org/10.1007/s11747-012-0308-3'], 'type': 'article', 'author': [{'family': 'Gr\xf6nroos', 'given': 'Christian'}, {'family': 'Voima', 'given': 'P\xe4ivi'}], 'abstract': 'Because extant literature on the service logic of marketing is dominated by a metaphorical view of value co-creation, the roles of both service providers and customers remain analytically unspecified, without a theoretically sound foundation for value creation or co-creation. This article analyzes value creation and co-creation in service by analytically defining the roles of the customer and the firm, as well as the scope, locus, and nature of value and value creation. Value creation refers to customers\u2019 creation of value-in-use; co-creation is a function of interaction. Both the firm\u2019s and the customer\u2019s actions can be categorized by spheres (provider, joint, customer), and their interactions are either direct or indirect, leading to different forms of value creation and co-creation. This conceptualization of value creation spheres extends knowledge about how value-in-use emerges and how value creation can be managed; it also emphasizes the pivotal role of direct interactions for value co-creation opportunities.', 'DOI': '10.1007/s11747-012-0308-3'}, {'id': 'exploring_the_relationship', 'title': 'Exploring the Relationship Between Aesthetic Design as an Element of New Service Development and Performance', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-5885.2011.00827.x', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-5885.2011.00827.x'], 'type': 'article', 'author': [{'family': 'Candi', 'given': 'Marina'}, {'family': 'Saemundsson', 'given': 'R\xf6gnvaldur J.'}], 'issued': {'date-parts': [[2011]]}, 'abstract': &quot;The purpose of this research is to investigate the conditions under which the use of aesthetic design as an element of new service development is likely to improve performance\u2014more specifically, to empirically examine how aesthetic design can contribute to competitive advantage, resistance to imitation, and profitability, and how these contributions are moderated by the process of commoditization. Based on analysis of three rounds of longitudinal data collected one year apart in a population of new technology-based firms, the findings are that aesthetic design as an element of new service development can contribute positively to competitive advantage, resistance to imitation, and profitability, but that the effectiveness of using aesthetic design to achieve these outcomes differs depending on the level of commoditization. Positive relationships are found between the use of aesthetic design and competitive advantage and profitability, respectively, when the level of commoditization is high. Furthermore, the positive relationship between aesthetic design and resistance to service imitation is stronger when the relative importance of aesthetic design in a firms' sector is low, that is, conditions under which aesthetic design is not already expected. This research suggests that practitioners should consider using aesthetic design to counteract commoditization when the markets in which they compete are characterized by ready access to services that meet customers' needs and expectations for features, performance, and reliability, and expectations for aesthetic design have not already become established. Furthermore, they should be aware that the use of aesthetic design may turn into a baseline customer requirement, implying that while attention to aesthetic design is necessary to compete it may cease to constitute a potential source of competitive advantage.&quot;}, {'id': 'doi_10_1016_j_jclepro_2018_02_001', 'title': 'Modelling environmental value: An examination of sustainable business models within the fashion industry', 'URL': 'https://doi.org/10.1016/j.jclepro.2018.02.001', 'extra_urls': ['https://doi.org/10.1016/j.jclepro.2018.02.001'], 'type': 'article', 'author': [{'family': 'Pal', 'given': 'Rudrajeet'}, {'family': 'Gander', 'given': 'Jonathan'}], 'abstract': 'The business models of enterprises in the global fashion industry produce highly negative outcomes for the environment. High water usage, pollution from chemical treatments used in dyeing and preparation and the disposal of large amounts of unsold stock through incineration or landfill deposits combine to make clothing one of the highest impact industries on the planet. This paper uses the sustainable logics of narrowing, slowing and closing the loop of resources used during the production, design, manufacture and distribution of fashion garments to analyse emerging business models that seek to reduce the environmental impact of the fashion system. Taking the business model conceptualization of an enterprise as a system designed to create value for the customer and capture value for the firm, we add a consideration of environmental value and derive propositions that test the possibility that emerging sustainable business models in fashion will replace the dominant, unsustainable model. The paper argues that lack of scalability, incompatibility with fashion customers value propositions plus obstacles to supply chain changes militate against the prospect of the currently designed sustainable business models becoming the standard model of the fashion industry.', 'DOI': '10.1016/j.jclepro.2018.02.001'}, {'id': 'doi_10_1016_j_jclepro_2018_02_014', 'title': 'The reDesign canvas: Fashion design as a tool for sustainability', 'URL': 'https://doi.org/10.1016/j.jclepro.2018.02.014', 'extra_urls': ['https://doi.org/10.1016/j.jclepro.2018.02.014'], 'type': 'article', 'author': [{'family': 'Kozlowski', 'given': 'Anika'}, {'family': 'Searcy', 'given': 'Cory'}, {'family': 'Bardecki', 'given': 'Michal'}], 'abstract': 'Many of the existing tools for design in a sustainable fashion context are too complex, overly conceptual, require experts to apply, have a high cost, were created for large corporations, or fall short in holistically supporting sustainable fashion design entrepreneurial practices. Micro-sized enterprises represent a significant portion of the fashion industry and can meaningfully contribute to the transition to a more sustainable apparel and textile industry. This paper addresses this gap through the development of an original design tool, the reDesign canvas, to support design entrepreneurs in developing sustainable fashion enterprises. Informed by design thinking and systems thinking, the canvas was developed based on an in-depth review of the academic literature and the collection of qualitative data. Qualitative data were gathered through both participatory action research (PAR) and interviews with 38 sustainable fashion design entrepreneurs and experts in sustainable fashion. Both the PAR and the interviews were used to test and refine the reDesign canvas in order to ensure it meets the needs of sustainable design entrepreneurs operating micro-sized companies. The final version of the canvas is based on 12 building blocks that a design entrepreneur would encounter in building a sustainable fashion brand. The reDesign canvas can help advance both the theory and practice of sustainable fashion design.', 'DOI': '10.1016/j.jclepro.2018.02.014'}, {'id': 'doi_10_1007_s10668-023-03943-1', 'title': 'Influencing mechanism of consumers\u2019 willingness to pay for circular products: a meta-analytic structural equation modeling', 'URL': 'https://doi.org/10.1007/s10668-023-03943-1', 'extra_urls': ['https://doi.org/10.1007/s10668-023-03943-1'], 'type': 'article', 'author': [{'family': 'Fu', 'given': 'Hanliang'}, {'family': 'He', 'given': 'Weijie'}, {'family': 'Guo', 'given': 'Xiaotong'}, {'family': 'Hou', 'given': 'Caixia'}], 'abstract': &quot;Consumer purchases of circular products help alleviate resource shortages and protect the environment. Therefore, it is necessary to explore the influencing mechanism of consumers' willingness to pay (WTP) for circular products. Based on the framework of the theory of planned behavior, combined with perceived risk, environmental concern, social value, and product knowledge, this study employed the meta-analytic structural equation modeling based on the results of existing relevant empirical studies (32 samples, N\u2009=\u200914,032) to construct an integrated theoretical model of consumers' WTP for circular products. The findings demonstrated support for the integrated framework, and consumer attitude played a significant mediating role in the model framework. Moreover, the results also suggested that national cultures, types of circular products, and types of respondents were potential reasons for the differences in the results of some relevant studies. The integrated theoretical model focused on the difference evaluation and multivariate path analysis of the influencing factors of consumers' WTP for circular products and prospered the explanatory power and predictability of consumers' WTP for circular products.&quot;, 'DOI': '10.1007/s10668-023-03943-1'}, {'id': 'our_vision_of', 'title': 'Our vision of a circular economy for fashion', 'URL': 'https://www.ellenmacarthurfoundation.org/our-vision-of-a-circular-economy-for-fashion', 'extra_urls': ['https://www.ellenmacarthurfoundation.org/our-vision-of-a-circular-economy-for-fashion'], 'type': 'webpage', 'author': [{'family': 'Ellen MacArthur Foundation'}], 'abstract': 'In a circular economy for fashion, products are used more, made to be made again, and made from safe and recycled or renewable inputs.'}, {'id': 'doi_10_1007_s10479-025-06534-7', 'title': 'Human-artificial intelligence collaboration in supply chain outcomes: the mediating role of responsible artificial intelligence', 'URL': 'https://doi.org/10.1007/s10479-025-06534-7', 'extra_urls': ['https://doi.org/10.1007/s10479-025-06534-7'], 'type': 'article', 'author': [{'family': 'Vann Yaroson', 'given': 'Emilia'}, {'family': 'Abadie', 'given': 'Am\xe9lie'}, {'family': 'Roux', 'given': 'M\xe9lanie'}], 'abstract': &quot;Human-artificial intelligence collaboration (CAIT) presents considerable opportunities for optimising supply chain outcomes. Nonetheless, it poses numerous ethical, technological, and organisational obstacles that could impede its efficacy. This study contends that responsible AI (RAI) systems can function as a conduit between CAIT and supply chain outcomes to tackle these challenges. Accordingly, we leveraged the resource-based view (RBV) and socio-technical system (STS) theoretical lenses to analyse the mediating role of RAI in the relationship between CAIT and two supply chain outcomes (supply chain wellbeing (SCWB) and sustainable business performance (SBP)). The suggested model was evaluated using PLS-SEM on survey data from 301 supply chain managers in the UK. Our analysed data revealed a statistically insignificant relationship between CAIT and supply chain outcomes (SCWB and SBP). However, the mediating role of RAI was confirmed. The findings suggest that CAIT is merely a component of a supply chain's capacity to produce intrinsic resources, rather than a universal solution. To harness the dividends of human-AI collaboration involves designing boundaries, aligning CAIT to supply chain goals and integrating ethical and transparent strategies. Our findings contribute to the discourse on AI use in supply chain literature by showing that CAIT can influence supply chain outcomes by bridging ethical, operational and technological gaps while fostering trust and efficiency.&quot;, 'DOI': '10.1007/s10479-025-06534-7'}, {'id': 'development_of_a', 'title': 'Development of a Decentralized Digital Product Passport for Enhanced Lifecycle Management of Electrical and Electronic Equipment', 'URL': 'https://www.sciencedirect.com/science/article/pii/S2212827125002860', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S2212827125002860'], 'type': 'article', 'author': [{'family': 'Paolucci', 'given': 'Alessandro'}, {'family': 'Gianvincenzi', 'given': 'Mattia'}, {'family': 'Marconi', 'given': 'Marco'}, {'family': 'Favi', 'given': 'Claudio'}, {'family': 'Pennino', 'given': 'Diego'}], 'abstract': 'The Eco-design for Sustainable Products Regulation has introduced the Digital Product Passport (DPP) as a key tool for tracking and promoting the sustainable development of products. Despite the growing interest in DPPs, standardized models are yet to be established, with only experimental alternatives available from various organizations. Moreover, no existing model fully exploits the data, as conducting a life cycle assessment (LCA) still necessitates acquiring additional data from various life cycle stages. This study aims to bridge this gap by developing a fully decentralized DPP prototype specifically for the Electrical and Electronic Equipment (EEE) sector. The research begins by defining a tree-structured hierarchical model for data collection and management, aligning with regulatory standards. The prototype\u2019s implementation employs an eXtended Markup Language (XML) file for data digitalization and blockchain technology to ensure secure data sharing and storage. Tested on a household appliance, the DPP prototype demonstrates how digital passports can enhance product lifecycle management, driving sustainability in the EEE sector and supporting the implementation of circular economy scenarios.'}, {'id': 'how_the_digital', 'title': 'How the digital product passport can embed sustainability in the supply chain: case study for the battery industry', 'URL': 'https://hdl.handle.net/10589/239975', 'extra_urls': ['https://hdl.handle.net/10589/239975'], 'type': 'article', 'author': [{'family': 'Pistoia', 'given': 'Alessandro'}], 'abstract': 'LAUREA MAGISTRALE'}, {'id': 'doi_10_1080_00405000_2025_2496840', 'title': 'Research status and development trends of digital twin technology in apparel production: a review', 'URL': 'https://doi.org/10.1080/00405000.2025.2496840', 'extra_urls': ['https://doi.org/10.1080/00405000.2025.2496840'], 'type': 'article', 'author': [{'family': 'Bi', 'given': 'Yanwei'}, {'family': 'Pan', 'given': 'Li'}, {'family': 'Cao', 'given': 'Liyao'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Research on the application of digital twin technology in apparel manufacturing is still in its early stages, with limited studies focusing specifically on its use in the apparel production process. This underscores the need for further promotion of the in-depth integration of digital twin technology into apparel manufacturing. This paper examines the need for its adoption in the apparel industry, highlighting key technologies such as multi-dimensional modeling, data analysis, and platform development. It also identifies potential improvements tailored to the specific needs of apparel production. Focusing on production line management, optimization, and maintenance, the paper assesses the current application of digital twins in the field. Additionally, it outlines technical challenges and explores emerging trends, including the integration of \u201cdesign-production-operations\u201d, data-driven worker behavior and production process interactions, global optimization for decision-making, resource-integrated cost control, and sustainable production maintenance through real-time monitoring. The study aims to analyze the unique characteristics of apparel production and promote the broader application of digital twin technology to enhance collaboration, optimize decision-making, and provide theoretical and practical guidance for its integration into apparel manufacturing.', 'DOI': '10.1080/00405000.2025.2496840'}, {'id': 'doi_10_1002_sd_2474', 'title': 'Sustainable value in the fashion industry: A case study of value construction/destruction using digital twins', 'URL': 'https://doi.org/10.1002/sd.2474', 'extra_urls': ['https://doi.org/10.1002/sd.2474'], 'type': 'article', 'author': [{'family': 'Wagner', 'given': 'Ralf'}, {'family': 'Kabalska', 'given': 'Agnieszka'}], 'issued': {'date-parts': [[2023]]}, 'abstract': 'New technologies\u2014especially the emergence of digital fashion and a growing interest in creating digital twins (DTs)\u2014are expected to alter existing value chains in the fashion industry as DT technology triggers a redesign of value creation processes. This qualitative case study demonstrates how and to what extent the development of DTs in the fashion industry addresses the sustainability needs of various stakeholders in both real-world and virtual-reality settings. The article examines the possibilities, benefits, and challenges of creating sustainable value in two distinct ways: traditionally, through physical processes, and through digital transformation by employing virtual processes via DTs. The main implication for further research is to examine the distribution of value facilitated by DT among heterogeneous stakeholders.', 'DOI': '10.1002/sd.2474'}, {'id': 'doi_10_1007_978-3-031-70262-4_5', 'title': 'Carbon Footprint of Fashion: Assessing and Addressing Carbon Emissions in Textile Production', 'URL': 'https://doi.org/10.1007/978-3-031-70262-4_5', 'type': 'article', 'author': [{'family': 'Mayer', 'given': 'Philomena'}, {'family': 'Tama Birkocak', 'given': 'Derya'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'Springer Nature Switzerland', 'abstract': 'The textile and apparel industry on global carbon emissions contributes approximately 10% to worldwide emissions. This sector, a major environmental polluter, involves energy-intensive processes from fiber production to textile care and disposal, including recycling and landfill. This chapter is focused on assessing textile products\u2019 CO2 emissions throughout their lifecycle, addressing the role of carbon footprinting in understanding the relative importance of different greenhouse gases.', 'DOI': '10.1007/978-3-031-70262-4_5'}, {'id': 'redefining_how', 'title': 'Redefining Choices. How Does Artificial Intelligence Support Decision-Making in Urban and Architectural Development?', 'URL': 'https://webthesis.biblio.polito.it/34480/', 'extra_urls': ['https://webthesis.biblio.polito.it/34480/'], 'type': 'thesis', 'author': [{'family': 'Calderon Herrera', 'given': 'Diana Sofia'}], 'publisher': 'Politecnico di Torino', 'abstract': 'In response to the increasing complexity of urban and architectural projects and the need for informed, viable, and objective problem-solving processes, this research examines the decision-making processes in urban and architectural realms. In particular, it explores how artificial intelligence (AI) can enhance specific stages of decision-support approaches. Through a combination of theoretical analysis with practical application, this thesis explores the use of Multi-Values Appraisal Methodology (MuVAM) to support decision-making in architecture with or without the support of artificial intelligence (AI). MuVAM is a new tool that combines problem structuring methods (PSMs) and multi-criteria decision analyses (MCDAs), offering a framework to address complex problems and evaluate multiple criteria. The research examines two aspects of the application of MuVAM: its stand-alone use, focusing on its ability to structure and analyze problems, and its integration with AI, exploring how this digital technology enhances its functionality. By addressing these complementary perspectives, the thesis highlights the features of MuVAM and the potential of AI in decision support systems. In particular, the thesis draws upon the observation and reporting of participants interacting in the workshops\u2019 environment. The workshops were experimented with through three case studies, at different scales: (i) the transformation of the district \u201cPointe Nord\u201d in Geneva; (ii) the adaptive reuse of the former Paracchi carpet factory in Turin; and (iii) the requalification of the San Salvario neighborhood in Turin. Each case study illustrates how structured decision-making, guided by the integrated methodology, can be applied in architecture to address site-specific challenges and optimize urban decision outcomes. Also, since the first one was performed without the use of AI combined with MuVAM, the applications were compared in this sense. Accordingly, by connecting theoretical research with practical experiments observation, the thesis highlights the challenges and opportunities of such integrations, incorporating decision-making processes and artificial intelligence into architecture.'}, {'id': 'doi_10_1007_s11301-025-00526-4', 'title': 'Exploring the role of trust in AI-driven decision-making: a systematic literature review', 'URL': 'https://doi.org/10.1007/s11301-025-00526-4', 'extra_urls': ['https://doi.org/10.1007/s11301-025-00526-4'], 'type': 'article', 'author': [{'family': 'Montealegre-L\xf3pez', 'given': 'Nathalie'}], 'abstract': 'The increasing integration of artificial intelligence (AI) into managerial decision-making is transforming how organizations operate. It enables both decision augmentation in which AI supports human managers by providing recommendations, and decision automation in which AI independently makes decisions. Trust in AI systems is a critical factor in successful human-AI collaboration, as it affects the acceptance, adoption, and effectiveness of AI-driven decisions. However, the literature on the interplay among trust, AI, and decision-making remains fragmented due to the multidisciplinary nature of this issue. This systematic literature review addresses this issue by synthesizing extant research on the role of trust in AI-driven decision-making within a managerial context. Using a categorization framework, the review classifies 70 relevant articles across two key dimensions: the type of AI-driven decision-making \u2014 augmented or automated \u2014 and the aspect of trust, including its foundations, dynamics, and outcomes. This structured approach highlights key findings in the literature and identifies areas requiring further investigation. The article not only provides a comprehensive overview of the current state of research but also proposes avenues for future research that could deepen our understanding of trust\u2019s role in AI-driven decision-making and its implications for managerial practices.', 'DOI': '10.1007/s11301-025-00526-4'}, {'id': 'doi_10_1108_JKM-03-2025-0375', 'title': 'The nexus between learning engagement, knowledge acquisition and valence of use: role of generative AI adoption in business context', 'URL': 'https://doi.org/10.1108/JKM-03-2025-0375', 'extra_urls': ['https://doi.org/10.1108/JKM-03-2025-0375'], 'type': 'article', 'author': [{'family': 'Jiang', 'given': 'Xuping'}, {'family': 'Yuan', 'given': 'Ling'}, {'family': 'O. Alshaghdali', 'given': 'Nourah'}, {'family': 'Galgotia', 'given': 'Aradhana'}, {'family': 'Monaco', 'given': 'Antonio'}, {'family': 'Dell\u2019Aversano', 'given': 'Speranza'}], 'abstract': 'This study aims to examine how generative artificial intelligence (Gen AI)-based knowledge acquisition and learning engagement relate to business executives\u2019 valence for using Gen AI.Based on expectancy-value theory and Vroom\u2019s theory of motivation, this study developed a theoretical model to analyze how performance expectancy and instrumentality of Gen AI relate to business executives\u2019 knowledge acquisition and learning engagement, which further influences their Gen AI valence. Motivation acts as a moderating variable to evaluate how business executives\u2019 motivation and competence in utilizing Gen AI enhance their knowledge and learning abilities, complementing their valence for Gen AI.The results indicate a positive relationship between performance expectancy and the instrumentality of Gen AI regarding business executives\u2019 knowledge acquisition and learning engagement, which positively correlates with their outcome valence of Gen AI.The results indicate a positive relationship between performance expectancy and the instrumentality of Gen AI regarding business executives\u2019 knowledge acquisition and learning engagement, which positively correlates with their outcome valence of Gen AI.', 'DOI': '10.1108/JKM-03-2025-0375'}, {'id': 'conditioned', 'title': 'Img2CAD: Conditioned 3-D CAD Model Generation From Single Image With Structured Visual Geometry', 'URL': 'https://ieeexplore.ieee.org/document/11089972', 'extra_urls': ['https://ieeexplore.ieee.org/document/11089972'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Tianrun'}, {'family': 'Yu', 'given': 'Chunan'}, {'family': 'Hu', 'given': 'Yuanqi'}, {'family': 'Li', 'given': 'Jing'}, {'family': 'Xu', 'given': 'Tao'}, {'family': 'Cao', 'given': 'Runlong'}, {'family': 'Zhu', 'given': 'Lanyun'}, {'family': 'Zang', 'given': 'Ying'}, {'family': 'Zhang', 'given': 'Yong'}, {'family': 'Li', 'given': 'Zejian'}, {'family': 'Sun', 'given': 'Lingyun'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'In this article, we propose Img2CAD, the first approach to our knowledge that uses 2-D image inputs to generate computer-aided design (CAD) models with editable parameters. Unlike existing artificial intelligence (AI) methods for 3-D model generation using text or image inputs often rely on mesh-based representations, which are incompatible with CAD tools and lack editability and fine control, Img2CAD enables seamless integration between AI-based 3-D reconstruction and CAD software. We have identified an innovative intermediate representation called structured visual geometry, characterized by vectorized wireframes extracted from objects. This representation significantly enhances the performance of generating conditioned CAD models. In addition, we introduce two new datasets to further support research in this area: a big cad model dataset (ABC)-mono, the largest known dataset comprising over 200 000 3-D CAD models with rendered images, and KOCAD, the first dataset featuring real-world captured objects alongside their ground truth CAD models, supporting further research in conditioned CAD model generation.'}, {'id': 'leveraging_large_language', 'title': 'Leveraging large language models in next generation intelligent manufacturing: Retrospect and prospect', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0278612525001943', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0278612525001943'], 'type': 'article', 'author': [{'family': 'Ma', 'given': 'Yunfei'}, {'family': 'Zheng', 'given': 'Shuai'}, {'family': 'Yang', 'given': 'Zheng'}, {'family': 'Zheng', 'given': 'Pai'}, {'family': 'Leng', 'given': 'Jiewu'}, {'family': 'Hong', 'given': 'Jun'}], 'abstract': 'Industry 5.0, as the guiding ideology of the new generation intelligent manufacturing, points the way for global industrial transformation. It emphasizes the collaborative cooperation between humans, machines and intelligent systems, and places humans at the core of the industrial production process, aiming to create a more flexible, personalized and sustainable production paradigm. Large language model, as an advanced natural language processing technology, has received attention from researchers related to Industry 5.0 due to its ease of use and powerful language processing capability. LLM is considered to be one of the key enabling technologies to drive the development of Industry 5.0 and has great application potential. After a rigorous review of existing approaches, we find there is few existing survey papers that focuses on how LLM will drive the development of Industry 5.0 applications. Therefore, this paper provides a comprehensive review of the application of LLM in the field of Industry 5.0. Firstly, we conduct a literature review to explore the current state of research related to Industry 5.0. Subsequently, we analyze LLM-based technologies, synergizing LLMs with Industry 5.0 enablers and the applications of LLM in various domains of intelligent manufacturing. Finally, we explore the challenges of LLM in real-world scenarios and future research directions in the context of Industry 5.0. It is hoped that this study will contribute to the further development of LLM-based solutions in the context of Industry 5.0 and unite various efforts to achieve the vision of Industry 5.0.'}, {'id': 'advanced_smart_contract', 'title': 'Advanced Smart Contract Vulnerability Detection via LLM-Powered Multi-Agent Systems', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11121619', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11121619'], 'type': 'article', 'author': [{'family': 'Wei', 'given': 'Zhiyuan'}, {'family': 'Sun', 'given': 'Jing'}, {'family': 'Sun', 'given': 'Yuqiang'}, {'family': 'Liu', 'given': 'Ye'}, {'family': 'Wu', 'given': 'Daoyuan'}, {'family': 'Zhang', 'given': 'Zijian'}, {'family': 'Zhang', 'given': 'Xianhao'}, {'family': 'Li', 'given': 'Meng'}, {'family': 'Liu', 'given': 'Yang'}, {'family': 'Li', 'given': 'Chunmiao'}, {'family': 'Wan', 'given': 'Mingchao'}, {'family': 'Dong', 'given': 'Jin'}, {'family': 'Zhu', 'given': 'Liehuang'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Blockchain\u2019s inherent immutability, while transformative, creates critical security risks in smart contracts, where undetected vulnerabilities can result in irreversible financial losses. Current auditing tools and approaches often address specific vulnerability types, yet there is a need for a comprehensive solution that can detect a wide range of vulnerabilities with high accuracy. We propose LLM-SmartAudit, a novel framework that leverages Large Language Models (LLMs) to automate smart contract vulnerability detection and analysis. Using a multi-agent conversational architecture with a bufferof-thought mechanism, LLM-SmartAudit maintains a dynamic record of insights generated throughout the audit process. This enables a collaborative system of specialized agents to iteratively refine their assessments, enhancing the accuracy and depth of vulnerability detection. To evaluate its effectiveness, LLMSmartAudit was tested on three datasets: a benchmark for common vulnerabilities, a real-world project corpus, and a CVE dataset. It outperformed existing tools with 98% accuracy on common vulnerabilities and demonstrates higher accuracy in real-world scenarios. Additionally, it successfully identifies 12 out of 13 CVEs, surpassing other LLM-based methods. These results demonstrate the effectiveness of multi-agent collaboration in automated smart contract auditing, offering a scalable, adaptive, and highly efficient solution for blockchain security analysis.'}, {'id': 'detecting_bad', 'title': 'SCALM: Detecting Bad Practices in Smart Contracts Through LLMs', 'URL': 'https://ojs.aaai.org/index.php/AAAI/article/view/32026', 'extra_urls': ['https://ojs.aaai.org/index.php/AAAI/article/view/32026'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Zongwei'}, {'family': 'Li', 'given': 'Xiaoqi'}, {'family': 'Li', 'given': 'Wenkai'}, {'family': 'Wang', 'given': 'Xin'}], 'abstract': 'As the Ethereum platform continues to mature and gain widespread usage, it is crucial to maintain high standards of smart contract writing practices. While bad practices in smart contracts may not directly lead to security issues, they do elevate the risk of encountering problems. Therefore, to understand and avoid these bad practices, this paper introduces the first systematic study of bad practices in smart contracts, delving into over 35 specific issues. Specifically, we propose a large language models (LLMs)-based framework, SCALM. It combines Step-Back Prompting and Retrieval-Augmented Generation (RAG) to effectively identify and address various bad practices. Our extensive experiments using multiple LLMs and datasets have shown that SCALM outperforms existing tools in detecting bad practices in smart contracts.'}, {'id': 'beyond', 'title': 'Beyond single-model AI: How architectural design drives reliable multi-agent orchestration', 'URL': 'https://venturebeat.com/ai/beyond-single-model-ai-how-architectural-design-drives-reliable-multi-agent-orchestration', 'extra_urls': ['https://venturebeat.com/ai/beyond-single-model-ai-how-architectural-design-drives-reliable-multi-agent-orchestration'], 'type': 'article', 'author': [{'family': 'Gupta', 'given': 'Nikhil'}], 'abstract': 'Successful AI agents require enterprises to orchestrate interactions, manage shared knowledge and plan for failure.'}, {'id': 'federated_smart', 'title': 'Federated learning-empowered smart manufacturing and product lifecycle management: A review', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1474034625000722', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1474034625000722'], 'type': 'article', 'author': [{'family': 'Leng', 'given': 'Jiewu'}, {'family': 'Li', 'given': 'Rongjie'}, {'family': 'Xie', 'given': 'Junxing'}, {'family': 'Zhou', 'given': 'Xueliang'}, {'family': 'Li', 'given': 'Xiang'}, {'family': 'Liu', 'given': 'Qiang'}, {'family': 'Chen', 'given': 'Xin'}, {'family': 'Shen', 'given': 'Weiming'}, {'family': 'Wang', 'given': 'Lihui'}], 'abstract': 'The proliferation of data silos poses a significant impediment to the advancement of machine learning applications. The traditional approach of centralized data learning is becoming increasingly impractical in certain domains, primarily due to escalating concerns over data privacy and security. Particularly in the manufacturing sector, the integration of Federated Learning (FL) presents a promising avenue for safeguarding collaborative data mining efforts across a network of distributed manufacturers. This paper offers an in-depth review of research about FL in the realms of smart manufacturing and product lifecycle management. We elucidate the imperative need for FL applications from a socio-technical systems perspective, underscoring the interplay between societal and technological factors. Subsequently, we delve into the categorization of FL methodologies and their pivotal enablers, contextualized within the framework of manufacturing engineering. This paper further presents a comprehensive overview of FL applications, complemented by an analysis of the key performance metrics that are germane to the manufacturing industry. In conclusion, we engage in a discourse on the technical challenges, societal barriers, and prospective research trajectories for FL. Our discussion is anchored towards the emerging paradigm of Industry 5.0, which envisions a future where resilient, human-centric, and sustainable manufacturing systems are seamlessly integrated with cutting-edge digital technologies.'}, {'id': 'doi_10_1080_00207543_2025_2543964', 'title': 'Enhancing supply chain visibility with generative AI: an exploratory case study on relationship prediction in knowledge graphs', 'URL': 'https://doi.org/10.1080/00207543.2025.2543964', 'extra_urls': ['https://doi.org/10.1080/00207543.2025.2543964'], 'type': 'article', 'author': [{'family': 'Zheng', 'given': 'Ge'}, {'family': 'Brintrup', 'given': 'Alexandra'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'A key stumbling block in effective supply chain risk management for companies and policymakers is a lack of visibility on interdependent supply network relationships. Relationship prediction, also called link prediction is an emergent area of supply chain surveillance research that aims to increase the visibility of supply chains using data-driven techniques. Existing methods have been successful for predicting relationships but struggle to extract the context in which these relationships are embedded \u2013 such as the products being supplied or locations they are supplied from. Lack of context prevents practitioners from distinguishing transactional relations from established supply chain relations, hindering accurate estimations of risk. In this work, we develop a new Generative Artificial Intelligence (GenAI) enhanced machine learning framework that leverages pre-trained language models as embedding models combined with machine learning models to predict supply chain relationships within knowledge graphs. By integrating Generative AI techniques, our approach captures the nuanced semantic relationships between entities, thereby improving supply chain visibility and facilitating more precise risk management. Using data from a real case study, we show that GenAI-enhanced link prediction surpasses all benchmarks, and demonstrate how GenAI models can be explored and effectively used in supply chain risk management.', 'DOI': '10.1080/00207543.2025.2543964'}, {'id': 'secure_federated_learning', 'title': 'Secure Federated Learning for Cloud-Fog Automation: Vulnerabilities, Challenges, Solutions, and Future Directions', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10870877', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10870877'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Zhuangzhuang'}, {'family': 'Wu', 'given': 'Libing'}, {'family': 'Jin', 'given': 'Jiong'}, {'family': 'Wang', 'given': 'Enshu'}, {'family': 'Liu', 'given': 'Bingyi'}, {'family': 'Han', 'given': 'Qing-Long'}], 'abstract': 'With the intelligence and automation of industrial Internet of Things, a new collaborative Cloud-Fog Automation paradigm has emerged. The emergence of federated learning (FL) has further enhanced the capabilities of Cloud-Fog Automation, making it possible to develop more secure and versatile collaborative industrial models. However, FL faces various security risks. More importantly, the security risks faced by FL when applied in Cloud-Fog Automation, along with corresponding security measures, have not yet been explored. To address this issue, we make an initial attempt to analyze the security of FL within the context of Cloud-Fog Automation, with the aim of facilitating the design of a more secure FL framework for this paradigm. Specifically, we first analyze the security risks that may be encountered at different phases, then analyze the challenges that need to be faced to resolve these risks. Subsequently, we conduct a systematic review of the state-of-the-art security solutions, and finally summarize the future research directions.'}, {'id': 'integration_of_distributed', 'title': 'Integration of Distributed Technologies for Intelligent Food Quality and Safety Management: Blockchain, IoT, and Federated Learning', 'URL': 'https://www.tandfonline.com/doi/full/10.1080/87559129.2025.2517292', 'extra_urls': ['https://www.tandfonline.com/doi/full/10.1080/87559129.2025.2517292'], 'type': 'article', 'author': [{'family': 'Ding', 'given': 'Haohan'}, {'family': 'Cheng', 'given': 'Wenxu'}, {'family': 'Song', 'given': 'Xiaodong'}, {'family': 'Dong', 'given': 'Guanjun'}, {'family': 'Cui', 'given': 'Xiaohui'}, {'family': 'Yu', 'given': 'Wei'}, {'family': 'Wilson', 'given': 'David I.'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'from_trust_to', 'title': 'From trust to truth: Advancements in mitigating the Blockchain Oracle problem', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1084804523000917', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1084804523000917'], 'type': 'article', 'author': [{'family': 'Hassan', 'given': 'Ammar'}, {'family': 'Makhdoom', 'given': 'Imran'}, {'family': 'Iqbal', 'given': 'Waseem'}, {'family': 'Ahmad', 'given': 'Awais'}, {'family': 'Raza', 'given': 'Asad'}], 'abstract': 'Smart contracts gave a new dimension to Blockchain applications. Subsequently, Blockchains evolved from decentralized cryptocurrency ledgers to platforms for developing decentralized applications. A decentralized application needs a variety of data from the real world that cannot be directly provided by smart contracts. Oracles provide a mechanism to input data to the smart contracts for decentralized applications in a trusted manner. Oracles are the entities that collect data from data sources, verify it and then transmit it to the Blockchain. The introduction of Oracles has brought back the issues of centralization, single point of failure and reliance on a trusted third party in the Blockchain ecosystem. Oracles have adopted different means to reduce centralization and achieve some trustless operating mechanisms involving decentralized algorithms based on voting or reputation. In this paper, we analyse the concept of the Blockchain Oracle problem, its effects on various Blockchain applications, various Oracle types and trust mechanisms. We also analyse some of the significant Oracles (like chainlink, provable), and their underlying mechanisms and compare them. In the end, we carry out a gap analysis and discuss some open research issues that must be addressed to achieve robust and secure decentralization.'}, {'id': 'arxiv_2506.00274v1', 'title': 'Chances and Challenges of the Model Context Protocol in Digital Forensics and Incident Response', 'URL': 'https://arxiv.org/abs/2506.00274v1', 'extra_urls': ['https://arxiv.org/abs/2506.00274v1'], 'type': 'webpage', 'author': [{'family': 'Hilgert', 'given': 'Jan-Niclas'}, {'family': 'Jakobs', 'given': 'Carlo'}, {'family': 'K\xfclper', 'given': 'Michael'}, {'family': 'Lambertz', 'given': 'Martin'}, {'family': 'Mahr', 'given': 'Axel'}, {'family': 'Padilla', 'given': 'Elmar'}], 'abstract': 'Large language models hold considerable promise for supporting forensic investigations, but their widespread adoption is hindered by a lack of transparency, explainability, and reproducibility. This paper explores how the emerging Model Context Protocol can address these challenges and support the meaningful use of LLMs in digital forensics. Through a theoretical analysis, we examine how MCP can be integrated across various forensic scenarios - ranging from artifact analysis to the generation of interpretable reports. We also outline both technical and conceptual considerations for deploying an MCP server in forensic environments. Our analysis reveals a wide range of use cases in which MCP not only strengthens existing forensic workflows but also facilitates the application of LLMs to areas of forensics where their use was previously limited. Furthermore, we introduce the concept of the inference constraint level - a way of characterizing how specific MCP design choices can deliberately constrain model behavior, thereby enhancing both auditability and traceability. Our insights demonstrate that MCP has significant potential as a foundational component for developing LLM-assisted forensic workflows that are not only more transparent, reproducible, and legally defensible, but also represent a step toward increased automation in digital forensic analysis. However, we also highlight potential challenges that the adoption of MCP may pose for digital forensics in the future.'}, {'id': 'doi_10_1108_IJCST-01-2023-0002', 'title': 'A review of parametric clothing pattern CAD software methodology', 'URL': 'https://doi.org/10.1108/IJCST-01-2023-0002', 'extra_urls': ['https://doi.org/10.1108/IJCST-01-2023-0002'], 'type': 'article', 'author': [{'family': 'Lee', 'given': 'Ah Lam'}, {'family': 'Han', 'given': 'Hyunsook'}], 'abstract': 'The main issue in the mass customization of apparel products is how to efficiently produce products of various sizes. A parametric pattern-making system is one of the notable ways to rectify this issue, but there is a lack of information on the parametric design itself and its application to the apparel industry. This study compares and analyzes three types of parametric clothing pattern CAD (P-CAD) software currently in use to identify the characteristics of each, and suggest a basic guideline for efficient and adaptable P-CAD software in the apparel industry.This study compared three different types of P-CAD software with different characteristics: SuperALPHA: PLUS(as known as YUKA), GRAFIS and Seamly2D. The authors analyzed the types and management methodologies of each software, according to the three essential components that refer to previous studies about parametric design systems: entities, constraints and parameters.The results demonstrated the advantages and disadvantages of methodology in terms of three essential components of each software. Based on the results, the authors proposed five strategies for P-CAD development that can be applied to the mass customization of clothing.This study is meaningful in that it consolidates and organizes information about P-CAD software that has previously been scattered. The framework used in this study has an academic value suggesting guidelines to analyze P-CAD systems.', 'DOI': '10.1108/IJCST-01-2023-0002'}, {'id': 'virtual_evaluation_of', 'title': &quot;Virtual Evaluation of CLO 3D Auto-Grading Tool in Attaining the Fit of Women's Clothing with Complex Patterns&quot;, 'URL': 'https://journals.ekb.eg/article_432643.html', 'extra_urls': ['https://journals.ekb.eg/article_432643.html'], 'type': 'article', 'author': [{'family': 'Abdelazez Aborady', 'given': 'Asmaa G.'}, {'family': 'Al-Qatry', 'given': 'Doaa AQ'}], 'abstract': &quot;Grading is a crucial task for pattern makers, involving increasing or decreasing the original pattern according to body measurements to produce different sizes for clothing production. Computer grading systems have advanced significantly; CLO 3D is one such system that provides distinctive grading features, including auto-grading and edit grading, which improve industrial efficiency and productivity. The auto-grading technique creates new patterns in different sizes based on existing patterns, reducing errors and eliminating the necessity for manual grading. This study employs the auto-grading features of CLO 3D in grading complex patterns. Besides, it ensures that the various graded sizes fit and conform to the body. Furthermore, evaluate the fit of the graded patterns for each style on the 3D parametric virtual mannequin using the fit maps supplied by the CLO 3D program. The basic bodice block pattern was drafted and graded with the CLO 3D auto-grading tool, then the fit of the graded pattern was evaluated with fit maps on a 3D parametric virtual mannequin. Therefore, two complex women's styles were selected and drafted using the CLO 3D program with size XS. The auto-grading technique was applied to the style's patterns with the sizes (S-M-L). The graded pattern fit was then evaluated with fit maps on a 3D parametric virtual mannequin. The results indicate that the auto-grading tool within the CLO 3D program has proven highly effective in grading complex styles, considering virtual Evaluation using the fit maps method. This tool facilitates the automatic grading of such complex styles, achieving accurate and well-fitted outcomes.&quot;}, {'id': 'doi_10_1177_00405175251318243', 'title': 'Personalized digital human modeling in the customized clothing industry under Industry 5.0', 'URL': 'https://doi.org/10.1177/00405175251318243', 'extra_urls': ['https://doi.org/10.1177/00405175251318243'], 'type': 'article', 'author': [{'family': 'Yu', 'given': 'Jinjing'}, {'family': 'Shi', 'given': 'Hui'}, {'family': 'Duan', 'given': 'Wenjie'}], 'abstract': 'To accelerate transformation in the clothing industry under Industry 5.0, in this study, a digital human model of regional young men was investigated, using a linear regression model approach. A total of 263 young men, supported by a 3D body scanning system, were selected for the experimental sample. Body indicators guiding a reverse model of the upper body were chosen, with body features identified through descriptive analysis and principal component analysis. Subsequently, a personalized linear regression model could be statistically analyzed, and personalized inverse models could be visualized by designing the algorithm flow of the digital human modeling system in Grasshopper. The model can be changed in real time to fit the concept of the human digital twin. Meanwhile, hierarchical clustering and fast clustering methods were used in combination to establish representative body shapes for young men in the region, and clustering centers were used as validation samples to demonstrate that the prediction accuracy of this digital human model system was more than 80% for most body indicators, validating the feasibility and reliability of the digital human model, based on linear regression. This study offers technical support for regional digital human modeling, establishes a model foundation for research on human surface details, and supplies a data reference for tailored clothing patterns.', 'DOI': '10.1177/00405175251318243'}, {'id': 'doi_10_1080_1362704X_2021_1981657', 'title': 'Digital 3D Fashion Designers: Cases of Atacac and The Fabricant', 'URL': 'https://doi.org/10.1080/1362704X.2021.1981657', 'extra_urls': ['https://doi.org/10.1080/1362704X.2021.1981657'], 'type': 'article', 'author': [{'family': 'S\xe4rm\xe4kari', 'given': 'Natalia'}], 'abstract': 'The phenomenon of \u201cdigital fashion\u201d has been lately addressed in media as the next significant step in the fashion industry. The increasing use of the 3D-software in fashion design processes is part of a wider \u201cfashion 4.0\u201d digitalization process. This article frames the phenomenon of digital fashion and presents an in-depth case study research on two pioneering companies in this area, Atacac and The Fabricant. How and why are they building their fashion design practice on digital 3D-design? How are these companies redefining the fashion design culture and the fashion designer? Drawing from sociology of professions, this article proposes that digital fashion is an emerging subfield within the field of fashion design, differentiating itself from the professional conventions and building new strategies of jurisdiction and legitimation. Driven by sociotechnical affordances and elevation of professional pride through ethical, conceptual, artistic and skill differentiation, digital fashion designer becomes also a digital artisan. In the increasingly virtual, or \u201cphygital\u201d space and a networked synergetic community of digital fashion, the professional, authorial, bodily and material boundaries of designers become fluid, transforming the traditional figure of fashion designer.', 'DOI': '10.1080/1362704X.2021.1981657'}, {'id': 'doi_10_1108_IJCST-12-2021-0179', 'title': 'Developing a prediction model for improving bifurcated garment fit for mass customization', 'URL': 'https://dx.doi.org/10.1108/IJCST-12-2021-0179', 'extra_urls': ['https://dx.doi.org/10.1108/IJCST-12-2021-0179'], 'type': 'article', 'author': [{'family': 'Galada', 'given': 'Aditi'}, {'family': 'Baytar', 'given': 'Fatma'}], 'abstract': 'Purpose. The purpose of the present study was to improve the fit of women\u2019s bifurcated garments by developing an equation that can predict the crotch length accurately by using a few basic body measurements. This equation could provide a simple mass-customization approach to the design of bifurcated garments.Design/methodology/approach. Demographic characteristics and easy-to-record body measurements available in the size USA database were used to predict the crotch length. Different methodologies including best subset regression, lasso regression and principal components regression were experimented with to identify the most important predictor variables and establish a relationship between the significant predictors and crotch length.Findings. The lasso regression model provided the highest accuracy, required only five body dimensions and dealt with multicollinearity. The preliminary pattern preparation and garment fit tests indicated that by utilizing the proposed equation, patterns of customized garments could be successfully altered to match the crotch length of the customer, thereby, improving the precision and efficiency of the pattern making process.Originality/value. Crotch length is a crucial measurement as it determines bifurcated garment comfort as well as aesthetic fit. The crotch length is usually estimated arbitrarily based on non-scientific methods while drafting patterns, and this increases the likelihood of dissatisfaction with the fit of the lower-body garments. The present study suggested an algorithm that could predict crotch length with 90.53% accuracy using the body dimensions height, hips, waist height, knee height and arm length.', 'DOI': '10.1108/IJCST-12-2021-0179'}, {'id': 'doi_10_1177_00405175241289578', 'title': 'An intelligent generative method of fashion design combining attribute knowledge and Stable Diffusion Model', 'URL': 'https://doi.org/10.1177/00405175241289578', 'extra_urls': ['https://doi.org/10.1177/00405175241289578'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Yumiao'}, {'family': 'Ma', 'given': 'Jingyi'}], 'abstract': 'Artificial intelligence generation technology has brought new opportunities to the field of fashion design. Attribute knowledge has a significant impact on the overall effect of fashion design. Contemporary generative methods of fashion design frequently yield results lacking semantic information or missing specific attributes. To address the problem, this study aims for an intelligent generative method of fashion design through constructing prompt templates and a specific attribute low-rank adaption (LoRA) to combine fashion attribute knowledge into the generative process of the Stable Diffusion Model. First, a fashion attribute knowledge graph is constructed to establish prompt templates, and natural language descriptions are transformed into professional and complete prompt through GPT-4. Second, the fashion dataset is annotated with templates to filter specific attributes for LoRA training, followed by controlling fashion attributes in generation. Furthermore, analyses of the generation of women\u2019s jacket designs show that the proposed method consistently improves the accuracy and stability of attributes in fashion design generation.', 'DOI': '10.1177/00405175241289578'}, {'id': 'garment_pattern', 'title': 'Garment pattern definition, development and application with associative feature approach', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0166361510000199', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0166361510000199'], 'type': 'article', 'author': [{'family': 'Au', 'given': 'C. K.'}, {'family': 'Ma', 'given': 'Y. -S.'}], 'abstract': 'Garment virtual design has been evolved significantly with the rapid development of 3D CAD tools, especially with the convenient availability of NURBS surface modeling capability. Parametric development of clothes is demanded in line with the trend of mass customization according to the true measures of customers or regulated sizes of certain markets. Virtual design features with well-defined associations with the parametric mannequins are enablers. To achieve an intelligent mass customization approach, the development of surface patches from 3D clothing designs to 2D flattened patterns become essential. This article addresses the definition, development and application of garment features with an associative feature approach.'}, {'id': 'doi_10_1177_00405175241290436', 'title': 'Dynamic modeling of deformation in traditional smocking in apparel', 'URL': 'https://doi.org/10.1177/00405175241290436', 'extra_urls': ['https://doi.org/10.1177/00405175241290436'], 'type': 'article', 'author': [{'family': 'Zhao', 'given': 'Yu'}, {'family': 'Cheng', 'given': 'Yan'}, {'family': 'Zhou', 'given': 'Feng'}, {'family': 'Zhou', 'given': 'Li'}, {'family': 'Xiang', 'given': 'Yi'}], 'abstract': 'Traditional smocking, as a cultural heritage, has been widely employed in the design of modern apparel for its unique aesthetics. However, it often faces deformation when worn by a moving person, resulting in diminished aesthetics. The aim in this study is to detect the deformation threshold of a garment created with traditional smocking in a dynamic environment to assist in an aesthetic design. To reach this objective, first a 3D model was created of the cross-section of a garment with traditional smocking at the waistline, worn by a human avatar in a standing position. Then, by inputting the pressure triggered by level walking, ascending stairs, or twisting at the waist, finite-element models of the cross-sectional outlines were constructed to determine the displacements occurring on a garment with traditional smocking. The deformation threshold was determined afterwards, and validated. There are two contributions from this work: (1) the proposal of a deformation threshold for traditional smocking to assist in modern design, which generalizes an implication of promoting the aesthetics of heritage apparel in modern society; (2) the presentation of, it is believed, the first ever evaluation of the aesthetics of traditional smocking, which provides a new method to identify the interaction of pressure and displacement for traditional smocking in a dynamic environment.', 'DOI': '10.1177/00405175241290436'}, {'id': 'enriching_garments', 'title': 'Foldsketch: enriching garments with physically reproducible folds', 'URL': 'https://dl.acm.org/doi/10.1145/3197517.3201310', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3197517.3201310'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Minchen'}, {'family': 'Sheffer', 'given': 'Alla'}, {'family': 'Grinspun', 'given': 'Eitan'}, {'family': 'Vining', 'given': 'Nicholas'}], 'issued': {'date-parts': [[2018]]}, 'abstract': &quot;While folds and pleats add interest to garments and cloth objects, incorporating them into an existing design manually or using existing software requires expertise and time. We present FoldSketch, a new system that supports simple and intuitive fold and pleat design. FoldSketch users specify the fold or pleat configuration they seek using a simple schematic sketching interface; the system then algorithmically generates both the fold-enhanced 3D garment geometry that conforms to user specifications, and the corresponding 2D patterns that reproduce this geometry within a simulation engine. While previous work aspired to compute the desired patterns for a given target 3D garment geometry, our main algorithmic challenge is that we do not have target geometry to start with. Real-life garment folds have complex profile shapes, and their exact geometry and location on a garment are intricately linked to a range of physical factors such as fabric properties and the garment's interaction with the wearer's body; it is therefore virtually impossible to predict the 3D shape of a fold-enhanced garment using purely geometric means. At the same time, using physical simulation to model folds requires appropriate 2D patterns and initial drape, neither of which can be easily provided by the user. We obtain both the 3D fold-enhanced garment and its corresponding patterns and initial drape via an alternating 2D-3D algorithm. We first expand the input patterns by allocating excess material for the expected fold formation; we then use these patterns to produce an estimated fold-enhanced drape geometry that balances designer expectations against physical reproducibility. We use the patterns and the estimated drape as input to a simulation generating an initial reproducible output. We improve the output's alignment with designer expectations by progressively refining the patterns and the estimated drape, converging to a final fully physically reproducible fold-enhanced garment. Our experiments confirm that FoldSketch reliably converges to a desired garment geometry and corresponding patterns and drape, and works well with different physical simulators. We demonstrate the versatility of our approach by showcasing a collection of garments augmented with diverse fold and pleat layouts specified via the FoldSketch interface, and further validate our approach via comparisons to alternative solutions and feedback from potential users.&quot;}, {'id': 'garment_modeling_with', 'title': 'Garment modeling with a depth camera', 'URL': 'https://dl.acm.org/doi/10.1145/2816795.2818059', 'extra_urls': ['https://dl.acm.org/doi/10.1145/2816795.2818059'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Xiaowu'}, {'family': 'Zhou', 'given': 'Bin'}, {'family': 'Lu', 'given': 'Feixiang'}, {'family': 'Wang', 'given': 'Lin'}, {'family': 'Bi', 'given': 'Lang'}, {'family': 'Tan', 'given': 'Ping'}], 'issued': {'date-parts': [[2015]]}, 'abstract': 'Previous garment modeling techniques mainly focus on designing novel garments to dress up virtual characters. We study the modeling of real garments and develop a system that is intuitive to use even for novice users. Our system includes garment component detectors and design attribute classifiers learned from a manually labeled garment image database. In the modeling time, we scan the garment with a Kinect and build a rough shape by KinectFusion from the raw RGBD sequence. The detectors and classifiers will identify garment components (e.g. collar, sleeve, pockets, belt, and buttons) and their design attributes (e.g. falbala collar or lapel collar, hubble-bubble sleeve or straight sleeve) from the RGB images. Our system also contains a 3D deformable template database for garment components. Once the components and their designs are determined, we choose appropriate templates, stitch them together, and fit them to the initial garment mesh generated by KinectFusion. Experiments on various different garment styles consistently generate high quality results.'}, {'id': 'doi_10_1007_978-981-97-7528-6_7', 'title': 'The Advancement of Computer-Aided Design and Computer-Aided Manufacturing in the Fashion Apparel Industry: Toward a Sustainable Development', 'URL': 'https://doi.org/10.1007/978-981-97-7528-6_7', 'type': 'article', 'author': [{'family': 'Bui', 'given': 'Loan Thi Cam'}, {'family': 'Nguyen', 'given': 'Hang Thi Thu'}, {'family': 'Do', 'given': 'Luu Thanh'}, {'family': 'Huynh', 'given': 'Thuc Van'}, {'family': 'Ta', 'given': 'Thang Duc'}, {'family': 'Duong', 'given': 'An Thi Binh'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Springer Nature', 'abstract': 'The fashion apparel business has a transient nature regarding product lifecycles, which requires the adoption of adaptable production cycles to accommodate the constantly evolving customer preferences. The labour-intensive production and escalating sustainability concerns catalyse industrial advancements. The industrial landscape is undergoing significant transformations due to the implementation of industrial 4.0 technologies, specifically computer-aided design (CAD) and computer-aided manufacturing (CAM). CAD software facilitates the fabrication of intricate digital garment models, augmenting fashion designers\u2019 capabilities. The capacity to swiftly produce prototypes enables the investigation and execution of inventive concepts. Consequently, the design process becomes more efficient, leading to faster product launches. Moreover, CAD effectively incorporates CAM technologies, automating cutting and sewing operations. This serves to reduce errors and enhance manufacturing efficiency. The convergence of CAD and CAM technologies is fostering a more sustainable approach to apparel production. Firstly, CAD-CAM optimises material utilisation by enabling precise digital garment creation. This reduces fabric waste generated during the cutting process. Secondly, by automating production processes and minimising human error, CAD-CAM decreases overall production waste. Hence, the collective impact of these factors reduces the ecological impact in the context of garment production. Nevertheless, deploying CAD-CAM systems presents several challenges. One notable obstacle is the substantial initial capital commitment necessary for the acquisition of software, hardware, and complete people training initiatives. Additionally, the effective operation of these systems requires specialised knowledge, potentially aggravating pre-existing skill deficiencies within the business. Finally, ensuring seamless integration between CAD-CAM software suites is crucial to avoid data disruptions and workflow inefficiencies. Remarkably, CAD-CAM technologies are transforming fashion apparel manufacturing by increasing efficiency, elevating product quality, and fostering a more sustainable production method. As the industry embraces these groundbreaking advancements, finding a vital equilibrium between automation and the invaluable worth of human innovation is paramount.', 'DOI': '10.1007/978-981-97-7528-6_7'}, {'id': 'simulation', 'title': 'High-resolution fiber-level simulation of knitted patterns', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0010448525000740', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0010448525000740'], 'type': 'article', 'author': [{'family': 'Yang', 'given': 'Xin'}, {'family': 'Lu', 'given': 'Cheng'}, {'family': 'Shao', 'given': 'Huiqi'}, {'family': 'Shao', 'given': 'Guangwei'}, {'family': 'Jiang', 'given': 'Jinhua'}, {'family': 'Bi', 'given': 'Siyi'}, {'family': 'Chen', 'given': 'Nanliang'}], 'abstract': 'Knitted fabrics, characterized by intricate patterns, vibrant colors, and soft tactile properties, have long served as a source of inspiration in textile design. Leveraging digital technology to translate these design concepts into realistic models, this paper proposes a fiber-level 3D simulation framework for complex knitted structures, inspired by the digital element methodology. In this approach, yarns are discretized into fiber assemblies represented by sequences of control points. Improved beam elements connect adjacent points to model bending behavior, while rod elements simulate inter-fiber interactions. To improve structural controllability, dynamic boundary conditions and variable driving forces are introduced, enabling accurate capture of both global and local deformations. An efficient Array operation is developed to support scalable generation of fabric patterns under a modified periodic boundary condition. Experimental evaluations demonstrate that the proposed method achieves visually and structurally accurate simulations within a limited number of iterations. Comparative analysis with real fabric samples validates the effectiveness and fidelity of the simulation framework, making it suitable for applications in virtual textile design and performance prediction.'}, {'id': '3d_pattern', 'title': 'Goal-oriented 3D pattern adjustment with machine learning', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1524070325000190', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1524070325000190'], 'type': 'article', 'author': [{'family': 'Shastry', 'given': 'Megha'}, {'family': 'Fan', 'given': 'Ye'}, {'family': 'Martins', 'given': 'Clarissa'}, {'family': 'Pai', 'given': 'Dinesh K.'}], 'abstract': 'Fit and sizing of clothing are fundamental problems in the field of garment design, manufacture, and retail. Here we propose new computational methods for adjusting the fit of clothing on realistic models of the human body by interactively modifying desired fit attributes. Clothing fit represents the relationship between the body and the garment, and can be quantified using physical fit attributes such as ease and pressure on the body. However, the relationship between pattern geometry and such fit attributes is notoriously complex and nonlinear, requiring deep pattern making expertise to adjust patterns to achieve fit goals. Such attributes can be computed by physically based simulations, using soft avatars. Here we propose a method to learn the relationship between the fit attributes and the space of 2D pattern edits. We demonstrate our method via interactive tools that directly edit fit attributes in 3D and instantaneously predict the corresponding pattern adjustments. The approach has been tested with a range of garment types, and validated by comparing with physical prototypes. Our method introduces an alternative way to directly express fit adjustment goals, making pattern adjustment more broadly accessible. As an additional benefit, the proposed approach allows pattern adjustments to be systematized, enabling better communication and audit of decisions.'}, {'id': 'dress_anyone', 'title': 'Dress Anyone : Automatic Physically-Based Garment Pattern Refitting', 'URL': 'https://dl.acm.org/doi/10.1145/3747858', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3747858'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Hsiao-Yu'}, {'family': 'Larionov', 'given': 'Egor'}, {'family': 'Kavan', 'given': 'Ladislav'}, {'family': 'Lin', 'given': 'Gene'}, {'family': 'Roble', 'given': 'Doug'}, {'family': 'Sorkine-Hornung', 'given': 'Olga'}, {'family': 'Stuyck', 'given': 'Tuur'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Well-fitted clothing is essential for both real and virtual garments to enable self-expression and accurate representation for a large variety of body types. Common practice in the industry is to provide a pre-made selection of distinct garment sizes such as small, medium and large. While these may cater to certain groups of individuals that fall within this distribution, they often exclude large sections of the population. In contrast, individually tailored clothing offers a solution to obtain custom-fit garments that are tailored to each individual. However, manual tailoring is time-consuming and requires specialized knowledge, prohibiting the approach from being applied to produce fitted clothing at scale. To address this challenge, we propose a novel method leveraging differentiable simulation for refitting and draping 3D garments and their corresponding 2D pattern panels onto a new body shape. This enables a workflow where garments only need to be designed once, in a single size, and they can be automatically refitted to support numerous body size and shape variations. Our method enables downstream applications, where our optimized 3D drape can be directly ingested into game engines or other applications. Our 2D sewing patterns allow for accurate physics-based simulations and enables manufacturing clothing for the real world.'}, {'id': 'reconstructing_sewing', 'title': 'NeuralTailor: reconstructing sewing pattern structures from 3D point clouds of garments', 'URL': 'https://dl.acm.org/doi/10.1145/3528223.3530179', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3528223.3530179'], 'type': 'article', 'author': [{'family': 'Korosteleva', 'given': 'Maria'}, {'family': 'Lee', 'given': 'Sung-Hee'}], 'issued': {'date-parts': [[2022]]}, 'abstract': 'The fields of SocialVR, performance capture, and virtual try-on are often faced with a need to faithfully reproduce real garments in the virtual world. One critical task is the disentanglement of the intrinsic garment shape from deformations due to fabric properties, physical forces, and contact with the body. We propose to use a garment sewing pattern, a realistic and compact garment descriptor, to facilitate the intrinsic garment shape estimation. Another major challenge is a high diversity of shapes and designs in the domain. The most common approach for Deep Learning on 3D garments is to build specialized models for individual garments or garment types. We argue that building a unified model for various garment designs has the benefit of generalization to novel garment types, hence covering a larger design domain than individual models would. We introduce NeuralTailor, a novel architecture based on point-level attention for set regression with variable cardinality, and apply it to the task of reconstructing 2D garment sewing patterns from the 3D point cloud garment models. Our experiments show that NeuralTailor successfully reconstructs sewing patterns and generalizes to garment types with pattern topologies unseen during training.'}, {'id': 'a_neural_rendering', 'title': 'A Neural Rendering system for fashion design process', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0952197625007730', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0952197625007730'], 'type': 'article', 'author': [{'family': 'Balloni', 'given': 'Emanuele'}, {'family': 'Stacchio', 'given': 'Lorenzo'}, {'family': 'Mancini', 'given': 'Adriano'}, {'family': 'Frontoni', 'given': 'Emanuele'}, {'family': 'Zingaretti', 'given': 'Primo'}, {'family': 'Paolanti', 'given': 'Marina'}], 'abstract': 'The translation of images into detailed three-dimensional (3D) models represents a critical challenge in digital content creation, particularly for the Creative Industries (CI). Traditional 3D modeling methods are resource-intensive, while recent advances in Neural Rendering (NR) have introduced efficient and automated solutions. In the fashion industry, where visual fidelity and rapid prototyping are crucial, NR techniques such as Neural Radiance Fields (NeRFs) and 3D Gaussian Splatting (3DGS) are becoming relevant resources to digitize complex geometries and textures with a low-cost approach, enabling different applications like virtual fitting rooms, immersive e-commerce, and digital prototyping. However, the evaluation of their effectiveness in this field is still in its early phases. To address the industry\u2019s needs, we propose Fashion immersive Neural Rendering Interface (FENRI), a novel framework that integrates NR techniques for reconstructing 3D models from 2D images of fashion items. FENRI includes a WebXR-based visualization platform that allows immersive comparison and evaluation of NR-generated 3D models, supporting both experts and non-experts in selecting optimal designs. We applied FENRI to footwear design, collecting a novel dataset to compare NeRF and 3DGS methods through quantitative and qualitative analyses. In our study, the 3DGS method demonstrated superior performance over NeRF, as highlighted by the higher Peak Signal-to-Noise Ratio (PSNR) values (37.65 vs. 29.03, respectively) and Structural Similarity Index Measure (SSIM) scores (0.99 vs 0.96), while exhibiting a lower Learned Perceptual Image Patch Similarity (LPIPS) values (0.01 vs 0.04). Moreover, we showed that, by applying classical mesh post-processing techniques, we can increase the topological and visual quality of the 3D models synthesized by NR methods. These findings highlight the potential of NR techniques in the fashion industry\u2019s digital pipeline. By enabling rapid, immersive, and visually compelling design iterations, FENRI offers a scalable solution to the fashion industry\u2019s demand for high-quality 3D reconstructions, promoting innovation and sustainability.'}, {'id': 'leveraging_fashion', 'title': 'Leveraging Fashion E-commerce Data and Computer Graphics Toward Automated Pattern Making for Pants: A Preliminary Study', 'URL': 'https://www.iastatedigitalpress.com/itaa/article/id/17912/', 'extra_urls': ['https://www.iastatedigitalpress.com/itaa/article/id/17912/'], 'type': 'article', 'author': [{'family': 'Kong', 'given': 'Doyeon'}, {'family': 'Baytar', 'given': 'Fatma'}], 'abstract': 'Ergonomic pattern-making, based on anthropometric measurements, is essential to ensuring fit and comfort but faces challenges including cost and privacy issues. This study explores an economical way of creating patterns for pants by leveraging computer graphics and fashion e-commerce data, such as model and garment sizes, which are readily available online. In this study, 100% cotton denim jeans were selected as sample pants. Computer graphics algorithms were applied to an image of a pair of jeans to automatically detect edges from the image and generate pants patterns by calculating key measurements, such as the waist, hip, crotch, and leg openings. For evaluation, the same pair of jeans was purchased and the patterns were manually traced and digitized into Optitex PDS v.21. The resulting patterns were compared with the algorithm-generated pattern and evaluated using Clo3D v.7. The hip measurements showed the biggest difference between the two patterns, where the algorithm-generated pattern had crooked side seams. In addition, the horizontal lines (e.g., the hip and leg openings) appeared more distorted because those parts were photographed closer to the lens and displayed larger than the vertical lines. While some aspects of geometric distortion in imagery could be improved, this study presented a new method for generating patterns for jeans by synthesizing publicly available e-commerce data and computer graphics. Future studies on deep learning-based models, such as segmentation, could allow for the extraction of more precise edge points for use as critical measurement points.'}, {'id': 'doi_10_1186_s40691-025-00417-y', 'title': 'Developing an instrument with simulations to measure 3D to 2D fit correction skills in fashion design', 'URL': 'https://doi.org/10.1186/s40691-025-00417-y', 'extra_urls': ['https://doi.org/10.1186/s40691-025-00417-y'], 'type': 'article', 'author': [{'family': 'Galada', 'given': 'Aditi'}, {'family': 'Baytar', 'given': 'Fatma'}], 'abstract': &quot;In fashion design education, students are taught how to prepare 2D patterns to create 3D garments through flat pattern making and draping courses. However, there is a lack of focus on garment fitting, and students are expected to have a natural intuition regarding fit corrections. As a result, most students graduate without gaining the crucial skill of reading misfit signs in 3D and acting on correcting 2D patterns accordingly. For this reason, in the current study, we developed a novel skill test instrument based on the Extended Skill Cycle Model using 3D simulations to quantify students' fit correction skills. We evaluated the instrument\u2019s reliability and validity for its suitability in teaching and research applications. Fit correction questions with virtual garment simulations were designed, and participants were provided with three potential pattern modification options, out of which one option corrected garment fit. The reliability of the questionnaire was determined using Cronbach\u2019s alpha, and validity was analyzed by comparing pre- and post-training scores, comparing scores of participants with different levels of experience, and calculating the item difficulty and discrimination index. There was a positive correlation between the pre- and posttraining test scores, confirming that the instrument could measure the increase in skill level. In addition, the pre-training scores of participants at the very minimum patternmaking experience level were lower than those of participants with higher experience levels. Therefore, our instrument could be used in patternmaking courses in fashion design education to measure student skill development.&quot;, 'DOI': '10.1186/s40691-025-00417-y'}, {'id': 'fabricable_discretized_ruled', 'title': 'Fabricable Discretized Ruled Surfaces', 'URL': 'https://dl.acm.org/doi/10.1145/3734519', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3734519'], 'type': 'article', 'author': [{'family': 'Baharami', 'given': 'Hassan'}, {'family': 'Piovarci', 'given': 'Michal'}, {'family': 'Tarini', 'given': 'Marco'}, {'family': 'Bickel', 'given': 'Bernd'}, {'family': 'Pietroni', 'given': 'Nico'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'We present a method to automatically approximate a given surface with a small set of patches, each being a developable ruled surface featuring long-ruling lines. These construction primitives are attractive for their inherent ease of fabrication by cutting and folding inextensible materials and for their favo rable structural properties. Our algorithm strikes a good tradeoff between the simplicity of produced designs (in terms of the number and shapes of the patches) and approximation quality. To this end, it is guided by a smooth curvature-aligned cross-field.Compared to traditional methods, we rely on final discretization steps to ensure the developability of the ruled surfaces and produce a fabricable layout, bypassing the need to enforce that the strips are strictly developable in continuous settings (which requires difficulty in enforcing geometric conditions). We demonstrate the effectiveness of the proposed algorithm by producing several viable designs and using them to physically fabricate various physical objects.'}, {'id': 'complex_surface_fabrication', 'title': 'Complex Surface Fabrication Via Developable Surface Approximation: A Survey', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10870379', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10870379'], 'type': 'article', 'author': [{'family': 'Yuan', 'given': 'Chao'}, {'family': 'Cao', 'given': 'Nan'}, {'family': 'Shi', 'given': 'Yang'}], 'abstract': 'Complex surfaces are commonly observed in various applications and have significant value in enhancing comfort, aesthetics, and functionality. However, their fabrication often involves complex and costly processes. To simplify the fabrication difficulty, significant research has focused on using 3D developable surfaces to approximate target 3D surfaces. This process involves converting target 3D surfaces into developable surfaces and then flattening them into 2D patterns. Since the geometric and topological diversity of target surfaces, this task is both comprehensive and intricate, encompassing multiple aspects from design to fabrication. In this paper, we review relevant technologies and methods in fabrication processes, classify them, and summarize a pipeline from design to fabrication. This provides a comprehensive introduction to the field for researchers and practitioners. Through the analysis of relevant literature, we also discuss some of the research challenges and future research opportunities.'}, {'id': 'doi_10_1177_0887302X241311027', 'title': 'Drivers and Enablers of Digital Readiness in the Fashion Industry: A Systematic Literature Review', 'URL': 'https://doi.org/10.1177/0887302X241311027', 'extra_urls': ['https://doi.org/10.1177/0887302X241311027'], 'type': 'article', 'author': [{'family': 'Sun', 'given': 'Xun (Catherine)'}, {'family': 'Ha-Brookshire', 'given': 'Jung E.'}], 'abstract': &quot;The fashion industry is undertaking transformative changes driven by various digital technologies. However, these changes present challenges, ranging from employee resistance to slow organizational response to digital change, leading to a high rate of failure in digital transformations. Guided by the change readiness theory and Porter's Diamond Model, this study aims to conceptualize fashion digital readiness and systematically understand digital readiness in fashion business organizations, endeavoring to uncover the crucial drivers and enablers from a practical business perspective. Through a systematic review method, 64 peer-reviewed articles from Google Scholar reveals 5 clusters on the current state of literature, identifies 6 main drivers and 21 main enablers, and proposes the Fashion Digital Readiness\u2014Drivers and Enablers (FDR-D, E) framework. The study expands on the advancements in change readiness theory into fashion digital readiness, provides insights into the propositions, theoretical and practical implications, and highlights further research avenues.&quot;, 'DOI': '10.1177/0887302X241311027'}, {'id': 'doi_10_1080_17543266_2024_2413568', 'title': '3D digital technology in upcycling apparel design: the creation of a modular redesign system and designer perspectives', 'URL': 'https://doi.org/10.1080/17543266.2024.2413568', 'extra_urls': ['https://doi.org/10.1080/17543266.2024.2413568'], 'type': 'article', 'author': [{'family': 'Choi', 'given': 'Kyung-Hee'}], 'abstract': 'Despite advancements in sustainable apparel design, upcycling practices still face challenges limiting creativity and efficiency. This study develops a Modular Redesign System (MRS) using 3D digital technology to improve the upcycling process. The MRS was created with CLO3D and Aftereffects, producing ten redesign samples and demonstration videos. In-depth interviews with South Korean upcycling apparel designers were conducted to assess the system\u2019s perceived effectiveness and explore key issues in upcycling design. The MRS involves four stages: Selection, Virtualisation, Virtual Ideation, and Construction and Fitting. Findings highlight the MRS\u2019s ability to enhance ideation, reduce material waste, and save time and costs, offering practical solutions to current challenges in apparel redesign. The MRS also shows potential for mass customisation, serving as an effective communication tool for personalised upcycling services. This study bridges a gap in the literature by integrating 3D virtual simulation with modular design to advance sustainable and efficient upcycling practices.', 'DOI': '10.1080/17543266.2024.2413568'}, {'id': 'doi_10_1108_EJIM-03-2023-0223', 'title': 'Business model innovation of 3D-printing garment enterprises in digital transformation: business model innovation canvas approach', 'URL': 'https://doi.org/10.1108/EJIM-03-2023-0223', 'extra_urls': ['https://doi.org/10.1108/EJIM-03-2023-0223'], 'type': 'article', 'author': [{'family': 'Jin', 'given': 'Yuran'}, {'family': 'Zhu', 'given': 'Xiaolin'}, {'family': 'Zhang', 'given': 'Xiaoxu'}, {'family': 'Wang', 'given': 'Hui'}, {'family': 'Liu', 'given': 'Xiaoqin'}], 'abstract': '3D printing has been warmly welcomed by clothing enterprises for its customization capacity in recent years. However, such clothing enterprises have to face the digital transformation challenges brought by 3D printing. Since the business model is a competitive weapon for modern enterprises, there is a research gap between business model innovation and digital transformation challenges for 3D-printing garment enterprises. The aim of the paper is to innovate a new business model for 3D-printing garment enterprises in digital transformation.A business model innovation canvas (BMIC), a new method for business model innovation, is used to innovate a new 3D-printing clothing enterprises business model in the context of digital transformation. The business model canvas (BMC) method is adopted to illustrate the new business model. The business model ecosystem is used to design the operating architecture and mechanism of the new business model.First, 3D-printing clothing enterprises are facing digital transformation, and they urgently need to innovate new business models. Second, mass customization and distributed manufacturing are important ways of solving the business model problems faced by 3D-printing clothing enterprises in the process of digital transformation. Third, BMIC has proven to be an effective tool for business model innovation.The new mass deep customization-distributed manufacturing (MDC-DM) business model is universal. As such, it can provide an important theoretical reference for other scholars to study similar problems. The digital transformation background is taken into account in the process of business model innovation. Therefore, this is the first hybrid research that has been focused on 3D printing, garment enterprises, digital transformation and business model innovation. On the other hand, business model innovation is a type of exploratory research, which means that the MDC-DM business model\u2019s application effect cannot be immediately observed and requires further verification in the future.The new business model MDC-DM is not only applicable to 3D-printing garment enterprises but also to some other enterprises that are either using or will use 3D printing to enhance their core competitiveness.A new business model, MDC-DM, is created through BMIC, which allows 3D-printing garment enterprises to meet the challenges of digital transformation. In addition, the original canvas of the MDC-DM business model is designed using BMC. Moreover, the ecosystem of the MDC-DM business model is constructed, and its operation mechanisms are comprehensively designed.', 'DOI': '10.1108/EJIM-03-2023-0223'}, {'id': 'is_the_digitalisation', 'title': 'Is the digitalisation the future of the luxury industry?', 'URL': 'https://www.cell.com/heliyon/abstract/S2405-8440(24)16060-4', 'extra_urls': ['https://www.cell.com/heliyon/abstract/S2405-8440(24)16060-4'], 'type': 'article', 'author': [{'family': 'Sanz-Lopez', 'given': 'Francisco'}, {'family': 'Gallego-Losada', 'given': 'Roc\xedo'}, {'family': 'Montero-Navarro', 'given': 'Antonio'}, {'family': 'Garc\xeda-Abajo', 'given': 'Elisa'}]}, {'id': 'doi_10_1108_JFMM-09-2024-0380', 'title': 'Mapping the digital transformation in the fashion industry: the past, present and future', 'URL': 'https://doi.org/10.1108/JFMM-09-2024-0380', 'extra_urls': ['https://doi.org/10.1108/JFMM-09-2024-0380'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Sujun'}, {'family': 'Liu', 'given': 'Chuanlan'}], 'abstract': 'Fashion Industry Digital Transformation (FIDT) is critical for fostering a more informed, adaptive, technologically advanced and sustainable industry. There is a gap in up-to-date reviews regarding the fast-evolving application of digital technology in the fashion industry. This study provides an extensive and up-to-date examination of the current literature and proposes future research directions in FIDT.A systematic review was conducted using bibliometric and thematic analyses of 224 peer-reviewed journal articles published between 2011 and 2024. Seminal works predating 2011 were also reviewed to answer research questions and establish a foundational context for FIDT research.The review identified growing global interest in digital innovations, particularly in sustainability. Analysis revealed three intellectual clusters and six thematic keyword clusters, underscoring focal areas such as sustainability, AI-enhanced luxury experiences and consumer engagement in digital retail. Key challenges, including technological barriers and data security concerns, were also mapped alongside future research priorities.This study presents a comprehensive analysis of FIDT to date, offering a structured research agenda to guide future investigations. Insights provided can support stakeholders in leveraging digital transformation to foster innovation, enhance consumer experiences and promote sustainability in the fashion industry.', 'DOI': '10.1108/JFMM-09-2024-0380'}, {'id': 'collaboration_in', 'title': 'Human-AI Collaboration in the Fashion Design Process', 'URL': 'https://ojs.aaai.org/index.php/AAAI-SS/article/view/35573', 'extra_urls': ['https://ojs.aaai.org/index.php/AAAI-SS/article/view/35573'], 'type': 'article', 'author': [{'family': 'Tocchetti', 'given': 'Andrea'}, {'family': 'Monterosso', 'given': 'Giulia'}, {'family': 'Romualdi', 'given': 'Francesca Palazzetti'}, {'family': 'Bertola', 'given': 'Paola'}, {'family': 'Brambilla', 'given': 'Marco'}, {'family': 'Vandi', 'given': 'Angelica'}, {'family': 'Vacca', 'given': 'Federica'}], 'abstract': &quot;The recent development of Generative AI (GenAI) revolutionized the fashion industry, automating tasks like market analysis and trend forecasting, as well as innovating cloth design. However, its potential application in supporting designers in the fashion design process for creativity purposes has yet to be explored. Our research studied the complexity and pitfalls of such a process through interviews with domain experts. Starting from that assessment, this article compares generic and context-specific GenAI tools from several perspectives to explore their features and capabilities in enhancing the cooperation between fashion designers and AI tools and agents in the creative process. The most promising systems are tested on typical creative tasks, including generating images from textual descriptions (specified according to technical criteria), generating variations of existing designs and pictures, and generating photographic images from sketches. The experiments involved two data sets and five domain-specific tasks. The effectiveness and limitations of the tools are evaluated quantitatively to assess how they can properly support the designers' work.&quot;}, {'id': 'generative_ai_in', 'title': 'Generative AI in Fashion: Overview', 'URL': 'https://dl.acm.org/doi/10.1145/3718098', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3718098'], 'type': 'article', 'author': [{'family': 'Shi', 'given': 'Wenda'}, {'family': 'Wong', 'given': 'Waikeung'}, {'family': 'Zou', 'given': 'Xingxing'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Generative Artificial Intelligence (GenAI) has recently gained immense popularity by offering various applications for generating high-quality and aesthetically pleasing content of image, 3D, and video data format. The innovative GenAI solutions have shifted paradigms across various design-related industries, particularly fashion. In this article, we explore the incorporation of GenAI into fashion-related tasks and applications. Our examination encompasses a thorough review of more than 470 research papers and an in-depth analysis of over 300 applications, focusing on their contributions to the field. These contributions are identified as 13 tasks within four categories: multi-modal fashion understanding, and fashion synthesis of image, 3D, and dynamic (video and animatable 3D) formats We delve into these methods, recognizing their potential to propel future endeavors toward achieving state-of-the-art performance. Furthermore, we present a comprehensive overview of 53 publicly available datasets suitable for training and benchmarking fashion-centric models, accompanied by the relevant evaluation metrics. Finally, we review real-world applications, unveiling existing challenges and future directions. With comprehensive investigation and in-depth analysis, this article is targeted to serve as a useful resource for understanding the current landscape of GenAI in fashion, paving the way for future innovations in this dynamic field. Papers discussed in this article, along with public code and datasets links are available at: .'}, {'id': 'sustainable_digital_fashion', 'title': 'Sustainable digital fashion in a metaverse ecosystem', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0969698924003953', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0969698924003953'], 'type': 'article', 'author': [{'family': 'Xin', 'given': 'Baogui'}, {'family': 'Song', 'given': 'Yaping'}, {'family': 'Tan', 'given': 'Hui'}, {'family': 'Peng', 'given': 'Wei'}], 'abstract': &quot;The fashion industry ranks among the top polluters globally, yet the emergence of virtual worlds offers a chance for brands to switch to digital clothing as a greener option. This research explores whether the metaverse can enhance sustainability in fashion or worsen environmental issues, especially those linked to non-fungible tokens (NFTs). We introduce a game theory model to analyze the strategic dynamics between brand manufacturers and digital fashion platforms, factoring in platforms' abilities to reduce emissions. The model uncovers how these uncertainties influence pricing, investment, and performance outcomes. Our analysis is supported by a case study on DressX, a prominent digital fashion platform, showing that digital fashion brings technological innovation and environmental advantages. Platforms with greater emission reduction capacities and their collaborators witness increased revenues. However, information asymmetry complicates strategic decision-making, and the environmental implications of digital technologies underpinning the metaverse remain a critical concern. Platforms with advanced capabilities gain a competitive edge by managing costs effectively, whereas manufacturers profit at the platforms' expense. However, there is a strategic equilibrium that benefits both sides. Our study indicates that maximizing the environmental benefits of digital fashion demands responsible actions from all stakeholders, including careful technology selection, clear communication of capabilities, cost management, and strategic cooperation. Our game theory approach, combined with a real-world case study, provides a unique perspective on the strategic and environmental dynamics of digital fashion in the metaverse, contributing to the growing body of literature on sustainable fashion and digital ecosystems.&quot;}, {'id': 'doi_10_1108_APJML-11-2022-0945', 'title': 'The perceived value of digital fashion product and purchase intention: the mediating role of the flow experience in\xa0metaverse platforms', 'URL': 'https://doi.org/10.1108/APJML-11-2022-0945', 'extra_urls': ['https://doi.org/10.1108/APJML-11-2022-0945'], 'type': 'article', 'author': [{'family': 'Park', 'given': 'Yeonseo'}, {'family': 'Ko', 'given': 'Eunju'}, {'family': 'Do', 'given': 'Boram'}], 'abstract': &quot;This paper aims to explore digital fashion products in the metaverse platform contexts and empirically examine the effect of the metaverse platform characteristics on the purchase intention of digital fashion products through users' flow experience and perceived value of the products.A survey method was used in this study. Answers from 314 metaverse users were analyzed, and the hypotheses were tested using the structural equations modeling and bootstrapping analysis.The analyses showed that telepresence, social interaction and economic flow had significant effects on users' flow experience among the metaverse platform characteristics, while the continuity and content creation of the metaverse platform did not have significant effects. The flow experience also appeared to have significant effects on multiple consumption values, including pleasure value, self-expression value and economic value. Last, the perceived pleasure value and economic value of digital fashion products had a positive effect on purchase intention.The main contribution of this research is that it is one of the first empirical attempts to investigate individual consumers' perceptions and experiences of digital fashion products in the context of metaverse platforms.&quot;, 'DOI': '10.1108/APJML-11-2022-0945'}, {'id': 'doi_10_1080_20932685_2023_2251033', 'title': 'The adoption of digital fashion as an end product: A systematic literature review of research foci and future research agenda', 'URL': 'https://doi.org/10.1080/20932685.2023.2251033', 'extra_urls': ['https://doi.org/10.1080/20932685.2023.2251033'], 'type': 'article', 'author': [{'family': 'Chan', 'given': 'Hazel Hoi Yau'}, {'family': 'Henninger', 'given': 'Claudia'}, {'family': 'Boardman', 'given': 'Rosy'}, {'family': 'Blazquez Cano', 'given': 'Marta'}], 'abstract': 'With the advancement of 3D design software, \u201cdigital fashion\u201d has evolved from a retail and design tool for physical fashion to a virtual-only end-product sold to consumers in wholly digital form. As many brands are now developing digital fashion end products as a new revenue stream, given its potential to reduce some levels of overconsumption of physical clothing, it warrants academic attention. However, the literature has predominantly defined digital fashion as a tool rather than an end-product, resulting in an incomplete definition of digital fashion. This hinders scholars\u2019 ability to fully comprehend and explore this emerging product category. This article aims to synthesize the current marketing/management literature on digital fashion and investigate the theories, context, characteristics, and methodology of digital fashion as an end-product. This study contributes to the literature by providing a comprehensive industry-accepted definition of digital fashion within a conceptual framework, categorizing six different types of digital fashion end-products, and establishing a future research agenda that will lead to new research streams.', 'DOI': '10.1080/20932685.2023.2251033'}, {'id': 'defining_digital', 'title': 'Defining digital fashion: Reshaping the field via a systematic review', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0747563222002291', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0747563222002291'], 'type': 'article', 'author': [{'family': 'Baek', 'given': 'Eunsoo'}, {'family': 'Haines', 'given': 'Shelley'}, {'family': 'Fares', 'given': 'Omar H.'}, {'family': 'Huang', 'given': 'Zhihong'}, {'family': 'Hong', 'given': 'Yuwei'}, {'family': 'Lee', 'given': 'Seung Hwan Mark'}], 'abstract': &quot;The field of digital fashion is rapidly evolving, yet what constitutes digital fashion, and how it should be defined has not been firmly established. This study aims to conceptualize and define digital fashion and its components (themes). Applying an inductive approach, we initially identified 10 keywords linked to digital fashion via a Twitter analysis. Then, a systematic literature review was conducted (n\xa0=\xa0116 articles). Six themes related to digital fashion were identified: design, consumer, virtual, body, printing, and supply. Themes include topics relating to the advancement of digital technologies in the fashion design process, innovation to enhance consumer experiences, and improvements to the value chain. Inspired by the six themes, we define digital fashion as \u201cthe virtual creation, production, and representation of one's identity via computer-generated design.\u201d An overview of each theme and its contribution to the field of digital fashion is discussed. Future research developments to extend this domain are considered.&quot;}, {'id': 'unlocking_the_potential', 'title': 'Unlocking the Potential of Artificial Intelligence in Fashion Design and E-Commerce Applications: The Case of Midjourney', 'URL': 'https://www.mdpi.com/0718-1876/19/1/35', 'extra_urls': ['https://www.mdpi.com/0718-1876/19/1/35'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Yanbo'}, {'family': 'Liu', 'given': 'Chuanlan'}], 'abstract': 'The fashion industry has shown increasing interest in applying artificial intelligence (AI), yet there is a significant gap in exploring the potential of emerging diffusion-modeling-based AI image-generation systems for fashion design and commerce. Therefore, this study aims to assess the effectiveness of Midjourney, one such AI system, in both fashion design and related commerce applications. We employed the action research approach with the Functional, Expressive, and Aesthetic (FEA) Consumer Needs Model as the theoretical framework. Our research comprised three stages: refining an initial idea into well-defined textual design concepts, facilitating concept development, and validating the preceding observations and reflections by creating a new line of hemp-based products that were evaluated by targeted consumers through an online survey. Findings reveal that this AI tool can assist fashion designers in creating both visually expressive attire and ready-to-wear products, meeting defined design criteria and consumer needs. Midjourney shows promise in streamlining the fashion design process by enhancing ideation and optimizing design details. Potential e-commercial applications of such AI systems were proposed, benefiting physical and digital fashion businesses. It is noted that, to date, the major limitations of using Midjourney encompass its restriction to only facilitating early fashion design stages and necessitating substantial involvement from designers.'}, {'id': 'doi_10_1080_15487733_2022_2125640', 'title': 'Exploring the nature of digital transformation in the fashion industry: opportunities for supply chains, business models, and sustainability-oriented innovations', 'URL': 'https://doi.org/10.1080/15487733.2022.2125640', 'extra_urls': ['https://doi.org/10.1080/15487733.2022.2125640'], 'type': 'article', 'author': [{'family': 'Casciani', 'given': 'Daria'}, {'family': 'Chkanikova', 'given': 'Olga'}, {'family': 'Pal', 'given': 'Rudrajeet'}], 'abstract': 'This article provides a comprehensive overview of the digital transformation of the fashion industry and describes the opportunities and influences on supply chains, business models, and sustainability-oriented innovations that it offers. Desk research was performed to review emerging cases of companies that engage actively in using 3-dimensional virtual and digital (3DVD) technologies, such as 3D modeling, virtual and augmented reality (VR and AR), 2- and 3-dimensional (2D/3D) scanning, and digital twinning (DT). The analysis shows how the adoption of digital technologies provides opportunities to dematerialize the traditional fashion supply-chain model of garment production and distribution and maps the innovative shifts occurring in the fashion industry\u2019s processes, products, and services. The adoption of 3DVD technologies by fashion companies unleashes new opportunities with respect to innovation in products/services and optimization of operational processes to streamline activities, shorten the lead time for designing, prototyping, manufacturing, marketing and retailing, and reorganizing the working phases. These capabilities also drive multicentred business-model innovations and thus affect value creation and delivery and capture changes. In addition, the analysis shows that digital transformation affects the four dimensions of sustainability that are interconnected intrinsically across supply-chain processes. Cultural sustainability is paramount, as fashion is a complex cultural system that is able to create products/services that influence the environment, economy, and society. In particular, 3DVD technologies promote cultural transformation of design processes to achieve a remix of skills and open knowledge, a behavioral shift from the consumer perspective in terms of diversity and self-expression, and a change in the organizational culture of companies that drive the digital transformation.', 'DOI': '10.1080/15487733.2022.2125640'}, {'id': 'doi_10_1108_JFMM-10-2017-0114', 'title': '3D technology in fashion: from concept to consumer', 'URL': 'https://doi.org/10.1108/JFMM-10-2017-0114', 'extra_urls': ['https://doi.org/10.1108/JFMM-10-2017-0114'], 'type': 'article', 'author': [{'family': 'Arribas', 'given': 'Veronica'}, {'family': 'Alfaro', 'given': 'Jos\xe9 A.'}], 'abstract': 'The purpose of this paper is to show how 3D digital technology can bring value to the fashion industry by analysing the specific benefits it offers along the value chain. Additionally, the authors show some of the challenges ahead identified for both software and fashion firms.The authors present by means of a case study the experience of an haute couture designer who used 3D digital technology \u2013 in collaboration with a recognised 3D software company \u2013 for developing his first luxury footwear collection.The enhancement of creativity and a better communication with suppliers are just some of the benefits identified in the case study from the use of 3D digital technology. In addition, challenges such as the development of a digital culture or the need for technology simplification are drawn from the case.Apart from the benefits and challenges drawn from the case study, which can be useful to practitioners in this industry, the authors also identify the collaboration through which the experience took place as an interesting practice to implement as a previous step of a digital transformation strategy.Despite the growing interest the fashion industry is showing in the use of new digital technologies, academic research on this topic is still scarce. Therefore, the case study presented in this paper adds value to the literature showing how 3D technology can help fashion from concept to consumer.', 'DOI': '10.1108/JFMM-10-2017-0114'}, {'id': 'parametric_cad', 'title': 'Parametric CAD modeling: An analysis of strategies for design reusability', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0010448516000051', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0010448516000051'], 'type': 'article', 'author': [{'family': 'Camba', 'given': 'Jorge D.'}, {'family': 'Contero', 'given': 'Manuel'}, {'family': 'Company', 'given': 'Pedro'}], 'abstract': 'CAD model quality in parametric design scenarios largely determines the level of flexibility and adaptability of a 3D model (how easy it is to alter the geometry) as well as its reusability (the ability to use existing geometry in other contexts and applications). In the context of mechanical CAD systems, the nature of the feature-based parametric modeling paradigm, which is based on parent\u2013child interdependencies between features, allows a wide selection of approaches for creating a specific model. Despite the virtually unlimited range of possible strategies for modeling a part, only a small number of them can guarantee an appropriate internal structure which results in a truly reusable CAD model. In this paper, we present an analysis of formal CAD modeling strategies and best practices for history-based parametric design: Delphi\u2019s horizontal modeling, explicit reference modeling, and resilient modeling. Aspects considered in our study include the rationale to avoid the creation of unnecessary feature interdependencies, the sequence and selection criteria for those features, and the effects of parent/child relations on model alteration. We provide a comparative evaluation of these strategies in the form of a series of experiments using three industrial CAD models with different levels of complexity. We analyze the internal structure of the models and compare their robustness and flexibility when the geometry is modified. The results reveal significant advantages of formal modeling methodologies, particularly resilient techniques, over non-structured approaches as well as the unexpected problems of the horizontal strategy in numerous modeling situations.'}, {'id': 'doi_10_1108_FS-10-2021-0202', 'title': 'Augmented and virtual reality in apparel industry: a bibliometric review and future research agenda', 'URL': 'https://doi.org/10.1108/FS-10-2021-0202', 'extra_urls': ['https://doi.org/10.1108/FS-10-2021-0202'], 'type': 'article', 'author': [{'family': 'Goel', 'given': 'Pooja'}, {'family': 'Mahadevan', 'given': 'Kala'}, {'family': 'Punjani', 'given': 'Krunal K.'}], 'abstract': 'The purpose of the present study is to synthesize the extant literature on augmented reality and virtual reality in the apparel industry using bibliometric and network visualization techniques. This paper also highlights the existing gaps in the literature and sets out the future research trajectory.This study investigated research articles in the domain of augmented and virtual reality in the apparel industry to assess global trends in research production in this area, and top contributors to research by way of authors, journals, countries and institutions. The study carried out an analysis of 239 research articles from the Scopus database during the period 1995 to 2021. The study used open-source bibliometric tools such as Biblioshiny and VOSviewer to analyze the research literature over the search period and also identify emerging research avenues.The bibliometric analysis reveals that there is significant interest in this research domain. A total of 673 authors contributed to the 239 research articles analyzed and the number of multi-author documents exceeded those by single authors. Research in this domain is led by China with the maximum number of articles in the data set followed by the USA and France. However, the USA has received the highest number of citations. Donghua University from China is the largest contributor to research in this domain with 13 articles in the data set. The keyword co-occurrence analysis indicates that \u201cvirtual reality\u201d has the most number of co-occurrences and linkages with other keywords. Other important keywords include \u201caugmented reality,\u201d \u201cvirtual try-on\u201d and \u201ccloth simulation.\u201d The network visualization exercise also revealed significant collaboration between different countries in this research domain.The gaps highlighted in this study will act as a reference point for researchers to conduct future studies in the field of augmented and virtual reality in apparel industry. Practitioners will also gain a comprehensive understanding of this research domain.This study, to the best of the authors\u2019 knowledge, is the first attempt to integrate the disjoint literature of augmented and virtual reality in apparel industry through a mapping of the intellectual structure of this research domain. The study also contributes by way of providing a snapshot of future research avenues in the knowledge domain of augmented and virtual reality in the apparel industry.', 'DOI': '10.1108/FS-10-2021-0202'}, {'id': 'doi_10_1108_RJTA-02-2025-0017', 'title': 'Empowering students through generative AI and cultural diversity in interdisciplinary fashion design education', 'URL': 'https://doi.org/10.1108/RJTA-02-2025-0017', 'extra_urls': ['https://doi.org/10.1108/RJTA-02-2025-0017'], 'type': 'article', 'author': [{'family': 'Lee', 'given': 'Jennifer'}], 'abstract': 'This study aims to examine how integrating cultural diversity and generative AI into coursework can enhance students\u2019 creativity, critical thinking and innovation, enabling them to design culturally aware products for the global market.Grounded in Stanford\u2019s design thinking framework, the proposed course designs were developed to incorporate a range of cutting-edge artificial intelligence (AI) tools. A portion of the curriculum was pilot-tested in actual college courses with 52 students to assess its effectiveness in achieving the intended learning outcomes.Integrating generative AI and cultural diversity in a fashion design course enhanced students\u2019 creativity, critical thinking, cultural awareness and teamwork. AI tools simplified research and design tasks for those with fewer technical skills, allowing them to focus on innovation, whereas cultural diversity fostered collaboration and the exchange of ideas for global markets. This approach could also apply to Science, Technology, Engineering, and Mathematics (STEM) fields like engineering, where AI supports coding and design to improve learning and develop globally relevant solutions. This study had some limits. It used a small group of students from one school, so the results may not fit all. Some AI tools produced errors or were difficult to use, highlighting the need for clarity about AI\u2019s limitations and careful attention to cultural appropriateness in generated results. Future studies should have more students, better AI tools and focus on fair use.This research integrates generative AI with cultural diversity in a fashion design course to develop product design and development skills for the global market \u2013 a combination rarely examined in existing studies. It demonstrates how AI can empower students from diverse backgrounds to collaborate creatively while honoring cultural authenticity.', 'DOI': '10.1108/RJTA-02-2025-0017'}, {'id': 'doi_10_1177_00405175251352800', 'title': 'Body data-driven garment pattern construction in digital fashion innovations: a review', 'URL': 'https://doi.org/10.1177/00405175251352800', 'extra_urls': ['https://doi.org/10.1177/00405175251352800'], 'type': 'article', 'author': [{'family': 'Lyu', 'given': 'Yingrui'}, {'family': 'Wang', 'given': 'Zhaohui'}, {'family': 'Ye', 'given': 'Qinwen'}, {'family': 'Sun', 'given': 'Yuexin'}, {'family': 'Chao', 'given': 'Jing'}], 'abstract': 'Body data are indispensable for garment pattern construction, not only influencing garment quality but also shaping the competitiveness of apparel enterprises and driving the digital transformation of the fashion industry. Traditional pattern construction practices primarily rely on a limited number of one-dimensional (1D) measurements, with less consideration given to higher-dimensional body data, such as three-dimensional (3D) shapes and four-dimensional (4D) motion information. This underutilization of advanced anthropometric data reflects the technological limitations of past eras. With the rapid advancement of digital technologies, cutting-edge anthropometry and digital tools have significantly enhanced the integration of body data into pattern construction. To comprehensively understand the utilization of body data in digital pattern construction, as well as to clarify the current technological landscape and future directions, this review provides a thorough analysis of the evolution of body data utilization and facilitators in pattern construction, pattern construction methods based on multidimensional body data (1D\u20134D), as well as the distinctions and applications of these approaches. Furthermore, this review offers a comprehensive examination of the prospects and challenges in pattern construction, considering key aspects such as dynamic pattern construction, AI-driven generation, CAD system integration, and emerging business opportunities. It underscores the scientific and innovative potential of high-dimensional 4D body data and AI-powered tools in advancing modern garment pattern construction. By highlighting these developments, this review aims to provide researchers with valuable insights, enabling them to anticipate and explore uncharted possibilities in the field.', 'DOI': '10.1177/00405175251352800'}, {'id': 'mapping_the_research', 'title': 'Mapping the Research Landscape of Sustainable Fashion: A Bibliometric Analysis', 'URL': 'https://www.mdpi.com/3042-5042/2/4/21', 'extra_urls': ['https://www.mdpi.com/3042-5042/2/4/21'], 'type': 'article', 'author': [{'family': 'Ng', 'given': 'Sai-Leung'}, {'family': 'Chen', 'given': 'Shou-Hung'}], 'abstract': 'The fashion industry, despite its global economic importance, is a major contributor to environmental degradation and social inequality. In response, sustainable fashion has emerged as a growing movement advocating ethical, ecological, and socially responsible practices. This study presents a comprehensive bibliometric analysis of 1134 peer-reviewed journal articles on sustainable fashion indexed in Scopus from 1986 to 2025. Results show an exponential rise in research output after 2015, with interdisciplinary contributions from social sciences, business, environmental science, and engineering. By applying performance analysis and science mapping techniques, the study identifies five major research themes: \u201cConsumer Behavior,\u201d \u201cDesign Ethics,\u201d \u201cCircular Economy,\u201d \u201cInnovation,\u201d and \u201cDigital Media.\u201d The geographic distribution reveals strong outputs from both developed and emerging economies. This study provides an integrative overview of the intellectual landscape of sustainable fashion and serves as a roadmap for researchers, policymakers, and practitioners who are interested in the development of sustainable fashion.'}, {'id': 'analysis_of_woven', 'title': 'Analysis of Woven Fabric Mechanical Properties in the Context of Sustainable Clothing Development Process', 'URL': 'https://www.mdpi.com/2073-4360/17/15/2013', 'extra_urls': ['https://www.mdpi.com/2073-4360/17/15/2013'], 'type': 'article', 'author': [{'family': 'Mahni\u0107 Nagli\u0107', 'given': 'Maja'}, {'family': 'Petrak', 'given': 'Slavenka'}, {'family': 'Tomljenovi\u0107', 'given': 'Antoneta'}], 'abstract': 'This paper presents research in the field of computer-aided 3D clothing design, focusing on an investigation of three methods for determining the mechanical properties of woven fabrics and their impact on 3D clothing simulations in the context of sustainable apparel development. Five mechanical parameters were analyzed: tensile elongation in the warp and weft directions, shear stiffness, bending stiffness, specific weight, and fabric thickness. These parameters were integrated into the CLO3D CAD software v.2025.0.408, using data obtained via the KES-FB system, the Fabric Kit protocol, and the AI-based tool, SEDDI Textura 2024. Simulations of women\u2019s blouse and trousers were evaluated using dynamic tests and validated by real prototypes measured with the ARAMIS optical 3D system. Results show average differences between digital and real prototype deformation data up to 6% with an 8% standard deviation, confirming the high accuracy of 3D simulations based on the determined mechanical parameters of the real fabric sample. Notably, the AI-based method demonstrated excellent simulation results compared with real garments, highlighting its potential for accessible, sustainable, and scalable fabric digitization. Presented research is entirely in line with the current trends of digitization and sustainability in the textile industry. It contributes to the advancement of efficient digital prototyping workflows and emphasizes the importance of reliable mechanical characterization for predictive garment modeling.'}, {'id': 'doi_10_1108_TECHS-03-2025-0068', 'title': 'Augmented reality and sustainable luxury: transforming fashion retail in the UAE', 'URL': 'https://doi.org/10.1108/TECHS-03-2025-0068', 'extra_urls': ['https://doi.org/10.1108/TECHS-03-2025-0068'], 'type': 'article', 'author': [{'family': 'Zoubi', 'given': 'Munif'}, {'family': 'Estaitia', 'given': 'Huda'}, {'family': 'Morshed', 'given': 'Amer'}, {'family': 'Khrais', 'given': 'Laith T.'}, {'family': 'Haikal', 'given': 'Ehab'}, {'family': 'AlSheikh', 'given': 'Maha'}], 'abstract': 'This study aims to explore the potential of augmented reality (AR) in luxury retail in the United Arab Emirates (UAE) in terms of enhancing consumer engagement, purchase confidence and sustainability awareness. It also focuses on the demographic factors that affect the adoption of AR and to what extent it may promote sustainable consumption of fashion.A quantitative method using partial least squares structural equation modeling and multi-group analysis is employed to examine AR adoption and its impact on consumer behavior. Age demographics, gender, educational attainment and income are tested as moderators of AR-based sustainable fashion decisions.AR significantly enhances consumer confidence, reduces product return rates and builds trust in sustainable fashion. Younger, tech-savvy consumers have higher engagement, while artificial intelligence (AI)-powered AR solutions, such as virtual try-ons and sustainability transparency tools, foster ethical fashion awareness. AR adoption rate disparities persist among demographics, requiring tailored engagement strategies.Policymakers, retailers and technology developers have strategic learnings from the research. It emphasizes the requirement for hybrid retail models, AI-driven personalization and regulatory intervention to combat greenwashing and establish sustainability standards.Unlike more general studies on AR in digital retail, this one provides region-specific insight on its function in sustainable luxury fashion. Emphasizing rich areas like the UAE, it describes luxury retail as unique, premium and technologically forward. Following how AR interacts with consumer behavior and sustainability in line with Sustainable Development Goals 12 and 13 helps to add to knowledge.', 'DOI': '10.1108/TECHS-03-2025-0068'}, {'id': 'digital_technologies_in', 'title': 'Digital Technologies in the Sustainable Design and Development of Textiles and Clothing\u2014A Literature Review', 'URL': 'https://www.mdpi.com/2071-1050/17/4/1371', 'extra_urls': ['https://www.mdpi.com/2071-1050/17/4/1371'], 'type': 'article', 'author': [{'family': 'Glogar', 'given': 'Martina'}, {'family': 'Petrak', 'given': 'Slavenka'}, {'family': 'Mahni\u0107 Nagli\u0107', 'given': 'Maja'}], 'abstract': 'This paper examines the digital transformation of the textile and fashion industry, focusing on the alignment with sustainability principles through the integration of Industry 4.0 technologies. The introduction highlights the urgency of transitioning from conventional production methods to innovative, digitally enabled systems that promote a circular economy and resource efficiency. The main research questions address the contribution of Industry 4.0 elements to sustainable solutions, the directions of digitalization within the apparel sector, and the significant impact of digital technologies on the achievement of sustainability goals. The theoretical framework examines sustainability in the textile industry and emphasizes the need for a green transformation facilitated by digital technologies to reduce environmental impacts. Industry 4.0 concepts, as discussed in The Concept of Industry 4.0 in the Textile and Apparel Sector, are revolutionizing production through technologies such as IoT, AI, and blockchain, enabling traceability, customization, and energy-efficient operations. The paper also explores the evolution of the fashion and apparel industry into a high-tech sector, highlighting advances such as CAD-CAM systems, digital printing, and 3D technologies that improve precision, reduce waste, and support sustainable practices. In its conclusion, the paper emphasizes the crucial role of interdisciplinary collaboration, regulatory frameworks, and investment in skills development to overcome the challenges of implementing digital and sustainable practices. It posits that a strategic embrace of digital ecosystems and Industry 4.0 technologies is essential for creating a resilient and sustainable textile industry that is aligned with environmental and societal goals.'}, {'id': 'a_survey_on', 'title': 'A survey on CAD methods in 3D garment design', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0166361510000242', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0166361510000242'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Yong-Jin'}, {'family': 'Zhang', 'given': 'Dong-Liang'}, {'family': 'Yuen', 'given': 'Matthew Ming-Fai'}], 'abstract': 'With the advance in virtual reality applications, garment industry has strived for new developments. This paper reviews state-of-the-art CAD methods in 3D garment design. A large range of techniques are selected and organized into several key modules which form the core of a 3D garment design technology platform. In each module, basic techniques are presented first. Then advanced developments are systematically discussed and commented. The selected key modules \u2013 digital human modeling, 3D garment design and modification, numerical integration of draping, 2D pattern generation, geometric details modeling, parallel computation and GPU acceleration \u2013 are discussed in turn. Major challenges and solutions that have been addressed over the years are discussed. Finally, some of the ensuing challenges in 3D garment CAD technologies are outlined.'}, {'id': 'use_of_computational', 'title': 'Use of Computational Design Technology to Automate Sew Pattern Design for Dress Garment', 'URL': '#item_19790', 'type': 'article', 'author': [{'family': 'Minaoglou', 'given': 'Prodromos'}, {'family': 'Oancea', 'given': 'Gheorghe'}, {'family': 'Gupta', 'given': 'Manoj'}, {'family': 'Kyratsis', 'given': 'Panagiotis'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'CRC Press', 'abstract': 'Computational product design is a method that uses initial parameter values with an aim to automatically complete the design process. A 2D drawing or 3D computer model can be redefined with every change in the initial values and used for fabrication. Via Computational product design the designer does not manually complete the necessary geometry but uses programming languages and incorporates algorithms within a computer aided design application. The present chapter highlights the use of computational product design in designing and fabricating a garment. The algorithm produced, fully automates the design of the sew pattern and presents the final product. The only input needed is the dimensional definition of the user\u2019s body in the application and the rest of the process is carried out automatically. Dimensioning is carried out either by manual insertion or by using a 3D scanned digital model. Several downstream applications support the whole process i.e. 3D digital visualization facility of the product, definition of the code needed for manufacturing.'}, {'id': 'deep_shape', 'title': 'Three-dimensional deep shape optimization with a limited dataset', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0952197625015064', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0952197625015064'], 'type': 'article', 'author': [{'family': 'Kwon', 'given': 'Yongmin'}, {'family': 'Kang', 'given': 'Namwoo'}], 'abstract': 'Generative models have attracted considerable attention for their ability to produce novel shapes. However, their application in mechanical design remains constrained due to the limited size and variability of available datasets. This study proposes a deep learning-based optimization framework specifically tailored for shape optimization with limited datasets, leveraging positional encoding and a Lipschitz regularization term to robustly learn geometric characteristics and maintain a meaningful latent space. Through extensive experiments, the proposed approach demonstrates robustness, generalizability and effectiveness in addressing typical limitations of conventional optimization frameworks. The validity of the methodology is confirmed through multi-objective shape optimization experiments conducted on diverse three-dimensional datasets, including wheels and cars, highlighting the model\u2019s versatility in producing practical and high-quality design outcomes even under data-constrained conditions.'}, {'id': 'doi_10_1007_s42452-025-06833-5', 'title': 'Generative AI and CAD automation for diverse and novel mechanical component designs under data constraints', 'URL': 'https://doi.org/10.1007/s42452-025-06833-5', 'extra_urls': ['https://doi.org/10.1007/s42452-025-06833-5'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Kun-Ying'}, {'family': 'Huang', 'given': 'Cheng-Kai'}, {'family': 'Chen', 'given': 'Qing-Wei'}, {'family': 'Zhang', 'given': 'Hsuan-Cheng'}, {'family': 'Tang', 'given': 'Tsann-Tay'}], 'abstract': 'The efficient design of complex engineering components in data-constrained environments presents significant challenges to traditional methodologies. Existing deep learning-based generative design approaches often depend on large datasets, which limits their applicability in data-scarce contexts. Additionally, conventional image generation techniques often produce impractical designs, requiring extensive manual validation by engineers. This paper presents a novel method that integrates stable diffusion-based Generative AI with computer-aided design automation to minimize data requirements while maintaining high design accuracy. Through the implementation of low-rank adaptation fine-tuning, the proposed method reduces the required training data from over 16,600 to approximately 200 samples. This significant reduction in data ensures efficiency in data-scarce environments while ensuring compliance with stringent mechanical and aesthetic design requirements. Experimental results demonstrate a consistent 90% accuracy in generating feasible designs that meet these constraints. This paper also explores the relevant background and technological developments that support these experimental results, offering context for the challenges and solutions addressed. Furthermore, the automated validation system further enhances efficiency by filtering out all infeasible designs, thereby eliminating the need for manual expert validation. Experimental results demonstrate a 30% reduction in the overall design process, from initial concept to prototyping preparation, compared to traditional workflows, confirming the method\u2019s effectiveness in real-world applications. This research provides a scalable solution to the challenges of generative design in data-limited settings and contributes to advancing intelligent design systems across various engineering sectors.', 'DOI': '10.1007/s42452-025-06833-5'}, {'id': 'towards_agentic_smart', 'title': 'Towards agentic smart design: An industrial large model-driven human-in-the-loop agentic workflow for geometric modelling', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1568494625012335', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1568494625012335'], 'type': 'article', 'author': [{'family': 'Zheng', 'given': 'Keyou'}, {'family': 'Zhong', 'given': 'Yuanwei'}, {'family': 'Su', 'given': 'Xuyang'}, {'family': 'Leng', 'given': 'Jiewu'}, {'family': 'Liu', 'given': 'Qiang'}, {'family': 'Chen', 'given': 'Xin'}], 'abstract': 'Agentic workflows, powered by Industrial Large Models (ILMs), represent a significant development emphasizing collaboration between humans and intelligent systems. This paper presents a structured perspective on the role of agentic workflows for smart design and manufacturing, grounded in integrating ILMs. We define an agentic workflow as a labeled Activity-on-Vertex (AOV) graph, where each node represents a functionally closed subtask and is executed by an ILM-based agent, a human operator, or an automated system. This formalism supports analyzable, modular, and hybrid execution, offering a foundation for modeling complex, mixed-initiative processes in manufacturing environments. To support real-world deployment, we introduce a set of reusable agentic workflow patterns that describe how ILM agents perceive, plan, and act in coordination with other components. Besides, a proof-of-concept case study illustrates the practical application of the human-in-the-loop framework through the agentic generation of CAD models. The study covers task decomposition, workflow implementation, and benchmarking, providing evidence for the feasibility of agentic workflows. Building upon these findings, this work contributes to advancing the development and application of agentic workflows in smart manufacturing contexts.'}, {'id': 'diffusion_smart', 'title': 'Diffusion model-driven smart design and manufacturing: Prospects and challenges', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0278612525001864', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0278612525001864'], 'type': 'article', 'author': [{'family': 'Leng', 'given': 'Jiewu'}, {'family': 'Su', 'given': 'Xuyang'}, {'family': 'Liu', 'given': 'Zean'}, {'family': 'Zhou', 'given': 'Lianhong'}, {'family': 'Chen', 'given': 'Chong'}, {'family': 'Guo', 'given': 'Xin'}, {'family': 'Wang', 'given': 'Yiwei'}, {'family': 'Wang', 'given': 'Ru'}, {'family': 'Zhang', 'given': 'Chao'}, {'family': 'Liu', 'given': 'Qiang'}, {'family': 'Chen', 'given': 'Xin'}, {'family': 'Shen', 'given': 'Weiming'}, {'family': 'Wang', 'given': 'Lihui'}], 'abstract': 'Artificial Intelligence-Generated Content (AIGC), particularly diffusion models as a key component of Generative Artificial Intelligence (GenAI), are transforming smart design and manufacturing in the interplay of Industry 4.0 and Industry 5.0. This paper analyzes the applications of diffusion models in smart design and manufacturing, focusing on three key pillars: diffusion-driven generative design, smart control, and fault diagnosis. Diffusion models enhance manufacturing system flexibility, resilience, and sustainability through their applications as generative design engines, intelligent controllers for adaptive manufacturing processes, and predictive tools for fault diagnosis. This study provides a comprehensive review of the current state of diffusion model-driven smart design and manufacturing. It analyzes key challenges such as model efficiency, data dependency, and system integration, while providing a constructive perspective on potential solutions. This paper also integrates Industry 5.0 considerations by connecting the applications and technical solutions to the core values of human-centricity, sustainability, and resilience. It concludes by emphasizing the necessity of continuous refinement of diffusion models and interdisciplinary research to integrate them into smart design and manufacturing systems further, fostering a more human-centric, resilient, and sustainable industry.'}, {'id': 'controllable_diffusion', 'title': 'Diffusion-CAD: Controllable Diffusion Model for Generating Computer-Aided Design Models', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10857640', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10857640'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Aijia'}, {'family': 'Jia', 'given': 'Weiqiang'}, {'family': 'Zou', 'given': 'Qiang'}, {'family': 'Feng', 'given': 'Yixiong'}, {'family': 'Wei', 'given': 'Xiaoxiang'}, {'family': 'Zhang', 'given': 'Ye'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Generative methods for creating computer-aided design (CAD) models have gained significant attention over the past two years. However, existing methods lack fine-grained control over the generated CAD models, making it difficult to manage details such as model dimensions and the relative structure of components. To address these limitations, this study introduces Diffusion-CAD, a diffusion-based generative approach that outputs CAD construction sequences. Diffusion-CAD iteratively denoises Gaussian noise into continuous CAD vectors, which are then transformed into discrete CAD sequences. We designed classifier-free and classifier-guided methods to control the distribution of Gaussian noise, CAD sequences, and noisy CAD vectors separately, thereby achieving a variety of fine-grained control tasks. Extensive experiments demonstrated the superior performance and novel capabilities of the proposed method for conditional generation tasks.'}, {'id': 'doi_10_1007_s11704-024-40417-7', 'title': 'CAD-NeRF: learning NeRFs from uncalibrated few-view images by CAD model retrieval', 'URL': 'https://doi.org/10.1007/s11704-024-40417-7', 'extra_urls': ['https://doi.org/10.1007/s11704-024-40417-7'], 'type': 'article', 'author': [{'family': 'Wen', 'given': 'Xin'}, {'family': 'Zhu', 'given': 'Xuening'}, {'family': 'Yi', 'given': 'Renjiao'}, {'family': 'Wang', 'given': 'Zhifeng'}, {'family': 'Zhu', 'given': 'Chenyang'}, {'family': 'Xu', 'given': 'Kai'}], 'abstract': 'Reconstructing from multi-view images is a longstanding problem in 3D vision, where neural radiance fields (NeRFs) have shown great potential and get realistic rendered images of novel views. Currently, most NeRF methods either require accurate camera poses or a large number of input images, or even both. Reconstructing NeRF from few-view images without poses is challenging and highly ill-posed. To address this problem, we propose CAD-NeRF, a method reconstructed from less than 10 images without any known poses. Specifically, we build a mini library of several CAD models from ShapeNet and render them from many random views. Given sparse-view input images, we run a model and pose retrieval from the library, to get a model with similar shapes, serving as the density supervision and pose initializations. Here we propose a multi-view pose retrieval method to avoid pose conflicts among views, which is a new and unseen problem in uncalibrated NeRF methods. Then, the geometry of the object is trained by the CAD guidance. The deformation of the density field and camera poses are optimized jointly. Then texture and density are trained and fine-tuned as well. All training phases are in self-supervised manners. Comprehensive evaluations of synthetic and real images show that CAD-NeRF successfully learns accurate densities with a large deformation from retrieved CAD models, showing the generalization abilities.', 'DOI': '10.1007/s11704-024-40417-7'}, {'id': 'reinforcement_parametric', 'title': 'Reinforcement learning-based parametric CAD models reconstruction from 2D orthographic drawings', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0010448525000867', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0010448525000867'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Chao'}, {'family': 'Polette', 'given': 'Arnaud'}, {'family': 'Pinqui\xe9', 'given': 'Romain'}, {'family': 'Iida', 'given': 'Mirai'}, {'family': 'Charnace', 'given': 'Henri De'}, {'family': 'Pernot', 'given': 'Jean-Philippe'}], 'abstract': 'This paper introduces a reinforcement learning-based approach for reconstructing 3D parametric CAD models from 2D orthographic drawings. First, the 2D drawings are parsed to extract their constituent vertices and edges. These entities are subsequently converted into a newly defined loop-path representation, generating a list of loop-path pairs along with their associated parameters and candidates for the reconstruction process. The core of the approach is a DQN-based agent trained to select the sequences of loop-path pairs, which are then used to reconstruct the parametric CAD models in any CAD modeler. A parallel environment leveraging a neural network is proposed to accelerate the training process and eliminate the need for calls to an external CAD modeler to compute the rewards, which would otherwise break the training loop. The proposed approach reconstructs 3D parametric CAD models in less than a second, and it outperforms existing methods against traditional metrics on two datasets. The reconstructed CAD models are fully editable and can be easily modified for downstream applications. While the loop-path representation supports extrusion, revolution and sweep operations, experimental results on the two selected datasets highlight the superiority of the RL-based approach in handling sketch-extrude modeling operations.'}, {'id': 'overview_of_personalized', 'title': 'Overview of Personalized 3d Human Body Modeling Technology for Garment CAD', 'URL': 'https://jceim.org/index.php/ojs/article/view/95', 'extra_urls': ['https://jceim.org/index.php/ojs/article/view/95'], 'type': 'article', 'author': [{'family': 'Cai', 'given': 'Xiaoyao'}], 'abstract': '3D human models serve as the foundation for 3D garment design, while personalized human modeling has emerged as a significant research focus in computer graphics and computer vision. Over time, numerous implementation approaches have been developed. This paper reviews and summarizes recent advancements in personalized human modeling, categorizing them into scanning-based methods, standard model deformation techniques, template matching approaches, image-based model reconstruction, and wireframe-assisted deep learning methods. The study analyzes the strengths and limitations of existing methodologies while outlining future development trends.'}, {'id': 'cad_3d', 'title': 'CAD Model-Based 3D Scene Reconstruction', 'URL': 'https://www.repository.cam.ac.uk/handle/1810/379710', 'extra_urls': ['https://www.repository.cam.ac.uk/handle/1810/379710'], 'type': 'article', 'author': [{'family': 'Langer', 'given': 'Florian'}], 'abstract': 'Accurate scene reconstruction from an image or a video is essential for various applications in robotics and augmented reality. One common method involves retrieving the best-matching CAD model for each observed object from a database and aligning it with the corresponding input. This technique yields a CAD model-based 3D scene representation that is compact, contains realistic shapes, and is well-suited for a wide range of downstream tasks. This thesis addresses the challenges of deriving such a representation by answering four key research questions. First, we investigate how to retrieve and align a CAD model from a database for an object detected in an image, assuming that an exact match exists for the detected object. We show that retrieving CAD model renders from an embedding space and predicting cross-domain keypoint correspondences between the render and the input image enables accurate alignments. Next, we tackle the problem of adapting CAD models when their shapes do not perfectly match the observed objects. Here we show that the established keypoint correspondences can not only be used to align the CAD model but also to modify its shape, and thereby better represent a wider range of object shapes. The third challenge involves accurately aligning retrieved CAD models when discrep- ancies exist between their shapes and the observed objects. To this end, we introduce a learned render-and-compare framework for CAD model-based scene reconstruction. In this framework, a neural network receives dual input streams \u2014 information about the observed image and the CAD model rendered in an initial pose \u2014 and is trained to iteratively refine the object\u2019s pose. This method yields significantly more accurate alignments compared to existing approaches and improves further by jointly predicting alignments for multiple objects, leveraging regularities in the natural arrangement of objects in indoor scenes. Finally, we focus on achieving efficient, real-time CAD model-based scene reconstruction. For this purpose, we train a neural network to predict CAD model retrieval and alignment simultaneously and jointly for all objects present in a scene. This method significantly reduces the inference time by a factor of 50 compared to existing techniques. It can process both input point clouds and RGB videos, enabling real-time performance at 10 frames per second.'}, {'id': 'a', 'title': 'OrthoCAD-322K: A cross-modal approach for retrieving 3D CAD models from orthographic views using a graph-based framework on a developed large-scale dataset', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0097849325001980', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0097849325001980'], 'type': 'article', 'author': [{'family': 'Mahajan', 'given': 'Swapnil Nagnath'}, {'family': 'M.', 'given': 'Karthik Krishna'}, {'family': 'Muthuganapathy', 'given': 'Ramanathan'}], 'abstract': 'Despite the widespread adoption of 3D CAD systems, 2D orthographic drawings remain integral to engineering workflows. However, millions of legacy drawings lack corresponding 3D models, hindering their integration into modern simulation, manufacturing, and digital twin systems. Existing methods for 2D to 3D CAD retrieval often fall short of meeting the structural precision required for engineering-grade drawings. We propose a cross-modal retrieval framework that aligns vector-based 2D DXF (Drawing Exchange Format) views with 3D CAD models using contrastive learning. Our architecture integrates a Graphormer-based encoder for 2D input and a PointNet-based encoder for 3D CAD models. We introduce a novel proximity-based spatial encoding to enhance structural precision and robustness across varying view configurations. Using the filtered subset (\u223c283K) of the newly developed large-scale dataset OrthoCAD-322K, extensive ablation and comparison studies demonstrate the robustness and generalization of the model in different input conditions and architectures. Source code is available at https://github.com/Swapnil-Mahajan-MS/OrthoCAD-322K.'}, {'id': 'llms_driven_fusion', 'title': 'LLMs driven fusion AI-AD system for mechanical design: From understanding to generation', 'URL': 'https://www.sciencedirect.com/science/article/pii/S147403462500638X', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S147403462500638X'], 'type': 'article', 'author': [{'family': 'Xiaorui', 'given': 'Liu'}, {'family': 'Yuhao', 'given': 'Zhang'}, {'family': 'Leiqi', 'given': 'Wang'}, {'family': 'Lexiang', 'given': 'Gu'}, {'family': 'Yaning', 'given': 'Xu'}, {'family': 'Ke', 'given': 'Zheng'}, {'family': 'Qianqian', 'given': 'Cai'}, {'family': 'Gang', 'given': 'Zhou'}], 'abstract': 'The intelligentization of mechanical design CAD systems is still remarkably slow despite decades of development. Recently, the rapid advancement of LLMs offers new opportunities for enhancing CAD intelligence. However, the inherent illusions and black-box nature of LLMs compromise the reliability of design outcomes. To enhance the intelligence of mechanical design and integrate LLMs into CAD, this paper develops a novel fusion AI-AD (Artificial Intelligence-Aided Design) architecture that adheres to the concept of \u201cFrom Understanding to Generation\u201d. With LLMs as the intelligent core, integrating components and modules such as knowledge processing, cloud data exchange and secondary development of SolidWorks (SW), this architecture realizes the full-process intelligence from understanding of mechanical design knowledge to the generation of 3D models. In terms of knowledge understanding, a new approach which is distinct from the past is proposed that data is processed based on the categories of knowledge representation to eliminate the illusions of LLMs. On the generation side, workflows based on the chain-of-thought mechanism are developed, and the granularity of each workflow is refined to overcome the illusions of LLMs, ensuring the accuracy and precision of the generated model. Based on the understood knowledge and the natural language requirements from users, the design content is automatically generated and modeling files (VBA type) are automatically output to SW where the model is automatically completed. Compared with traditional programmatic CAD systems, AI-AD demonstrates its strong intelligent capabilities in mechanical part design, multi-agent collaborative design, and autonomous design. The AI-AD architecture uses NLP as an interactive interface and advocates a low-code model development, significantly reducing the technical obstacles for developers to promote the development of the intelligent CAD industry.'}, {'id': 'the', 'title': 'The status, evolution, and future challenges of multimodal large language models (LLMs) in parametric CAD', 'URL': 'https://www.sciencedirect.com/science/article/pii/S095741742501142X', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S095741742501142X'], 'type': 'article', 'author': [{'family': 'Zhou', 'given': 'Jiwei'}, {'family': 'Camba', 'given': 'Jorge D.'}], 'abstract': 'Parametric Computer-Aided Design (CAD) systems are fundamental tools in mechanical and product design to facilitate the precise generation of complex geometries. However, their steep learning curve restricts accessibility to non-experts, hindering collaboration and creativity in engineering workflows. Recent breakthroughs in Artificial Intelligence (AI), especially Large Language Models (LLMs), are providing new opportunities to redefine parametric CAD workflows. By enabling natural language and multimodal interactions, LLMs can reduce technical obstacles and allow users to intuitively convey design intents and requirements. This work critically examines the intersection between LLMs and parametric CAD modeling, emphasizing key advancements in automating tasks such as 2D sketching, 3D model generation, and design optimization. It also discusses progress in natural language interface development and identifies current challenges. Although LLMs exhibit the capacity to improve productivity and design accessibility, obstacles remain in understanding design intent and context, managing intricate geometries, optimizing model training with diverse datasets and benchmarking frameworks, guaranteeing interoperability, scalability, and security within CAD systems, and expanding industrial applications. Through a thorough analysis, this review identifies essential areas for future research to enable the practical integration of LLMs and parametric CAD modeling. The results highlight the potential of LLMs to simplify design processes, stimulate creativity, and reshape engineering design practices across applications in mechanical product development.'}, {'id': 'doi_10_1007_s10462-025-11290-y', 'title': 'From concept to manufacturing: evaluating vision-language models for engineering design', 'URL': 'https://doi.org/10.1007/s10462-025-11290-y', 'extra_urls': ['https://doi.org/10.1007/s10462-025-11290-y'], 'type': 'article', 'author': [{'family': 'Picard', 'given': 'Cyril'}, {'family': 'Edwards', 'given': 'Kristen M.'}, {'family': 'Doris', 'given': 'Anna C.'}, {'family': 'Man', 'given': 'Brandon'}, {'family': 'Giannone', 'given': 'Giorgio'}, {'family': 'Alam', 'given': 'Md Ferdous'}, {'family': 'Ahmed', 'given': 'Faez'}], 'abstract': 'Engineering design is undergoing a transformative shift with the advent of AI, marking a new era in how we approach product, system, and service planning. Large language models have demonstrated impressive capabilities in enabling this shift. Yet, with text as their only input modality, they cannot leverage the large body of visual artifacts that engineers have used for centuries and are accustomed to. This gap is addressed with the release of multimodal vision-language models (VLMs), such as GPT-4V, enabling AI to impact many more types of tasks. Our work presents a comprehensive evaluation of VLMs across a spectrum of engineering design tasks, categorized into four main areas: Conceptual Design, System-Level and Detailed Design, Manufacturing and Inspection, and Engineering Education Tasks. Specifically in this paper, we assess the capabilities of two VLMs, GPT-4V and LLaVA 1.6 34B, in design tasks such as sketch similarity analysis, CAD generation, topology optimization, manufacturability assessment, and engineering textbook problems. Through this structured evaluation, we not only explore VLMs\u2019 proficiency in handling complex design challenges but also identify their limitations in complex engineering design applications. Our research establishes a foundation for future assessments of vision language models. It also contributes a set of benchmark testing datasets, with more than 1000 queries, for ongoing advancements and applications in this field.', 'DOI': '10.1007/s10462-025-11290-y'}, {'id': 'synthesising_cad', 'title': 'CAD-GPT: Synthesising CAD Construction Sequence with Spatial Reasoning-Enhanced Multimodal LLMs', 'URL': 'https://ojs.aaai.org/index.php/AAAI/article/view/32849', 'extra_urls': ['https://ojs.aaai.org/index.php/AAAI/article/view/32849'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Siyu'}, {'family': 'Chen', 'given': 'Cailian'}, {'family': 'Le', 'given': 'Xinyi'}, {'family': 'Xu', 'given': 'Qimin'}, {'family': 'Xu', 'given': 'Lei'}, {'family': 'Zhang', 'given': 'Yanzhou'}, {'family': 'Yang', 'given': 'Jie'}], 'abstract': 'Computer-aided design (CAD) significantly enhances the efficiency, accuracy, and innovation of design processes by enabling precise 2D and 3D modeling, extensive analysis, and optimization. Existing methods for creating CAD models rely on latent vectors or point clouds, which are difficult to obtain, and storage costs are substantial. Recent advances in Multimodal Large Language Models (MLLMs) have inspired researchers to use natural language instructions and images for CAD model construction. However, these models still struggle with inferring accurate 3D spatial location and orientation, leading to inaccuracies in determining the spatial 3D starting points and extrusion directions for constructing geometries. This work introduces CAD-GPT, a CAD synthesis method with spatial reasoning-enhanced MLLM that takes either a single image or a textual description as input. To achieve precise spatial inference, our approach introduces a 3D Modeling Spatial Mechanism. This method maps 3D spatial positions and 3D sketch plane rotation angles into a 1D linguistic feature space using a specialized spatial unfolding mechanism, while discretizing 2D sketch coordinates into an appropriate planar space to enable precise determination of spatial starting position, sketch orientation, and 2D sketch coordinate translations. Extensive experiments demonstrate that CAD-GPT consistently outperforms existing state-of-the-art methods in CAD model synthesis, both quantitatively and qualitatively.'}, {'id': 'a_multimodal', 'title': 'CADInstruct: A multimodal dataset for natural language-guided CAD program synthesis', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0010448525000879', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0010448525000879'], 'type': 'article', 'author': [{'family': 'Lv', 'given': 'Chaofan'}, {'family': 'Bao', 'given': 'Jinsong'}], 'abstract': 'While large language models (LLMs) have demonstrated remarkable success in general-purpose code generation, their application in computer-aided design (CAD) program synthesis remains constrained by the scarcity of high-quality natural language-annotated datasets. To address this challenge, we propose CADInstruct, a novel approach aimed at constructing a multimodal CAD instruction dataset to enhance the CAD program synthesis capabilities of LLMs. First, we introduce a parametric modification module for modeling sequences, which extracts geometric constraints and critical dimensions from sketches, transforming CAD construction sequences into design-intent-oriented instructions. Second, we incorporate a shape semantic recognition module that leverages model names and visually enriched rendered views to generate precise shape descriptions using multimodal large models, enabling accurate semantic representation of complex geometries. Lastly, a modeling instruction semantic alignment module utilizes the extracted shape descriptions and modeling instructions to generate hierarchical natural language descriptions, encompassing geometric forms and detailed modeling steps, ensuring consistency between textual descriptions and CAD instructions. We fine-tuned the Qwen2.5-Coder-7B model using the CADInstruct dataset to evaluate the effectiveness of this framework. Experimental results demonstrated its capability to significantly enhance CAD program synthesis. The code and dataset will be made publicly available at https://github.com/dxlcf/CADInstruct.'}, {'id': 'revisiting_cad_model', 'title': 'Revisiting CAD Model Generation by Learning Raster Sketch', 'URL': 'https://ojs.aaai.org/index.php/AAAI/article/view/32515', 'extra_urls': ['https://ojs.aaai.org/index.php/AAAI/article/view/32515'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Pu'}, {'family': 'Zhang', 'given': 'Wenhao'}, {'family': 'Guo', 'given': 'Jianwei'}, {'family': 'Chen', 'given': 'Jinglu'}, {'family': 'Yan', 'given': 'Dong-Ming'}], 'abstract': 'The integration of deep generative networks into generating Computer-Aided Design (CAD) models has garnered increasing attention over recent years. Traditional methods often rely on discrete sequences of parametric line/curve segments to represent sketches. Differently, we introduce RECAD, a novel framework that generates Raster sketches and 3D Extrusions for CAD models. Representing sketches as raster images offers several advantages over discrete sequences: 1) it breaks the limitations on the types and numbers of lines/curves, providing enhanced geometric representation capabilities; 2) it enables interpolation within a continuous latent space; and 3) it allows for more intuitive user control over the output. Technically, RECAD employs two diffusion networks: the first network generates extrusion boxes conditioned on the number and types of extrusions, while the second network produces sketch images conditioned on these extrusion boxes. By combining these two networks, RECAD effectively generates sketch-and-extrude CAD models, offering a more robust and intuitive approach to CAD model generation. Experimental results indicate that RECAD achieves strong performance in unconditional generation, while also demonstrating effectiveness in conditional generation and output editing.'}, {'id': 'pose_estimation', 'title': '6-DoF Pose Estimation from Single RGB Image and CAD Model Retrieval Using Feature Similarity Measurement.', 'URL': 'https://openurl.ebsco.com/contentitem/doi:10.3390%2Fapp15031501?sid=ebsco:plink:crawler&amp;id=ebsco:doi:10.3390%2Fapp15031501', 'extra_urls': ['https://openurl.ebsco.com/contentitem/doi:10.3390%2Fapp15031501?sid=ebsco:plink:crawler&amp;id=ebsco:doi:10.3390%2Fapp15031501'], 'type': 'article', 'author': [{'family': 'Park', 'given': 'Sieun'}, {'family': 'Jeong', 'given': 'Won-Je'}, {'family': 'Manawadu', 'given': 'Mayura'}, {'family': 'Park', 'given': 'Soon-Yong'}], 'abstract': &quot;Discover this 2025 paper in Applied Sciences (2076-3417) by Park, Sieun; Jeong, Won-Je; Manawadu, Mayura; et. al. focusing on: WEB search engines; SINGLE-degree-of-freedom systems; COMPUTER vision; IMAGE retrieval; DEEP learning Abstract: This study presents six degrees of freedom (6-DoF) pose estimation of an object from a single RGB image and retrieval of the matching CAD model by measuring the similarity between RGB and CAD rendering images. The 6-DoF pose estimation of an RGB object is one of the important techniques in 3D computer vision. However, in addition to 6-DoF pose estimation, retrieval and alignment of the matching CAD model with the RGB object should be performed for various industrial applications such as eXtended Reality (XR), Augmented Reality (AR), robot's pick and place, and so on. This paper addresses 6-DoF pose estimation and CAD model retrieval problems simultaneously and quantitatively analyzes how much the 6-DoF pose estimation affects the CAD model retrieval performance. This study consists of two main steps. The first step is 6-DoF pose estimation based on the PoseContrast network. We enhance the structure of PoseConstrast by adding variance uncertainty weight and feature attention modules. The second step is the retrieval of the matching CAD model by an image similarity measurement between the CAD rendering and the RGB object. In our experiments, we used 2000 RGB images collected from Google and Bing search engines and 100 CAD models from ShapeNetCore. The Pascal3D dataset is used to train the pose estimation network and DELF features are used for the similarity measurement. Comprehensive ablation studies about the proposed network show the quantitative performance analysis with respect to the baseline model. Experimental results show that the pose estimation performance has a positive correlation with the CAD retrieval performance.&quot;}, {'id': 'toward_ai', 'title': 'Toward Knowledge-Guided AI for Inverse Design in Manufacturing: A Perspective on Domain, Physics, and Human\u2013AI Synergy', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1002/aidi.202500107', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1002/aidi.202500107'], 'type': 'article', 'author': [{'family': 'Lee', 'given': 'Hugon'}, {'family': 'Moon', 'given': 'Hyeonbin'}, {'family': 'Lee', 'given': 'Junhyeong'}, {'family': 'Ryu', 'given': 'Seunghwa'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Artificial intelligence (AI) is reshaping inverse design in manufacturing, enabling high-performance discovery in materials, products, and processes. However, purely data-driven approaches often struggle in realistic manufacturing settings characterized by sparse data, high-dimensional design spaces, and complex constraints. This perspective proposes an integrated framework built on three complementary pillars: domain knowledge to establish physically meaningful objectives and constraints while removing variables with limited relevance, physics-informed machine learning to enhance generalization under limited or biased data, and large language model-based interfaces to support intuitive, human\u2013centered interaction. Using injection molding as an illustrative example, we demonstrate how these components can operate in practice and conclude by highlighting key challenges for applying such approaches in realistic manufacturing environments.'}, {'id': 'automated_bim_generation', 'title': 'Automated BIM generation for MEP systems from CAD data using multi-drawing graph integration', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0926580525005825', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0926580525005825'], 'type': 'article', 'author': [{'family': 'Zhao', 'given': 'Qian'}, {'family': 'Shi', 'given': 'Hao'}, {'family': 'Zhou', 'given': 'Liangchen'}, {'family': 'Lv', 'given': 'Guonian'}], 'abstract': 'Building information modeling (BIM) of mechanical, electrical, and plumbing (MEP) systems is essential for building facility management. Computer-aided-design (CAD) data are detailed sources for MEP BIM modeling. However, existing methods for MEP BIM are complex, leading to heavy reliance on manual intervention. This paper addresses this challenge by proposing an approach for generating MEP BIM models from CAD data. Graph structures are introduced to represent MEP systems, and multiple graph structures converted from CAD drawings are utilized to match pipeline components and aggregate dispersed information across various drawings. Based on the integrated pipeline graph, missing information is inferred and completed considering the relationships between components, ensuring detailed and accurate modeling results. Experiments on an actual factory case demonstrate the reliability and efficiency of this approach. This paper contributes to the MEP BIM theory by providing a perspective on interpreting MEP CAD data and a robust technical route of CAD-to-BIM conversion for MEP systems.'}, {'id': 'from_2d_cad', 'title': 'From 2D CAD Drawings to 3D Parametric Models: A Vision-Language Approach', 'URL': 'https://ojs.aaai.org/index.php/AAAI/article/view/32858', 'extra_urls': ['https://ojs.aaai.org/index.php/AAAI/article/view/32858'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Xilin'}, {'family': 'Zheng', 'given': 'Jia'}, {'family': 'Hu', 'given': 'Yuanchao'}, {'family': 'Zhu', 'given': 'Hao'}, {'family': 'Yu', 'given': 'Qian'}, {'family': 'Zhou', 'given': 'Zihan'}], 'abstract': 'In this paper, we present CAD2Program, a new method for reconstructing 3D parametric models from 2D CAD drawings. Our proposed method is inspired by recent successes in vision-language models (VLMs), and departs from traditional methods which rely on task-specific data representations and/or algorithms. Specifically, on the input side, we simply treat the 2D CAD drawing as a raster image, regardless of its original format, and encode the image with a standard ViT model. We show that such an encoding scheme achieves competitive performance against existing methods that operate on vector-graphics inputs, while imposing substantially fewer restrictions on the 2D drawings. On the output side, our method auto-regressively predicts a general-purpose language describing 3D parametric models in text form. Compared to other sequence modeling methods for CAD which use domain-specific sequence representations with fixed-size slots, our text-based representation is more flexible, and can be easily extended to arbitrary geometric entities and semantic or functional properties. Experimental results on a large-scale dataset of cabinet models demonstrate the effectiveness of our method.'}, {'id': 'a_lightweight', 'title': 'GuideCAD: A Lightweight Multimodal Framework for 3D CAD Model Generation via Prefix Embedding', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11146789', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11146789'], 'type': 'article', 'author': [{'family': 'Kim', 'given': 'Minseong'}, {'family': 'Park', 'given': 'Jinyeong'}, {'family': 'Park', 'given': 'Sungho'}, {'family': 'Kim', 'given': 'Jibum'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Multi-modal approaches used for 3D CAD generation require substantial computational resources, necessitating efficient training. To address this, we propose GuideCAD, which leverages semantically rich visual-textual representations having only a small number of trainable parameters to generate 3D CAD models. Specifically, GuideCAD uses a mapping network that converts image embeddings into prefix embeddings, enabling a pretrained large language model to integrate visual and textual information. As a result, a transformer-based decoder predicts the construction sequence using the visual-textual embeddings in order to generate the 3D CAD model. For experimental evaluation, we construct a new dataset, referred to as GuideCAD, which consists of text-image pairs. Each pair includes a text prompt that represents a 3D CAD construction sequence and its corresponding 3D CAD image. Our experimental results show that GuideCAD generates comparably high-quality 3D CAD models while using approximately four times fewer parameters and achieving twice the training efficiency compared to fine-tuning approaches. We have released the source code and dataset for our method at: https://github.com/mskimS2/GuideCAD'}, {'id': 'adaptive_method_of', 'title': 'Adaptive method of designing a swimsuit bra', 'URL': 'https://c-bulletin.com.ua/en/journals/tom-18-1-2025/adaptivny-metod-konstruyuvannya-byustgaltera-dlya-kupalnika', 'extra_urls': ['https://c-bulletin.com.ua/en/journals/tom-18-1-2025/adaptivny-metod-konstruyuvannya-byustgaltera-dlya-kupalnika'], 'type': 'article', 'author': [{'family': 'Slavinska', 'given': 'Alla'}, {'family': 'Matiukh', 'given': 'Serhii'}, {'family': 'Mytsa', 'given': 'Viktoriia'}, {'family': 'Dombrovska', 'given': '\u041eksana'}, {'family': 'Syrotenko', 'given': 'Oksana'}], 'abstract': 'The relevance of the research lies in the need to develop accurate and effective methods for designing swimwear bras, considering the elastic properties of modern knitted fabrics, which will enhance the comfort and quality of the products. The purpose of the study was to develop a method of adjusting the size of the bra cup to the amount of stretching using the method of geodetic parallels. The study employed methods of mathematical modelling for the development and optimisation of swimsuit bra cups design and analysed the mechanical properties of knitted materials. The study identified representative groups of elastic knitted fabrics based on the analysis of their tensile characteristics. Two primary groups of fabrics were identified based on their fibrous composition: the first group consisted of polyamide threads blended with elastane, while the second group comprised polyester threads combined with elastane. Anthropomorphic factors affecting the inaccuracies in the unfolding of the hard surface of the cup have been identified. Recommendations have been developed for transforming the rigid unfolding into a soft shell of moulded cup parts, considering discrete elongations of knitted materials. The soft-shell construction method was based on recalculating the main dimensions of the cup, taking into account the deformation coefficients of the materials. The effectiveness of the proposed method was confirmed by comparing the deviation&amp;nbsp;&amp;nbsp;areas of the moulded cup sweeps of the basic design. The deviation of the area of 3.56% indicated the compliance of the rigid sweep with the breast surface. Mathematical models of modification methods for four types of bra cup separation have been developed. The practical value lies in the use of an effective method of designing swimwear bras that ensures precise fit and comfort by considering the elastic properties of knitted materials'}, {'id': 'doi_10_1177_14780771251353791', 'title': 'From NURBS to neural networks: Efficient geometry encoding for generative AI in architectural design', 'URL': 'https://doi.org/10.1177/14780771251353791', 'extra_urls': ['https://doi.org/10.1177/14780771251353791'], 'type': 'article', 'author': [{'family': 'Sebestyen', 'given': 'Adam'}, {'family': 'Wiltsche', 'given': 'Albert'}, {'family': 'Stavric', 'given': 'Milena'}, {'family': '\xd6zdenizci', 'given': 'Ozan'}], 'abstract': 'The existing 3D representations for AI models, such as meshes, voxels, signed distance functions, and point clouds, are not compatible with architectural design workflows that rely on NURBS geometry, which is mainly used in CAD programs. \u200bThese formats lead to large datasets, high computational costs, and loss of geometric precision, limiting further usability in CAD software. This research introduces a novel methodology for encoding NURBS geometries into compact, tensor-based NumPy data for training generative AI models and vice versa. Our methodology involves the design of comparative experiments, the comparison of NURBS tensor representations with other 3D representations, and the use of reconstruction accuracy as a key metric to evaluate performance. \u200bCustom components for the Rhinoceros 3D parametric environment Grasshopper were developed enabling bidirectional conversion between NURBS geometry and NumPy tensors. These components are being released as a Grasshopper plugin under the name Wiener Dog as a free download. \u200bOur approach maintains geometric accuracy, reduces data size, and integrates seamlessly with existing deep learning libraries. \u200bThe proposed methodology was tested on datasets of helicoid surfaces and lofted polysurfaces, demonstrating high reconstruction accuracy and generative potential. The ultimate aim is to build an AI tool that aids in exploring the great variety of geometric forms for architectural design.', 'DOI': '10.1177/14780771251353791'}, {'id': 'implicit_relevance_inference', 'title': 'Implicit relevance inference for assembly CAD model retrieval based on design correlation representation', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0097849325000615', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0097849325000615'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Yixuan'}, {'family': 'Ji', 'given': 'Baoning'}, {'family': 'Zhang', 'given': 'Jie'}, {'family': 'Pang', 'given': 'Jiazhen'}, {'family': 'Li', 'given': 'Weibo'}], 'abstract': 'Assembly retrieval is a crucial technology for leveraging the extensive design knowledge embedded in CAD product instances. Current methods predominantly employ pairwise similarity measurements, which treat each product model as an isolated entity and overlook the intricate design correlations that reveal high-level design development relationships. To enhance the comprehension of product design correlations within retrieval systems, this paper introduces a novel method for implicit relevance inference in assembly retrieval based on design correlation. We define a part co-occurring relationship to capture the design correlations among assemblies by clustering parts based on shape similarity. At a higher level, all assemblies in the database are constructed as a multiple correlation network based on hypergraph, where the hyperedges represent the part co-occurring relationships. For a given query assembly, the implicit relevance between the query and other assemblies can be calculated by network structure inference. The problem is solved by using a random walk algorithm on the assembly hypergraph network. Comprehensive experiments have shown the effectiveness of the proposed assembly retrieval approach. The proposed method can be seen as an extension of existing pairwise similarity retrieval by further considering assembly relevance, which shows it has versatility and can enhance the effectiveness of existing pairwise similarity retrieval methods.'}, {'id': 'harnessing_unsupervised_learning', 'title': 'Harnessing unsupervised learning for retrieving CAD assembly models from public datasets', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1474034625000758', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1474034625000758'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Yixuan'}, {'family': 'Zhang', 'given': 'Jie'}, {'family': 'Pang', 'given': 'Jiazhen'}, {'family': 'Yao', 'given': 'Ya'}], 'abstract': 'Retrieving assembly models from public datasets can yield enriched outcomes and broaden the spectrum of insights. However, public datasets often present unique challenges, such as variance in quality and granularity of assembly models, lack of standardized methods for organizing and labeling, which hinder efficient and accurate retrieval. To address these issues, this paper presents a robust two-step retrieval method tailored for CAD assembly models from public datasets. The first phase utilizes hierarchical clustering in an unsupervised learning framework to systematically organize CAD assembly models. Each assembly model is represented by a feature vector that encapsulates geometrical and topological features derived from its Boundary Representation (B-rep), and reflects hierarchical relationships among parts and components. These feature vectors serve as the basis for systematic indexing via hierarchical clustering, grouping models based on similarity measurement. Each cluster\u2019s centroid, representing the collective feature vector, facilitates efficient and targeted retrieval. In the second phase, the query model is directly compared to cluster centroids, enabling rapid identification of similar assembly collections. To enhance precision within identified clusters, we introduce a fine-grained retrieval technique that integrates Optimal Subsequence Bijection (OSB) with Maximum Mean Discrepancy (MMD). Evaluations on a heterogeneous dataset demonstrate that our method not only streamlines dataset organization but also effectively addresses quality variations, significantly improving retrieval efficiency across extensive collections.'}, {'id': 'geometric_deep_learning', 'title': 'Geometric Deep Learning for Computer-Aided Design: A Survey', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11075586', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11075586'], 'type': 'article', 'author': [{'family': 'Heidari', 'given': 'Negar'}, {'family': 'Iosifidis', 'given': 'Alexandros'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Geometric Deep Learning techniques have become a transformative force in the field of Computer-Aided Design (CAD), and have the potential to revolutionize how designers and engineers approach and enhance the design process. By harnessing the power of machine learning-based methods, CAD designers can optimize their workflows, save time and effort while making better informed decisions, and create designs that are both innovative and practical. The ability to process the CAD designs represented by geometric data and to analyze their encoded features enables the identification of similarities among diverse CAD models, the proposition of alternative designs and enhancements, and even the generation of novel design alternatives. This survey offers a comprehensive overview of learning-based methods in computer-aided design across various categories, including similarity analysis and retrieval, 2D and 3D CAD model synthesis, and CAD generation from point clouds, and single/multi-view images. Additionally, it provides a complete list of benchmark datasets and their characteristics, along with open-source codes that have propelled research in this domain. The final discussion delves into the challenges prevalent in this field, followed by potential future research directions in this rapidly evolving field.'}, {'id': 'doi_10_1115_1_4069276', 'title': 'GenCAD-Three-Dimensional: Computer-Aided Design Program Generation Using Multimodal Latent Space Alignment and Synthetic Dataset Balancing', 'URL': 'https://doi.org/10.1115/1.4069276', 'extra_urls': ['https://doi.org/10.1115/1.4069276'], 'type': 'article', 'author': [{'family': 'Yu', 'given': 'Nomi'}, {'family': 'Ferdous Alam', 'given': 'Md'}, {'family': 'Hart', 'given': 'A. John'}, {'family': 'Ahmed', 'given': 'Faez'}], 'abstract': 'Computer-aided design (CAD) programs, structured as parametric sequences of commands that compile into precise 3D geometries, are fundamental to accurate and efficient engineering design processes. Generating these programs from nonparametric data such as point clouds and meshes remains a crucial yet challenging task, typically requiring extensive manual intervention. Current deep generative models aimed at automating CAD generation are significantly limited by imbalanced and insufficiently large datasets, particularly those lacking representation for complex CAD programs. To address this, we introduce GenCAD-3D, a multimodal generative framework utilizing contrastive learning for aligning latent embeddings between CAD and geometric encoders, combined with latent diffusion models for CAD sequence generation and retrieval. In addition, we present SynthBal, a synthetic data augmentation strategy specifically designed to balance and expand datasets, notably enhancing representation of complex CAD geometries. Our experiments show that SynthBal significantly boosts reconstruction accuracy, reduces the generation of invalid CAD models, and markedly improves performance on high-complexity geometries, surpassing existing benchmarks. These advancements hold substantial implications for streamlining reverse engineering and enhancing automation in engineering design. We will publicly release our datasets and code, including a set of 51 3D-printed and laser-scanned parts on our project site.', 'DOI': '10.1115/1.4069276'}, {'id': 'doi_10_1145_3730842', 'title': 'HoLa: B-Rep Generation using a Holistic Latent Representation', 'URL': 'https://doi.org/10.1145/3730842', 'extra_urls': ['https://doi.org/10.1145/3730842'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Yilin'}, {'family': 'Xu', 'given': 'Duoteng'}, {'family': 'Yu', 'given': 'Xingyao'}, {'family': 'Xu', 'given': 'Xiang'}, {'family': 'Cohen-Or', 'given': 'Daniel'}, {'family': 'Zhang', 'given': 'Hao'}, {'family': 'Huang', 'given': 'Hui'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'We introduce a novel representation for learning and generating Computer-Aided Design (CAD) models in the form of boundary representations (B-Reps). Our representation unifies the continuous geometric properties of B-Rep primitives in different orders (e.g., surfaces and curves) and their discrete topological relations in a holistic latent (HoLa) space. This is based on the simple observation that the topological connection between two surfaces is intrinsically tied to the geometry of their intersecting curve. Such a prior allows us to reformulate topology learning in B-Reps as a geometric reconstruction problem in Euclidean space. Specifically, we eliminate the presence of curves, vertices, and all the topological connections in the latent space by learning to distinguish and derive curve geometries from a pair of surface primitives via a neural intersection network. To this end, our holistic latent space is only defined on surfaces but encodes a full B-Rep model, including the geometry of surfaces, curves, vertices, and their topological relations. Our compact and holistic latent space facilitates the design of a first diffusion-based generator to take on a large variety of inputs including point clouds, single/multi-view images, 2D sketches, and text prompts. Our method significantly reduces ambiguities, redundancies, and incoherences among the generated B-Rep primitives, as well as training complexities inherent in prior multi-step B-Rep learning pipelines, while achieving greatly improved validity rate over current state of the art: 82% vs. \u224850%.', 'DOI': '10.1145/3730842'}, {'id': 'doi_10_1177_00405175251360399', 'title': 'Transformative effect of 3D sampling technology for the ready-made garment industry: A review', 'URL': 'https://doi.org/10.1177/00405175251360399', 'extra_urls': ['https://doi.org/10.1177/00405175251360399'], 'type': 'article', 'author': [{'family': 'Baria', 'given': 'Badhon'}, {'family': 'Shahid', 'given': 'Md Abdus'}, {'family': 'Misra', 'given': 'Aditi'}, {'family': 'Hoque', 'given': 'Mohammad Bellal'}, {'family': 'Rahman', 'given': 'Md Mostafizur'}, {'family': 'Hossain', 'given': 'Md Delwar'}, {'family': 'Das', 'given': 'Dip'}], 'abstract': 'The increasing demand for sustainable and efficient manufacturing in the ready-made garment (RMG) industry has driven interest in digital solutions. This review article explores the effect of 3D sampling technology (i.e., CLO 3D, Optitex, Lectra, and Browzwear) over traditional physical sampling on reducing material waste, improving efficiency, and reducing costs. This study examines the role of digital sampling in addressing critical challenges within the garment manufacturing process, specifically focusing on efficiency, sustainability, and lead time. In the RMG sector of Bangladesh, these technologies have great potential due to their proven effectiveness in enhancing design precision and optimizing production workflows. However, challenges such as expensive setup costs, a lack of realistic materials, and training needs continue to be major problems. The current article offers a thorough review of the economic and environmental effects linked to 3D sampling. It also highlights key obstacles to adopting this technology and provides strategic recommendations aimed at industry 4.0 stakeholders.', 'DOI': '10.1177/00405175251360399'}, {'id': 'doi_10_1177_00405175251339102', 'title': 'Application of 3D digital technology in design practices within the circular fashion system: Implications for sustainability', 'URL': 'https://doi.org/10.1177/00405175251339102', 'extra_urls': ['https://doi.org/10.1177/00405175251339102'], 'type': 'article', 'author': [{'family': 'Liang', 'given': 'Jiaqi'}, {'family': 'Dong', 'given': 'Wentong'}, {'family': 'Suh', 'given': 'Seunghee'}], 'abstract': 'This study provides a systematic review of the application of 3D digital technologies (3DDT) in fashion design practice. The aim is to analyze how 3DDT alters traditional design processes and its effect on sustainability within the circular fashion system (CFS), exploring its core role and offering theoretical support and practical guidance for decision-makers and stakeholders in the fashion industry. The study addresses two key questions. 1. How does 3DDT apply to change design practices processes and enhance sustainability? 2. Within the CFS, what key challenges can 3DDT address to advance sustainability? Through a review of 30 peer-reviewed studies published between 2011 and 2024, the research highlights how 3DDT facilitating the advancement of different CFS prototypes by facilitating design\u2013production integration, diverse applications of sustainable materials, optimizing resource utilization, improving design accuracy, and enhancing communication. It demonstrates 3DDT\u2019s unique ability to break down barriers between the barrier between abstract thinking and visualized feedback, bridging the gap between creative visions, actual production materials and techniques, and consumption realities, thus fostering collaboration and communication among participants such designers, manufacturers, and consumers. By, 3DDT enhances the sustainable effect of design practices within the CFS, providing strong technical support for sustainable design\u2013production decision-making in the fashion industry.', 'DOI': '10.1177/00405175251339102'}, {'id': 'amazon_1138021016', 'title': 'Craft of Use: Post-Growth Fashion', 'URL': 'https://www.amazon.de/-/en/Craft-Use-Post-Growth-Kate-Fletcher/dp/1138021016', 'extra_urls': ['https://www.amazon.de/-/en/Craft-Use-Post-Growth-Kate-Fletcher/dp/1138021016'], 'type': 'book', 'author': [{'family': 'Fletcher', 'given': 'Kate'}], 'issued': {'date-parts': [[2016]]}, 'publisher': 'Routledge', 'abstract': &quot;This book explores the 'craft of use', the cultivated, ordinary and ingenious ideas and practices that promote satisfying and resourceful use of garments, presenting them as an alternative, dynamic, experiential frame with which to articulate and foster sustainability in the fashion sector.Here Kate Fletcher provides a broad imagination of sustainability in fashion that gives attention to tending and wearing garments, and favors their use as much as their creation. She offers a diversified view of fashion beyond the market and the market's purpose and reveals fashion provision and expression in a world not dependent on continuous consumption.Framing design and use as a single whole, the book uncovers a more contingent and time-dependent role for design in sustainability, recognizing that garments, while sold as a product, are lived as a process. Drawing from stories and portrait photography that document the ways in which members of the public from across three continents use their clothes, and the work of seven international design teams seeking to amplify these use practices, Craft of Use presents a changed social narrative for fashion, borne out of ideas of satisfaction and interdependence, of action, knowledge and human agency, that glimpses fashion post-growth.&quot;}, {'id': 'and', 'title': 'France\u2019s Anti-waste and Circular Economy Law', 'URL': 'https://www.ellenmacarthurfoundation.org/circular-examples/frances-anti-waste-and-circular-economy-law', 'extra_urls': ['https://www.ellenmacarthurfoundation.org/circular-examples/frances-anti-waste-and-circular-economy-law'], 'type': 'webpage', 'author': [{'family': 'Ellen MacArthur Foundation'}], 'abstract': 'France is shaping a system-wide transition towards a circular economy with an ambitious law'}, {'id': 'doi_10_1145_3731205', 'title': 'Offset Geometric Contact', 'URL': 'https://doi.org/10.1145/3731205', 'extra_urls': ['https://doi.org/10.1145/3731205'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Anka He'}, {'family': 'Hsu', 'given': 'Jerry'}, {'family': 'Liu', 'given': 'Ziheng'}, {'family': 'Macklin', 'given': 'Miles'}, {'family': 'Yang', 'given': 'Yin'}, {'family': 'Yuksel', 'given': 'Cem'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1145/3731205'}, {'id': 'reconstructing_inner', 'title': 'ClothingTwin: Reconstructing Inner and Outer Layers of Clothing Using 3D Gaussian Splatting', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.70240', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.70240'], 'type': 'article', 'author': [{'family': 'Jung', 'given': 'Munkyung'}, {'family': 'Lee', 'given': 'Dohae'}, {'family': 'Lee', 'given': 'In-Kwon'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'We introduce ClothingTwin, a novel end-to-end framework for reconstructing 3D digital twins of clothing that capture both the outer and inner fabric \u2014without the need for manual mannequin removal. Traditional 2D \u201cghost mannequin\u201d photography techniques remove the mannequin and composite partial inner textures to create images in which the garment appears as if it were worn by a transparent model. However, extending such method to photorealistic 3D Gaussian Splatting (3DGS) is far more challenging. Achieving consistent inner-layer compositing across the large sets of images used for 3DGS optimization quickly becomes impractical if done manually. To address these issues, ClothingTwin introduces three key innovations. First, a specialized image acquisition protocol captures two sets of images for each garment: one worn normally on the mannequin (outer layer exposed) and one worn inside-out (inner layer exposed). This eliminates the need to painstakingly edit out mannequins in thousands of images and provides full coverage of all fabric surfaces. Second, we employ a mesh-guided 3DGS reconstruction for each layer and leverage Non-Rigid Iterative Closest Point (ICP) to align outer and inner point-clouds despite distinct geometries. Third, our enhanced rendering pipeline\u2014featuring mesh-guided back-face culling, back-to-front alpha blending, and recalculated spherical harmonic angles\u2014ensures photorealistic visualization of the combined outer and inner layers without inter-layer artifacts. Experimental evaluations on various garments show that ClothingTwin outperforms conventional 3DGS-based methods, and our ablation study validates the effectiveness of each proposed component.'}, {'id': 'summoning', 'title': 'We\u2019re summoning ghosts, not building animals', 'URL': 'https://www.youtube.com/watch?v=lXUZvyajciY', 'extra_urls': ['https://www.youtube.com/watch?v=lXUZvyajciY'], 'type': 'article', 'abstract': 'The Andrej Karpathy episode. During this interview, Andrej explains why reinforcement learning is terrible (but everything else is much worse), why AGI will just blend into the previous ~2.5 centuries of 2% GDP growth, why self driving took so long to crack, and what he sees as the future of education. It was a pleasure chatting with him.'}, {'id': 'managing_large', 'title': 'LLMOps: Managing Large Language Models in Production', 'URL': 'urn:isbn:978-1-0981-5420-2', 'type': 'book', 'author': [{'family': 'Aryan', 'given': 'Abi'}, {'family': 'Meyer', 'given': 'Lucas'}], 'issued': {'date-parts': [[2025]]}, 'publisher': &quot;O'Reilly Media&quot;, 'abstract': &quot;Here's the thing about large language models: they don't play by the old rules. Traditional MLOps completely falls apart when you're dealing with GenAI. The model hallucinates, security assumptions crumble, monitoring breaks, and agents can't operate. Suddenly you're in uncharted territory. That's exactly why LLMOps has emerged as its own discipline.   LLMOps: Managing Large Language Models in Production is your guide to actually running these systems when real users and real money are on the line. This book isn't about building cool demos. It's about keeping LLM systems running smoothly in the real world.Navigate the new roles and processes that LLM operations require Monitor LLM performance when traditional metrics don't tell the whole story Set up evaluations, governance, and security audits that actually matter for GenAI Wrangle the operational mess of agents, RAG systems, and evolving prompts Scale infrastructure without burning through your compute budget&quot;}, {'id': 'doi_10_1016_j_bcra_2024_100266', 'title': 'Blockchain-driven innovation in fashion supply chain contractual party evaluations as an emerging collaboration model', 'URL': 'https://doi.org/10.1016/j.bcra.2024.100266', 'extra_urls': ['https://doi.org/10.1016/j.bcra.2024.100266'], 'type': 'article', 'author': [{'family': 'Qiao', 'given': 'Minhao'}, {'family': 'Chen', 'given': 'Xuanchang'}, {'family': 'Zhou', 'given': 'Yangping'}, {'family': 'Mok', 'given': 'P.Y.'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1016/j.bcra.2024.100266'}, {'id': 'doi_10_1080_21681015_2016_1172124', 'title': 'Product design and business model strategies for a circular economy', 'URL': 'https://doi.org/10.1080/21681015.2016.1172124', 'extra_urls': ['https://doi.org/10.1080/21681015.2016.1172124'], 'type': 'article', 'author': [{'family': 'Bocken', 'given': 'Nancy M. P.'}, {'family': 'de Pauw', 'given': 'Ingrid'}, {'family': 'Bakker', 'given': 'Conny'}, {'family': 'van der Grinten', 'given': 'Bram'}], 'issued': {'date-parts': [[2016]]}, 'DOI': '10.1080/21681015.2016.1172124'}, {'id': 'doi_10_1016_j_buildenv_2023_110432', 'title': &quot;Modular construction's capacity to reduce embodied carbon emissions in California's housing sector&quot;, 'URL': 'https://doi.org/10.1016/j.buildenv.2023.110432', 'extra_urls': ['https://doi.org/10.1016/j.buildenv.2023.110432'], 'type': 'article', 'author': [{'family': 'Greer', 'given': 'Fiona'}, {'family': 'Horvath', 'given': 'Arpad'}], 'issued': {'date-parts': [[2023]]}, 'DOI': '10.1016/j.buildenv.2023.110432'}, {'id': 'doi_10_1007_s10551-023-05569-9', 'title': 'Exercising the \u201cRight to Repair\u201d: A Customer\u2019s Perspective', 'URL': 'https://doi.org/10.1007/s10551-023-05569-9', 'extra_urls': ['https://doi.org/10.1007/s10551-023-05569-9'], 'type': 'article', 'author': [{'family': 'Marikyan', 'given': 'Davit'}, {'family': 'Papagiannidis', 'given': 'Savvas'}], 'issued': {'date-parts': [[2023]]}, 'DOI': '10.1007/s10551-023-05569-9'}, {'id': 'doi_10_1016_j_joi_2020_101094', 'title': 'The pace of artificial intelligence innovations: Speed, talent, and trial-and-error', 'URL': 'https://doi.org/10.1016/j.joi.2020.101094', 'extra_urls': ['https://doi.org/10.1016/j.joi.2020.101094'], 'type': 'article', 'author': [{'family': 'Tang', 'given': 'Xuli'}, {'family': 'Li', 'given': 'Xin'}, {'family': 'Ding', 'given': 'Ying'}, {'family': 'Song', 'given': 'Min'}, {'family': 'Bu', 'given': 'Yi'}], 'issued': {'date-parts': [[2020]]}, 'DOI': '10.1016/j.joi.2020.101094'}, {'id': 'doi_10_1145_3706598_3714001', 'title': 'Exploring Assumptions about Sustainability: Towards a Constructive Framework for Action in Sustainable HCI', 'URL': 'https://doi.org/10.1145/3706598.3714001', 'extra_urls': ['https://doi.org/10.1145/3706598.3714001'], 'type': 'article', 'author': [{'family': 'Laurell Thorslund', 'given': 'Minna'}, {'family': 'Leifler', 'given': 'Ola'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1145/3706598.3714001'}, {'id': 'doi_10_1145_3706598_3713663', 'title': 'Sustainability, Development, and Human\u2013Computer Interaction', 'URL': 'https://doi.org/10.1145/3706598.3713663', 'extra_urls': ['https://doi.org/10.1145/3706598.3713663'], 'type': 'article', 'author': [{'family': 'Sharma', 'given': 'Vishal'}, {'family': 'Kumar', 'given': 'Neha'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1145/3706598.3713663'}, {'id': 'doi_10_1007_978-3-031-84628-1_12', 'title': 'The Role of Platform Economies in Contributing to Innovation and Entrepreneurship Within Digital Ecosystems: A Systematic Literature Review', 'URL': 'https://doi.org/10.1007/978-3-031-84628-1_12', 'extra_urls': ['https://doi.org/10.1007/978-3-031-84628-1_12'], 'type': 'article', 'author': [{'family': 'Ayob', 'given': 'Muhammad'}, {'family': 'Hattingh', 'given': 'Marie'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1007/978-3-031-84628-1_12'}, {'id': 'doi_10_3390_su9010039', 'title': 'The Effect of Elite Polarization: A Comparative Perspective on How Party Elites Influence Attitudes and Behavior on Climate Change in the European Union', 'URL': 'https://doi.org/10.3390/su9010039', 'extra_urls': ['https://doi.org/10.3390/su9010039'], 'type': 'article', 'author': [{'family': 'Sohlberg', 'given': 'Jacob'}], 'issued': {'date-parts': [[2016]]}, 'DOI': '10.3390/su9010039'}, {'id': 'doi_10_1038_s43017-020-0039-9', 'title': 'The environmental price of fast fashion', 'URL': 'https://doi.org/10.1038/s43017-020-0039-9', 'extra_urls': ['https://doi.org/10.1038/s43017-020-0039-9'], 'type': 'article', 'author': [{'family': 'Niinim\xe4ki', 'given': 'Kirsi'}, {'family': 'Peters', 'given': 'Greg'}, {'family': 'Dahlbo', 'given': 'Helena'}, {'family': 'Perry', 'given': 'Patsy'}, {'family': 'Rissanen', 'given': 'Timo'}, {'family': 'Gwilt', 'given': 'Alison'}], 'issued': {'date-parts': [[2020]]}, 'DOI': '10.1038/s43017-020-0039-9'}, {'id': 'doi_10_1007_s11280-024-01276-1', 'title': 'When large language models meet personalization: perspectives of challenges and opportunities', 'URL': 'https://doi.org/10.1007/s11280-024-01276-1', 'extra_urls': ['https://doi.org/10.1007/s11280-024-01276-1'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Jin'}, {'family': 'Liu', 'given': 'Zheng'}, {'family': 'Huang', 'given': 'Xu'}, {'family': 'Wu', 'given': 'Chenwang'}, {'family': 'Liu', 'given': 'Qi'}, {'family': 'Jiang', 'given': 'Gangwei'}, {'family': 'Pu', 'given': 'Yuanhao'}, {'family': 'Lei', 'given': 'Yuxuan'}, {'family': 'Chen', 'given': 'Xiaolong'}, {'family': 'Wang', 'given': 'Xingmei'}, {'family': 'Zheng', 'given': 'Kai'}, {'family': 'Lian', 'given': 'Defu'}, {'family': 'Chen', 'given': 'Enhong'}], 'abstract': 'The advent of large language models marks a revolutionary breakthrough in artificial intelligence. With the unprecedented scale of training and model parameters, the capability of large language models has been dramatically improved, leading to human-like performances in understanding, language synthesizing, common-sense reasoning, etc. Such a major leap forward in general AI capacity will fundamentally change the pattern of how personalization is conducted. For one thing, it will reform the way of interaction between humans and personalization systems. Instead of being a passive medium of information filtering, like conventional recommender systems and search engines, large language models present the foundation for active user engagement. On top of such a new foundation, users\u2019 requests can be proactively explored, and users\u2019 required information can be delivered in a natural, interactable, and explainable way. For another thing, it will also considerably expand the scope of personalization, making it grow from the sole function of collecting personalized information to the compound function of providing personalized services. By leveraging large language models as a general-purpose interface, the personalization systems may compile user\u2019s requests into plans, calls the functions of external tools (e.g., search engines, calculators, service APIs, etc.) to execute the plans, and integrate the tools\u2019 outputs to complete the end-to-end personalization tasks. Today, large language models are still being rapidly developed, whereas the application in personalization is largely unexplored. Therefore, we consider it to be right the time to review the challenges in personalization and the opportunities to address them with large language models. In particular, we dedicate this perspective paper to the discussion of the following aspects: the development and challenges for the existing personalization system, the newly emerged capabilities of large language models, and the potential ways of making use of large language models for personalization.', 'DOI': '10.1007/s11280-024-01276-1'}, {'id': 'doi_10_1177_23794607251347020', 'title': 'The governance &amp; behavioral challenges of generative artificial intelligence\u2019s hypercustomization capabilities', 'URL': 'https://doi.org/10.1177/23794607251347020', 'extra_urls': ['https://doi.org/10.1177/23794607251347020'], 'type': 'article', 'author': [{'family': 'Abels', 'given': 'Christoph M.'}, {'family': 'Lopez-Lopez', 'given': 'Ezequiel'}, {'family': 'Burton', 'given': 'Jason W.'}, {'family': 'Holford', 'given': 'Dawn L.'}, {'family': 'Brinkmann', 'given': 'Levin'}, {'family': 'Herzog', 'given': 'Stefan M.'}, {'family': 'Lewandowsky', 'given': 'Stephan'}], 'abstract': 'Generative artificial intelligence (GenAI) is changing human\u2013machine interactions and the broader information ecosystem. Much as social media algorithms personalize online experiences, GenAI applications can align with user preferences to customize the way individuals interact with information. However, through training, fine-tuning, and prompting, GenAI applications can introduce a new level of customization: hypercustomization. By dynamically tailoring responses to an individual\u2019s explicit and implicit preferences, hypercustomization can reinforce biases, false beliefs, or misconceptions. As a result, it can heighten significant societal challenges, such as the spread of misinformation and political and social polarization. In this article, we explore the risks associated with hypercustomization and the governance and behavioral challenges that might impede effective risk mitigation. These challenges include a lack of transparency in GenAI applications, opacity of the nature of their interactions with users, users\u2019 overreliance on these systems, and the inefficacy of warning messages. We also provide recommendations for overcoming these challenges.', 'DOI': '10.1177/23794607251347020'}, {'id': 'data_harmonization_and', 'title': 'Data harmonization and federated learning for multi-cohort dementia research using the OMOP common data model: A Netherlands consortium of dementia cohorts case study', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1532046424000790', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1532046424000790'], 'type': 'article', 'author': [{'family': 'Mateus', 'given': 'Pedro'}, {'family': 'Moonen', 'given': 'Justine'}, {'family': 'Beran', 'given': 'Magdalena'}, {'family': 'Jaarsma', 'given': 'Eva'}, {'family': 'van der Landen', 'given': 'Sophie M.'}, {'family': 'Heuvelink', 'given': 'Joost'}, {'family': 'Birhanu', 'given': 'Mahlet'}, {'family': 'Harms', 'given': 'Alexander G. J.'}, {'family': 'Bron', 'given': 'Esther'}, {'family': 'Wolters', 'given': 'Frank J.'}, {'family': 'Cats', 'given': 'Davy'}, {'family': 'Mei', 'given': 'Hailiang'}, {'family': 'Oomens', 'given': 'Julie'}, {'family': 'Jansen', 'given': 'Willemijn'}, {'family': 'Schram', 'given': 'Miranda T.'}, {'family': 'Dekker', 'given': 'Andre'}, {'family': 'Bermejo', 'given': 'Inigo'}], 'abstract': 'Background\nEstablishing collaborations between cohort studies has been fundamental for progress in health research. However, such collaborations are hampered by heterogeneous data representations across cohorts and legal constraints to data sharing. The first arises from a lack of consensus in standards of data collection and representation across cohort studies and is usually tackled by applying data harmonization processes. The second is increasingly important due to raised awareness for privacy protection and stricter regulations, such as the GDPR. Federated learning has emerged as a privacy-preserving alternative to transferring data between institutions through analyzing data in a decentralized manner.\nMethods\nIn this study, we set up a federated learning infrastructure for a consortium of nine Dutch cohorts with appropriate data available to the etiology of dementia, including an extract, transform, and load (ETL) pipeline for data harmonization. Additionally, we assessed the challenges of transforming and standardizing cohort data using the Observational Medical Outcomes Partnership (OMOP) common data model (CDM) and evaluated our tool in one of the cohorts employing federated algorithms.\nResults\nWe successfully applied our ETL tool and observed a complete coverage of the cohorts\u2019 data by the OMOP CDM. The OMOP CDM facilitated the data representation and standardization, but we identified limitations for cohort-specific data fields and in the scope of the vocabularies available. Specific challenges arise in a multi-cohort federated collaboration due to technical constraints in local environments, data heterogeneity, and lack of direct access to the data.\nConclusion\nIn this article, we describe the solutions to these challenges and limitations encountered in our study. Our study shows the potential of federated learning as a privacy-preserving solution for multi-cohort studies that enhance reproducibility and reuse of both data and analyses.'}, {'id': 'federated_graph_neural', 'title': 'Federated graph neural network for privacy-preserved supply chain data sharing', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1568494624012493', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1568494624012493'], 'type': 'article', 'author': [{'family': 'Tang', 'given': 'Xiaochuan'}, {'family': 'Wang', 'given': 'Yu'}, {'family': 'Liu', 'given': 'Xin'}, {'family': 'Yuan', 'given': 'Xiaojun'}, {'family': 'Fan', 'given': 'Chao'}, {'family': 'Hu', 'given': 'Yanmei'}, {'family': 'Miao', 'given': 'Qiang'}], 'abstract': 'Machine learning plays an increasingly important role in supply chain management. Due to privacy and security concerns, enterprises are reluctant to share their raw data, which leads to missing links in supply chains. To address privacy issue and promote data sharing in supply chain, we propose a new federated graph neural network named Isomorphic Federated Graph Neural Network (IFGNN) for supply chain data sharing. IFGNN consists of a server and multiple clients. The server is a lightweight parameter server with an efficient parameter updating algorithm. A client is assigned to each node in the supply chain network. Every supplier client is linked to its first-order neighbors, which means they have supply\u2013demand relationship. The topology of the input network is identical to that of the supplier clients. Experimental results on a newly collected vehicle supply chain dataset show that the performance of IFGNN is close to its centralized counterpart. This work demonstrates that it is feasible to protect supply chain data privacy without a significant loss of prediction accuracy. Federated learning provides a new solution for promoting data sharing and collaborative machine learning in supply chain.'}, {'id': 'arxiv_2505.10468', 'title': 'AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges', 'URL': 'http://arxiv.org/abs/2505.10468', 'extra_urls': ['http://arxiv.org/abs/2505.10468'], 'type': 'article', 'author': [{'family': 'Sapkota', 'given': 'Ranjan'}, {'family': 'Roumeliotis', 'given': 'Konstantinos I.'}, {'family': 'Karkee', 'given': 'Manoj'}], 'abstract': 'This review critically distinguishes between AI Agents and Agentic AI, offering a structured, conceptual taxonomy, application mapping, and analysis of opportunities and challenges to clarify their divergent design philosophies and capabilities. We begin by outlining the search strategy and foundational definitions, characterizing AI Agents as modular systems driven and enabled by LLMs and LIMs for task-specific automation. Generative AI is positioned as a precursor providing the foundation, with AI agents advancing through tool integration, prompt engineering, and reasoning enhancements. We then characterize Agentic AI systems, which, in contrast to AI Agents, represent a paradigm shift marked by multi-agent collaboration, dynamic task decomposition, persistent memory, and coordinated autonomy. Through a chronological evaluation of architectural evolution, operational mechanisms, interaction styles, and autonomy levels, we present a comparative analysis across both AI agents and agentic AI paradigms. Application domains enabled by AI Agents such as customer support, scheduling, and data summarization are then contrasted with Agentic AI deployments in research automation, robotic coordination, and medical decision support. We further examine unique challenges in each paradigm including hallucination, brittleness, emergent behavior, and coordination failure, and propose targeted solutions such as ReAct loops, retrieval-augmented generation (RAG), automation coordination layers, and causal modeling. This work aims to provide a roadmap for developing robust, scalable, and explainable AI-driven systems.'}, {'id': 'doi_10_1145_3686803', 'title': 'Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap', 'URL': 'https://doi.org/10.1145/3686803', 'extra_urls': ['https://doi.org/10.1145/3686803'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Jialong'}, {'family': 'Zhang', 'given': 'Mingyue'}, {'family': 'Li', 'given': 'Nianyu'}, {'family': 'Weyns', 'given': 'Danny'}, {'family': 'Jin', 'given': 'Zhi'}, {'family': 'Tei', 'given': 'Kenji'}], 'issued': {'date-parts': [[2024]]}, 'abstract': 'Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this article aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI\u2019s within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.\u2020', 'DOI': '10.1145/3686803'}, {'id': 'doi_10_1007_s10458-020-09489-0', 'title': 'Enabling scalable and fault-tolerant multi-agent systems by utilizing cloud-native computing', 'URL': 'https://doi.org/10.1007/s10458-020-09489-0', 'extra_urls': ['https://doi.org/10.1007/s10458-020-09489-0'], 'type': 'article', 'author': [{'family': 'D\xe4hling', 'given': 'Stefan'}, {'family': 'Razik', 'given': 'Lukas'}, {'family': 'Monti', 'given': 'Antonello'}], 'abstract': 'Multi-agent systems (MAS) represent a distributed computing paradigm well suited to tackle today\u2019s challenges in the field of the Internet of Things (IoT). Both share many similarities such as the interconnection of distributed devices and their cooperation. The combination of MAS and IoT would allow the transfer of the experience gained in MAS research to the broader range of IoT applications. The key enabler for utilizing MAS in the IoT is the ability to build large-scale and fault-tolerant MASs since IoT concepts comprise possibly thousands or even millions of devices. However, well known multi-agent platforms (MAP), e.\xa0g., Java Agent DE-velopment Framework (JADE), are not able to deal with these challenges. To this aim, we present a cloud-native Multi-Agent Platform (cloneMAP) as a modern MAP based on cloud-computing techniques to enable scalability and fault-tolerance. A microservice architecture is used to implement it in a distributed way utilizing the open-source container orchestration system Kubernetes. Thereby, bottlenecks and single-points of failure are conceptually avoided. A comparison with JADE via relevant performance metrics indicates the massively improved scalability. Furthermore, the implementation of a large-scale use case verifies cloneMAP\u2019s suitability for IoT applications. This leads to the conclusion that cloneMAP extends the range of possible MAS applications and enables the integration with IoT concepts.', 'DOI': '10.1007/s10458-020-09489-0'}, {'id': 'doi_10_1186_s40537-025-01099-5', 'title': 'Adapting security and decentralized knowledge enhancement in federated learning using blockchain technology: literature review', 'URL': 'https://doi.org/10.1186/s40537-025-01099-5', 'extra_urls': ['https://doi.org/10.1186/s40537-025-01099-5'], 'type': 'article', 'author': [{'family': 'Orabi', 'given': 'Menna Mamdouh'}, {'family': 'Emam', 'given': 'Osama'}, {'family': 'Fahmy', 'given': 'Hanan'}], 'abstract': 'Federated Learning (FL) is a promising form of distributed machine learning that preserves privacy by training models locally without sharing raw data. While FL ensures data privacy through collaborative learning, it faces several critical challenges. These include vulnerabilities to reverse engineering, risks to model architecture privacy, susceptibility to model poisoning attacks, threats to data integrity, and the high costs associated with communication and connectivity. This paper presents a comprehensive review of FL, categorizing data partitioning formats into horizontal federated learning, vertical federated learning, and federated transfer learning. Furthermore, it explores the integration of FL with blockchain, leveraging blockchain\u2019s decentralized nature to enhance FL\u2019s security, reliability, and performance. The study reviews existing FL models, identifying key challenges such as privacy risks, communication overhead, model poisoning vulnerabilities, and ethical dilemmas. It evaluates privacy-preserving mechanisms and security strategies in FL, particularly those enabled by blockchain, such as cryptographic methods, decentralized consensus protocols, and tamper-proof data logging. Additionally, the research analyzes regulatory and ethical considerations for adopting blockchain-based FL solutions. Key findings highlight the effectiveness of blockchain in addressing FL challenges, particularly in mitigating model poisoning, ensuring data integrity, and reducing communication costs. The paper concludes with future directions for integrating blockchain and FL, emphasizing areas such as interoperability, lightweight consensus mechanisms, and regulatory compliance.', 'DOI': '10.1186/s40537-025-01099-5'}, {'id': 'arxiv_2207.09708', 'title': 'RV4JaCa -- Runtime Verification for Multi-Agent Systems', 'URL': 'http://arxiv.org/abs/2207.09708', 'extra_urls': ['http://arxiv.org/abs/2207.09708'], 'type': 'article', 'author': [{'family': 'Engelmann', 'given': 'Debora C.'}, {'family': 'Ferrando', 'given': 'Angelo'}, {'family': 'Panisson', 'given': 'Alison R.'}, {'family': 'Ancona', 'given': 'Davide'}, {'family': 'Bordini', 'given': 'Rafael H.'}, {'family': 'Mascardi', 'given': 'Viviana'}], 'abstract': 'This paper presents a Runtime Verification (RV) approach for Multi-Agent Systems (MAS) using the JaCaMo framework. Our objective is to bring a layer of security to the MAS. This layer is capable of controlling events during the execution of the system without needing a specific implementation in the behaviour of each agent to recognise the events. MAS have been used in the context of hybrid intelligence. This use requires communication between software agents and human beings. In some cases, communication takes place via natural language dialogues. However, this kind of communication brings us to a concern related to controlling the flow of dialogue so that agents can prevent any change in the topic of discussion that could impair their reasoning. We demonstrate the implementation of a monitor that aims to control this dialogue flow in a MAS that communicates with the user through natural language to aid decision-making in hospital bed allocation.'}, {'id': 'doi_10_1007_s10845-024-02424-0', 'title': 'A reference framework for the digital twin smart factory based on cloud-fog-edge computing collaboration', 'URL': 'https://doi.org/10.1007/s10845-024-02424-0', 'extra_urls': ['https://doi.org/10.1007/s10845-024-02424-0'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Zhiyuan'}, {'family': 'Mei', 'given': 'Xuesong'}, {'family': 'Sun', 'given': 'Zheng'}, {'family': 'Xu', 'given': 'Jun'}, {'family': 'Zhang', 'given': 'Jianchen'}, {'family': 'Zhang', 'given': 'Dawei'}, {'family': 'Zhu', 'given': 'Jingyi'}], 'abstract': 'Digital twin (DT) is an important approach for the factory to achieve intelligence. Due to the different scenarios and definitions, the generalization of frameworks for DT-based smart factories is weak, slowing down the overall process of industrial intelligence. Meanwhile, the pressure of data transmission and processing increases dramatically because of data explosion, which poses a challenge to the rational allocation of computing resources. In addition, more advanced strategies for training and running models are needed to support more sophisticated services. This paper proposes a reference framework that combines DT and cloud-fog-edge computing collaboration (CFE). First, the DT fuses physical and virtual spaces. The virtual-real fusion provides more information for operations, and the virtual space gives more accurate and timely decisions based on the constantly refreshed state. Secondly, by introducing CFE, suitable operating platforms for each layer of the DT-based smart factory are set, which enhances data interaction and reduces the dependence on cloud computing. The DT-CFE framework is well generalized. This paper first introduces the definition of the DT-based smart factory and its components. Then the methodology of the DT-CFE-based smart factory is proposed, and the network topology and operation mechanism are introduced. In this framework, the transmission and response performance of its data interaction is tested, and the interference of dynamic events occurring through scheduling is studied to illustrate the effectiveness and superiority of the framework.', 'DOI': '10.1007/s10845-024-02424-0'}, {'id': 'big_data_driven', 'title': 'Big data driven Hierarchical Digital Twin Predictive Remanufacturing paradigm: Architecture, control mechanism, application scenario and benefits', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0959652619341691', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0959652619341691'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Yankai'}, {'family': 'Wang', 'given': 'Shilong'}, {'family': 'Yang', 'given': 'Bo'}, {'family': 'Zhu', 'given': 'Lingzi'}, {'family': 'Liu', 'given': 'Feng'}], 'abstract': 'Remanufacturing is deemed to be an effective method for recycling resources, achieving sustainable production. However, little importance of remanufacturing has been attached in PLM. Surely, there are many problems in implementation of the remanufacturing strategy, such as inability to effectively reduce uncertainty, lack of product multi-life-cycle remanufacturing process tracking management, lack of smart enabling technology application in the full lifecycle that focusing on multi-life-cycle remanufacturing. After analyzing the reasons, through integrating smart enabling technologies, a new PLM paradigm focusing on the multi-life-cycle remanufacturing process: Big Data driven Hierarchical Digital Twin Predictive Remanufacturing (BDHDTPREMfg) is proposed. And the definition of BDHDTPREMfg is proposed. A big data driven layered architecture and the hierarchical CPS-Digital-Twin(CPSDT) reconfiguration control mechanism of BDHDTPREMfg are respectively developed. Then, this paper presents an application scenario of BDHDTPREMfg to validate the feasibility and effectiveness. Based on the above application analysis, the benefits of penetrating BDHDTPREMfg into the entire lifecycle are demonstrated. The summary of this paper and future research work is discussed in the end.'}, {'id': 'the_role_of', 'title': 'The role of complexity for digital twins of cities', 'URL': 'https://www.nature.com/articles/s43588-023-00431-4', 'extra_urls': ['https://www.nature.com/articles/s43588-023-00431-4'], 'type': 'article', 'author': [{'family': 'Caldarelli', 'given': 'G.'}, {'family': 'Arcaute', 'given': 'E.'}, {'family': 'Barthelemy', 'given': 'M.'}, {'family': 'Batty', 'given': 'M.'}, {'family': 'Gershenson', 'given': 'C.'}, {'family': 'Helbing', 'given': 'D.'}, {'family': 'Mancuso', 'given': 'S.'}, {'family': 'Moreno', 'given': 'Y.'}, {'family': 'Ramasco', 'given': 'J. J.'}, {'family': 'Rozenblat', 'given': 'C.'}, {'family': 'S\xe1nchez', 'given': 'A.'}, {'family': 'Fern\xe1ndez-Villaca\xf1as', 'given': 'J. L.'}], 'abstract': 'We argue that theories and methods drawn from complexity science are urgently needed to guide the development and use of digital twins for cities. The theoretical framework from complexity science takes into account both the short-term and the long-term dynamics of cities and their interactions. This is the foundation for a new approach that treats cities not as large machines or logistic systems but as mutually interwoven self-organizing phenomena, which evolve, to an extent, like living systems.'}, {'id': 'doi_10_1038_s43588-024-00603-w', 'title': 'Advancements and challenges of digital twins in industry', 'URL': 'https://doi.org/10.1038/s43588-024-00603-w', 'extra_urls': ['https://doi.org/10.1038/s43588-024-00603-w'], 'type': 'article', 'author': [{'family': 'Tao', 'given': 'Fei'}, {'family': 'Zhang', 'given': 'He'}, {'family': 'Zhang', 'given': 'Chenyuan'}], 'abstract': 'Digital twins, which are considered an effective approach to realize the fusion between virtual and physical spaces, have attracted a substantial amount of attention in the past decade. With their rapid development in recent years, digital twins have been applied in various fields, particularly in industry. However, there are still some gaps to be filled and some limitations to be addressed. Here we provide a brief overview of digital twin advancements in industry and highlight the main pitfalls to avoid and challenges to overcome, to improve the maturity of digital twins and facilitate large-scale industrial applications in the future.', 'DOI': '10.1038/s43588-024-00603-w'}, {'id': 'doi_10_1186_s42162-024-00385-5', 'title': 'Digital Twins of smart energy systems: a systematic literature review on enablers, design, management and computational challenges', 'URL': 'https://doi.org/10.1186/s42162-024-00385-5', 'extra_urls': ['https://doi.org/10.1186/s42162-024-00385-5'], 'type': 'article', 'author': [{'family': 'Aghazadeh Ardebili', 'given': 'Ali'}, {'family': 'Zappatore', 'given': 'Marco'}, {'family': 'Ramadan', 'given': 'Amro Issam Hamed Attia'}, {'family': 'Longo', 'given': 'Antonella'}, {'family': 'Ficarella', 'given': 'Antonio'}], 'abstract': 'Energy systems, as critical infrastructures (CI), constitute Cyber-Physical-Social Systems (CPSS). Due to their inherent complexity and the importance of service continuity of CIs, digitization in this context encounters significant practical challenges. Digital Twins (DT) have emerged over the recent years as a promising solution for managing CPSSs by facilitating real-time interaction, synchronization, and control of physical assets. The selection of an appropriate architectural framework is crucial in constructing a DT, to ensure integration of enabling technologies and data from diverse sources.', 'DOI': '10.1186/s42162-024-00385-5'}, {'id': 'use_case_scenarios', 'title': 'Use Case Scenarios for Digital Twin Implementation Based on ISO 23247', 'URL': 'https://www.nist.gov/publications/use-case-scenarios-digital-twin-implementation-based-iso-23247', 'extra_urls': ['https://www.nist.gov/publications/use-case-scenarios-digital-twin-implementation-based-iso-23247'], 'type': 'article', 'author': [{'family': 'Shao', 'given': 'Guodong'}], 'abstract': 'As a key part of digital transformation, digital twin is an important concept for achieving smart manufacturing'}, {'id': 'interoperability_of_digital', 'title': 'Interoperability of Digital Twins: Challenges, Success Factors, and Future Research Directions', 'URL': 'https://www.nist.gov/publications/interoperability-digital-twins-challenges-success-factors-and-future-research', 'extra_urls': ['https://www.nist.gov/publications/interoperability-digital-twins-challenges-success-factors-and-future-research'], 'type': 'article', 'author': [{'family': 'David', 'given': 'Istvan'}, {'family': 'Shao', 'given': 'Guodong'}, {'family': 'Tilbury', 'given': 'Dawn'}, {'family': 'Gomes', 'given': 'Claudio'}, {'family': 'Zarkhout', 'given': 'Bassam'}], 'abstract': 'The widespread adoption of digital twins gave rise to emerging systems of interconnected digital twins, often dubbed aggregated or hierarchical digital twins'}, {'id': 'privacy_preservation_in', 'title': 'Privacy preservation in federated learning: An insightful survey from the GDPR perspective', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0167404821002261', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0167404821002261'], 'type': 'article', 'author': [{'family': 'Truong', 'given': 'Nguyen'}, {'family': 'Sun', 'given': 'Kai'}, {'family': 'Wang', 'given': 'Siyao'}, {'family': 'Guitton', 'given': 'Florian'}, {'family': 'Guo', 'given': 'YiKe'}], 'abstract': 'In recent years, along with the blooming of Machine Learning (ML)-based applications and services, ensuring data privacy and security have become a critical obligation. ML-based service providers not only confront with difficulties in collecting and managing data across heterogeneous sources but also challenges of complying with rigorous data protection regulations such as EU/UK General Data Protection Regulation (GDPR). Furthermore, conventional centralised ML approaches have always come with long-standing privacy risks to personal data leakage, misuse, and abuse. Federated learning (FL) has emerged as a prospective solution that facilitates distributed collaborative learning without disclosing original training data. Unfortunately, retaining data and computation on-device as in FL are not sufficient for privacy-guarantee because model parameters exchanged among participants conceal sensitive information that can be exploited in privacy attacks. Consequently, FL-based systems are not naturally compliant with the GDPR. This article is dedicated to surveying of state-of-the-art privacy-preservation techniques in FL in relations with GDPR requirements. Furthermore, insights into the existing challenges are examined along with the prospective approaches following the GDPR regulatory guidelines that FL-based systems shall implement to fully comply with the GDPR.'}, {'id': 'doi_10_2196_41588', 'title': 'Federated Machine Learning, Privacy-Enhancing Technologies, and Data Protection Laws in Medical Research: Scoping Review', 'URL': 'https://doi.org/10.2196/41588', 'extra_urls': ['https://doi.org/10.2196/41588'], 'type': 'article', 'author': [{'family': 'Brauneck', 'given': 'Alissa'}, {'family': 'Schmalhorst', 'given': 'Louisa'}, {'family': 'Majdabadi', 'given': 'Mohammad Mahdi Kazemi'}, {'family': 'Bakhtiari', 'given': 'Mohammad'}, {'family': 'V\xf6lker', 'given': 'Uwe'}, {'family': 'Baumbach', 'given': 'Jan'}, {'family': 'Baumbach', 'given': 'Linda'}, {'family': 'Buchholtz', 'given': 'Gabriele'}], 'abstract': 'Background: The collection, storage, and analysis of large data sets are relevant in many sectors. Especially in the medical field, the processing of patient data promises great progress in personalized health care. However, it is strictly regulated, such as by the General Data Protection Regulation (GDPR). These regulations mandate strict data security and data protection and, thus, create major challenges for collecting and using large data sets. Technologies such as federated learning (FL), especially paired with differential privacy (DP) and secure multiparty computation (SMPC), aim to solve these challenges.\nObjective: This scoping review aimed to summarize the current discussion on the legal questions and concerns related to FL systems in medical research. We were particularly interested in whether and to what extent FL applications and training processes are compliant with the GDPR data protection law and whether the use of the aforementioned privacy-enhancing technologies (DP and SMPC) affects this legal compliance. We placed special emphasis on the consequences for medical research and development.\nMethods: We performed a scoping review according to the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews). We reviewed articles on Beck-Online, SSRN, ScienceDirect, arXiv, and Google Scholar published in German or English between 2016 and 2022. We examined 4 questions: whether local and global models are \u201cpersonal data\u201d as per the GDPR; what the \u201croles\u201d as defined by the GDPR of various parties in FL are; who controls the data at various stages of the training process; and how, if at all, the use of privacy-enhancing technologies affects these findings.\nResults: We identified and summarized the findings of 56 relevant publications on FL. Local and likely also global models constitute personal data according to the GDPR. FL strengthens data protection but is still vulnerable to a number of attacks and the possibility of data leakage. These concerns can be successfully addressed through the privacy-enhancing technologies SMPC and DP.\nConclusions: Combining FL with SMPC and DP is necessary to fulfill the legal data protection requirements (GDPR) in medical research dealing with personal data. Even though some technical and legal challenges remain, for example, the possibility of successful attacks on the system, combining FL with SMPC and DP creates enough security to satisfy the legal requirements of the GDPR. This combination thereby provides an attractive technical solution for health institutions willing to collaborate without exposing their data to risk. From a legal perspective, the combination provides enough built-in security measures to satisfy data protection requirements, and from a technical perspective, the combination provides secure systems with comparable performance with centralized machine learning applications.', 'DOI': '10.2196/41588'}, {'id': 'federated_learning_for', 'title': 'Federated learning for digital twin applications: a privacy-preserving and low-latency approach', 'URL': 'https://peerj.com/articles/cs-2877', 'extra_urls': ['https://peerj.com/articles/cs-2877'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Jie'}, {'family': 'Wang', 'given': 'Dong'}], 'abstract': 'The digital twin (DT) concept has recently gained widespread application for mapping the state of physical entities, enabling real-time analysis, prediction, and optimization, thereby enhancing the management and control of physical systems. However, when sensitive information is extracted from physical entities, it faces potential leakage risks, as DT service providers are typically honest yet curious. Federated learning (FL) offers a new distributed learning paradigm that protects privacy by transmitting model updates from edge servers to local devices, allowing training on local datasets. Nevertheless, the training parameters communicated between local mobile devices and edge servers may contain raw data that malicious adversaries could exploit. Furthermore, variations in mapping bias across local devices and the presence of malicious clients can degrade FL training accuracy. To address these security and privacy threats, this paper proposes the FL-FedDT scheme\u2014a privacy-preserving and low-latency FL method that employs an enhanced Paillier homomorphic encryption algorithm to safeguard the privacy of local device parameters without transmitting data to the server. Our approach introduces an improved Paillier encryption method with a new hyperparameter and pre-calculates multiple random intermediate values during the key generation stage, significantly reducing encryption time and thereby expediting model training. Additionally, we implement a trusted FL global aggregation method that incorporates learning quality and interaction records to identify and mitigate malicious updates, dynamically adjusting weights to counteract the threat of malicious clients. To evaluate the efficiency of our proposed scheme, we conducted extensive experiments, with results validating that our approach achieves training accuracy and security on par with baseline methods, while substantially reducing FL iteration time. This enhancement contributes to improved DT mapping and service quality for physical entities. (The code for this study is publicly available on GitHub at: https://github.com/fujianU/federated-learning. The URL address of the MNIST dataset is: https://gitcode.com/Resource-Bundle-Collection/d47b0/overview?utm_source=pan_gitcode&amp;index=top&amp;type=href&amp;;.)'}, {'id': 'doi_10_1007_s42979-024-03413-z', 'title': 'Mirroring Privacy Risks with Digital Twins: When Pieces of Personal Data Suddenly Fit Together', 'URL': 'https://doi.org/10.1007/s42979-024-03413-z', 'extra_urls': ['https://doi.org/10.1007/s42979-024-03413-z'], 'type': 'article', 'author': [{'family': 'B\xe4umer', 'given': 'Frederik Simon'}, {'family': 'Schultenk\xe4mper', 'given': 'Sergej'}, {'family': 'Geierhos', 'given': 'Michaela'}, {'family': 'Lee', 'given': 'Yeong Su'}], 'abstract': 'With the proliferation of social media, more personal information is being shared online than ever before, raising significant privacy concerns. This paper presents a novel approach to identify and mitigate privacy risks by generating digital twins from social media data. We propose a comprehensive framework that includes data collection, processing, and analysis, with special attention to data standardization, pseudonymization, and the use of synthetic data to ensure privacy compliance. We apply and evaluate state-of-the-art techniques such as Large Language Models, Generative Adversarial Networks, and Vision-Language Models to generate synthetic but realistic social media data that support the construction of accurate and representative digital twins while ensuring strict privacy compliance. Our approach demonstrates the potential for digital twins to help identify and mitigate privacy risks associated with social media use. We discuss the value and feasibility of this concept and suggest that further refinement of the techniques and conditions involved is needed.', 'DOI': '10.1007/s42979-024-03413-z'}, {'id': 'iterative_updating_of', 'title': 'Iterative updating of digital twin for equipment: Progress, challenges, and trends', 'URL': 'https://www.sciencedirect.com/science/article/pii/S147403462400421X', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S147403462400421X'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Bin'}, {'family': 'Ding', 'given': 'Guofu'}, {'family': 'Zheng', 'given': 'Qing'}, {'family': 'Zhang', 'given': 'Kai'}, {'family': 'Qin', 'given': 'Shengfeng'}], 'abstract': 'Digital twin (DT) technology enables the creation of DT that are synchronized with the state and behavior of physical entities. DT simulates physical entities, which can enable the evaluation, prediction, and optimal control of physical entities. During the operation and service of a physical equipment, its structure will change, and its performance will gradually decrease. The iterative update of the DT can maintain \u201cvirtual and real synchronization\u201d with the physical equipment, meeting the accuracy requirements for twin applications. Therefore, updating the DT model of an equipment based on the actual status of the physical equipment is a key challenge for DT applications in equipment health management (PHM). Scholars have studied many methods for updating DT iteratively. However, there is currently no systematic review of iterative updates for equipment DT, especially those focusing on updates. Therefore, two questions are raised by this study: (1) What is the latest state of the art in this research field? (2) What are the future research directions? In light of these inquiries, related research on the iterative renewal of equipment DT is systematically reviewed by this paper and potential development trends are discussed. Firstly, the research status of the iterative update method of the equipment DT was reviewed and summarized. Then, the high-fidelity evaluation methods of DT iterative update are reviewed. Thirdly, the challenges of iterative updating of DT models are analyzed. Finally, the potential development trend of iterative updating of equipment DT models is discussed. This study aims to sort out the research status of iterative updates of equipment DT. The iterative update technology system of DT is constructed to pave the way for further research in this field.'}, {'id': 'doi_10_1038_s41598-025-85457-6', 'title': 'Real-time update algorithms for digital twin models of distribution network equipment under internet of things and optical imaging technology', 'URL': 'https://doi.org/10.1038/s41598-025-85457-6', 'extra_urls': ['https://doi.org/10.1038/s41598-025-85457-6'], 'type': 'article', 'author': [{'family': 'Shen', 'given': 'Jian'}, {'family': 'Hu', 'given': 'Liang'}, {'family': 'Yang', 'given': 'Yang'}, {'family': 'Li', 'given': 'Yong'}, {'family': 'Lou', 'given': 'Peng'}], 'abstract': 'In order to achieve more efficient, accurate and intelligent substation equipment management and overall work efficiency of the substation, improve the work quality of the substation, innovate the data transmission mode and basic algorithm of the distribution network, and improve the traditional shortcomings and defects. With the increasing digitalization of distribution network equipment (DNE), real-time update algorithms for digital twin (DT) models have become a focus of research on digitalization of DNE. However, traditional real-time update algorithms for DT models still have problems such as poor real-time and accuracy, robustness, and scalability. The article first described the problems existing in the traditional DT model of DNE. Then it used IoT sensors and optical devices to collect data related to DNE; then it used the Savitzky\u2013Golay filtering algorithm to denoise the data. This article combined the IoT and optical imaging technology to construct a DT model; by using the recursive least squares method again, key parameters and state parameters were extracted from the constructed DT mechanism model, achieving real-time updates of the DNE DT model. Finally, to verify the application effect of the IoT and optical imaging technology in real-time update algorithms for DT models of DNE, this paper compared them with traditional parameter sensitivity analysis and state estimation. The research results showed that in the real-time and accuracy testing of test case 13, the algorithm used in this paper had a time of 0.014\xa0s and an accuracy of 93.2%. The parameter sensitivity analysis method had a time of 0.045\xa0s and an accuracy of 80.4%. The state estimation method took 0.056\xa0s and had an accuracy of 82.7%. In addition, the robustness and scalability of the real-time update algorithm for the DNE DT model using the method proposed in this article are significantly better than the other two traditional methods. The results show that the real-time update algorithm of the DT model of DNE based on the IoT and optical imaging technology has better real-time performance, higher accuracy, and better robustness and scalability. This study highlights the significant impact of the IoT and optical imaging technology on the accuracy, robustness, and real-time performance of real-time update algorithms for DT models. This provides more solutions for real-time monitoring, prediction, and control of DNE.', 'DOI': '10.1038/s41598-025-85457-6'}, {'id': 'doi_10_2308_HORIZONS-2023-060', 'title': 'Patience is Key: The Time It Takes to See Benefits from Continuous Auditing', 'URL': 'https://doi.org/10.2308/HORIZONS-2023-060', 'extra_urls': ['https://doi.org/10.2308/HORIZONS-2023-060'], 'type': 'article', 'author': [{'family': 'Eulerich', 'given': 'Marc'}, {'family': 'Fligge', 'given': 'Benjamin'}, {'family': 'L\xf3pez Kasper', 'given': 'Vanessa I.'}, {'family': 'Wood', 'given': 'David A.'}], 'abstract': 'Despite research showing numerous benefits of continuous auditing, uptake by internal audit functions has been quite slow. Using a case study approach and field data from a multinational company, we study two possible reasons for the slow uptake of continuous auditing: (1) the time it takes for continuous auditing to result in measurable reductions in audit risks and (2) that not every type of risk is equally likely to improve from continuous auditing. In our case company, it takes three years (on average) before observing significant risk reductions from implementing continuous auditing. We also find that the benefits of implementing continuous auditing vary by risk factor, ranging from no improvement to 51.6 percent for each additional year of continuous auditing use. These findings can provide internal auditors with a realistic expectation of the benefits and limitations, as well as the timetable for realizing benefits, when adopting continuous auditing.Data Availability: The data used in this study cannot be made publicly available due to confidentiality agreements with the participating organization.JEL Classifications: M42; G32.', 'DOI': '10.2308/HORIZONS-2023-060'}, {'id': 'compliance', 'title': 'RegTech: Technology-driven compliance and its effects on profitability, operations, and market structure', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0304405X24000151', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0304405X24000151'], 'type': 'article', 'author': [{'family': 'Charoenwong', 'given': 'Ben'}, {'family': 'Kowaleski', 'given': 'Zachary T.'}, {'family': 'Kwan', 'given': 'Alan'}, {'family': 'Sutherland', 'given': 'Andrew G.'}], 'abstract': 'Compliance-driven investments in technology\u2014or \u201cRegTech\u201d\u2014are growing rapidly. To understand the effects on the financial sector, we study firms\u2019 responses to new internal control requirements. Affected firms make significant investments in ERP and hardware. These expenditures then enable complementary investments that are leveraged for noncompliance purposes, leading to modest savings from avoided customer complaints and misconduct. IT budgets rise and profits fall, especially at small firms, and acquisition activity and market concentration increase. Our results illustrate how regulation can directly and indirectly affect technology adoption, which in turn affects noncompliance functions and market structure.'}, {'id': 'espr_crash_course', 'title': 'ESPR crash course - How the Ecodesign for Sustainable Products Regulation will impact apparel and footwear brands', 'URL': 'https://www.carbonfact.com/blog/policy/espr-textile', 'extra_urls': ['https://www.carbonfact.com/blog/policy/espr-textile'], 'type': 'article', 'author': [{'family': 'L\xfcttin', 'given': 'Lidia'}], 'issued': {'date-parts': [[2024]]}, 'abstract': &quot;ESPR brief for apparel and footwear: This comprehensive guide delves into the ESPR's impact on textiles, from eco-design to information requirements.&quot;}, {'id': 'guide_to_ecodesign', 'title': 'Guide to Ecodesign for Sustainable Products Regulation (ESPR)', 'URL': 'https://oneclicklca.com/en/resources/articles/ecodesign-sustainable-products-regulation-guide', 'extra_urls': ['https://oneclicklca.com/en/resources/articles/ecodesign-sustainable-products-regulation-guide'], 'type': 'article', 'author': [{'family': 'Zacharia', 'given': 'Melina'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'The Ecodesign for Sustainable Products Regulation (ESPR) entered into force on July 18, 2024, enforcing stricter criteria for sustainable products.'}, {'id': 'doi_10_1108_jcm-07-2024-7005', 'title': 'How do transparency and traceability enhance purchasing behaviors via consumer trust? Insights for food supply chains', 'URL': 'https://doi.org/10.1108/jcm-07-2024-7005', 'extra_urls': ['https://doi.org/10.1108/jcm-07-2024-7005'], 'type': 'article', 'author': [{'family': 'Nguyen', 'given': 'Minh Hue'}, {'family': 'Nguyen', 'given': 'Duy Ha'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1108/jcm-07-2024-7005'}, {'id': 'doi_10_1002_mar_22048', 'title': 'Perceived brand transparency: A conceptualization and measurement scale', 'URL': 'https://doi.org/10.1002/mar.22048', 'extra_urls': ['https://doi.org/10.1002/mar.22048'], 'type': 'article', 'author': [{'family': 'Montecchi', 'given': 'Matteo'}, {'family': 'Plangger', 'given': 'Kirk'}, {'family': 'West', 'given': 'Douglas'}, {'family': 'de Ruyter', 'given': 'Ko'}], 'issued': {'date-parts': [[2024]]}, 'DOI': '10.1002/mar.22048'}, {'id': 'doi_10_1080_00207543_2025_2507112', 'title': 'Integrating digital twin and blockchain for responsive working capital management in supply chains facing financial disruptions', 'URL': 'https://doi.org/10.1080/00207543.2025.2507112', 'extra_urls': ['https://doi.org/10.1080/00207543.2025.2507112'], 'type': 'article', 'author': [{'family': 'Badakhshan', 'given': 'Ehsan'}, {'family': 'Ivanov', 'given': 'Dmitry'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1080/00207543.2025.2507112'}, {'id': 'doi_10_3390_logistics9010022', 'title': 'State of the Art of Digital Twins in Improving Supply Chain Resilience', 'URL': 'https://doi.org/10.3390/logistics9010022', 'extra_urls': ['https://doi.org/10.3390/logistics9010022'], 'type': 'article', 'author': [{'family': 'Roman', 'given': 'Eugenia-Alina'}, {'family': 'Stere', 'given': 'Armand-Serban'}, {'family': 'Ro\u0219ca', 'given': 'Eugen'}, {'family': 'Radu', 'given': 'Adriana-Valentina'}, {'family': 'Codroiu', 'given': 'Denis'}, {'family': 'Anamaria', 'given': 'Ilie'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.3390/logistics9010022'}, {'id': 'doi_10_1177_15589250241302435', 'title': 'Research on identification of wool and cashmere by ANN based on hyperspectral imaging technology', 'URL': 'https://doi.org/10.1177/15589250241302435', 'extra_urls': ['https://doi.org/10.1177/15589250241302435'], 'type': 'article', 'author': [{'family': 'Qiu', 'given': 'Yingjie'}, {'family': 'Jin', 'given': 'Xiaoke'}, {'family': 'Tian', 'given': 'Wei'}, {'family': 'Zhang', 'given': 'Huifang'}, {'family': 'Shao', 'given': 'Lingda'}, {'family': 'Feng', 'given': 'XuHuang'}, {'family': 'Zhu', 'given': 'Chengyan'}], 'issued': {'date-parts': [[2024]]}, 'DOI': '10.1177/15589250241302435'}, {'id': 'doi_10_1038_s41586-024-08109-1', 'title': 'A broadband hyperspectral image sensor with high spatio-temporal resolution', 'URL': 'https://doi.org/10.1038/s41586-024-08109-1', 'extra_urls': ['https://doi.org/10.1038/s41586-024-08109-1'], 'type': 'article', 'author': [{'family': 'Bian', 'given': 'Liheng'}, {'family': 'Wang', 'given': 'Zhen'}, {'family': 'Zhang', 'given': 'Yuzhe'}, {'family': 'Li', 'given': 'Lianjie'}, {'family': 'Zhang', 'given': 'Yinuo'}, {'family': 'Yang', 'given': 'Chen'}, {'family': 'Fang', 'given': 'Wen'}, {'family': 'Zhao', 'given': 'Jiajun'}, {'family': 'Zhu', 'given': 'Chunli'}, {'family': 'Meng', 'given': 'Qinghao'}, {'family': 'Peng', 'given': 'Xuan'}, {'family': 'Zhang', 'given': 'Jun'}], 'issued': {'date-parts': [[2024]]}, 'DOI': '10.1038/s41586-024-08109-1'}, {'id': 'doi_10_1155_2017_3154035', 'title': 'Comprehensive Study of a Handheld Raman Spectrometer for the Analysis of Counterfeits of Solid-Dosage Form Medicines', 'URL': 'https://doi.org/10.1155/2017/3154035', 'extra_urls': ['https://doi.org/10.1155/2017/3154035'], 'type': 'article', 'author': [{'family': 'D\xe9gardin', 'given': 'Klara'}, {'family': 'Guillemain', 'given': 'Aur\xe9lie'}, {'family': 'Roggo', 'given': 'Yves'}], 'issued': {'date-parts': [[2017]]}, 'DOI': '10.1155/2017/3154035'}, {'id': 'doi_10_1609_aaai_v38i18_30040', 'title': 'Bayesian Inference with Complex Knowledge Graph Evidence', 'URL': 'https://doi.org/10.1609/aaai.v38i18.30040', 'extra_urls': ['https://doi.org/10.1609/aaai.v38i18.30040'], 'type': 'article', 'author': [{'family': 'Toroghi', 'given': 'Armin'}, {'family': 'Sanner', 'given': 'Scott'}], 'issued': {'date-parts': [[2024]]}, 'DOI': '10.1609/aaai.v38i18.30040'}, {'id': 'doi_10_3390_su12062391', 'title': 'Overcoming the Blockchain Oracle Problem in the Traceability of Non-Fungible Products', 'URL': 'https://doi.org/10.3390/su12062391', 'extra_urls': ['https://doi.org/10.3390/su12062391'], 'type': 'article', 'author': [{'family': 'Caldarelli', 'given': 'Giulio'}, {'family': 'Rossignoli', 'given': 'Cecilia'}, {'family': 'Zardini', 'given': 'Alessandro'}], 'issued': {'date-parts': [[2020]]}, 'DOI': '10.3390/su12062391'}, {'id': 'doi_10_3390_info11110509', 'title': 'Understanding the Blockchain Oracle Problem: A Call for Action', 'URL': 'https://doi.org/10.3390/info11110509', 'extra_urls': ['https://doi.org/10.3390/info11110509'], 'type': 'article', 'author': [{'family': 'Caldarelli', 'given': 'Giulio'}], 'issued': {'date-parts': [[2020]]}, 'DOI': '10.3390/info11110509'}, {'id': 'doi_10_1145_3531146_3533231', 'title': 'Data Cards: Purposeful and Transparent Dataset Documentation for Responsible AI', 'URL': 'https://doi.org/10.1145/3531146.3533231', 'extra_urls': ['https://doi.org/10.1145/3531146.3533231'], 'type': 'article', 'author': [{'family': 'Pushkarna', 'given': 'Mahima'}, {'family': 'Zaldivar', 'given': 'Andrew'}, {'family': 'Kjartansson', 'given': 'Oddur'}], 'issued': {'date-parts': [[2022]]}, 'DOI': '10.1145/3531146.3533231'}, {'id': 'doi_10_1145_3287560_3287596', 'title': 'Model Cards for Model Reporting', 'URL': 'https://doi.org/10.1145/3287560.3287596', 'extra_urls': ['https://doi.org/10.1145/3287560.3287596'], 'type': 'article', 'author': [{'family': 'Mitchell', 'given': 'Margaret'}, {'family': 'Wu', 'given': 'Simone'}, {'family': 'Zaldivar', 'given': 'Andrew'}, {'family': 'Barnes', 'given': 'Parker'}, {'family': 'Vasserman', 'given': 'Lucy'}, {'family': 'Hutchinson', 'given': 'Ben'}, {'family': 'Spitzer', 'given': 'Elena'}, {'family': 'Raji', 'given': 'Inioluwa Deborah'}, {'family': 'Gebru', 'given': 'Timnit'}], 'issued': {'date-parts': [[2019]]}, 'DOI': '10.1145/3287560.3287596'}, {'id': 'doi_10_1371_journal_pone_0121221', 'title': 'Product Carbon Footprints and Their Uncertainties in Comparative Decision Contexts', 'URL': 'https://doi.org/10.1371/journal.pone.0121221', 'extra_urls': ['https://doi.org/10.1371/journal.pone.0121221'], 'type': 'article', 'author': [{'family': 'Henriksson', 'given': 'Patrik J. G.'}, {'family': 'Heijungs', 'given': 'Reinout'}, {'family': 'Dao', 'given': 'Hai M.'}, {'family': 'Phan', 'given': 'Lam T.'}, {'family': 'de Snoo', 'given': 'Geert R.'}, {'family': 'Guin\xe9e', 'given': 'Jeroen B.'}], 'issued': {'date-parts': [[2015]]}, 'DOI': '10.1371/journal.pone.0121221'}, {'id': 'doi_10_1145_3736575', 'title': 'Conformal Prediction: A Data Perspective', 'URL': 'https://doi.org/10.1145/3736575', 'extra_urls': ['https://doi.org/10.1145/3736575'], 'type': 'article', 'author': [{'family': 'Zhou', 'given': 'Xiaofan'}, {'family': 'Chen', 'given': 'Baiting'}, {'family': 'Gui', 'given': 'Yu'}, {'family': 'Cheng', 'given': 'Lu'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1145/3736575'}, {'id': 'doi_10_1016_j_patcog_2011_06_019', 'title': 'A unifying view on dataset shift in classification', 'URL': 'https://doi.org/10.1016/j.patcog.2011.06.019', 'extra_urls': ['https://doi.org/10.1016/j.patcog.2011.06.019'], 'type': 'article', 'author': [{'family': 'Moreno-Torres', 'given': 'Jose G.'}, {'family': 'Raeder', 'given': 'Troy'}, {'family': 'Alaiz-Rodr\xedguez', 'given': 'Roc\xedo'}, {'family': 'Chawla', 'given': 'Nitesh V.'}, {'family': 'Herrera', 'given': 'Francisco'}], 'issued': {'date-parts': [[2012]]}, 'DOI': '10.1016/j.patcog.2011.06.019'}, {'id': 'doi_10_1214_23-AOS2276', 'title': 'Conformal prediction beyond exchangeability', 'URL': 'https://doi.org/10.1214/23-AOS2276', 'extra_urls': ['https://doi.org/10.1214/23-AOS2276'], 'type': 'article', 'author': [{'family': 'Barber', 'given': 'Rina Foygel'}, {'family': 'Cand\xe8s', 'given': 'Emmanuel J.'}, {'family': 'Ramdas', 'given': 'Aaditya'}, {'family': 'Tibshirani', 'given': 'Ryan J.'}], 'issued': {'date-parts': [[2023]]}, 'DOI': '10.1214/23-AOS2276'}, {'id': 'doi_10_1561_2200000101', 'title': 'Conformal Prediction: A Gentle Introduction', 'URL': 'https://doi.org/10.1561/2200000101', 'extra_urls': ['https://doi.org/10.1561/2200000101'], 'type': 'article', 'author': [{'family': 'Angelopoulos', 'given': 'Anastasios N.'}, {'family': 'Bates', 'given': 'Stephen'}], 'issued': {'date-parts': [[2023]]}, 'DOI': '10.1561/2200000101'}, {'id': 'doi_10_1162_tacl_a_00638', 'title': 'Lost in the Middle: How Language Models Use Long Contexts', 'URL': 'https://doi.org/10.1162/tacl_a_00638', 'extra_urls': ['https://doi.org/10.1162/tacl_a_00638'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Nelson F.'}, {'family': 'Lin', 'given': 'Kevin'}, {'family': 'Hewitt', 'given': 'John'}, {'family': 'Paranjape', 'given': 'Ashwin'}, {'family': 'Bevilacqua', 'given': 'Michele'}, {'family': 'Petroni', 'given': 'Fabio'}, {'family': 'Liang', 'given': 'Percy'}], 'issued': {'date-parts': [[2024]]}, 'DOI': '10.1162/tacl_a_00638'}, {'id': 'doi_10_1002_widm_1555', 'title': 'A taxonomy of automatic differentiation pitfalls', 'URL': 'https://doi.org/10.1002/widm.1555', 'extra_urls': ['https://doi.org/10.1002/widm.1555'], 'type': 'article', 'author': [{'family': 'H\xfcckelheim', 'given': 'Jan'}, {'family': 'Menon', 'given': 'Harshitha'}, {'family': 'Moses', 'given': 'William'}, {'family': 'Christianson', 'given': 'Bruce'}, {'family': 'Hovland', 'given': 'Paul'}, {'family': 'Hasco\xebt', 'given': 'Laurent'}], 'issued': {'date-parts': [[2024]]}, 'DOI': '10.1002/widm.1555'}, {'id': 'doi_10_1145_3053600_3053653', 'title': 'Performance Engineering for Microservices', 'URL': 'https://doi.org/10.1145/3053600.3053653', 'extra_urls': ['https://doi.org/10.1145/3053600.3053653'], 'type': 'article', 'author': [{'family': 'Heinrich', 'given': 'Robert'}, {'family': 'van Hoorn', 'given': 'Andr\xe9'}, {'family': 'Knoche', 'given': 'Holger'}, {'family': 'Li', 'given': 'Fei'}, {'family': 'Lwakatare', 'given': 'Lucy Ellen'}, {'family': 'Pahl', 'given': 'Claus'}, {'family': 'Schulte', 'given': 'Stefan'}, {'family': 'Wettinger', 'given': 'Johannes'}], 'issued': {'date-parts': [[2017]]}, 'DOI': '10.1145/3053600.3053653'}, {'id': 'doi_10_1016_j_jss_2024_112232', 'title': 'Unveiling the microservices testing methods, challenges, solutions, and solutions gaps: A systematic mapping study', 'URL': 'https://doi.org/10.1016/j.jss.2024.112232', 'extra_urls': ['https://doi.org/10.1016/j.jss.2024.112232'], 'type': 'article', 'author': [{'family': 'Hui', 'given': 'Mingxuan'}, {'family': 'Wang', 'given': 'Lu'}, {'family': 'Li', 'given': 'Hao'}, {'family': 'Yang', 'given': 'Ren'}, {'family': 'Song', 'given': 'Yuxin'}, {'family': 'Zhuang', 'given': 'Huiying'}, {'family': 'Cui', 'given': 'Di'}, {'family': 'Li', 'given': 'Qingshan'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1016/j.jss.2024.112232'}, {'id': 'doi_10_1109_JIOT_2024_3407584', 'title': 'Decentralized Federated Learning: A Survey and Perspective', 'URL': 'https://doi.org/10.1109/JIOT.2024.3407584', 'extra_urls': ['https://doi.org/10.1109/JIOT.2024.3407584'], 'type': 'article', 'author': [{'family': 'Yuan', 'given': 'Liangqi'}, {'family': 'Wang', 'given': 'Ziran'}, {'family': 'Sun', 'given': 'Lichao'}, {'family': 'Yu', 'given': 'Philip S.'}, {'family': 'Brinton', 'given': 'Christopher G.'}], 'issued': {'date-parts': [[2024]]}, 'DOI': '10.1109/JIOT.2024.3407584'}, {'id': 'doi_10_1007_s10664-025-10646-w', 'title': 'A systematic review on smart contracts security design patterns', 'URL': 'https://doi.org/10.1007/s10664-025-10646-w', 'extra_urls': ['https://doi.org/10.1007/s10664-025-10646-w'], 'type': 'article', 'author': [{'family': 'Azimi', 'given': 'Sadaf'}, {'family': 'Golzari', 'given': 'Ali'}, {'family': 'Ivaki', 'given': 'Naghmeh'}, {'family': 'Laranjeiro', 'given': 'Nuno'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1007/s10664-025-10646-w'}, {'id': 'doi_10_1257_aer_104_1_183', 'title': &quot;Risk Sharing and Transactions Costs: Evidence from Kenya's Mobile Money Revolution&quot;, 'URL': 'https://doi.org/10.1257/aer.104.1.183', 'extra_urls': ['https://doi.org/10.1257/aer.104.1.183'], 'type': 'article', 'author': [{'family': 'Jack', 'given': 'William'}, {'family': 'Suri', 'given': 'Tavneet'}], 'issued': {'date-parts': [[2014]]}, 'DOI': '10.1257/aer.104.1.183'}, {'id': 'doi_10_1063_5_0123942', 'title': 'Solving the blockchain oracle problem to enable supply chain mass adoption', 'URL': 'https://doi.org/10.1063/5.0123942', 'extra_urls': ['https://doi.org/10.1063/5.0123942'], 'type': 'article', 'author': [{'family': 'Teoh', 'given': 'Bryan'}], 'issued': {'date-parts': [[2023]]}, 'DOI': '10.1063/5.0123942'}, {'id': 'doi_10_3389_fbloc_2025_1503595', 'title': 'Exploring the failure factors of blockchain adopting projects: a case study of tradelens through the lens of commons theory', 'URL': 'https://doi.org/10.3389/fbloc.2025.1503595', 'extra_urls': ['https://doi.org/10.3389/fbloc.2025.1503595'], 'type': 'article', 'author': [{'family': 'Najati', 'given': 'Issam'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.3389/fbloc.2025.1503595'}, {'id': 'doi_10_1145_3567582', 'title': 'Connect API with Blockchain: A Survey on Blockchain Oracle Implementation', 'URL': 'https://doi.org/10.1145/3567582', 'extra_urls': ['https://doi.org/10.1145/3567582'], 'type': 'article', 'author': [{'family': 'Pasdar', 'given': 'Amirmohammad'}, {'family': 'Lee', 'given': 'Young Choon'}, {'family': 'Dong', 'given': 'Zhongli'}], 'issued': {'date-parts': [[2023]]}, 'DOI': '10.1145/3567582'}, {'id': 'doi_10_1108_SCM-04-2018-0152', 'title': 'Traceability for sustainability \u2013 literature review and conceptual framework', 'URL': 'https://doi.org/10.1108/SCM-04-2018-0152', 'extra_urls': ['https://doi.org/10.1108/SCM-04-2018-0152'], 'type': 'article', 'author': [{'family': 'Garcia-Torres', 'given': 'Sofia'}, {'family': 'Albareda', 'given': 'Laura'}, {'family': 'Rey-Garcia', 'given': 'Marta'}, {'family': 'Seuring', 'given': 'Stefan'}], 'issued': {'date-parts': [[2019]]}, 'DOI': '10.1108/SCM-04-2018-0152'}, {'id': 'alliance_for_bangladesh', 'title': 'Alliance for Bangladesh Worker Safety, 2024', 'URL': 'https://www.bangladeshworkersafety.org', 'extra_urls': ['https://www.bangladeshworkersafety.org'], 'type': 'webpage', 'author': [{'family': 'Alliance for Bangladesh Worker Safety'}], 'issued': {'date-parts': [[2024]]}}, {'id': 'doi_10_1108_SCM-10-2017-0336', 'title': 'Assessment of traditional food supply chain performance using triadic approach: the role of relationships quality', 'URL': 'https://doi.org/10.1108/SCM-10-2017-0336', 'extra_urls': ['https://doi.org/10.1108/SCM-10-2017-0336'], 'type': 'article', 'author': [{'family': 'Mesic', 'given': '\u017deljka'}, {'family': 'Moln\xe1r', 'given': 'Adrienn'}, {'family': 'Cerjak', 'given': 'Marija'}], 'issued': {'date-parts': [[2018]]}, 'DOI': '10.1108/SCM-10-2017-0336'}, {'id': 'doi_10_3390_en14082289', 'title': 'Towards a Digital Product Passport Fit for Contributing to a Circular Economy', 'URL': 'https://doi.org/10.3390/en14082289', 'extra_urls': ['https://doi.org/10.3390/en14082289'], 'type': 'article', 'author': [{'family': 'Adisorn', 'given': 'Thomas'}, {'family': 'Tholen', 'given': 'Lena'}, {'family': 'G\xf6tz', 'given': 'Thomas'}], 'issued': {'date-parts': [[2021]]}, 'DOI': '10.3390/en14082289'}, {'id': 'doi_10_1007_s10207-025-01043-x', 'title': 'Leveraging digital twins for advanced threat modeling in cyber-physical systems cybersecurity', 'URL': 'https://doi.org/10.1007/s10207-025-01043-x', 'extra_urls': ['https://doi.org/10.1007/s10207-025-01043-x'], 'type': 'article', 'author': [{'family': 'Erceylan', 'given': 'Gizem'}, {'family': 'Akbarzadeh', 'given': 'Aida'}, {'family': 'Gkioulos', 'given': 'Vasileios'}], 'abstract': 'Threat modeling is a critical proactive security technique for identifying threats and determining mitigations. However, traditional approaches often fall short for Industrial Control Systems (ICS), which automate operations in domains like manufacturing and energy and are a subset of Cyber-Physical Systems (CPS). CPS integrates computation, networking, and physical processes, with ICS requiring specialized cybersecurity approaches due to its operational and safety-critical nature. This study explores the use of digital twin technology as a promising cybersecurity tool for ICS, enabling testing and analysis without disrupting operations. By examining the capabilities of digital twins in analysis, simulation, and replication, the research evaluates their potential to enhance threat modeling across the CPS life-cycle. Insights from the European Cyber Security Organisation (ECSO) Technical Paper on Cybersecurity Scenarios and Digital Twins guide the exploration of their role in threat modeling. The study addresses four research questions: 1. What purposes do digital twins serve in cybersecurity? 2. What benefits do digital twins offer in cybersecurity? 3. How can digital twin technology be leveraged for threat modeling? 4. What advantages can the use of digital twins bring to threat modeling? Our findings reveal that digital twins enhance ICS threat modeling by enabling continuous, dynamic, and autonomous assessment, offering valuable insights for advancing cybersecurity strategies in ICS, CPS, and related domains.', 'DOI': '10.1007/s10207-025-01043-x'}, {'id': 'systematic_review_of', 'title': 'Systematic review of predictive maintenance and digital twin technologies challenges, opportunities, and best practices', 'URL': 'https://peerj.com/articles/cs-1943', 'extra_urls': ['https://peerj.com/articles/cs-1943'], 'type': 'article', 'author': [{'family': 'Wahab', 'given': 'Nur Haninie Abd'}, {'family': 'Hasikin', 'given': 'Khairunnisa'}, {'family': 'Lai', 'given': 'Khin Wee'}, {'family': 'Xia', 'given': 'Kaijian'}, {'family': 'Bei', 'given': 'Lulu'}, {'family': 'Huang', 'given': 'Kai'}, {'family': 'Wu', 'given': 'Xiang'}], 'abstract': 'Background Maintaining machines effectively continues to be a challenge for industrial organisations, which frequently employ reactive or premeditated methods. Recent research has begun to shift its attention towards the application of Predictive Maintenance (PdM) and Digital Twins (DT) principles in order to improve maintenance processes. PdM technologies have the capacity to significantly improve profitability, safety, and sustainability in various industries. Significantly, precise equipment estimation, enabled by robust supervised learning techniques, is critical to the efficacy of PdM in conjunction with DT development. This study underscores the application of PdM and DT, exploring its transformative potential across domains demanding real-time monitoring. Specifically, it delves into emerging fields in healthcare, utilities (smart water management), and agriculture (smart farm), aligning with the latest research frontiers in these areas. Methodology Employing the Preferred Reporting Items for Systematic Review and Meta-Analyses (PRISMA) criteria, this study highlights diverse modeling techniques shaping asset lifetime evaluation within the PdM context from 34 scholarly articles. Results The study revealed four important findings: various PdM and DT modelling techniques, their diverse approaches, predictive outcomes, and implementation of maintenance management. These findings align with the ongoing exploration of emerging applications in healthcare, utilities (smart water management), and agriculture (smart farm). In addition, it sheds light on the critical functions of PdM and DT, emphasising their extraordinary ability to drive revolutionary change in dynamic industrial challenges. The results highlight these methodologies\u2019 flexibility and application across many industries, providing vital insights into their potential to revolutionise asset management and maintenance practice for real-time monitoring. Conclusions Therefore, this systematic review provides a current and essential resource for academics, practitioners, and policymakers to refine PdM strategies and expand the applicability of DT in diverse industrial sectors.'}, {'id': 'a_conceptual_framework', 'title': 'A conceptual framework for supply chain digital twins \u2013 development and evaluation', 'URL': 'https://www.tandfonline.com/doi/full/10.1080/13675567.2024.2324895', 'extra_urls': ['https://www.tandfonline.com/doi/full/10.1080/13675567.2024.2324895'], 'type': 'article', 'author': [{'family': 'Freese', 'given': 'Falk'}, {'family': 'Ludwig', 'given': 'Andr\xe9'}]}, {'id': 'doi_10_1007_978-981-96-7734-4', 'title': 'Sustainable Enterprise Resource Planning', 'URL': 'https://doi.org/10.1007/978-981-96-7734-4', 'type': 'book', 'author': [{'family': 'Anjaria', 'given': 'Kushal'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Springer', 'abstract': 'This book delves into integrating sustainable practices within enterprise resource planning (S-ERP) systems framework, particularly in the context of Industry 4.0. It offers a comprehensive exploration of how S-ERP systems can be developed and implemented to enhance operational efficiency and promote environmental and social sustainability, which is achieved by incorporating cutting-edge technologies such as the internet of things (IoT), artificial intelligence (AI), and cloud computing, which are instrumental in Industry 4.0. Targeted primarily at professionals and academics in business management, information technology, and sustainability, the book will be a crucial resource for those seeking to understand and implement S-ERP solutions. It is particularly beneficial for MBA students, business strategists, ERP consultants, and IT professionals involved in planning, developing, and managing ERP systems.Key topics include the principles of sustainable business practices, the role of digital technologies in enhancing ERP systems, and the challenges and opportunities presented by Industry 4.0. The book also provides practical insights into implementing S-ERP systems, offering case studies and real-world examples to illustrate key concepts. It is thus not just an academic treatise, but a practical guide that addresses the need for a new ERP approach in the digital transformation age. It seeks to equip its readers with the knowledge and tools required to successfully navigate the complexities of modern business environments, emphasising the importance of sustainability in achieving long-term success. In summary, this book is a vital addition to the literature on ERP systems, offering a fresh perspective on how businesses can evolve to meet the demands of the 21st century while maintaining a commitment to sustainability.', 'DOI': '10.1007/978-981-96-7734-4'}, {'id': 'machine_learning_and', 'title': 'Machine learning and internet of things applications in enterprise architectures: Solutions, challenges, and open issues', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13467', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13467'], 'type': 'article', 'author': [{'family': 'Rehman', 'given': 'Zubaida'}, {'family': 'Tariq', 'given': 'Noshina'}, {'family': 'Moqurrab', 'given': 'Syed Atif'}, {'family': 'Yoo', 'given': 'Joon'}, {'family': 'Srivastava', 'given': 'Gautam'}], 'issued': {'date-parts': [[2024]]}, 'abstract': 'The rapid growth of the Internet of Things (IoT) has led to its widespread adoption in various industries, enabling enhanced productivity and efficient services. Integrating IoT systems with existing enterprise application systems has become common practice. However, this integration necessitates reevaluating and reworking current Enterprise Architecture (EA) models and Expert Systems (ES) to accommodate IoT and cloud technologies. Enterprises must adopt a multifaceted view and automate various aspects, including operations, data management, and technology infrastructure. Machine Learning (ML) is a powerful IoT and smart automation tool within EA. Despite its potential, a need for dedicated work focuses on ML applications for IoT services and systems. With IoT being a significant field, analyzing IoT-generated data and IoT-based networks is crucial. Many studies have explored how ML can solve specific IoT-related challenges. These mutually reinforcing technologies allow IoT applications to leverage sensor data for ML model improvement, leading to enhanced IoT operations and practices. Furthermore, ML techniques empower IoT systems with knowledge and enable suspicious activity detection in smart systems and objects. This survey paper conducts a comprehensive study on the role of ML in IoT applications, particularly in the domains of automation and security. It provides an in-depth analysis of the state-of-the-art ML approaches within the context of IoT, highlighting their contributions, challenges, and potential applications.'}, {'id': 'integrated_and', 'title': 'Integrated data-driven and artificial intelligence framework to develop digital twins in distribution system of supply chains: A real industrial case', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0925527325002282', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0925527325002282'], 'type': 'article', 'author': [{'family': 'Ziari', 'given': 'Matineh'}, {'family': 'Taleizadeh', 'given': 'Ata Allah'}], 'abstract': 'The development of digital twins and the application of industry 4.0, Artificial Intelligence (AI), and recent Machine Learning (ML) approaches have significantly advanced supply chain management and garnered considerable attention. The importance of digital twins in the supply chain became specifically clear following the outbreak of the COVID-19 pandemic, demonstrating substantial benefits in risk and disruption management. We propose an integrated framework for developing digital twins in distribution systems for managing demand risks, and it designs a decision support system for data-driven modeling to respond to two scenarios: (1) proactive design for managing future demand risks and (2) reactive design for managing real-time demand risks. This research aims to provide a more comprehensive study compared to previous investigations by designing this conceptual framework for development of digital twin in distribution systems and creating a support system using technical analysis and demand data via Regression algorithm in machine learning based on a real industrial case problem. The results of the current paper contribute to practical actions and research in demand risk management and the discovery of patterns, trends, and potential changes, enhancing both proactive and reactive decision-making. By integrating the visualization of the distribution system, analyzing historical and online demand data, implementing exogenous variables and connecting it to Enterprise Resource Planning (ERP) systems, this approach ensures the resilience and agility of systems, as well as the continuity of business operations in global companies.'}, {'id': 'are_retail_consumers', 'title': 'Are Retail Consumers Willing to Pay for All Circular Products? A Study on Consumer Perception of the Circular Economy in Retail', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1002/bse.4269', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1002/bse.4269'], 'type': 'article', 'author': [{'family': 'Toth-Peter', 'given': 'Agnes'}, {'family': 'Cheema', 'given': 'Sadia'}, {'family': 'Torres de Oliveira', 'given': 'Rui'}, {'family': 'Nguyen', 'given': 'Tam'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'The planetary crisis, stemming from overconsumption and unsustainable production patterns, necessitates a shift towards balanced economic, environmental and social growth. The circular economy presents a promising solution by promoting material recirculation. While its success relies on collaboration among various stakeholders, consumers are crucial for accepting circular economy products and business models. However, despite increasing environmental awareness, the literature shows that many consumers resist purchasing previously used products due to perceived inferiority, risk and low quality, which could hinder the adoption of circular economy products. Understanding consumer behaviour, particularly their willingness to buy and pay for circular economy products, is essential for businesses seeking to promote sustainable consumption and achieve market growth. This study investigates consumer perceptions of circular economy, using simplified terms of reused, recycled and recovered, across 11 product categories through a quantitative survey of 607 Australian respondents. The results indicate that personal financial benefits are prioritised over ecological reasons, and there is variability in perceived product performance across categories. Additionally, price sensitivity and affordability play a key role in consumer decision-making. Notably, while younger and male consumers show a greater inclination to purchase circular economy products, the broader consumer base remains unwilling to pay a premium. These insights can guide businesses and policymakers in developing targeted strategies emphasising price, functionality and quality to enhance consumer acceptance and adoption of circular economy products. We advance theory by demonstrating that consumer decisions are primarily driven by personal financial savings, rather than ecological or social benefits, challenging the prevailing assumption in literature that environmental and social motivations are the key drivers of sustainable consumption, even in developed economies. We also emphasise the need for theories to account for significant variability in perceived product performance across categories when investigating willingness to pay for circular economy products.'}, {'id': 'collaborative_fashion', 'title': 'Collaborative fashion forecasting: Integrating demand and supply-chain forecasting into the fashion industry', 'URL': '#item_20165', 'type': 'article', 'author': [{'family': 'Hur', 'given': 'Eunsuk'}, {'family': 'Sinha', 'given': 'Pammi'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Routledge', 'abstract': &quot;The fashion industry is known for its complex supply-chain systems involving multiple actors and producing trend-sensitive items that are often seasonal or have short product life cycles. Incorrect forecasting can have a direct influence not only on financial losses due to overstocking or understocking but also on the increasing environmental impact of unsold stock, consumer returns and dead stock. It is imperative that forecasters effectively capture consumer demand and expectations to facilitate effective inventory and waste management as well as circular fashion practices. This chapter aims to examine how different actors in the fashion supply chain are involved in the complex fashion system and how this system works in relation to the fashion forecasting timeline. The chapter discusses the challenges of the current supply and demand forecasting process, the role of forecasters in guiding a business's strategic direction and the importance of understanding consumer segmentation for fashion trend forecasting. Finally, the chapter reviews how forecasters support multiple stakeholders in the fashion system, including design, production, buying, merchandising, marketing and sales teams.&quot;}, {'id': 'doi_10_1080_13675567_2020_1803246', 'title': 'Machine learning demand forecasting and supply chain performance', 'URL': 'https://doi.org/10.1080/13675567.2020.1803246', 'extra_urls': ['https://doi.org/10.1080/13675567.2020.1803246'], 'type': 'article', 'author': [{'family': 'Feizabadi', 'given': 'Javad'}], 'abstract': 'In many supply chains, firms staged in upstream of the chain suffer from variance amplification emanating from demand information distortion in a multi-stage supply chain and, consequently, their operation inefficiency. Prior research suggest that employing advanced demand forecasting, such as machine learning, could mitigate the effect and improve the performance; however, it is less known what is the extent and magnitude of savings as tangible supply chain performance outcomes. In this research, hybrid demand forecasting methods grounded on machine learning i.e. ARIMAX and Neural Network is developed. Both time series and explanatory factors are feed into the developed method. The method was applied and evaluated in the context of functional product and a steel manufacturer. The statistically significant supply chain performance improvement differences were found across traditional and ML-based demand forecasting methods. The implications for the theory and practice are also presented.', 'DOI': '10.1080/13675567.2020.1803246'}, {'id': 'doi_10_1186_s41072-022-00110-z', 'title': 'Internet of Things enabled real time cold chain monitoring in a container port', 'URL': 'https://doi.org/10.1186/s41072-022-00110-z', 'extra_urls': ['https://doi.org/10.1186/s41072-022-00110-z'], 'type': 'article', 'author': [{'family': 'Cil', 'given': 'Ahmet Yunus'}, {'family': 'Abdurahman', 'given': 'Dini'}, {'family': 'Cil', 'given': 'Ibrahim'}], 'abstract': 'Seaports are regarded as significant actors in global logistics and supply chains since a large part of the cargoes carried over the globe are being processed there. When the cold chain broken down during transport and storage in the ports, the humidity, nutrition, temperature and time conditions to be required for the growth of the bacteria occur, and rapid reproduction occurs and the properties of the products are rapidly deteriorating. It is imperative that especially medicines, some chemical substances and foodstuffs need to be transported without breaking the cold chain in the logistics. The monitoring and control of the temperature and humidity level is important in the time period between the loading of these containers in special areas in ports, the loading of freight in open areas, or the loading of freight on roads and railway carriages. For this reason, precise monitoring and control of the system is vital in the port logistics management.', 'DOI': '10.1186/s41072-022-00110-z'}, {'id': 'unlocking_the_potential', 'title': 'Unlocking the potential of digital twins in supply chains: A systematic review', 'URL': 'https://www.sciencedirect.com/science/article/pii/S2949863524000189', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S2949863524000189'], 'type': 'article', 'author': [{'family': 'Zaidi', 'given': 'Syed Adeel Haneef'}, {'family': 'Khan', 'given': 'Sharfuddin Ahmed'}, {'family': 'Chaabane', 'given': 'Amin'}], 'abstract': 'Digital Twins (DTs) developments are still in the pilot stages of deployment in supply chain management (SCM), and their full integration with real-time synchronization and autonomous decision-making poses many challenges. This paper aims to identify these common challenges and provide a conceptual framework for establishing a Digital Twin (DT) system to improve supply chain management performance. The paper presents a systematic literature review of 129 research papers on DT applications for SCM improvement. The selected papers were reviewed and classified into three categories: manufacturing and production, supply chain, and logistics. The development of digital technologies such as the Internet of Things (IoT), Radio Frequency Identification (RFID) devices, cloud computing, cyber-physical systems (CPSs), cybersecurity (CS), and simulation modeling has increased the opportunities to explore the creation of supply chain DTs. However, there are limitations and various challenges due to the complexity of most systems. The results indicate that DT for SCM should include external links (i.e. suppliers, distributors) and internal links (i.e. procurement, production, logistics) to deal with any disruption through data-driven modeling with real-time synchronization. Based on the review findings, this study proposes a three-layered conceptual framework to improve supply chain management performance. The proposed framework provides future directions for DT research in SCM. It provides a holistic and integrated approach to DT implementation, the common DT technologies, and data analytics techniques for improved supply chain performance.'}, {'id': 'doi_10_1007_978-3-319-38756-7_4', 'title': 'Digital Twin: Mitigating Unpredictable, Undesirable Emergent Behavior in Complex Systems', 'URL': 'https://doi.org/10.1007/978-3-319-38756-7_4', 'type': 'article', 'author': [{'family': 'Grieves', 'given': 'Michael'}, {'family': 'Vickers', 'given': 'John'}], 'issued': {'date-parts': [[2017]]}, 'publisher': 'Springer International Publishing', 'abstract': 'Systems do not simply pop into existence. They progress through lifecycle phases of creation, production, operations, and disposal. The issues leading to undesirable and unpredicted emergent behavior are set in place during the phases of creation and production and realized during the operational phase, with many of those problematic issues due to human interaction. We propose that the idea of the Digital Twin, which links the physical system with its virtual equivalent can mitigate these problematic issues. We describe the Digital Twin concept and its development, show how it applies across the product lifecycle in defining and understanding system behavior, and define tests to evaluate how we are progressing. We discuss how the Digital Twin relates to Systems Engineering and how it can address the human interactions that lead to \u201cnormal accidents.\u201d We address both Digital Twin obstacles and opportunities, such as system replication and front running. We finish with NASA\u2019s current work with the Digital Twin.', 'DOI': '10.1007/978-3-319-38756-7_4'}, {'id': 'doi_10_1108_JFMM-07-2024-0275', 'title': 'Communicating Australian cotton\u2019s sustainable value in the cotton value chain', 'URL': 'https://doi.org/10.1108/JFMM-07-2024-0275', 'extra_urls': ['https://doi.org/10.1108/JFMM-07-2024-0275'], 'type': 'article', 'author': [{'family': 'Mellick', 'given': 'Zoe'}, {'family': 'Street', 'given': 'Paige'}, {'family': 'Payne', 'given': 'Alice Ruth'}], 'abstract': 'This qualitative study explores the dynamics of communicating Australian cotton\u2019s on-farm sustainability to actors throughout global value chains. The research is guided by two objectives: first, to understand how sustainability in Australian cotton is perceived by value chain members, and second, to pinpoint strategies for cultivating a shared understanding of on-farm sustainability within the Australian cotton value chain (ACVC).Employing qualitative research methods, the study conducts interviews with 21 participants from two distinct ACVCs.Effectively communicating the sustainability of clothing fibre demands thoughtful consideration of how knowledge is translated from farmer to retailer. The diverse nature of cotton production practices leads to varied understandings of sustainability, making it challenging to establish a consistent narrative. The study found that clear information and visual storytelling of on-farm practices enhance stakeholders\u2019 understanding. The use of complex technical information was a barrier to effective communication, and there was general scepticism among retailers regarding industry-funded sustainability credentials. These findings underscore the importance of building trust through two-way communication between retailers and farmers.This study highlights the need for more collaborative efforts to foster a shared understanding of sustainability across the value chain. The findings of this study may not be broadly representative of the entire Australian or global cotton industry, but the depth of insights and methodological approach may be applied to other value chains.This research advances the literature on sustainability communication in the context of fashion production and consumption. It takes a unique perspective by focussing on how sustainability is communicated by different stakeholders working with Australian cotton.', 'DOI': '10.1108/JFMM-07-2024-0275'}, {'id': 'doi_10_1007_978-3-030-22018-1_14', 'title': 'Labels in the Textile and Fashion Industry: Communicating Sustainability to Effect Sustainable Consumption', 'URL': 'https://doi.org/10.1007/978-3-030-22018-1_14', 'type': 'article', 'author': [{'family': 'Morris', 'given': 'Jonathan'}, {'family': 'Koep', 'given': 'Lisa'}, {'family': 'Damert', 'given': 'Matthias'}], 'issued': {'date-parts': [[2021]]}, 'publisher': 'Springer International Publishing', 'abstract': 'The textile and fashion industry is associated with numerous ethical problems such as poor labour conditions, low wages, long hours and unsafe working conditions, as well as a range of negative environmental impacts. A key challenge is to reconcile the behavioural impacts across the value chain, from producers and manufacturers to consumers. Achieving real change requires organizational shifts across multiple levels of the textile and fashion value chain, away from focusing on the focal firm but across the entire value chain, as well as overcoming the information and knowledge deficits held by consumers and professionals alike. Awareness and information strategies such as sustainability labelling are a crucial step in promoting sustainable consumption through improved information provision which may facilitate an institutionalized shift towards embedding sustainability criteria into consumer decision-making processes.', 'DOI': '10.1007/978-3-030-22018-1_14'}, {'id': 'can_we_play', 'title': 'Can we play our way to a more circular fashion world? : A quantitative study about the impact of gamification on consumer attitudes and intentions to use C2C apps', 'URL': 'https://urn.kb.se/resolve?urn=urn:nbn:se:umu:diva-197002', 'extra_urls': ['https://urn.kb.se/resolve?urn=urn:nbn:se:umu:diva-197002'], 'type': 'thesis', 'author': [{'family': 'Arnesson', 'given': 'Amanda'}, {'family': 'Westman', 'given': 'Sofia'}], 'issued': {'date-parts': [[2022]]}, 'publisher': 'Ume\xe5 University', 'abstract': 'DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.'}, {'id': 'platform_to', 'title': 'Eco-Gamification Platform to Promote Consumers\u2019 Engagement in the Textile and Clothing Circular Value Chain', 'URL': 'https://www.mdpi.com/2071-1050/15/6/5398', 'extra_urls': ['https://www.mdpi.com/2071-1050/15/6/5398'], 'type': 'article', 'author': [{'family': 'Alves', 'given': 'Lu\xeds'}, {'family': 'Faria', 'given': 'Pedro Miguel'}, {'family': 'Cruz', 'given': 'Estrela Ferreira'}, {'family': 'Lopes', 'given': 'S\xe9rgio Ivan'}, {'family': 'Rosado da Cruz', 'given': 'Ant\xf3nio Miguel'}], 'abstract': 'The textile and clothing (T&amp;C) value chain is one of the most polluting in the world and one that produces the most waste. It is, therefore, important to encourage the circular economy (CE) model in this sector to reduce pollution, mitigate the effects of waste production, and, consequently, increase environmental sustainability. Leveraging end-consumer engagement in a CE mindset in the T&amp;C sector is crucial, as they are the last player in a typical linear value chain. Therefore, a platform that supports and promotes sustainable tasks to manage one\u2019s fashion products, through the use of gamification techniques, can be of utmost importance. In this article, we identify impactful carbon footprint consumer actions and solutions for the T&amp;C consumer phase. After that, we survey gamification frameworks for analyzing techniques, at the system design level, which enable the engagement of the final consumer in the CE process. Then, we select and use one of such frameworks, Gameful Design Heuristics (GDH), for defining the gamification structure needed to implement on a business-to-consumer-to-consumer (B2C2C) context of a circular economy process, linking it to the aforementioned actions and solutions. As result, we present a B2C2C circular business process model for the T&amp;C value chain and propose the design model of a gamified platform for the final consumers, which allows them to register the consumer-to-business (C2B) and consumer-to-consumer (C2C) activities, from the circular value chain\u2019s business process, and benefit from a game-like experience. All the model features have been mapped to the GDH framework heuristics, validating that it is possible to support a set of defined heuristics of applied gamification for promoting CE in the T&amp;C value chain.'}, {'id': 'gamifying_evaluating', 'title': 'Gamifying Green: Evaluating the Impact of Gamification on Zero-Waste Product Use - ProQuest', 'URL': 'https://www.proquest.com/openview/3de02f26fd7ba740b9ec9a5bc194603f/1?pq-origsite=gscholar&amp;cbl=18750&amp;diss=y', 'extra_urls': ['https://www.proquest.com/openview/3de02f26fd7ba740b9ec9a5bc194603f/1?pq-origsite=gscholar&amp;cbl=18750&amp;diss=y'], 'type': 'thesis', 'author': [{'family': 'Bouchillon', 'given': 'Natasha'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Capella University', 'abstract': 'Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.'}, {'id': 'doi_10_1007_s43681-025-00725-5', 'title': 'Transparency requirements across AI legislative acts, frameworks and organizations: shaping a sample transparency card', 'URL': 'https://doi.org/10.1007/s43681-025-00725-5', 'extra_urls': ['https://doi.org/10.1007/s43681-025-00725-5'], 'type': 'article', 'author': [{'family': 'Cousineau', 'given': 'Carter'}, {'family': 'Herger', 'given': 'Nadja'}, {'family': 'Dara', 'given': 'Rozita'}], 'abstract': 'As AI-driven solutions become increasingly common, end users of those systems continue to lack transparency in understanding the AI system\u2019s functionality leading to a lack of trust, and AI systems not reaching their full potential. Our research aims to address this research gap by developing a novel sample transparency card. This transparency card is grounded in key transparency requirements from the prominent AI legislation (the European Union\u2019s (EU) AI Act), the international standards (national institute of standards and technology (NIST) and international organization for standardization (ISO)), and public transparency principles from 25 global organizations. The research follows a 2-phase research approach. First, we analyze the transparency requirements to gain a greater understanding of the legislative and organizational requirements. Second, based on transparency requirements, create common categories and develop a proposed sample transparency card. This research offers a novel contribution by developing a sample transparency card that can be seen by the AI end users and aligns with legislative acts and frameworks, promoting trust in AI systems.', 'DOI': '10.1007/s43681-025-00725-5'}, {'id': 'programming_parametric', 'title': 'GarmentCode: Programming Parametric Sewing Patterns', 'URL': 'https://dl.acm.org/doi/10.1145/3618351', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3618351'], 'type': 'article', 'author': [{'family': 'Korosteleva', 'given': 'Maria'}, {'family': 'Sorkine-Hornung', 'given': 'Olga'}], 'issued': {'date-parts': [[2023]]}, 'abstract': 'Garment modeling is an essential task of the global apparel industry and a core part of digital human modeling. Realistic representation of garments with valid sewing patterns is key to their accurate digital simulation and eventual fabrication. However, little-to-no computational tools provide support for bridging the gap between high-level construction goals and low-level editing of pattern geometry, e.g., combining or switching garment elements, semantic editing, or design exploration that maintains the validity of a sewing pattern. We suggest the first DSL for garment modeling - GarmentCode - that applies principles of object-oriented programming to garment construction and allows designing sewing patterns in a hierarchical, component-oriented manner. The programming-based paradigm naturally provides unique advantages of component abstraction, algorithmic manipulation, and free-form design parametrization. We additionally support the construction process by automating typical low-level tasks like placing a dart at a desired location. In our prototype garment configurator, users can manipulate meaningful design parameters and body measurements, while the construction of pattern geometry is handled by garment programs implemented with GarmentCode. Our configurator enables the free exploration of rich design spaces and the creation of garments using interchangeable, parameterized components. We showcase our approach by producing a variety of garment designs and retargeting them to different body shapes using our configurator. The library and garment configurator are available at https://github.com/maria-korosteleva/GarmentCode.'}, {'id': 'computational_pattern_making', 'title': 'Computational pattern making from 3D garment models', 'URL': 'https://dl.acm.org/doi/10.1145/3528223.3530145', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3528223.3530145'], 'type': 'article', 'author': [{'family': 'Pietroni', 'given': 'Nico'}, {'family': 'Dumery', 'given': 'Corentin'}, {'family': 'Falque', 'given': 'Raphael'}, {'family': 'Liu', 'given': 'Mark'}, {'family': 'Vidal-Calleja', 'given': 'Teresa'}, {'family': 'Sorkine-Hornung', 'given': 'Olga'}], 'issued': {'date-parts': [[2022]]}, 'abstract': 'We propose a method for computing a sewing pattern of a given 3D garment model. Our algorithm segments an input 3D garment shape into patches and computes their 2D parameterization, resulting in pattern pieces that can be cut out of fabric and sewn together to manufacture the garment. Unlike the general state-of-the-art approaches for surface cutting and flattening, our method explicitly targets garment fabrication. It accounts for the unique properties and constraints of tailoring, such as seam symmetry, the usage of darts, fabric grain alignment, and a flattening distortion measure that models woven fabric deformation, respecting its anisotropic behavior. We bootstrap a recent patch layout approach developed for quadrilateral remeshing and adapt it to the purpose of computational pattern making, ensuring that the deformation of each pattern piece stays within prescribed bounds of cloth stress. While our algorithm can automatically produce the sewing patterns, it is fast enough to admit user input to creatively iterate on the pattern design. Our method can take several target poses of the 3D garment into account and integrate them into the sewing pattern design. We demonstrate results on both skintight and loose garments, showcasing the versatile application possibilities of our approach.'}, {'id': 'doi_10_1093_jcde_qwaf065', 'title': 'Real-to-sim high-resolution cloth modeling: Physical parameter optimization using particle-based simulation with robot manipulation data', 'URL': 'https://doi.org/10.1093/jcde/qwaf065', 'extra_urls': ['https://doi.org/10.1093/jcde/qwaf065'], 'type': 'article', 'author': [{'family': 'Yoon', 'given': 'Kang-il'}, {'family': 'Lim', 'given': 'Soo-Chul'}], 'abstract': 'This study proposes an optimized real-to-sim model that reflects the physical properties of real cloth to replicate realistic cloth behavior in simulation environments. While previous research has used data-driven or physics-guided methods to build simulation environments, those approaches are significantly limited due to reliance on data and restricted accuracy. In this study, we collect data from real robots manipulating cloth samples of various size and material, and develop a particle system-based cloth simulation model. By optimizing parameters based on real-world data, such as stretching, bending, friction, and damping, the simulation model reproduces the shapes of real cloth. In consequence, in comparison to previous studies that used physical parameter estimation, the proposed methodology demonstrates accuracy and generalization performance. Notably, the model maintains consistent similarity in unseen tasks, proving its adaptability across diverse tasks. This study presents a crucial step towards enhancing the practical applicability of simulation-based robotic learning and improving robot abilities to manipulate deformable objects.', 'DOI': '10.1093/jcde/qwaf065'}, {'id': 'clothed', 'title': 'PICA: Physics-Integrated Clothed Avatar', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11180929', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11180929'], 'type': 'article', 'author': [{'family': 'Peng', 'given': 'Bo'}, {'family': 'Tao', 'given': 'Yunfan'}, {'family': 'Zhan', 'given': 'Haoyu'}, {'family': 'Guo', 'given': 'Yudong'}, {'family': 'Zhang', 'given': 'Juyong'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'We introduce PICA, a novel representation for high-fidelity animatable clothed human avatars with physics-plausible dynamics, even for loose clothing. Previous neural rendering-based representations of animatable clothed humans typically employ a single model to represent both the clothing and the underlying body. While efficient, these approaches often fail to represent complex garment dynamics, leading to incorrect deformations and noticeable rendering artifacts, especially for sliding or loose garments. Furthermore, most previous works represent garment dynamics as pose-dependent deformations and facilitate novel pose animations in a data-driven manner. This often results in outcomes that do not faithfully represent the mechanics of motion and are prone to generating artifacts in out-of-distribution poses. To address these issues, we employ two individual 2D Gaussian Splatting (2DGS) models with different deformation characteristics, modeling the human body and clothing separately. This distinction allows for better handling of their respective motion characteristics. With this representation, we integrate a graph neural network (GNN)-based clothing physics simulation module to ensure a better representation of clothing dynamics. Our method, through its carefully designed features, achieves high-fidelity rendering of clothed human bodies in complex and novel driving poses, outperforming previous methods under the same settings. The source code will be available on our project page: https://ustc3dv.github.io/PICA/'}, {'id': 'doi_10_1177_00405175251358497', 'title': 'Example-based approach for automatic garment pattern generation', 'URL': 'https://doi.org/10.1177/00405175251358497', 'extra_urls': ['https://doi.org/10.1177/00405175251358497'], 'type': 'article', 'author': [{'family': 'Hong', 'given': 'Roujia'}, {'family': 'Zhang', 'given': 'Yarui'}, {'family': 'Zhang', 'given': 'Qi'}, {'family': 'Qian', 'given': 'Diqing'}, {'family': 'Jin', 'given': 'Yao'}, {'family': 'Zhang', 'given': 'Huaxiong'}, {'family': 'He', 'given': 'Lili'}], 'abstract': 'This paper proposes an example-based method for automated garment pattern generation, addressing challenges in craftsmanship standardization and geometric fidelity in existing 2D pattern techniques. This approach integrates graph neural network (GNN)-based garment panel segmentation with manufacturing-constrained flat pattern modeling to establish a seamless bridge between digital fashion design and traditional garment craftsmanship. More specifically, a sparse graph transformer is employed to efficiently segment 3D garment meshes into individual panels. Leveraging the technique of virtual node sparsification, this method remarkably reduces the computational complexity, enabling a more efficient segmentation process. To ensure its practical viability in industrial applications, the methodology incorporates two critical types of manufacturing constraints. Symmetry constraints are imposed on the internal boundaries of panels and seams, while boundary constraints are applied to guarantee smooth and production-friendly edges. A hybrid boundary optimization strategy, which combines geometric constraints with B-spline fitting, is then utilized to refine the generated 2D patterns. Comprehensive experimental evaluations demonstrate the superiority of the proposed method. On a self-constructed dataset, it achieves an impressive 99.99% segmentation accuracy, and on cross-domain models, the accuracy reaches 99.91%. Moreover, compared with conventional approaches, the training time is reduced by 34%. For dresses and T-shirts, the generated patterns exhibit 100% structural similarity to template patterns, significantly outperforming the compared methods. Although the proposed method results in a slightly higher stretching ratio (ranging from 0.0157 to 0.0378) compared with the baseline methods (0.0112\u20130.0189), it ensures well-organized panel layouts and smooth boundaries, strictly adhering to industry standards and effectively preventing cutting errors caused by irregular shapes. By maintaining regular panel layouts and enforcing geometric constraints explicitly, the generated patterns preserve high fidelity during 3D-to-2D flattening while meeting industrial production standards.', 'DOI': '10.1177/00405175251358497'}, {'id': 'doi_10_1177_00405175251335188', 'title': 'Deep learning for 3D garment generation: A review', 'URL': 'https://doi.org/10.1177/00405175251335188', 'extra_urls': ['https://doi.org/10.1177/00405175251335188'], 'type': 'article', 'author': [{'family': 'Sun', 'given': 'Yuexin'}, {'family': 'Hao', 'given': 'Zhenhua'}, {'family': 'Wang', 'given': 'Zhaohui'}, {'family': 'Jin', 'given': 'Jiping'}, {'family': 'Ye', 'given': 'Qinwen'}, {'family': 'Lyu', 'given': 'Yingrui'}], 'abstract': '3D garment models enhance the consumer experience by enabling virtual trying-on and personalized customization. Additionally, they streamline design and manufacturing processes, reduce resource waste, and drive the garment industry toward greater digitalization and sustainability. Nevertheless, the complexities of 3D garment modeling have impeded its widespread adoption. Recent significant advances in deep learning have catalyzed improvements in 3D garment model generation. This technology circumvents traditional time-consuming 3D modeling processes, enabling the direct generation of 3D garment models, and has garnered substantial attention. This paper presents a comprehensive and systematic review of advances in deep learning for 3D garment generation. It commences with an introduction to essential preliminaries, encompassing data representations, generation objectives and tasks, generative models, datasets, and evaluation methods. The review categorizes works in 3D garment generation into three distinct areas: mesh, texture, and pattern generation, providing an in-depth analysis of the most recent and advanced methods. Furthermore, the paper examines applications of 3D garment generation, discusses current challenges, and proposes directions for future research, offering valuable insights for continued exploration in this rapidly expanding field.', 'DOI': '10.1177/00405175251335188'}, {'id': 'doi_10_1007_s10489-025-06596-x', 'title': 'ClotheDreamer: Text-guided garment generation with 3D gaussians', 'URL': 'https://doi.org/10.1007/s10489-025-06596-x', 'extra_urls': ['https://doi.org/10.1007/s10489-025-06596-x'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Yufei'}, {'family': 'Tang', 'given': 'Junshu'}, {'family': 'Zheng', 'given': 'Chu'}, {'family': 'Zhu', 'given': 'Junwei'}, {'family': 'Wang', 'given': 'Chengjie'}, {'family': 'Huang', 'given': 'Dongjin'}], 'abstract': 'High-fidelity 3D garment synthesis from text is desirable yet challenging for digital avatar creation. Recent diffusion-based approaches via Score Distillation Sampling (SDS) have enabled new possibilities but either intricately couple with human body or struggle to reuse. We introduce ClotheDreamer, a 3D Gaussian-based method for generating wearable, production-ready 3D garment assets from text prompts. We propose a novel representation Disentangled Clothe Gaussian Splatting (DCGS) to enable separate optimization. DCGS represents clothed avatar as one gaussian model but freezes body Gaussian splats. To enhance quality and completeness, we incorporate bidirectional SDS to supervise clothed avatar and garment RGBD renderings respectively with pose conditions and propose a new pruning strategy for loose clothing. Our approach can also support custom clothing templates as input. Benefiting from our design, the synthetic 3D garment can be easily applied to virtual try-on and support physically accurate animation. Extensive experiments showcase our method\u2019s superior and competitive performance. Our project page is at https://ggxxii.github.io/clothedreamer.', 'DOI': '10.1007/s10489-025-06596-x'}, {'id': 'autoregressively_sewing', 'title': 'DressCode: Autoregressively Sewing and Generating Garments from Text Guidance', 'URL': 'https://dl.acm.org/doi/10.1145/3658147', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3658147'], 'type': 'article', 'author': [{'family': 'He', 'given': 'Kai'}, {'family': 'Yao', 'given': 'Kaixin'}, {'family': 'Zhang', 'given': 'Qixuan'}, {'family': 'Yu', 'given': 'Jingyi'}, {'family': 'Liu', 'given': 'Lingjie'}, {'family': 'Xu', 'given': 'Lan'}], 'issued': {'date-parts': [[2024]]}, 'abstract': &quot;Apparel's significant role in human appearance underscores the importance of garment digitalization for digital human creation. Recent advances in 3D content creation are pivotal for digital human creation. Nonetheless, garment generation from text guidance is still nascent. We introduce a text-driven 3D garment generation framework, DressCode, which aims to democratize design for novices and offer immense potential in fashion design, virtual try-on, and digital human creation. We first introduce SewingGPT, a GPT-based architecture integrating cross-attention with text-conditioned embedding to generate sewing patterns with text guidance. We then tailor a pre-trained Stable Diffusion to generate tile-based Physically-based Rendering (PBR) textures for the garments. By leveraging a large language model, our framework generates CG-friendly garments through natural language interaction. It also facilitates pattern completion and texture editing, streamlining the design process through user-friendly interaction. This framework fosters innovation by allowing creators to freely experiment with designs and incorporate unique elements into their work. With comprehensive evaluations and comparisons with other state-of-the-art methods, our method showcases superior quality and alignment with input prompts. User studies further validate our high-quality rendering results, highlighting its practical utility and potential in production settings. Our project page is https://IHe-KaiI.github.io/DressCode/.&quot;}, {'id': 'garment_pattern_generation', 'title': 'Garment pattern generation from image data', 'URL': 'https://patents.google.com/patent/US12198290B1/en', 'extra_urls': ['https://patents.google.com/patent/US12198290B1/en'], 'type': 'patent'}, {'id': 'image_generation', 'title': 'GenAI-Driven Image Generation Pipeline for Sustainable Garment Design and Waste Reduction in Fashion Production', 'URL': 'https://ojs.aaai.org/index.php/AAAI-SS/article/view/36056', 'extra_urls': ['https://ojs.aaai.org/index.php/AAAI-SS/article/view/36056'], 'type': 'article', 'author': [{'family': 'Ghori', 'given': 'Ilham'}, {'family': 'Karim', 'given': 'Kayvan'}, {'family': 'Alkawadri', 'given': 'Dima'}], 'abstract': 'The fashion industry\u2019s linear production model generates significant pre-consumer textile waste, especially during pattern cutting. In response to the environmental impact of fashion consumption, strategies such as reuse, recycling, and refashioning aim to divert textiles from landfills and promote sustainable practices. However, challenges in the textile sector\u2014such as raw material variability and complex manufacturing\u2014require more targeted solutions. Recent studies have identified Artificial Intelligence (AI) as a promising tool to enhance sustainability, streamline production, and enable personalised design. One such advancement is Generative AI (GenAI), which supports applications like virtual try-ons, fabric-to-garment transformations, and multimodal garment design via tools such as FashionGAN, StyleGAN, and Latent Diffusion Models. Despite these developments, current image generation methods struggle with preserving fabric detail and structural accuracy. This research proposes an image generation pipeline that accurately reflects specific fabric textures and visual attributes, offering designers greater creative control while reducing the need for physical samples\u2014thereby minimising process waste. The system is implemented using ComfyUI and LoRA-enhanced Stable Diffusion 1.5 models to overcome limitations found in existing methods. To evaluate performance, quantitative metrics such as FID, KID, SSIM, LPIPS, and CLIP-S were used to assess visual quality, structural similarity, and semantic alignment. A qualitative comparison was also conducted to evaluate fabric texture preservation and prompt consistency across models. Among the tested models, Realistic Vision v5.1 delivered the best results across most metrics and is recommended for photorealistic applications in sustainable fashion. DreamShaper v8 excelled in preserving fabric texture, while MajicMix v5 produced stylised outputs more suitable for conceptual design stages. This study aims to empower fashion designers with a flexible and sustainable design model, to reduce waste, accelerate prototyping, and explore AI-driven innovation in digital fashion.'}, {'id': 'doi_10_1108_IJCST-05-2024-0104', 'title': 'Development of garment design system using random polygon pattern generator', 'URL': 'https://doi.org/10.1108/IJCST-05-2024-0104', 'extra_urls': ['https://doi.org/10.1108/IJCST-05-2024-0104'], 'type': 'article', 'author': [{'family': 'Oh', 'given': 'Jihyun'}, {'family': 'Kim', 'given': 'Sungmin'}], 'abstract': 'This study aims to develop a random polygon garment pattern generator and a drape simulation system to automate the garment design process.Garments were categorized into four groups based on the geometric features of the human body. Garment patterns in each group consisted of basic points, and the patterns were automatically placed, sewn and simulated around the body in three-dimensional space. Additional pattern manipulation functions were developed to modify the shapes of patterns by adding darts and cuts, either manually or randomly.Users can produce new designs they had not considered before using the random manipulation functions. Since the three-dimensional simulation process is automated, users can focus solely on the design process.Garments composed of multiple layers were not considered.This system differs from existing clothing computer-aided design systems in that even users lacking prior knowledge of garment design can generate various examples. It can help users understand the relationship between 2D patterns and 3D garments without the need for a pattern drafting process.', 'DOI': '10.1108/IJCST-05-2024-0104'}, {'id': 'doi_10_1007_s00371-025-03876-y', 'title': 'Controllable fashion rendering via brownian bridge diffusion model with latent sketch encoding', 'URL': 'https://doi.org/10.1007/s00371-025-03876-y', 'extra_urls': ['https://doi.org/10.1007/s00371-025-03876-y'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Zengmao'}, {'family': 'Li', 'given': 'Jituo'}, {'family': 'Gao', 'given': 'Wei'}], 'abstract': 'Generating fashion designs from sketches and textures can significantly enhance design efficiency. While existing image generation frameworks can produce desired images based on language or sketch prompts, generating fine-grained fashion designs, especially with intricate sketches and textures, remains challenging. This necessitates models that can comprehend features at various levels within sketches and texture images. In this work, we propose FashionBBDM, a controllable fashion design framework built upon the Brownian Bridge Diffusion Model. FashionBBDM generates fashion designs from either existing or synthesized textures without relying on textual prompts. Our model employs a pre-trained UNet as the backbone network and introduces a latent space sketch encoder to extract multi-scale features from conditional images. Unlike traditional diffusion models, our image generation process commences from conditional images rather than Gaussian noise. In each generation iteration, the encoder output is integrated with the backbone network features to predictively output the next step, culminating in high-quality fashion design images. We quantitatively and qualitatively evaluate FashionBBDM using clothing and shoe datasets, demonstrating its superior conditional generation performance compared to state-of-the-art methods. Ablation experiments and result analyses further underscore the effectiveness of our framework\u2019s various components. Code and trained models are available on https://github.com/wzm206/FashionBBDM.', 'DOI': '10.1007/s00371-025-03876-y'}, {'id': 'doi_10_1108_IJCST-05-2024-0115', 'title': 'Fashion-tile: a tiled clothing image generation model based on improved conditional generative adversarial network', 'URL': 'https://doi.org/10.1108/IJCST-05-2024-0115', 'extra_urls': ['https://doi.org/10.1108/IJCST-05-2024-0115'], 'type': 'article', 'author': [{'family': 'Gu', 'given': 'Meihua'}, {'family': 'Chu', 'given': 'Yalu'}, {'family': 'Dong', 'given': 'Xiaoxiao'}], 'abstract': 'Clothing retrieval and matching tasks require the use of model clothing images as input. Due to the limitation of shooting postures and angles, direct using of model images for clothing retrieval or matching often faces many challenges. In view of this, this paper aims to propose a novel tiled clothing image generation model based on improved conditional generative adversarial network (GAN) that can generate clear and accurate tiled clothing images from selected model images.Aiming at the problems of local information loss and overall structure inaccuracy in tile clothing image generation, this paper optimizes pix2pixHD network model from three aspects: using spatial transformer network (STN) for spatial invariance optimization, using atrous spatial pyramid pooling (ASPP) for feature extraction optimization, using self-attention (SA) for global context information acquisition optimization. The improved network model is called fashion-tile, which can improve the quality and fidelity of tile clothing image generation.The experimental results show that the proposed method is obviously superior to the existing methods not only in the evaluation metrics, but also in the generating clothing image quality and fidelity. The peak signal-to-noise ratio (PSNR) value is increased by at least 6.6%, the structural similarity (SSIM) value is increased by at least 2.1%, and the Fr\xe9chet inception distance (FID) value is reduced by at least 8.6% on the person2cloth dataset.This work generates high-quality tiled clothing images that enhance the preservation of clothing details and structures, providing consumers with a clearer and more realistic visual experience, thereby increasing shopping satisfaction and purchase intention. With continuous technological advancements and deeper application, the proposed method is expected to play a greater role in the future of clothing e-commerce, offering consumers a richer and more authentic shopping experience.The proposed method provides an effective solution for generating tiled clothing from model images, which will help to improve the accuracy of subsequent clothing retrieval and matching, and help to enhance the consumers shopping experience and effectively promote sales.', 'DOI': '10.1108/IJCST-05-2024-0115'}, {'id': 'doi_10_1080_21650349_2025_2529167', 'title': 'Qualitative-empirical insights into generative AI for textile design in the fashion design process', 'URL': 'https://doi.org/10.1080/21650349.2025.2529167', 'extra_urls': ['https://doi.org/10.1080/21650349.2025.2529167'], 'type': 'article', 'author': [{'family': 'Wu', 'given': 'Xiaopei'}, {'family': 'Li', 'given': 'Li'}], 'abstract': 'With the popularization of generative AI, its application in fashion design has become a heavily explored area. However, despite this trend, existing studies of AI applications in fashion design have predominantly concentrated on addressing style attributes, and given less attention toward textile attributes and real-world practical implications. This indicates an opportunity to explore the practical industry application of generative AI specifically toward the textile design component of the fashion design process. This study aims fill this gap by setting out to empirically evaluate the potential value of using generative AI to create textile designs in the fashion design process. It addresses this objective by conducting a series of qualitative semi-structured interviews with 10 fashion industry professionals. Through thematic analysis of the interviews, this study uncovers the potential advantages and obstacles associated with implementing generative AI for textile design in the fashion industry. The outcome of this study sheds light on the potential benefits and barriers of integrating generative AI as a creative tool to facilitate textile design in the fashion design process.', 'DOI': '10.1080/21650349.2025.2529167'}, {'id': 'doi_10_1093_jcde_qwaf037', 'title': 'StitchingNet and deep transfer learning method for sewing stitch defect detection', 'URL': 'https://doi.org/10.1093/jcde/qwaf037', 'extra_urls': ['https://doi.org/10.1093/jcde/qwaf037'], 'type': 'article', 'author': [{'family': 'Jung', 'given': 'Woo-Kyun'}, {'family': 'Kang', 'given': 'Jingu'}, {'family': 'Kwon', 'given': 'Woojin'}, {'family': 'Kim', 'given': 'Hyungjung'}], 'abstract': 'The clothing manufacturing industry has been slow to adopt new technologies due to its labor-intensive nature, resulting in persistent defect rates averaging around 10%. Deep learning models offer a promising solution for automated sewing defect detection, but their effectiveness relies heavily on large training datasets. This study addresses this challenge by introducing StitchingNet, a comprehensive dataset comprising over 14.5K images of sewing stitches categorized into normal and ten different defect classes. The dataset covers diverse sewing conditions by incorporating eleven fabric-thread combinations. Furthermore, we propose a novel deep transfer learning method that leverages pre-trained deep learning models, including both convolutional neural networks and vision transformers. This method employs a two-stage approach: wide-screening to identify promising candidate models, followed by systematic fine-tuning to optimize their performance for sewing defect detection. Implementing the deep transfer learning method with StitchingNet and evaluating it through on-site feasibility testing and Grad-CAM visualization, we demonstrate that the fine-tuned MobileNetV1-S.C model achieves exceptional performance with an F1-score of 0.99. This highlights the effectiveness of our proposed dataset and deep transfer learning method in developing high-performing models for sewing defect detection, achieving superior results in terms of both accuracy (F1-score) and speed (inference time).', 'DOI': '10.1093/jcde/qwaf037'}, {'id': 'artistic_fashion', 'title': 'FS-control: Artistic fashion design with discriminated and conditional diffusion model', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0097849325001451', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0097849325001451'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Hang'}, {'family': 'Wu', 'given': 'Jionghang'}, {'family': 'Chen', 'given': 'Zhengkui'}, {'family': 'Xu', 'given': 'Weiwei'}, {'family': 'He', 'given': 'Lili'}], 'abstract': 'Deep learning-driven approaches to image-based fashion design have garnered significant attention in recent years. As a burgeoning area within the field, integrating fashion design with reference styles from non-fashion domains has become a focus of scholarly investigation. However, current methods for style transfer face notable challenges. These include the absence of representative fashion-guided samples and the substantial discrepancies between the fashion source domain and the reference style domain. Such limitations frequently compromise the structural coherence of generated outputs, leading to results that lack realism and fail to meet practical application standards. To mitigate these issues, we propose an unsupervised generative framework, FS-Control. This framework synthesizes diffusion models, GANs, and ControlNet to ensure structural fidelity and effective style-aware transfer across significant domain differences. ControlNet is utilized to explicitly regulate the structural features of the source fashion item, while a foreground mask is incorporated to bridge the domain gap between the fashion item and the style image. A specialized discriminator is employed, trained to differentiate between real and fake samples within the latent space. This discriminator guides the generative process, ensuring effective style transfer from a single style image to the fashion item while preserving its structural integrity. Extensive qualitative and quantitative analyses, supported by comprehensive ablation studies, demonstrate the effectiveness of our approach. The results consistently show that our method outperforms existing baseline models, achieving a superior balance between content fidelity and authentic style transfer.'}, {'id': 'doi_10_1177_00405175241279976', 'title': 'AI-driven computational creativity in fashion design: a review', 'URL': 'https://doi.org/10.1177/00405175241279976', 'extra_urls': ['https://doi.org/10.1177/00405175241279976'], 'type': 'article', 'author': [{'family': 'Wu', 'given': 'Jennifer Xiaopei'}, {'family': 'Li', 'given': 'Li'}], 'abstract': 'The emergence of text-to-image generative AI tools has garnered significant attention, particularly in creative design applications. This review article explores the field of AI-driven computational creativity, which has witnessed advancements in computational methods, ranging from traditional programming-based techniques to machine learning algorithms, and now to deep learning models. These deep learning models, including the recent text-to-image generative AI tools, have demonstrated impressive capabilities in creative content generation. While previous studies have examined the application of AI in the fashion industry, this review aims to provide a unique perspective. First, it presents AI-driven creativity within the framework of computational creativity, offering historical context. Second, it focuses specifically on the creative design applications in the fashion industry, rather than other aspects such as retail or supply chain. Lastly, it evaluates the outcomes of these studies from the perspective of industry fashion designers, considering the creative and practical value, instead of solely focusing on technical and theoretical performance from a computer science standpoint. By incorporating these distinct perspectives, this review contributes to the understanding of AI applications in fashion design and highlights their relevance in the creative domain.', 'DOI': '10.1177/00405175241279976'}, {'id': 'an_immersive', 'title': 'Made-In: An immersive human-in-the-loop analytics platform for enhancing creative processes in fashion', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1077314225001778', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1077314225001778'], 'type': 'article', 'author': [{'family': 'Balloni', 'given': 'Emanuele'}, {'family': 'Pietrini', 'given': 'Rocco'}, {'family': 'Sasso', 'given': 'Michele'}, {'family': 'Frontoni', 'given': 'Emanuele'}, {'family': 'Paolanti', 'given': 'Marina'}], 'abstract': 'The fashion industry is undergoing a digital transformation, driven by growing demands for sustainability, personalization and immersive experiences. In this paper, we present Made-In (Multimodal and Collaborative Artificial Intelligence for the Design of Inclusive and Sustainable Fashion): an immersive, human-in-the-loop analytics system designed to support fashion professionals in exploring, comparing and contextualizing product data across digital and social platforms. Unlike generative or simulation-based approaches, Made-In provides creative decision support by aggregating real-world data from luxury brand websites and social media. This enables designers and merchandisers to make informed, context-aware choices. The system comprises three core modules: a 3D configurator for visualizing product assortments; a collection grid interface for the comparative analysis of e-commerce data; and a social media trend detector based on deep learning pipelines for image classification, object detection and color clustering. Two curated datasets, one derived from Instagram and the other from fashion e-tailers, provide the system with analytics. A user study with domain experts confirms the platform\u2019s usability and relevance for trend forecasting, sustainability evaluation and visual merchandising strategy. The results demonstrate that Made-In effectively bridges the gap between data analytics and human creativity in fashion, offering a scalable solution that aligns with EU goals for digital sustainability and inclusivity.'}, {'id': 'multimodal_enhancement', 'title': 'MEF-GD: Multimodal Enhancement and Fusion Network for Garment Designer', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11145096', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11145096'], 'type': 'article', 'author': [{'family': 'Song', 'given': 'Dan'}, {'family': 'Zhou', 'given': 'Juan'}, {'family': 'Zeng', 'given': 'Jianhao'}, {'family': 'Tian', 'given': 'HongShuo'}, {'family': 'Zheng', 'given': 'Bolun'}, {'family': 'Kang', 'given': 'Rongbao'}, {'family': 'Liu', 'given': 'An-An'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'In recent years, with advancements in generative models, an increasing number of garment design methods have been proposed. A generative model capable of generating garment images from text and sketches can provide designers with valuable visual references and creative inspiration to aid in the design process. Existing multimodal garment design methods face the challenge of lacking precise control over the generated results in relation to both sketches and text. In this paper, we propose Multimodal Enhancement and Fusion Network for Garment Design (MEF-GD). Our model inputs image conditions into Stable Diffusion based on ControlNet. On one hand, directly inputting image conditions can lead to feature forgetting, defined as the phenomenon in deep neural networks where previously learned feature representations are lost. To address this issue, we propose a multiple feature injection module to more effectively enhance image condition features. On the other hand, ControlNet fuses control features into Stable Diffusion through pointwise addition, which ignores the interaction between multimodal features and results in the fused features being biased towards the control features, overlooking Stable Diffusion features. To address this limitation, we introduce content-guided attention for more effective feature fusion and improve the expression of text features. Additionally, existing datasets often contain vague textual descriptions of garments. It is difficult to train the model on such a dataset to learn accurate alignment between generated image and the textual descriptions. To address this issue, we have designed a multimodal large model text optimization module to improve the quality and clarity of text generation. Compared to existing multimodal garment design methods, MEF-GD achieves more effective alignment with both textual and sketch-based inputs in generating garment images. Compared to MGD, MEF-GD achieves a decrease of 2.44 in FID and an increase of 0.83 in CLIP Score on Multi-VITON-HD dataset. The code will be available at https://github.com/fengyun691340/MEF-GD.'}, {'id': 'collaborative_garment_design', 'title': 'Collaborative garment design through group chatting with generative industrial large models', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1474034625002599', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1474034625002599'], 'type': 'article', 'author': [{'family': 'Rachana Harish', 'given': 'Arjun'}, {'family': 'Yuan', 'given': 'Zhaolin'}, {'family': 'Li', 'given': 'Ming'}, {'family': 'Yang', 'given': 'Hongxia'}, {'family': 'Huang', 'given': 'George Q.'}], 'abstract': 'The collaborative garment designing lifecycle involves stages such as designing, styling, and patterning. Some of these stages can be partially or fully automated using industrial large models (LMs), such as generative and large language models. The key to quick and cost-effective order fulfillment is the orchestration of group interactions, or a group chat, between the stakeholders and LMs in garment design. However, certain unaddressed aspects, such as knowledge retention, generalization, and complexity of group interaction, are critical to realizing group chat for garment design. This study proposes a framework called ChatFashion for group chat in garment design. Transformer, a core construct of the proposed framework, orchestrates interaction among stakeholders and industrial LMs. It undergoes an evolution with the intelligence it picks up from its interaction with diverse stakeholders and industrial LMs, allowing it to act as a one-stop solution for multidisciplinary design needs. This study contributes to theory in the following aspects. First, it proposes transformers to eliminate concerns about knowledge retention by industrial LMs. Second, while other studies focus on the benefits of industrial LMs to simplify individual stages in garment design, this study introduces the design and demonstration of a ChatFashion framework for collaborative garment designing using industrial LMs. Finally, this study advances the literature on prompt engineering of industrial LMs by utilizing collaborative learning (or models learning from each other) to capture and orchestrate the group chat among stakeholders, signifying its practicality and value for research in garment design.'}, {'id': 'fashion', 'title': 'DiffFashion: Reference-Based Fashion Design With Structure-Aware Transfer by Diffusion Models', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10261222', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10261222'], 'type': 'article', 'author': [{'family': 'Cao', 'given': 'Shidong'}, {'family': 'Chai', 'given': 'Wenhao'}, {'family': 'Hao', 'given': 'Shengyu'}, {'family': 'Zhang', 'given': 'Yanting'}, {'family': 'Chen', 'given': 'Hangyue'}, {'family': 'Wang', 'given': 'Gaoang'}], 'issued': {'date-parts': [[2024]]}, 'abstract': 'Image-based fashion design with AI techniques has attracted increasing attention in recent years. We focus on the reference-based fashion design task, where we aim to combine a reference appearance image and a clothing image to generate a new fashion clothing image. Although existing diffusion-based image translation methods have enabled flexible style transfer, it is often difficult to transfer the appearance of the image realistically during reverse diffusion. When the referenced appearance domain greatly differs from the source domain, it often leads to the collapse in the translation. To tackle this issue, we present a novel diffusion model-based unsupervised structure-aware transfer method, namely DiffFashion. Our method is free of model tuning and structure-preserving and has high flexibility in transferring from images with large domain gaps. Specifically, based on the optimal transport properties, we keep a shared latent across the clothing image and reference appearance image to bridge the gap between the two domains in the denoising process, and the latent of the reference image is gradually adapted to the clothing domain. Simultaneously, the structure is transferred from the source clothing to the output fashion image with mixed guidance, including pre-trained Vision Transformer (ViT) guidance and a foreground mask guidance, to further preserve the structure and appearance semantics from source and reference images. Our experimental results show that the proposed method outperforms state-of-the-art baseline models, generating more realistic images in the fashion design task.'}, {'id': 'display_your', 'title': 'FashionGAN: Display your fashion design using Conditional Generative Adversarial Nets', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13552', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13552'], 'type': 'article', 'author': [{'family': 'Cui', 'given': 'Y. R.'}, {'family': 'Liu', 'given': 'Q.'}, {'family': 'Gao', 'given': 'C. Y.'}, {'family': 'Su', 'given': 'Z.'}], 'issued': {'date-parts': [[2018]]}, 'abstract': 'Virtual garment display plays an important role in fashion design for it can directly show the design effect of the garment without having to make a sample garment like traditional clothing industry. In this paper, we propose an end-to-end virtual garment display method based on Conditional Generative Adversarial Networks. Different from existing 3D virtual garment methods which need complex interactions and domain-specific user knowledge, our method only need users to input a desired fashion sketch and a specified fabric image then the image of the virtual garment whose shape and texture are consistent with the input fashion sketch and fabric image can be shown out quickly and automatically. Moreover, it can also be extended to contour images and garment images, which further improves the reuse rate of fashion design. Compared with the existing image-to-image methods, the quality of images generated by our method is better in terms of color and shape.'}, {'id': 'ai_assisted_fashion', 'title': 'AI Assisted Fashion Design: A Review', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10223039', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10223039'], 'type': 'article', 'author': [{'family': 'Guo', 'given': 'Ziyue'}, {'family': 'Zhu', 'given': 'Zongyang'}, {'family': 'Li', 'given': 'Yizhi'}, {'family': 'Cao', 'given': 'Shidong'}, {'family': 'Chen', 'given': 'Hangyue'}, {'family': 'Wang', 'given': 'Gaoang'}], 'issued': {'date-parts': [[2023]]}, 'abstract': 'This review explores the integration of enhanced personalization and seamless multimodal interfaces in the field of fashion design and recommendation. We examine the increasing demand for personalized fashion experiences and the potential of multimodal interfaces in facilitating effective communication between designers and users. By leveraging user preferences, body measurements, and style choices, artificial intelligence (AI) systems can deliver highly personalized fashion recommendations. The integration of various input modalities, including text, images and sketches, enables designers and users to communicate their design ideas with ease. The primary results highlight the transformative potential of enhanced personalization and seamless multimodal interfaces, empowering designers and consumers to co-create unique and personalized designs. This paradigm shift fosters a deeper level of engagement and creativity within the fashion industry. Embracing this advancement unlocks unprecedented opportunities for designers, brands, and consumers, ushering in a new era of innovation and creativity in fashion design.'}, {'id': 'doi_10_1080_00405000_2023_2236320', 'title': 'Textronics: a review of their technological aspects and applications', 'URL': 'https://doi.org/10.1080/00405000.2023.2236320', 'extra_urls': ['https://doi.org/10.1080/00405000.2023.2236320'], 'type': 'article', 'author': [{'family': 'Younes', 'given': 'Basel'}], 'abstract': 'The advancement of smart sensors, wireless communication technologies, embedded system and Nano-technologies makes Textronics possible to develop smart textiles to monitor activities in modern applications; in addition to form a significant of Internet of Things (IoT) by connecting smart electronic textiles securely for regular applications such as healthcare, sports, automobile, and defense. This paper reviews the recent advances in E-textiles and smart textile and Textronics, and identifies the relationship between Textronics and mechatronics, and nano-technologies, soft computing and signal lines, in addition to describe the connecting between Textronics system designs, developments, and evaluation techniques. Textronics react to physical parameters along with other features, and make combine between the electronic and smart textiles using textile-based sensors, electrodes and other smart devices and materials. Research and development investments will foster the adoption of novel Textronics applications as sustainable and cost-effective solutions with light-weight, high-performance wearable devices and products for monitoring a wide range of activities.', 'DOI': '10.1080/00405000.2023.2236320'}, {'id': 'doi_10_1080_16864360_2005_10738343', 'title': 'ClothAssembler: a CAD Module for Feature-based Garment Pattern Assembly', 'URL': 'https://doi.org/10.1080/16864360.2005.10738343', 'extra_urls': ['https://doi.org/10.1080/16864360.2005.10738343'], 'type': 'article', 'author': [{'family': 'Fontana', 'given': 'Marzia'}, {'family': 'Carubelli', 'given': 'Alberto'}, {'family': 'Rizzi', 'given': 'Caterina'}, {'family': 'Cugini', 'given': 'Umberto'}], 'abstract': 'This work presents a CAD prototype, named ClothAssembler, targeted at complex-shaped apparel design for real manufacturing. The intent is to fill a gap in the current CAD technology for garment design as it is mainly conceived for 2D/3D geometric modelling of cloth shapes, but generally does not provide high level operators that allow interactive and easy design of aesthetic/functional features that characterize the garment pieces, and relations/connections between parts. Though still an academic prototype, ClothAssembler allows to define/choose in an interactive way all the necessary geometric and functional information for the design and finishing of 2D pieces, such as insertion of textile layers, reinforcement lines, pockets, cut lines and pleats, as well as topological information about how pieces are pair-wise connected and assembled, by definition of seams, darts, zips, constraints such as buttons and hooks, etc. A taxonomy and parametrization of cloth tailoring features is discussed, and system functionalities are presented, with applications to garment models of real production.', 'DOI': '10.1080/16864360.2005.10738343'}, {'id': 'doi_10_1080_00405000_2024_2352183', 'title': 'Artificial intelligence-based precise prediction of anthropometric data for female garment pattern-making', 'URL': 'https://doi.org/10.1080/00405000.2024.2352183', 'extra_urls': ['https://doi.org/10.1080/00405000.2024.2352183'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Yuanjing'}, {'family': 'Shen', 'given': 'Hong'}, {'family': 'Shi', 'given': 'Yuyuan'}, {'family': 'Yang', 'given': 'Wenjing'}, {'family': 'Wang', 'given': 'Wei'}, {'family': 'Wan', 'given': 'Ruyu'}, {'family': 'Dodd', 'given': 'Linzi'}], 'abstract': 'Anthropometric data form the cornerstone of garment pattern-making. This article introduces an artificial intelligence-driven approach, employing a back-propagation artificial neural network (BP-ANN), to predict the anthropometric data essential for crafting patterns for women\u2019s upper tops. The model adeptly processes minimal critical data from women\u2019s upper bodies, yielding projected dimensions that are arduous to manually measure yet crucial for tailoring body-fitting tops. Utilising a three-dimensional body scanner for accurate anthropometric data collection from 196 women in Sichuan Province, China, our study compares the BP-ANN model with a Linear Regression (LR) model. Results demonstrate superior predictive accuracy for BP-ANN. Notably, the BP-ANN model excels in efficiency and accuracy, particularly in challenging anthropometric parameters. The findings underscore the transformative potential of AI-based models in optimizing garment production processes, offering a precise alternative to traditional methods. This research contributes valuable insights for the integration of AI technology in advancing pattern-making practices.', 'DOI': '10.1080/00405000.2024.2352183'}, {'id': 'doi_10_1080_17543261003689888', 'title': '3D CAD systems for the clothing industry', 'URL': 'https://doi.org/10.1080/17543261003689888', 'extra_urls': ['https://doi.org/10.1080/17543261003689888'], 'type': 'article', 'author': [{'family': 'Sayem', 'given': 'Abu Sadat Muhammad'}, {'family': 'Kennon', 'given': 'Richard'}, {'family': 'Clarke', 'given': 'Nick'}], 'abstract': 'The approaches for designing virtual garments may be categorised as \u20182D to 3D\u2019 and \u20183D to 2D\u2019. The former refers to draping flat digital pattern pieces on a virtual mannequin, and the later indicates the development of clothing design on a realistic body and subsequent flattening into 2D pattern pieces. Several computer-aided design (CAD) systems for garment visualisation in space from flat patterns have already been introduced into the clothing industry. Any industrial application of the pattern flattening technique is yet to be made, due to the non-availability of an appropriate CAD system on the market. This article reviews the historical developments of 3D CAD systems for the clothing industry, and assesses the features of currently available systems on market.', 'DOI': '10.1080/17543261003689888'}, {'id': 'doi_10_1080_00405000_2023_2249701', 'title': 'Automatic design-preserving virtual garment transfer', 'URL': 'https://doi.org/10.1080/00405000.2023.2249701', 'extra_urls': ['https://doi.org/10.1080/00405000.2023.2249701'], 'type': 'article', 'author': [{'family': 'Ye', 'given': 'Qinwen'}, {'family': 'Wang', 'given': 'Zhaohui'}, {'family': 'Huang', 'given': 'Rong'}, {'family': 'Liu', 'given': 'Huanhuan'}, {'family': 'Lyu', 'given': 'Yingrui'}], 'abstract': 'Design-preserving garment transfer which can transfer a garment from one body to another is a powerful technique in computer graphics. In this paper, we propose a novel method for automatic design-preserving garment transfer. Firstly, the correspondence between the source garment and the source body is automatically calculated by finding the nearest face\u2019s barycenter from the garment to the body. Secondly, the mesh deformation transfer algorithm is utilized to obtain the target garment. After aligning the target garment and body with the ICP algorithm, the virtual fitting result can finally be obtained by fitting the target garment onto the target body. For a new garment worn on the source body, our approach can quickly and effectively transfer the garment to the target body while preserving the designed details. Two experiments were carried out to validate the applicability and effectiveness of our method. The results showed that our method could be applied to different garments for human bodies with different shapes and poses. Additionally, we introduced a new method for evaluating our transferred garments based on similarity and fit. Moreover, our approach can be applied to garments with different particle distances and performs better than the \u2018Auto grading\u2019 technique of CLO 3D. Our proposed method is simple, effective, automated and fast. Therefore, it has a significant potential for improving personalized garment development efficiency.', 'DOI': '10.1080/00405000.2023.2249701'}, {'id': 'doi_10_1080_00405000_2024_2343120', 'title': 'Measurements-to-body: 3D human body reshaping based on anthropometric measurements', 'URL': 'https://doi.org/10.1080/00405000.2024.2343120', 'extra_urls': ['https://doi.org/10.1080/00405000.2024.2343120'], 'type': 'article', 'author': [{'family': 'Ye', 'given': 'Qinwen'}, {'family': 'Huang', 'given': 'Rong'}, {'family': 'Wang', 'given': 'Zhaohui'}, {'family': 'Lyu', 'given': 'Yingrui'}, {'family': 'Liu', 'given': 'Huanhuan'}, {'family': 'Sun', 'given': 'Yuexin'}], 'abstract': 'Accurate 3D human models are useful for many applications in virtual fitting, ergonomics, film and television, and video games. However, due to the limitations of 3D scanners and body privacy, creating a virtual human body that accurately represents a specific human body is challenging. Therefore, reshaping 3D human bodies based on anthropometric measurements has received extensive attention. However, the existing methods have some drawbacks, such as the inability of the reshaped body to change its posture, the lack of a good link between the real and virtual measurements, and unreasonable anthropometry definitions. In this paper, we propose a new framework for reshaping the 3D human body using five easily available measurements: height, weight, chest, waist, and hip. First, the STAR model was used to fit the SPRING dataset to obtain the SPRING-fitted dataset, where the shape parameters of the STAR model are used to characterize each 3D human body. Second, optimizing the virtual measurement algorithm constructed a good link between real and virtual measurements. Then, the measurements of the human bodies in the SPRING-fitted dataset were extracted. Finally, the semantic reshaping of the 3D human body can be achieved by constructing a neural network model that uses the five measurements to predict 20 shape parameters. The results show that the human body reconstructed by our method can keep its size close to the real human body and conform to the shape of the real human body. Thus, it can meet the needs of the garment industry. In addition, the reshaped human body can be adjusted to different postures, which is beneficial to virtual fitting.', 'DOI': '10.1080/00405000.2024.2343120'}, {'id': 'digital_tools_in', 'title': 'Digital Tools in Action: 3D Printing for Personalized Skincare in the Era of Beauty Tech', 'URL': 'https://www.mdpi.com/2079-9284/12/4/136', 'extra_urls': ['https://www.mdpi.com/2079-9284/12/4/136'], 'type': 'article', 'author': [{'family': 'Bom', 'given': 'Sara'}, {'family': 'Pinto', 'given': 'Pedro Contreiras'}, {'family': 'Ribeiro', 'given': 'Helena Margarida'}, {'family': 'Marto', 'given': 'Joana'}], 'abstract': '3D printing (3DP) enables the development of highly customizable skincare solutions, offering precise control over formulation, structure, and aesthetic properties. Therefore, this study explores the impact of patches\u2019 microstructure on hydration efficacy using conventional and advanced chemical/morphological confocal techniques. Moreover, it advances to the personalization of under-eye 3D-printed skincare patches and assesses consumer acceptability through emotional sensing, providing a comparative analysis against a non-3D-printed market option. The results indicate that increasing the patches\u2019 internal porosity enhances water retention in the stratum corneum (53.0 vs. 45.4% \xb5m). Additionally, patches were personalized to address individual skin needs/conditions (design and bioactive composition) and consumer preferences (color and fragrance). The affective analysis indicated a high level of consumer acceptance for the 3D-printed option, as evidenced by the higher valence (14.5 vs. 1.1 action units) and arousal (4.2 vs. 2.7 peaks/minute) scores. These findings highlight the potential of 3DP for personalized skincare, demonstrating how structural modifications can modulate hydration. Furthermore, the biometric-preference digital approach employed offers unparalleled versatility, enabling rapid customization to meet the unique requirements of different skin types. By embracing this advancement, a new era of personalized skincare emerges, where cutting-edge science powers solutions for enhanced skin health and consumer satisfaction.'}, {'id': 'doi_10_1177_15589250241254443', 'title': 'Development of a textile sheet mask design for facial care based on a 3D face model of an average woman', 'URL': 'https://doi.org/10.1177/15589250241254443', 'extra_urls': ['https://doi.org/10.1177/15589250241254443'], 'type': 'article', 'author': [{'family': 'Rudolf', 'given': 'Andreja'}, {'family': '\u0160terman', 'given': 'Sonja'}, {'family': 'Cupar', 'given': 'Andrej'}], 'abstract': 'Facial cosmetics moisturise the skin and remove sebum and impurities to maintain healthy skin. Face masks are available on the market in various forms such as gel, emulsion, sheet and paste. The textile sheet mask for facial care is used by all women, regardless of age. This study deals with 3D scanning of women\u2019s faces to create an average female 3D face model for the development of a textile sheet mask design for facial care. Screened Poisson surface reconstruction was used to create an average female 3D face model whose dimensions correspond to average dimensions of scanned female faces. A reliable average 3D face model of the women studied was therefore used to develop a textile sheet mask for facial care. A comparison of average facial measurements with the measurements of randomly selected masks on the market revealed differences. Therefore, a design for a textile sheet mask was developed based on average facial measurements and the average 3D face model of a woman and by using virtual prototyping. The use of software for prototyping and simulating the appearance of clothing has also proven to be effective in the development of a textile product such as a textile face mask. The developed pattern design of the textile sheet mask with optimal dimensions and shape adapts to the contours of an average woman\u2019s face. This fulfils all the requirements for wearing comfort of the textile sheet mask around the eyes, nose and lips during facial care and enables efficient transfer of the serum from the textile sheet mask to the skin.', 'DOI': '10.1177/15589250241254443'}, {'id': 'development_of_textile', 'title': 'Development of textile structures using 3D prototyping technologies', 'URL': 'https://journals.uran.ua/tarp/article/view/327068', 'extra_urls': ['https://journals.uran.ua/tarp/article/view/327068'], 'type': 'article', 'author': [{'family': 'Mytsa', 'given': 'Viktoriia'}, {'family': 'Riabchykov', 'given': 'Mykola'}, {'family': 'Popova', 'given': 'Tetyana'}, {'family': 'Nikulina', 'given': 'Anastasiia'}], 'abstract': 'The object of the research is pseudotextile mesh structures with three-dimensional hinged joints, manufactured by 3D prototyping methods. One of the main tasks in the field of 3D printing of textile materials is to ensure their flexibility, elasticity and adaptability to the shape of the human body. Materials produced by traditional 3D printing methods have high rigidity, which limits their application in the light industry. During the study, a concept for creating pseudotextile materials based on flexible network structures using spherical three-dimensional hinges was developed. The proposed structure allows for achieve the necessary flexibility and deformation capabilities characteristic of traditional textile materials. Modeling and experimental samples demonstrated that structures with three-layer hinged joints provide spatial variability of shape, while the use of eccentricity in the hinges allows to adjust the rigidity of the structures. The obtained results can be attributed to the use of three-level spherical hinge joints, which provide spatial mobility of individual elements of the structure, as well as numerical modeling to optimize the sizes of structural elements. The implemented models confirm that the mechanical properties of the synthesized structures can be controlled by changing their geometry. The developed structures can be utilized in the clothing production where high flexibility of the material is required, as well as in the creation of adaptive textile products for medical purposes, in particular for compression therapy or automated massage. Additionally, such materials can be used in the decorative design of fashion products.'}, {'id': 'the_impact_of', 'title': 'The Impact of Technological Advances on the Future of Counterfeiting', 'URL': '#item_20252', 'type': 'article', 'author': [{'family': 'Santos', 'given': 'Jo\xe3o Carlos Dias dos'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Routledge', 'abstract': 'This chapter examines the evolving landscape of counterfeiting, influenced by swift technological progress. It delves into the latest techniques employed in product counterfeiting, including 3D printing, digital manipulation, deepfake technologies, and advanced chemical synthesis. Various sectors are highlighted, such as pharmaceuticals, electronics, fashion, and food and beverages, providing insight into the strategies used by counterfeiters to create deceptively authentic replicas. The chapter also explores innovative countermeasures and leading-edge technologies, including blockchain, advanced authentication methods, artificial intelligence, and spectroscopy. Additionally, it addresses the prospective challenges posed by emerging technologies and the complexities involved in adapting legal frameworks to these changes. Through a thorough analysis, the chapter presents a forward-looking view on the implications of technological advancements on counterfeiting and the necessary strategies to effectively combat these illicit activities.'}, {'id': 'doi_10_1007_978-981-96-6530-3_2', 'title': 'Evolution and Engineering Concepts of Traditional Textiles', 'URL': 'https://doi.org/10.1007/978-981-96-6530-3_2', 'type': 'article', 'author': [{'family': 'Amjad', 'given': 'Akhtarul Islam'}, {'family': 'Sharma', 'given': 'Swati'}, {'family': 'Vaseem', 'given': 'Md.'}, {'family': 'Singh', 'given': 'J. P.'}, {'family': 'Pahuja', 'given': 'Bharti'}, {'family': 'Mukhopadhyay', 'given': 'Samrat'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Springer Nature', 'abstract': 'Textile has been part of human civilisation and culture since its inception and various cultural and geographical regions have had their methods and techniques of textile manufacturing. The textile methods and techniques in India have developed over time and have long historical and cultural importance. These techniques have been refined and optimised over time. The aim of this chapter is to explore the evolution and engineering advancements in traditional textiles and have an overview of the impact of these changes on stockholders. The first section of this chapter delves into traditional yarn manufacturing, focusing on hand-spinning techniques and the mechanics of the Indian spinning wheel (Charkha). This is followed by an in-depth review of traditional weaving, covering the various types of handlooms and their operational principles, as well as the materials and techniques employed in handloom weaving. The subsequent chapter examines recent innovations in handloom technology, highlighting their role in enhancing efficiency while preserving heritage. The next section explores India\u2019s natural dyeing and printing crafts, emphasising sustainable and traditional processes. Additionally, the chapter hand embroidery, showcasing the precision and skill involved in this intricate art form. The final section highlights the growing role of artificial intelligence (AI) in traditional textiles. It discusses AI-based applications that enhance design, improve weaving methods, and support sustainable practices.', 'DOI': '10.1007/978-981-96-6530-3_2'}, {'id': 'doi_10_1108_AA-07-2022-0183', 'title': 'The application of robotics and artificial intelligence in embroidery: challenges and benefits', 'URL': 'https://doi.org/10.1108/AA-07-2022-0183', 'extra_urls': ['https://doi.org/10.1108/AA-07-2022-0183'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Ling'}, {'family': 'Su', 'given': 'Zhi'}, {'family': 'He', 'given': 'Xiaotong'}, {'family': 'Chen', 'given': 'Xiang'}, {'family': 'Dong', 'given': 'Lin'}], 'abstract': &quot;Embroidery as a textile embellishment technique plays an important role in people's daily life. Esthetic embroidery artworks possess cultural values. With the development of robotics and artificial intelligence (AI), these technologies have been studied and applied in the embroidery process. This study aims to survey how these technologies facilitate embroidery from different aspects.This paper surveys how the technologies of robotics and AI are applied in the embroidery field. The applications are mainly reviewed from three aspects: computerized robotic embroidery systems has been widely used for the mass production of embroidered textiles, the advanced technological systems and techniques have greatly facilitated the development of smart textiles and the artificial intelligence plays an important role in the inheritance, innovation and protection of traditional handicraft artwork of embroidery.The programmable robotic embroidery machines have greatly improved the production efficiency of embroidered textiles and promoted the development of electronic textiles. The AI, mainly the deep learning technology, brings significant benefits to esthetic embroidery creation. Technology-based embroidery has become a hot research topic in the field of textiles.This paper summarizes the application of robotics and AI technologies in the field of embroidery, which provides readers a comprehensive and systematic understanding about the research progress of modern technology-oriented embroidery. This helps readers gain inspiration from the technology perspectives.&quot;, 'DOI': '10.1108/AA-07-2022-0183'}, {'id': 'knitting_a', 'title': 'Knitting Robots: A Deep Learning Approach for Reverse-Engineering Fabric Patterns', 'URL': 'https://www.mdpi.com/2079-9292/14/8/1605', 'extra_urls': ['https://www.mdpi.com/2079-9292/14/8/1605'], 'type': 'article', 'author': [{'family': 'Sheng', 'given': 'Haoliang'}, {'family': 'Cai', 'given': 'Songpu'}, {'family': 'Zheng', 'given': 'Xingyu'}, {'family': 'Lau', 'given': 'Mengcheng'}], 'abstract': 'Knitting, a cornerstone of textile manufacturing, is uniquely challenging to automate, particularly in terms of converting fabric designs into precise, machine-readable instructions. This research bridges the gap between textile production and robotic automation by proposing a novel deep learning-based pipeline for reverse knitting to integrate vision-based robotic systems into textile manufacturing. The pipeline employs a two-stage architecture, enabling robots to first identify front labels before inferring complete labels, ensuring accurate, scalable pattern generation. By incorporating diverse yarn structures, including single-yarn (sj) and multi-yarn (mj) patterns, this study demonstrates how our system can adapt to varying material complexities. Critical challenges in robotic textile manipulation, such as label imbalance, underrepresented stitch types, and the need for fine-grained control, are addressed by leveraging specialized deep-learning architectures. This work establishes a foundation for fully automated robotic knitting systems, enabling customizable, flexible production processes that integrate perception, planning, and actuation, thereby advancing textile manufacturing through intelligent robotic automation.'}, {'id': 'doi_10_1177_00405175241312407', 'title': 'Mesh-based simulation of knitted dresses with loop units', 'URL': 'https://doi.org/10.1177/00405175241312407', 'extra_urls': ['https://doi.org/10.1177/00405175241312407'], 'type': 'article', 'author': [{'family': 'Cheng', 'given': 'Bilian'}, {'family': 'Jiang', 'given': 'Gaoming'}, {'family': 'Zhang', 'given': 'Fanglue'}, {'family': 'Wan', 'given': 'Ailan'}, {'family': 'Peng', 'given': 'Jiajia'}, {'family': 'Liu', 'given': 'Haisang'}, {'family': 'Gao', 'given': 'Lizhong'}], 'abstract': 'The three-dimensional simulation of knitted garments is an integral part of the three-dimensional visualization of textile garments. To realize the three-dimensional structure simulation and dressing simulation of knitted dresses, this paper proposes a fast three-dimensional simulation method of knitted dresses based on mesh division and loop units. Based on studying the process characteristics of knitted dresses, the dress pattern is quantified and meshed, and the loop unit\u2019s geometric and mesh models are established. The spatial matrix is used to calculate the spatial transformation relationship of each pair of triangles in the flat model and surface model of the dress, and the spatial transformation relationship is used to calculate the position of the loop mesh point in the triangular mesh of the surface model, the three-dimensional coordinates of the loop unit control point are obtained, and the loop is drawn. Based on C# technology, the model data of the personalized human body model and knitted dress are read, and the three-dimensional graphics library OpenGL and loop drawing method are used to realize the three-dimensional simulation of the knitted dress based on loop structure. The simulation effect of a V-neck dress and high-neck dress under different particle spacing is used as an example to test the simulation method. The results show that when the mesh of the dress model is divided under the particle spacing of 20\u2009mm, the three-dimensional simulation of the dress based on the loop unit can be realized quickly and with high quality.', 'DOI': '10.1177/00405175241312407'}, {'id': 'doi_10_1177_00405175241306133', 'title': 'Topology, integrity, and stability analysis of weft-knitted textiles', 'URL': 'https://doi.org/10.1177/00405175241306133', 'extra_urls': ['https://doi.org/10.1177/00405175241306133'], 'type': 'article', 'author': [{'family': 'Maharaj', 'given': 'Levi Kapllani'}, {'family': 'Amantides', 'given': 'Chelsea'}, {'family': 'Dion', 'given': 'Genevieve'}, {'family': 'Shapiro', 'given': 'Vadim'}, {'family': 'Breen', 'given': 'David E.'}], 'abstract': 'Despite their long-time existence and significant capabilities, computational modeling, simulation, and design tools have been underutilized for textiles in general, specifically limiting the ability of knitted textiles to be widely deployed and to reach their full industrial potential in advanced functional fabrics and garments. These computational tools require a robust representation and efficient evaluation of the spatial, material, and physical properties of textile structures. An example of an efficient modeling method for knitted fabrics is TopoKnit, a process-oriented representation for capturing the topology of weft-knitted textiles. In this paper, we extend TopoKnit and present new algorithms that may be used to determine additional topological structures and assess the structural integrity and stability of knitted textiles modeled by this fundamental data structure. We compare our results with outputs from a commercial software system to confirm the effectiveness and validity of our algorithms. These new capabilities provide a foundation for open technologies that can accurately model and predict the geometric and mechanical properties/behaviors of knitted textiles. They will support the development of computational design and analysis tools that will obviate the expensive and wasteful trial-and-error process of knitting and testing actual fabrics in the preproduction phase of textile manufacturing.', 'DOI': '10.1177/00405175241306133'}, {'id': 'knit_deformation', 'title': 'Real-Time Knit Deformation and Rendering', 'URL': 'https://dl.acm.org/doi/10.1145/3731184', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3731184'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Tao'}, {'family': 'Shi', 'given': 'Haoyang'}, {'family': 'Wang', 'given': 'Mengdi'}, {'family': 'Qiu', 'given': 'Yuxing'}, {'family': 'Yang', 'given': 'Yin'}, {'family': 'Wu', 'given': 'Kui'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'The knit structure consists of interlocked yarns, with each yarn comprising multiple plies comprising tens to hundreds of twisted fibers. This intricate geometry and the large number of geometric primitives present substantial challenges for achieving high-fidelity simulation and rendering in real-time applications. In this work, we introduce the first real-time framework that takes an animated stitch mesh as input and enhances it with yarn-level simulation and fiber-level rendering. Our approach relies on a knot-based representation to model interlocked yarn contacts. The knot positions are interpolated from the underlying mesh, and associated yarn control points are optimized using a physically inspired energy formulation, which is solved through a GPU-based Gauss-Newton scheme for real-time performance. The optimized control points are sent to the GPU rasterization pipeline and rendered as yarns with fiber-level details. In real-time rendering, we introduce several decomposition strategies to enable realistic lighting effects on complex knit structures, even under environmental lighting, while maintaining computational and memory efficiency. Our simulation faithfully reproduces yarn-level structures under deformations, e.g., stretching and shearing, capturing interlocked yarn behaviors. The rendering pipeline achieves near-ground-truth visual quality while being 120,000\xd7 faster than path tracing reference with fiber-level geometries. The whole system provides real-time performance and has been evaluated through various application scenarios, including knit simulation for small patches and full garments and yarn-level relaxation in the design pipeline.'}, {'id': 'knittable_stitch_meshes', 'title': 'Knittable Stitch Meshes', 'URL': 'https://dl.acm.org/doi/10.1145/3292481', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3292481'], 'type': 'article', 'author': [{'family': 'Wu', 'given': 'Kui'}, {'family': 'Swan', 'given': 'Hannah'}, {'family': 'Yuksel', 'given': 'Cem'}], 'issued': {'date-parts': [[2019]]}, 'abstract': 'We introduce knittable stitch meshes for modeling complex 3D knit structures that can be fabricated via knitting. We extend the concept of stitch mesh modeling, which provides a powerful 3D design interface for knit structures but lacks the ability to produce actually knittable models. Knittable stitch meshes ensure that the final model can be knitted. Moreover, they include novel representations for handling important shaping techniques that allow modeling more complex knit structures than prior methods. In particular, we introduce shift paths that connect the yarn for neighboring rows, general solutions for properly connecting pieces of knit fabric with mismatched knitting directions without introducing seams, and a new structure for representing short rows, a shaping technique for knitting that is crucial for creating various 3D forms, within the stitch mesh modeling framework. Our new 3D modeling interface allows for designing knittable structures with complex surface shapes and topologies, and our knittable stitch mesh structure contains all information needed for fabricating these shapes via knitting. Furthermore, we present a scheduling algorithm for providing step-by-step hand knitting instructions to a knitter, so that anyone who knows how to knit can reproduce the complex models that can be designed using our approach. We show a variety of 3D knit shapes and garment examples designed and knitted using our system.'}, {'id': 'fits_like_a', 'title': 'Fits like a glove? Knowledge and use of size finders and high-end fashion retail returns', 'URL': 'https://www.sciencedirect.com/science/article/pii/S2444569X25001246', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S2444569X25001246'], 'type': 'article', 'author': [{'family': 'Patel', 'given': 'Pankaj C.'}, {'family': 'Karlsson', 'given': 'Stefan'}, {'family': 'Oghazi', 'given': 'Pejvak'}], 'abstract': 'With returns imposing a growing burden on retail supply chains, major e-commerce platforms are increasingly implementing size recommendations to curb returns. Based on a fit valence and fit reference framework, we test whether customers using the size finder are more likely or less likely to return products. We use confidential data from a major fashion e-commerce platform in Sweden that introduced a size finder based on customer-supplied information on weight, build, hips, waist, shoulders, leg-to-torso length, and body shape. In a sample of 496,365 items ordered by 75,707 customers from 113 countries between July 2015 to April 2022, those using the size finder are 0.65% more likely to return an item. The findings are robust to a variety of econometrics tests. Furthermore, machine learning analysis based on gradient boosted trees shows that size finder is among the least important features in predicting returns. However, for each unit quarterly increase in the use of the size finder with purchased items, the customer lifetime value (CLV) increases by 7.51% in the next quarter and 5.53% in the subsequent quarter. Post-hoc interviews with executives in the e-commerce sector demonstrated that, when implementing size recommendation tools, managers in fashion retailers must weigh a small increase in returns against higher CLV from repeat customers.'}, {'id': 'intelligent_automation_in', 'title': 'Intelligent Automation in Knitting Manufacturing: Advanced Software Integration and Structural Optimisation for Complex Textile Design', 'URL': 'https://www.mdpi.com/2076-3417/15/10/5775', 'extra_urls': ['https://www.mdpi.com/2076-3417/15/10/5775'], 'type': 'article', 'author': [{'family': 'Angelova', 'given': 'Radostina A.'}, {'family': 'Sofronova', 'given': 'Daniela'}, {'family': 'Raycheva', 'given': 'Violina'}, {'family': 'Borisova', 'given': 'Elena'}], 'abstract': 'Automation in textile manufacturing plays a pivotal role in enhancing production efficiency, precision, and innovation. This study investigates the integration of intelligent technologies in the knitting sector, focusing on industrial flat knitting machines from a leading manufacturer and the use of the advanced software platform M1plus V7.5. The software\u2019s capabilities for the digital design and simulation of complex patterned and structural knits are explored through the development and production of five experimental knitted designs. Each sample is evaluated in terms of its structural characteristics and dimensional behaviour after washing. The results highlight the potential of software-driven optimisation to improve product accuracy, reduce shrinkage variability, and support smart manufacturing practices in the textile industry.'}, {'id': 'intelligent_and_precise', 'title': 'Intelligent and Precise Textile Drop-Off: A New Strategy for Integrating Soft Fingers and Machine Vision Technology', 'URL': 'https://www.mdpi.com/2673-7248/5/3/34', 'extra_urls': ['https://www.mdpi.com/2673-7248/5/3/34'], 'type': 'article', 'author': [{'family': 'Shen', 'given': 'Jinzhu'}, {'family': 'Ram\xedrez-G\xf3mez', 'given': '\xc1lvaro'}, {'family': 'Wang', 'given': 'Jianping'}, {'family': 'Zhang', 'given': 'Fan'}, {'family': 'Li', 'given': 'Yitong'}], 'abstract': 'This study presents a novel drop-off strategy for automated fabric handling in intelligent apparel manufacturing, addressing the critical challenge of drift-free placement of lightweight, flexible textiles. A pneumatically driven retractable plate is introduced as an auxiliary device, along with machine vision technology, to eliminate drop-off deviations inherent in traditional soft grippers. By synchronizing the retraction motion of the plate with soft gripper release, the fabric is transferred onto the target surface without free-fall drift, achieving sub-0.5 mm alignment accuracy across 15 fabric types. Machine vision-based inspection validates drop-off quality in real time. This work offers a low-cost, drift-free drop-off solution for pre-sewing automation.'}, {'id': 'doi_10_1108_RJTA-08-2021-0106', 'title': 'Industry 4.0 in textile and apparel sector: a systematic literature review', 'URL': 'https://doi.org/10.1108/RJTA-08-2021-0106', 'extra_urls': ['https://doi.org/10.1108/RJTA-08-2021-0106'], 'type': 'article', 'author': [{'family': 'Dal Forno', 'given': 'Ana Julia'}, {'family': 'Bataglini', 'given': 'Walakis Vieira'}, {'family': 'Steffens', 'given': 'Fernanda'}, {'family': 'Ulson de Souza', 'given': 'Antonio Augusto'}], 'abstract': 'This paper aims to present a systematic review of the development process of Industry 4.0 in the textile and apparel sector, as well as to show some concepts, examples found in the literature on the application of the principles and technologies involved like the internet of things (IoT), cloud computing, Big Data, autonomous robots, three-dimensional (3D) printing, augmented reality, virtual prototyping, horizontal and vertical system integration and cybersecurity.The methodology adopted in this study was a systematic literature review aided by the use of SciMAT, a scientific mapping software. Documents were collected from the Web of Science and Scopus database from 2011 to 2020 using the words \u201cTextile\u201d and \u201cIndustry 4.0\u201d that result in 865 documents and 115 were analyzed.The literature review showed that the textile industry in the international context is at an incipient stage of the implementation of Industry 4.0. The main aspects of Industry 4.0 that were identified in the textile industry initially focus on the implementation of technologies aimed at computerization and automation of processes, whose main focuses are increasing productivity and reducing costs. Projects for the implementation of augmented reality and 3D printing and simulation technologies in the textile industry, clothing and apparel area are still embryonic, normally implemented through tools and software oriented toward the creation and development of new models of processes, products and commerce.The search in the databases was carried out on October 17, 2020. Therefore, for future study, other combinations of search terms and time update are suggested, in addition to including more databases besides Scopus and Web of Science.This literature review served as the basis for the development of a questionnaire that was applied to 72 people in an industry in the clothing sector, located in the state of Santa Catarina, southern Brazil.The benefits of industry 4.0 are perceived in people with its implementation, such as a reduction in energy consumption of around 15%, an increase of up to 25% in work efficiency, in addition to more assertive decision-making, improvement of processes and balance between life and work.Machine learning, artificial intelligence, smart fabrics, IoT, supply chain management, environmental protection, Big Data, autonomation and cyber physics were the strongest terms found, consolidating as a prominent field for current and future studies. From emerging and/or still unexplored areas of Industry 4.0 in the textile sector, there is real-time communication, computer applications, carbon, fibers, health care and sustainable development. Some strategic actions that are taking place in some countries are summarized and in Brazil the adoption rate is 29% for this sector, revealing itself as a needy area and suitable for the development of studies that address the subject.', 'DOI': '10.1108/RJTA-08-2021-0106'}, {'id': 'stitching_competition_with', 'title': 'Stitching competition with digital threads: Unveiling the drivers of competitive success in the apparel sector', 'URL': 'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325945', 'extra_urls': ['https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325945'], 'type': 'article', 'author': [{'family': 'Susitha', 'given': 'Emmanuel'}, {'family': 'Jayarathne', 'given': 'Amila'}, {'family': 'Herath', 'given': 'H. M. R. P.'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'This study explores and validates the dimensions of digital capabilities and competitive performance within the apparel industry, aiming to develop a robust, multidimensional measurement instrument. Employing a sequential QUAL\u2192QUAN exploratory design, the research began with in-depth interviews with key industry experts to identify critical constructs. These insights informed the subsequent quantitative phase, in which exploratory factor analysis and confirmatory factor analysis were applied to confirm the factor structure and validate the instrument. The study identifies four key dimensions of competitive performance in the apparel supply chain: customer satisfaction, better utilisation of resources, collaboration to compete, and strategic advantage. Process and technical digitalisation emerged as essential components of digital capabilities, reflecting the dual role of digital infrastructure and operational integration in enhancing performance. Theoretically, this research contributes by introducing validated instruments grounded in the Resource-based view, the Dynamic capabilities view, and the Extended resource-based view, offering an empirical framework that links digital capabilities with competitive performance. Practically, the instrument provides apparel manufacturers with a diagnostic tool to assess digital maturity and strategically align digital initiatives with performance goals. These findings are particularly relevant for firms navigating rapid technological change and seeking sustained global apparel supply chain competitiveness.'}, {'id': 'doi_10_1108_RJTA-08-2020-0090', 'title': 'Technology adoption in the apparel industry: insight from literature review and research directions', 'URL': 'https://dx.doi.org/10.1108/RJTA-08-2020-0090', 'extra_urls': ['https://dx.doi.org/10.1108/RJTA-08-2020-0090'], 'type': 'article', 'author': [{'family': 'Hoque', 'given': 'Md Aynul'}, {'family': 'Rasiah', 'given': 'Rajah'}, {'family': 'Furuoka', 'given': 'Fumitaka'}, {'family': 'Kumar', 'given': 'Sameer'}], 'abstract': 'Purpose. This paper aims to identify key theoretical cornerstones and research trends in the apparel industry. It also compares theoretical bases with those of the general research domain in technology adoption literature and, thus, provides future policy guidelines for practitioners and research gaps for further studies.Design/methodology/approach. Documents were collected from the Web of Science (core collection) database using systematic methods. The bibliometric coupling and co-citation analyses were conducted using VOSviewer software to construct theoretical cornerstones and research trends in the apparel industry.Findings. Literature in the apparel industry focuses mainly on the diffusion of innovation and the theory of reasoned action. Hence, the literature lacks investigations of technology\u2013organization\u2013environment and institutional theories for technology adoption in the apparel industry. This study also traces six clusters of prevalent research trends: radiofrequency identification, virtual-try on technology for e-commerce, computer-aided design, Industry 4.0 technologies, virtual-try on technology in design and information technology.Originality/value. Little research is done on theoretical cornerstones on technology adoption in the apparel industry. This study looks into the theoretical bases for technology adoption, research trends in the apparel supply chain and calls for future research necessities.', 'DOI': '10.1108/RJTA-08-2020-0090'}, {'id': 'a_compiler_for', 'title': 'A compiler for 3D machine knitting', 'URL': 'https://dl.acm.org/doi/10.1145/2897824.2925940', 'extra_urls': ['https://dl.acm.org/doi/10.1145/2897824.2925940'], 'type': 'article', 'author': [{'family': 'McCann', 'given': 'James'}, {'family': 'Albaugh', 'given': 'Lea'}, {'family': 'Narayanan', 'given': 'Vidya'}, {'family': 'Grow', 'given': 'April'}, {'family': 'Matusik', 'given': 'Wojciech'}, {'family': 'Mankoff', 'given': 'Jennifer'}, {'family': 'Hodgins', 'given': 'Jessica'}], 'issued': {'date-parts': [[2016]]}, 'abstract': 'Industrial knitting machines can produce finely detailed, seamless, 3D surfaces quickly and without human intervention. However, the tools used to program them require detailed manipulation and understanding of low-level knitting operations. We present a compiler that can automatically turn assemblies of high-level shape primitives (tubes, sheets) into low-level machine instructions. These high-level shape primitives allow knit objects to be scheduled, scaled, and otherwise shaped in ways that require thousands of edits to low-level instructions. At the core of our compiler is a heuristic transfer planning algorithm for knit cycles, which we prove is both sound and complete. This algorithm enables the translation of high-level shaping and scheduling operations into needle-level operations. We show a wide range of examples produced with our compiler and demonstrate a basic visual design interface that uses our compiler as a backend.'}, {'id': 'doi_10_3389_ejcmp_2025_13875', 'title': 'Exploring the generative AI potential in the fashion design process: an experimental experience on the collaboration between fashion design practitioners and generative AI tools', 'URL': 'https://doi.org/10.3389/ejcmp.2025.13875', 'extra_urls': ['https://doi.org/10.3389/ejcmp.2025.13875'], 'type': 'article', 'author': [{'family': 'Rizzi', 'given': 'Greta'}, {'family': 'Bertola', 'given': 'Paola'}], 'abstract': 'Over recent years, the rise of Generative Artificial Intelligence (Gen AI) has led to the emergence of numerous tools for the creation of visual and textual content. This technological advancement, supported by increasingly robust data management systems and targeted research efforts in this direction, has driven the continuous refinement of Machine Learning and Deep Learning models. As a result, Gen AI tools have demonstrated ever-increasing performance, leading to their rapid adoption in various sectors, including the Cultural and Creative Industries (CCI). Here, they are being integrated into value-creation pipelines, potentially impacting both production processes and career prospects for creative professionals.As a consequence, critical questions have emerged about the widespread use of Gen AI, related to the nature of their generative capabilities, often encapsulated under the umbrella term of &quot;computational creativity&quot;, which has begun to challenge the traditional conception of creativity as an intrinsic and exclusive capacity of human beings, with implications across all fields in which human creativity is central, such as the design disciplines.In light of the current scenario, the presented research aims to discuss the application of Gen AI tools for image, text, and video generation in fashion design. The analysis draws on the results of a didactic laboratory entitled Artificial A(i)rchive, which involved design practitioners from the Master\'s degree course in Design for the Fashion System at Politecnico di Milano.Within this workshop, the adoption of Gen AI was investigated, examining how AI was integrated at various stages of the design process and highlighting both the potential and shortcomings of applying Gen AI to support the activities of fashion designers. The article thus aims to contribute to the discussion and identification of collaborative models between fashion designers and AI, while situating the findings within a broader reflection on emerging creative practices and their potential implications.', 'DOI': '10.3389/ejcmp.2025.13875'}, {'id': 'doi_10_17918_00011002', 'title': 'Automating garment pattern making with AI: evaluating the performance and practical utility of fine-tuned large language models in fashion production', 'URL': 'https://doi.org/10.17918/00011002', 'extra_urls': ['https://doi.org/10.17918/00011002'], 'type': 'report', 'author': [{'family': 'Chen', 'given': 'Junyi'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Drexel University', 'abstract': 'This study investigates the effectiveness of machine learning models in automating garment pattern generation, addressing critical challenges in the fashion manufacturing industry. Traditional pattern-making methods, while refined through generations of practice, remain labor-intensive and constrained by human limitations in accommodating diverse body shapes and complex geometries. Through a comprehensive mixed-methods approach, this research develops and evaluates an AI-powered pattern generation system utilizing fine-tuned large language models (LLMs) including ChatGPT-4o, GPT-4o-mini, Gemini 1.5, and Llama 3.1. The methodology employed a two-stage AI pipeline architecture: (1) a vision model for extracting garment features from images and converting them to structured JSON format, and (2) specialized models for transforming JSON specifications into SVG pattern files. Training datasets were systematically constructed using over 10,000 garment patterns from industry partner URBN and the public GarmentCodeData repository. Three distinct fine-tuning approaches were evaluated: specialized training on 150 simple jumpsuit patterns, moderate training on 300 mixed-complexity pants patterns, and comprehensive training on 3,000 diverse garment types. Expert evaluation by professional pattern makers from URBN revealed counterintuitive findings regarding the relationship between training data characteristics and output quality. The specialized jumpsuit model achieved approximately 42% usability in manufacturing contexts, requiring only minor adjustments for production implementation. Conversely, models trained on larger, more diverse datasets (300 and 3,000 examples) produced patterns deemed unsuitable for real-world manufacturing, despite conventional machine learning expectations that larger datasets improve performance. The research identified an exponential relationship between pattern complexity and training data requirements, with simple patterns amenable to AI automation while complex designs continue to challenge current technological capabilities. Technical limitations included difficulties in capturing nuanced construction details, managing diverse human anatomical variations, and maintaining manufacturing-ready specifications. The vision component demonstrated robust performance in feature extraction, showing predictable scaling with dataset size. Key findings indicate that focused, application-specific AI models outperform general-purpose systems for pattern generation. The study provides empirical evidence that successful AI integration in pattern making requires strategic focus on specific garment categories with consistent construction principles rather than pursuing universal automation. These results suggest that AI should augment rather than replace human expertise, with optimal applications in standardized pattern production where consistency and efficiency are prioritized over creative complexity. This research contributes to understanding AI applications in creative industries by establishing performance benchmarks and identifying optimal training strategies for technical design automation. The findings offer practical guidance for fashion companies considering AI adoption, educators developing curricula that integrate AI literacy, and researchers advancing automated design technologies. Future work should explore hybrid human-AI approaches and specialized models for different garment categories while addressing material property integration and cultural design variations. Keywords: artificial intelligence, machine learning, garment pattern making, automated design, fashion technology, large language models, computer vision, human-AI collaboration.', 'DOI': '10.17918/00011002'}, {'id': 'doi_10_1088_1748-0221_20_05_C05006', 'title': 'New candidate polymeric wavelength shifters for noble liquid detectors', 'URL': 'https://doi.org/10.1088/1748-0221/20/05/C05006', 'extra_urls': ['https://doi.org/10.1088/1748-0221/20/05/C05006'], 'type': 'article', 'author': [{'family': 'Ku\u017aniak', 'given': 'M.'}, {'family': 'Choudhary', 'given': 'S.'}, {'family': 'Paw\u0142owski', 'given': 'S.'}, {'family': 'Cortez', 'given': 'A.F.V.'}, {'family': 'Kaczorowski', 'given': 'M.'}, {'family': 'Kumosi\u0144ski', 'given': 'M.'}, {'family': 'Abramowicz', 'given': 'A.'}, {'family': '\u0141\u0119cki', 'given': 'T.'}, {'family': 'Nieradka', 'given': 'G.'}, {'family': 'Sworobowicz', 'given': 'T.'}, {'family': 'Jamanek', 'given': 'D.'}], 'abstract': 'Polymeric wavelength shifters are of particular interest for large liquid argon detectors. Inspired by the success of polyethylene naphthalate (PEN), other new polymers exhibiting a similar type of excimer fluorescence were investigated. We report on the preliminary results of the first cryogenic wavelength shifting test of a solution-cast film of PVN, poly(2-vinyl naphthalene). Significant brittleness was identified as a factor potentially limiting the use of PVN. However, clear signs of wavelength shifting were observed, with the overall efficiency and time response comparable to those of PEN.', 'DOI': '10.1088/1748-0221/20/05/C05006'}, {'id': 'preparing_for_the', 'title': 'Preparing for the Digital Product Passport', 'URL': 'https://aaltodoc.aalto.fi/handle/123456789/137065', 'extra_urls': ['https://aaltodoc.aalto.fi/handle/123456789/137065'], 'type': 'thesis', 'author': [{'family': 'Siira', 'given': 'Salla'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Aalto University', 'abstract': &quot;Changes await the clothing industry as the European Union will soon require clothes to come with a digital product passport. A digital product passport is a system consisting of data, a digital platform, and a data carrier, which requires information about product responsibility, circularity, and legal compliance. The first requirements concerning digital product passports are likely to come into force in 2027. The textile digital product passport is introduced early, as textiles are one of the European Commission's priorities. For the digital product passport, companies will need to collect significant amounts of data about their supply chains and product sustainability. Clothing supply chains are known to be complex, so it is recommended to start preparations as early as possible. This thesis investigated the criteria that can be prepared for before the final requirements of the digital product passport are set. Additionally, the work examined the preparation and challenges of Finnish small and micro-sized clothing companies regarding the implementation of the digital product passport. The research was conducted by studying legislation and literature, as well as interviewing three experts. The experts worked in clothing companies and are involved in implementation process of the digital product passport. The literature revealed that there are several aspects of the digital product passport that companies can already prepare for. Companies can collect likely required data and centralize their data. Companies can also consider suitable data carriers as well as the execution of the digital platform. The research found that the examined companies are well prepared considering the current uncertainty in regulation. The companies have plenty of data from their supply chains. Moreover, two out of three companies would choose QR codes for the data carrier and two out of three would choose service providers to execute the digital platform. QR codes and service providers help implement the digital product passport faster. Companies still need to improve their data centralization, as data was stored on various platforms and not all data was accessible to all employees. One of the challenges identified in the work was the lack of resources. The companies do not have time, money, or employees to dedicate to studying digital product passports. The second challenge was collecting environmental impact data. Digital product passports and their impacts will need to be researched before and after the final implementation, since they will be required for almost all physical products, which results in a significant impact across industries.&quot;}, {'id': 'a_systematic_literature', 'title': 'A Systematic Literature Review on Digital Twins in Circular Supply Chain Management', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1002/bse.70038', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1002/bse.70038'], 'type': 'article', 'author': [{'family': 'Polimetla', 'given': 'Jeremiah Sunadh'}, {'family': 'Sindhwani', 'given': 'Rahul'}, {'family': 'Bag', 'given': 'Surajit'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'This study presents a systematic literature review exploring the role of Digital Twins (DTs) in Circular Supply Chain Management (CSCM). Employing a structured methodology based on the PRISMA protocol and analyzed through the Theory, Context, Characteristics, and Method (TCCM) framework, the review synthesizes 109 peer-reviewed articles published between 2000 and 2024. Using bibliographic coupling, the research identifies six thematic clusters: (1) Integration of DT in Supply Chain; (2) DT and Industry 4.0; (3) Big Data, AI, and Circular Economy; (4) Risk Management and Supply Chain Resilience; (5) Additive Manufacturing and Spare Parts Logistics; and (6) Metaverse and Smart Factory Operations. Additionally, the study categorizes 86 unique theories applied in the DT-CSCM literature, with Resource-Based Theory, Complexity Theory, and Control Theory among the most cited. Key contributions include clarifying the intellectual structure of DT-CSCM research, highlighting emerging research directions, and offering practical recommendations for industry practitioners and policymakers seeking to enhance supply chain sustainability and digital transformation. These deeply meaningful findings considerably improve our comprehension of the rapid pace of technological improvement in DT and its significant implications for the development of resilient, sustainable supply chains.'}, {'id': 'and', 'title': &quot;France's Anti-waste and Circular Economy Law&quot;, 'URL': 'https://content.ellenmacarthurfoundation.org/m/54c053dd73f80168/original/France-s-Anti-waste-and-Circular-Economy-Law.pdf', 'extra_urls': ['https://content.ellenmacarthurfoundation.org/m/54c053dd73f80168/original/France-s-Anti-waste-and-Circular-Economy-Law.pdf'], 'type': 'report', 'author': [{'family': 'Ellen MacArthur Foundation'}], 'issued': {'date-parts': [[2020]]}, 'publisher': 'Ellen MacArthur Foundation', 'abstract': &quot;Overview of France's Anti-waste and Circular Economy Law (AGEC Law)&quot;}, {'id': 'the_coasean', 'title': 'The Coasean Singularity? Demand, Supply, and Market Design with AI Agents', 'URL': '#item_20286', 'type': 'article', 'author': [{'family': 'Shahidi', 'given': 'Peyman'}, {'family': 'Rusak', 'given': 'Gili'}, {'family': 'Manning', 'given': 'Benjamin S'}, {'family': 'Fradkin', 'given': 'Andrey'}, {'family': 'Horton', 'given': 'John J'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'AI agents\u2014autonomous systems that perceive, reason, and act on behalf of human principals\u2014are poised to transform digital markets by dramatically reducing transaction costs. This chapter evaluates the economic implications of this transition, adopting a consumer-oriented view of agents as market participants that can search, negotiate, and transact directly. From the demand side, agent adoption reflects derived demand: users trade off decision quality against effort reduction, with outcomes mediated by agent capability and task context. On the supply side, firms will design, integrate, and monetize agents, with outcomes hinging on whether agents operate within or across platforms. At the market level, agents create efficiency gains from lower search, communication, and contracting costs, but also introduce frictions such as congestion and price obfuscation. By lowering the costs of preference elicitation, contract enforcement, and identity verification, agents expand the feasible set of market designs but also raise novel regulatory challenges. While the net welfare effects remain an empirical question, the rapid onset of AI-mediated transactions presents a unique opportunity for economic research to inform real-world policy and market design.'}, {'id': 'digital_product_passport', 'title': 'Digital product passport for the textile sector | Think Tank | European Parliament', 'URL': 'https://www.europarl.europa.eu/thinktank/en/document/EPRS_STU(2024)757808', 'extra_urls': ['https://www.europarl.europa.eu/thinktank/en/document/EPRS_STU(2024)757808'], 'type': 'webpage', 'author': [{'family': 'European Parliament'}], 'issued': {'date-parts': [[2024]]}, 'abstract': 'Digital product passport for the textile sector'}, {'id': 'security_attacks_in', 'title': 'Security attacks in Opportunistic Mobile Networks: A systematic literature review', 'URL': 'https://www.sciencedirect.com/science/article/abs/pii/S1084804523000917', 'extra_urls': ['https://www.sciencedirect.com/science/article/abs/pii/S1084804523000917'], 'type': 'article', 'author': [{'family': 'Altaweel', 'given': 'Ala'}, {'family': 'Aslam', 'given': 'Sidra'}, {'family': 'Kamel', 'given': 'Ibrahim'}], 'issued': {'date-parts': [[2024]]}}, {'id': 'walking_the', 'title': 'Zalando: Walking the talk | Zalando Corporate', 'URL': 'https://corporate.zalando.com/en/walking-talk', 'extra_urls': ['https://corporate.zalando.com/en/walking-talk'], 'type': 'webpage', 'author': [{'family': 'Zalando'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'All informations about \u201eWalking the talk\u201c at Zalando Corporate \u2713 Current information about Zalando SE'}, {'id': 'comply_or', 'title': 'Comply or Die, the future of fashion and the industry\u2019s potential mass extinction. | Dust Magazine', 'URL': 'https://dustmagazine.com/comply-or-die-the-future-of-fashion-and-the-industrys-potential-mass-extinction/', 'extra_urls': ['https://dustmagazine.com/comply-or-die-the-future-of-fashion-and-the-industrys-potential-mass-extinction/'], 'type': 'article', 'author': [{'family': 'Vitali', 'given': 'Luigi'}]}, {'id': 'doi_10_1080_0951192X_2025_2556440', 'title': 'From smart manufacturing in Industry 4.0 to industrial metaverse for Industry 5.0', 'URL': 'https://doi.org/10.1080/0951192X.2025.2556440', 'extra_urls': ['https://doi.org/10.1080/0951192X.2025.2556440'], 'type': 'article', 'author': [{'family': 'Jiang', 'given': 'Zhenhong'}, {'family': 'Ma', 'given': 'Nanfeng'}, {'family': 'Yao', 'given': 'Xifan'}, {'family': 'Zhou', 'given': 'Jiajun'}, {'family': 'Wang', 'given': 'Kesai'}, {'family': 'Xie', 'given': 'Tinbo'}, {'family': 'Meng', 'given': 'Junting'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Manufacturing is currently experiencing a pivotal transition, characterized by increasing complexity, market dynamism, diverse performance objectives, and a surplus of data accompanied by a dearth of actionable knowledge. This study conducts a systematic literature review from 2012 to 2023 to examine the paradigm shift from technology-centric smart manufacturing to human-centric industrial metaverse, proposing a conceptual framework for manufacturing systems design in the context of Industry 5.0. The findings indicate that this transformation is marked by a progressive enhancement in the connectivity between real and cyber entities. To date, the integration has primarily involved physical entities with limited human inclusion, but the trajectory suggests a future where a comprehensive spectrum of physical, social, and cyber entities will be seamlessly integrated within the industrial metaverse. Furthermore, the research examines the burgeoning role of humans within the manufacturing landscape and the critical importance of incorporating human factors into manufacturing systems. A conceptual framework for the industrial metaverse is introduced, highlighting its potential to integrate human factors effectively. Concurrently, forthcoming challenges pertinent to the practical realization of the industrial metaverse are identified and directives are provided to guide subsequent scholarly endeavors.', 'DOI': '10.1080/0951192X.2025.2556440'}, {'id': 'how_to_make', 'title': 'How to make digital product passports cool', 'URL': 'https://www.voguebusiness.com/story/technology/how-to-make-digital-product-passports-cool', 'extra_urls': ['https://www.voguebusiness.com/story/technology/how-to-make-digital-product-passports-cool'], 'type': 'webpage', 'author': [{'family': 'Kotsoni', 'given': 'Elektra'}], 'abstract': 'Innovation agency IoDF and tech giant Epam are announcing a partnership today; its goal is to make DPPs customer friendly. Here\u2019s how.'}, {'id': 'doi_10_1080_0951192X_2025_2455655', 'title': 'Global initiatives for industry 4.0 implementation and progress within the textile and apparel manufacturing sector: a comprehensive review', 'URL': 'https://doi.org/10.1080/0951192X.2025.2455655', 'extra_urls': ['https://doi.org/10.1080/0951192X.2025.2455655'], 'type': 'article', 'author': [{'family': 'Haq', 'given': 'Upama Nasrin'}, {'family': 'Khan', 'given': 'Md. Mashiur Rahman'}, {'family': 'Khan', 'given': 'Adnan Maroof'}, {'family': 'Hasanuzzaman', 'given': 'Md.'}, {'family': 'Hossain', 'given': 'Md. Riaz'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'A comprehensive picture on global initiatives to Industry 4.0 (I4.0), technological evolution within fibre-to-apparel manufacturing and its progression so far are reported here. Germany is the global progression leader while other developed countries; France, Italy, Spain, Portugal, and even the UK and USA have generic initiatives for upgraded manufacturing. Their initiatives are I4.0 strategies, funding, platforms, and model projects. Developing countries like Indonesia, Malaysia, Thailand, Brazil, Turkey, Vietnam, India, etc. have also taken I4.0 national initiatives. However, the apparel and textile manufacturing industry lags far behind other sectors, although applying I4.0 technologies in this sector has started. CPS, IOT, Cloud computing, Automatic bobbin changing, RFID, Blockchain, augmented reality, and digital twins, are found in the textile production and fashion retailing. Moreover, advanced machineries offer incorporated automation, remote maintenance and operability, cloud systems, self-optimization, and predictive maintenance facilities. The review identifies that technological gaps between concept and reality hinder commercial application. The readiness evaluation is predominantly grounded in academic literature, which requires field investigation from the start to the end of textile processing. Hence, case studies for empirical data, sustainability mapping for the upgraded technologies and integrated policy development are the future direction in this domain.', 'DOI': '10.1080/0951192X.2025.2455655'}, {'id': 'doi_10_1080_09537325_2025_2525440', 'title': 'Stakeholders\u2019 collaborative strategies of intelligent manufacturing innovation consortium: a tripartite evolutionary game perspective', 'URL': 'https://doi.org/10.1080/09537325.2025.2525440', 'extra_urls': ['https://doi.org/10.1080/09537325.2025.2525440'], 'type': 'article', 'author': [{'family': 'Zhu', 'given': 'Mengshan'}, {'family': 'Zhou', 'given': 'Wenyong'}, {'family': 'Zhou', 'given': 'Xinye'}, {'family': 'Duan', 'given': 'Chunyan'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'The Intelligent Manufacturing Innovation Consortium (IMIC) provides a framework for technological advancement in manufacturing by integrating efforts from industries, universities, and research institutes under enterprise leadership. However, these consortia face challenges, including technological spillovers and collaborative inertia. This paper develops a tripartite evolutionary game model examining interactions between the core intelligent manufacturing enterprise (IME), the complementary innovation entity (CIE), and the supplementary innovation organisation (SIO). The research analyzes stakeholder strategy evolution and identifies factors that affect collaboration stability. Findings indicate that higher initial probabilities accelerate collaborative innovation adoption. IME and CIE demonstrate greater risk sensitivity than SIO. Enhanced trust and cooperation within the consortium lead to greater information sharing and increased synergy motivation. There is an optimal range for the revfenue distribution coefficient from technological innovation, and excessive subsidy intensity may be counterproductive. Appropriate penalty mechanisms effectively discourage opportunistic behaviour and promote active cooperation. These insights offer practical guidance for policymakers to design effective governance mechanisms for innovation consortia, ultimately supporting technological breakthroughs in intelligent manufacturing.', 'DOI': '10.1080/09537325.2025.2525440'}, {'id': 'doi_10_1016_j_jclepro_2013_11_012', 'title': 'Transparency and value chain sustainability', 'URL': 'https://doi.org/10.1016/j.jclepro.2013.11.012', 'extra_urls': ['https://doi.org/10.1016/j.jclepro.2013.11.012'], 'type': 'article', 'author': [{'family': 'Mol', 'given': 'Arthur P. J.'}], 'abstract': 'The rise of transparency on the public and political agendas is not an accident or fad, soon to be replaced by another timely topic in sustainability politics and governance. Transparency will remain a key topic in global value chains and will further develop as it piggy-backs on wider social developments such as globalization, the information age, and the shifting role of states in environmental governance. Transparency in value chains is bound up with positive connotations: the more transparency the better it is for the sustainability of chains and for the empowerment of consumers and civil society. But an overall positive past assessment of value chain transparency does not automatically extend into the future as new challenges lie ahead. This paper investigates the new challenges for value chain transparency and their consequences. Due to the growing importance attached to transparency in value chains it becomes a central object of power struggles, with uncertain outcomes. Markets and states seek to capture transparency arrangements for their own goals, which may not be in line with the assumed normative linkages between value chain transparency and increased power for consumers and civil society. In that sense, transparency is losing its innocence: more transparency is no longer always the best for citizen-consumer empowerment and for the sustainability of value chains. But value chain secrecy is not an attractive alternative. This opens a new research agenda on how transparency should be organized and arranged in value chains to live up to the promises of democracy and sustainability.', 'DOI': '10.1016/j.jclepro.2013.11.012'}, {'id': 'implementing_the_digital', 'title': 'Implementing the digital product passport - A guidebook for businesses', 'URL': '#item_20299', 'type': 'book', 'author': [{'family': 'Ker\xe4nen', 'given': 'Jaana'}, {'family': 'Orko', 'given': 'Inka'}, {'family': 'Valtanen', 'given': 'Kristiina'}, {'family': '\xc5kerman', 'given': 'Maria'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'VTT Technical Research Centre of Finland', 'abstract': 'A digital product passport (DPP) is a digital description of a physical product. It includes information on the materials, manufacturing, repair, use and disposal of the product, defined by the type of product. The goal of the DPP is to extend the lifespan of products and promote their circular economy by providing standardised product data. The DPP will be mandatory for a large part of the products manufactured in and imported into the EU, with a phased rollout schedule for different product groups. The EU Ecodesign of Sustainable Products Regulation sets the frame for the DPP requirements and will be complemented by product-specific delegated acts. The first DPPs should be available by 2026-27.\n\nThe DPP requirements will impact the product manufacturers and importers as well as their value chains in many ways. They are required to provide data for further support more sustainable product designs and use patterns over the product life cycle, for improved supply chain management, and for new business opportunities. While mandatory, the DPP opens multiple new business opportunities and business models in the form of sharing platforms, predictive maintenance services, refurbishing etc. On the other hand, the increased information demand will require planning, management and collaboration internally and through the value network and will also take up resources, especially in the first implementation phases. Thus, it is advantageous to take charge of the DPP and start preparing and piloting early on.\n\nThis guidebook will complement other DPP publications already available, with the emphasis of providing considerations and a practical roadmap for the implementation. A particular target group are small and medium size businesses that may have limited resources for the DPP. A collective understanding and shared goals and collaboration are needed across the ecosystem, including the DPP beneficiaries, product owners, data management and service providers to build a coherent, reliable and relevant DPP system.'}, {'id': 'lightweight', 'title': 'SketchTailor: Lightweight sketch-driven modeling for high-fidelity garment pattern reconstruction', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0097849325001864', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0097849325001864'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Dongjin'}, {'family': 'Wang', 'given': 'Yanli'}, {'family': 'Qu', 'given': 'Jiantao'}, {'family': 'Wang', 'given': 'Ansheng'}, {'family': 'Tang', 'given': 'Yixiang'}], 'abstract': 'As a standard technical paradigm in the fashion industry, garment patterns serve as the core component throughout the entire process\u2014from conceptual design and digital pattern making to virtual garment simulation. Current mainstream approaches for generating garment patterns \u2013 such as those based on RGB images, 3D point clouds, textual inputs, or multimodal fusion techniques \u2013 have improved modeling capabilities but still face challenges including strong dependence on high-quality input data, complex data acquisition processes, limited semantic expressiveness, and high computational costs, which hinder their efficient and lightweight deployment. To address these limitations, we propose SketchTailor, a lightweight sketch-driven framework for generating 3D garment patterns with high efficiency and accuracy. We employ a vision prompt-tuned Vision Mamba (Vim) as the encoder to leverage its superior performance in processing abstract visual information and enhance the model\u2019s adaptability to input sketches. Within the Transformer decoder, we replace global attention with deformable attention to overcome the efficiency bottleneck of conventional Transformers in handling long sequences. This enables our model to progressively convert high-level semantic features extracted by the encoder into detailed 3D garment patterns that accurately represent both topological structures and geometric details. Experimental results on our extended large-scale, high-quality and diverse sketch-to-3D garment sewing pattern dataset demonstrate that our method significantly improves the quality of predicted garment patterns while substantially reducing computational and memory overhead. Our approach outperforms state-of-the-art methods across multiple metrics, including geometric error, edge accuracy, and inference time. Furthermore, user studies indicate that the generated patterns exhibit superior visual plausibility, detail fidelity, and overall aesthetics compared to existing baseline models, highlighting the practical applicability of our framework.'}, {'id': 'hierarchical_federated_transfer', 'title': 'Hierarchical federated transfer learning in digital twin-based vehicular networks', 'URL': 'https://www.sciencedirect.com/science/article/pii/S2667295225000078', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S2667295225000078'], 'type': 'article', 'author': [{'family': 'Zia', 'given': 'Qasim'}, {'family': 'Zhu', 'given': 'Saide'}, {'family': 'Wang', 'given': 'Haoxin'}, {'family': 'Iqbal', 'given': 'Zafar'}, {'family': 'Li', 'given': 'Yingshu'}], 'abstract': 'In recent research on the Digital Twin-based Vehicular Ad hoc Network (DT-VANET), Federated Learning (FL) has shown its ability to provide data privacy. However, Federated learning struggles to adequately train a global model when confronted with data heterogeneity and data sparsity among vehicles, which ensure suboptimal accuracy in making precise predictions for different vehicle types. To address these challenges, this paper combines Federated Transfer Learning (FTL) to conduct vehicle clustering related to types of vehicles and proposes a novel Hierarchical Federated Transfer Learning (HFTL). We construct a framework for DT-VANET, along with two algorithms designed for cloud server model updates and intra-cluster federated transfer learning, to improve the accuracy of the global model. In addition, we developed a data quality score-based mechanism to prevent the global model from being affected by malicious vehicles. Lastly, detailed experiments on real-world datasets are conducted, considering different performance metrics that verify the effectiveness and efficiency of our algorithm.'}, {'id': 'a_new_textiles', 'title': &quot;A new textiles economy: Redesigning fashion's future&quot;, 'URL': 'https://ellenmacarthurfoundation.org/a-new-textiles-economy', 'extra_urls': ['https://ellenmacarthurfoundation.org/a-new-textiles-economy'], 'type': 'report', 'author': [{'family': 'Ellen MacArthur Foundation'}], 'issued': {'date-parts': [[2017]]}, 'publisher': 'Ellen MacArthur Foundation'}, {'id': 'the_performance_economy', 'title': 'The performance economy', 'URL': 'urn:isbn:978-0-230-27490-7', 'type': 'book', 'author': [{'family': 'Stahel', 'given': 'Walter R.'}], 'issued': {'date-parts': [[2010]]}, 'publisher': 'Palgrave Macmillan'}, {'id': 'narrative_building', 'title': 'Narrative processing: Building consumer connections to brands', 'URL': '#item_20341', 'type': 'article', 'author': [{'family': 'Escalas', 'given': 'Jennifer Edson'}], 'issued': {'date-parts': [[2004]]}}, {'id': 'fiber_degradation_during', 'title': 'Fiber degradation during textile recycling', 'URL': '#item_20344', 'type': 'article', 'author': [{'family': 'Sandvik', 'given': 'Ingvild M\xf8rch'}, {'family': 'others'}], 'issued': {'date-parts': [[2018]]}}, {'id': 'environmental_impact_of', 'title': 'Environmental impact of textile reuse and recycling: A review', 'URL': '#item_20345', 'type': 'article', 'author': [{'family': 'Sandin', 'given': 'Gustav'}, {'family': 'Peters', 'given': 'Greg M.'}], 'issued': {'date-parts': [[2018]]}}, {'id': 'what_a_waste', 'title': 'What a waste 2.0: A global snapshot of solid waste management to 2050', 'URL': 'https://openknowledge.worldbank.org/handle/10986/30317', 'extra_urls': ['https://openknowledge.worldbank.org/handle/10986/30317'], 'type': 'report', 'author': [{'family': 'World Bank'}], 'issued': {'date-parts': [[2022]]}, 'publisher': 'World Bank Group'}, {'id': 'recent_trends_in', 'title': 'Recent trends in sustainable textile waste recycling methods: Current situation and future prospects', 'URL': '#item_20347', 'type': 'article', 'author': [{'family': 'Pensupa', 'given': 'Natthanon'}, {'family': 'Leu', 'given': 'Shao-Yuan'}, {'family': 'Hu', 'given': 'Yun'}, {'family': 'Du', 'given': 'Chenyu'}, {'family': 'Liu', 'given': 'Hongbo'}, {'family': 'Jing', 'given': 'Huirong'}, {'family': 'Wang', 'given': 'Hao'}, {'family': 'Lin', 'given': 'Carol Sze Ki'}], 'issued': {'date-parts': [[2017]]}}, {'id': 'understanding_the_blockchain', 'title': 'Understanding the blockchain oracle problem: A call for action', 'URL': '#item_20348', 'type': 'article', 'author': [{'family': 'Caldarelli', 'given': 'Giulio'}, {'family': 'Ellul', 'given': 'Joshua'}], 'issued': {'date-parts': [[2021]]}}, {'id': 'blockchain_oracle_design', 'title': 'Blockchain oracle design patterns', 'URL': '#item_20350', 'type': 'article', 'author': [{'family': 'Pasdar', 'given': 'Amirhossein'}, {'family': 'Dong', 'given': 'Zheng'}, {'family': 'Lee', 'given': 'Young Choon'}], 'issued': {'date-parts': [[2021]]}}, {'id': 'bayesian_knowledge_graphs', 'title': 'Bayesian knowledge graphs for supply chain verification under uncertainty', 'URL': '#item_20351', 'type': 'article', 'author': [{'family': 'Nafar', 'given': 'Mohsen'}, {'family': 'others'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'probabilistic_inference_in', 'title': 'Probabilistic inference in supply chain knowledge graphs', 'URL': '#item_20353', 'type': 'article', 'author': [{'family': 'Toroghi', 'given': 'Reza'}, {'family': 'Sanner', 'given': 'Scott'}], 'issued': {'date-parts': [[2024]]}}, {'id': 'digital_twins_for', 'title': 'Digital twins for circular supply chains: Architecture and implementation', 'URL': '#item_20354', 'type': 'article', 'author': [{'family': 'Roman', 'given': 'Dumitru'}, {'family': 'Stefanescu', 'given': 'Diana'}, {'family': 'Soylu', 'given': 'Ahmet'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'digital_supply', 'title': 'Digital twin-driven supply chain resilience and optimization', 'URL': '#item_20356', 'type': 'article', 'author': [{'family': 'Kim', 'given': 'Minkyun'}, {'family': 'Lee', 'given': 'Juhyun'}, {'family': 'Park', 'given': 'Sangwon'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'consumer_awareness_and', 'title': 'Consumer awareness and understanding of digital product passports: Survey results', 'URL': '#item_20358', 'type': 'report', 'author': [{'family': 'European Commission'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'European Commission, Directorate-General for Internal Market, Industry, Entrepreneurship and SMEs'}, {'id': 'how_to_shift', 'title': 'How to SHIFT consumer behaviors to be more sustainable: A literature review and guiding framework', 'URL': '#item_20360', 'type': 'article', 'author': [{'family': 'White', 'given': 'Katherine'}, {'family': 'Habib', 'given': 'Rishad'}, {'family': 'Hardisty', 'given': 'David J.'}], 'issued': {'date-parts': [[2019]]}}, {'id': 'synthetics_fashion', 'title': &quot;Synthetics anonymous: Fashion brands' addiction to fossil fuels&quot;, 'URL': 'https://changingmarkets.org/portfolio/fossil-fashion/', 'extra_urls': ['https://changingmarkets.org/portfolio/fossil-fashion/'], 'type': 'report', 'author': [{'family': 'Changing Markets Foundation'}], 'issued': {'date-parts': [[2021]]}, 'publisher': 'Changing Markets Foundation'}, {'id': '2023_resale_report', 'title': '2023 resale report', 'URL': 'https://www.thredup.com/resale/', 'extra_urls': ['https://www.thredup.com/resale/'], 'type': 'report', 'author': [{'family': 'ThredUp'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'ThredUp Inc.'}, {'id': 'mine_is', 'title': &quot;What's mine is yours: The rise of collaborative consumption&quot;, 'URL': 'urn:isbn:978-0-06-196354-4', 'type': 'book', 'author': [{'family': 'Botsman', 'given': 'Rachel'}, {'family': 'Rogers', 'given': 'Roo'}], 'issued': {'date-parts': [[2010]]}, 'publisher': 'HarperBusiness'}, {'id': 'something_something', 'title': &quot;Something old, something used: Determinants of women's purchase of vintage fashion vs second-hand fashion&quot;, 'URL': '#item_20364', 'type': 'article', 'author': [{'family': 'Cervellon', 'given': 'Marie-C\xe9cile'}, {'family': 'Carey', 'given': 'Lindsey'}, {'family': 'Harms', 'given': 'Trine'}], 'issued': {'date-parts': [[2012]]}}, {'id': 'cradle_to', 'title': 'Cradle to cradle: Remaking the way we make things', 'URL': 'urn:isbn:978-0-86547-587-8', 'type': 'book', 'author': [{'family': 'McDonough', 'given': 'William'}, {'family': 'Braungart', 'given': 'Michael'}], 'issued': {'date-parts': [[2002]]}, 'publisher': 'North Point Press'}, {'id': 'regenerative_how', 'title': 'Regenerative capitalism: How universal principles and patterns will shape our new economy', 'URL': 'https://capitalinstitute.org/regenerative-capitalism/', 'extra_urls': ['https://capitalinstitute.org/regenerative-capitalism/'], 'type': 'book', 'author': [{'family': 'Fullerton', 'given': 'John'}], 'issued': {'date-parts': [[2015]]}, 'publisher': 'Capital Institute'}, {'id': 'clarifying_the_concept', 'title': 'Clarifying the concept of product-service system', 'URL': '#item_20367', 'type': 'article', 'author': [{'family': 'Mont', 'given': 'Oksana K.'}], 'issued': {'date-parts': [[2002]]}}, {'id': 'eight_types_of', 'title': 'Eight types of product\u2013service system: Eight ways to sustainability? Experiences from SusProNet', 'URL': '#item_20368', 'type': 'article', 'author': [{'family': 'Tukker', 'given': 'Arnold'}], 'issued': {'date-parts': [[2004]]}}, {'id': 'the_naked', 'title': 'The naked corporation: How the age of transparency will revolutionize business', 'URL': 'urn:isbn:978-0-7432-2475-8', 'type': 'book', 'author': [{'family': 'Tapscott', 'given': 'Don'}, {'family': 'Ticoll', 'given': 'David'}], 'issued': {'date-parts': [[2003]]}, 'publisher': 'Free Press'}, {'id': 'circular_a', 'title': 'Circular transitions: A designerly approach to circular economy innovation in the textiles and clothing sector', 'URL': 'https://circularfashion.com/circular-transitions/', 'extra_urls': ['https://circularfashion.com/circular-transitions/'], 'type': 'report', 'author': [{'family': 'Earley', 'given': 'Rebecca'}, {'family': 'Goldsworthy', 'given': 'Kate'}], 'issued': {'date-parts': [[2019]]}, 'publisher': 'Circular Transitions Research Project, University of the Arts London'}, {'id': 'how_mcp_and', 'title': 'How MCP and AI are Modernizing Legacy Systems', 'URL': 'https://thenewstack.io/how-mcp-and-ai-are-modernizing-legacy-systems/', 'extra_urls': ['https://thenewstack.io/how-mcp-and-ai-are-modernizing-legacy-systems/'], 'type': 'article', 'author': [{'family': 'Saqib', 'given': 'Jan'}], 'abstract': 'A new strategy uses MCP, agentic AI and an intelligent abstraction layer to bridge the gap between old and new systems \u2014 no risky rewrite required.'}, {'id': 'burberry_burns', 'title': 'Burberry burns bags, clothes and perfume worth millions', 'URL': 'https://www.bbc.com/news/business-44885983', 'extra_urls': ['https://www.bbc.com/news/business-44885983'], 'type': 'article', 'author': [{'family': 'BBC'}], 'abstract': 'The fashion firm destroyed \xa328m of unwanted stock last year in a bid to protect its brand.'}, {'id': 'pile_of', 'title': &quot;H&amp;M's Pile of Unsold Garments Grows as Earnings Plunge&quot;, 'URL': 'https://www.bloomberg.com/news/articles/2018-03-27/h-m-profit-plunges-to-16-year-low-as-clothing-chain-loses-allure', 'extra_urls': ['https://www.bloomberg.com/news/articles/2018-03-27/h-m-profit-plunges-to-16-year-low-as-clothing-chain-loses-allure'], 'type': 'article', 'author': [{'family': 'Molin', 'given': 'Anna'}], 'abstract': 'Swedish fashion retailer Hennes &amp;amp; Mauritz AB said it\u2019s increasing markdowns this quarter after accumulating a record pile of unsold garments worth more than $4 billion.'}, {'id': 'doi_10_1453_1614-0885-2-2025-16677', 'title': 'From Cyberfeminism to Code Control: Cyborg Fashion under the Technological Gaze', 'URL': 'https://doi.org/10.1453/1614-0885-2-2025-16677', 'extra_urls': ['https://doi.org/10.1453/1614-0885-2-2025-16677'], 'type': 'article', 'author': [{'family': 'Wagemans', 'given': 'Esmay'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'In the late 20th century, Donna Haraway\u2019s Cyborg Manifesto (1985) introduced the \u201ccyborg\u201d as a hybrid figure of disruption, blurring boundaries between human and machine, nature and culture, body and code. Today, \u2018cyborg fashion\u2019, characterized by prosthetics, coded materials, and speculative aesthetics, is more visible than ever, largely due to its circulation within digital media ecosystems and the rise of AI-driven design. Yet this visibility is shaped by a new kind of control: the technological gaze of algorithmic moderation, platform standards, and commercial optimization.', 'DOI': '10.1453/1614-0885-2-2025-16677'}])">tests/test_rdf_parser_emergency_mode.py:74: in test_rdf_parser_finds_all_665_entries
    assert (
E   AssertionError: RDF parser should find exactly 665 entries (per Zotero), got 664
E   assert 664 == 665
E    +  where 664 = len([{'id': 'arxiv_2311.14570', 'title': 'RAISE -- Radiology AI Safety, an End-to-end lifecycle approach', 'URL': 'http://arxiv.org/abs/2311.14570', 'extra_urls': ['http://arxiv.org/abs/2311.14570'], 'type': 'article', 'author': [{'family': 'Cardoso', 'given': 'M. Jorge'}, {'family': 'Moosbauer', 'given': 'Julia'}, {'family': 'Cook', 'given': 'Tessa S.'}, {'family': 'Erdal', 'given': 'B. Selnur'}, {'family': 'Genereaux', 'given': 'Brad'}, {'family': 'Gupta', 'given': 'Vikash'}, {'family': 'Landman', 'given': 'Bennett A.'}, {'family': 'Lee', 'given': 'Tiarna'}, {'family': 'Nachev', 'given': 'Parashkev'}, {'family': 'Somasundaram', 'given': 'Elanchezhian'}, {'family': 'Summers', 'given': 'Ronald M.'}, {'family': 'Younis', 'given': 'Khaled'}, {'family': 'Ourselin', 'given': 'Sebastien'}, {'family': 'Pfister', 'given': 'Franz MJ'}], 'publisher': 'arXiv', 'abstract': 'The integration of AI into radiology introduces opportunities for improved clinical care provision and efficiency but it demands a meticulous approach to mitigate potential risks as with any other new technology. Beginning with rigorous pre-deployment evaluation and validation, the focus should be on ensuring models meet the highest standards of safety, effectiveness and efficacy for their intended applications. Input and output guardrails implemented during production usage act as an additional layer of protection, identifying and addressing individual failures as they occur. Continuous post-deployment monitoring allows for tracking population-level performance (data drift), fairness, and value delivery over time. Scheduling reviews of post-deployment model performance and educating radiologists about new algorithmic-driven findings is critical for AI to be effective in clinical practice. Recognizing that no single AI solution can provide absolute assurance even when limited to its intended use, the synergistic application of quality assurance at multiple levels - regulatory, clinical, technical, and ethical - is emphasized. Collaborative efforts between stakeholders spanning healthcare systems, industry, academia, and government are imperative to address the multifaceted challenges involved. Trust in AI is an earned privilege, contingent on a broad set of goals, among them transparently demonstrating that the AI adheres to the same rigorous safety, effectiveness and efficacy standards as other established medical technologies. By doing so, developers can instil confidence among providers and patients alike, enabling the responsible scaling of AI and the realization of its potential benefits. The roadmap presented herein aims to expedite the achievement of deployable, reliable, and safe AI in radiology.'}, {'id': 'arxiv_2402.00809v4', 'title': 'Position: Bayesian Deep Learning is Needed in the Age of Large-Scale AI', 'URL': 'https://arxiv.org/abs/2402.00809v4', 'extra_urls': ['https://arxiv.org/abs/2402.00809v4'], 'type': 'article', 'author': [{'family': 'Papamarkou', 'given': 'Theodore'}, {'family': 'Skoularidou', 'given': 'Maria'}, {'family': 'Palla', 'given': 'Konstantina'}, {'family': 'Aitchison', 'given': 'Laurence'}, {'family': 'Arbel', 'given': 'Julyan'}, {'family': 'Dunson', 'given': 'David'}, {'family': 'Filippone', 'given': 'Maurizio'}, {'family': 'Fortuin', 'given': 'Vincent'}, {'family': 'Hennig', 'given': 'Philipp'}, {'family': 'Hern\xe1ndez-Lobato', 'given': 'Jos\xe9 Miguel'}, {'family': 'Hubin', 'given': 'Aliaksandr'}, {'family': 'Immer', 'given': 'Alexander'}, {'family': 'Karaletsos', 'given': 'Theofanis'}, {'family': 'Khan', 'given': 'Mohammad Emtiyaz'}, {'family': 'Kristiadi', 'given': 'Agustinus'}, {'family': 'Li', 'given': 'Yingzhen'}, {'family': 'Mandt', 'given': 'Stephan'}, {'family': 'Nemeth', 'given': 'Christopher'}, {'family': 'Osborne', 'given': 'Michael A.'}, {'family': 'Rudner', 'given': 'Tim G. J.'}, {'family': 'R\xfcgamer', 'given': 'David'}, {'family': 'Teh', 'given': 'Yee Whye'}, {'family': 'Welling', 'given': 'Max'}, {'family': 'Wilson', 'given': 'Andrew Gordon'}, {'family': 'Zhang', 'given': 'Ruqi'}], 'abstract': 'In the current landscape of deep learning research, there is a predominant emphasis on achieving high predictive accuracy in supervised tasks involving large image and language datasets. However, a broader perspective reveals a multitude of overlooked metrics, tasks, and data types, such as uncertainty, active and continual learning, and scientific data, that demand attention. Bayesian deep learning (BDL) constitutes a promising avenue, offering advantages across these diverse settings. This paper posits that BDL can elevate the capabilities of deep learning. It revisits the strengths of BDL, acknowledges existing challenges, and highlights some exciting research avenues aimed at addressing these obstacles. Looking ahead, the discussion focuses on possible ways to combine large-scale foundation models with BDL to unlock their full potential.'}, {'id': 'arxiv_2510.10409', 'title': 'Trace Length is a Simple Uncertainty Signal in Reasoning Models', 'URL': 'http://arxiv.org/abs/2510.10409', 'extra_urls': ['http://arxiv.org/abs/2510.10409'], 'type': 'article', 'author': [{'family': 'Devic', 'given': 'Siddartha'}, {'family': 'Peale', 'given': 'Charlotte'}, {'family': 'Bradley', 'given': 'Arwen'}, {'family': 'Williamson', 'given': 'Sinead'}, {'family': 'Nakkiran', 'given': 'Preetum'}, {'family': 'Gollakota', 'given': 'Aravind'}], 'publisher': 'arXiv', 'abstract': 'Uncertainty quantification for LLMs is a key research direction towards addressing hallucination and other issues that limit their reliable deployment. In this work, we show that reasoning trace length is a simple and useful confidence estimator in large reasoning models. Through comprehensive experiments across multiple models, datasets, and prompts, we show that trace length performs in comparable but complementary ways to other zero-shot confidence estimators such as verbalized confidence. Our work reveals that reasoning post-training fundamentally alters the relationship between trace length and accuracy, going beyond prior work that had shown that post-training causes traces to grow longer in general (e.g., "overthinking"). We investigate the mechanisms behind trace length\'s performance as a confidence signal, observing that the effect remains even after adjusting for confounders such as problem difficulty and GRPO-induced length bias. We identify high-entropy or "forking" tokens as playing a key role in the mechanism. Our findings demonstrate that reasoning post-training enhances uncertainty quantification beyond verbal expressions, and establish trace length as a practical confidence measure for large reasoning models.'}, {'id': 'arxiv_2508.08204', 'title': 'Human-Alignment and Calibration of Inference-Time Uncertainty in Large Language Models', 'URL': 'http://arxiv.org/abs/2508.08204', 'extra_urls': ['http://arxiv.org/abs/2508.08204'], 'type': 'article', 'author': [{'family': 'Moore', 'given': 'Kyle'}, {'family': 'Roberts', 'given': 'Jesse'}, {'family': 'Watson', 'given': 'Daryl'}], 'publisher': 'arXiv', 'abstract': 'There has been much recent interest in evaluating large language models for uncertainty calibration to facilitate model control and modulate user trust. Inference time uncertainty, which may provide a real-time signal to the model or external control modules, is particularly important for applying these concepts to improve LLM-user experience in practice. While many of the existing papers consider model calibration, comparatively little work has sought to evaluate how closely model uncertainty aligns to human uncertainty. In this work, we evaluate a collection of inference-time uncertainty measures, using both established metrics and novel variations, to determine how closely they align with both human group-level uncertainty and traditional notions of model calibration. We find that numerous measures show evidence of strong alignment to human uncertainty, even despite the lack of alignment to human answer preference. For those successful metrics, we find moderate to strong evidence of model calibration in terms of both correctness correlation and distributional analysis.'}, {'id': 'arxiv_2503.15850', 'title': 'Uncertainty Quantification and Confidence Calibration in Large Language Models: A Survey', 'URL': 'http://arxiv.org/abs/2503.15850', 'extra_urls': ['http://arxiv.org/abs/2503.15850'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Xiaoou'}, {'family': 'Chen', 'given': 'Tiejin'}, {'family': 'Da', 'given': 'Longchao'}, {'family': 'Chen', 'given': 'Chacha'}, {'family': 'Lin', 'given': 'Zhen'}, {'family': 'Wei', 'given': 'Hua'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) excel in text generation, reasoning, and decision-making, enabling their adoption in high-stakes domains such as healthcare, law, and transportation. However, their reliability is a major concern, as they often produce plausible but incorrect responses. Uncertainty quantification (UQ) enhances trustworthiness by estimating confidence in outputs, enabling risk mitigation and selective prediction. However, traditional UQ methods struggle with LLMs due to computational constraints and decoding inconsistencies. Moreover, LLMs introduce unique uncertainty sources, such as input ambiguity, reasoning path divergence, and decoding stochasticity, that extend beyond classical aleatoric and epistemic uncertainty. To address this, we introduce a new taxonomy that categorizes UQ methods based on computational efficiency and uncertainty dimensions (input, reasoning, parameter, and prediction uncertainty). We evaluate existing techniques, assess their real-world applicability, and identify open challenges, emphasizing the need for scalable, interpretable, and robust UQ approaches to enhance LLM reliability.'}, {'id': 'arxiv_2509.22272', 'title': 'Fine-Grained Uncertainty Decomposition in Large Language Models: A Spectral Approach', 'URL': 'http://arxiv.org/abs/2509.22272', 'extra_urls': ['http://arxiv.org/abs/2509.22272'], 'type': 'article', 'author': [{'family': 'Walha', 'given': 'Nassim'}, {'family': 'Gruber', 'given': 'Sebastian G.'}, {'family': 'Decker', 'given': 'Thomas'}, {'family': 'Yang', 'given': 'Yinchong'}, {'family': 'Javanmardi', 'given': 'Alireza'}, {'family': 'H\xfcllermeier', 'given': 'Eyke'}, {'family': 'Buettner', 'given': 'Florian'}], 'publisher': 'arXiv', 'abstract': 'As Large Language Models (LLMs) are increasingly integrated in diverse applications, obtaining reliable measures of their predictive uncertainty has become critically important. A precise distinction between aleatoric uncertainty, arising from inherent ambiguities within input data, and epistemic uncertainty, originating exclusively from model limitations, is essential to effectively address each uncertainty source. In this paper, we introduce Spectral Uncertainty, a novel approach to quantifying and decomposing uncertainties in LLMs. Leveraging the Von Neumann entropy from quantum information theory, Spectral Uncertainty provides a rigorous theoretical foundation for separating total uncertainty into distinct aleatoric and epistemic components. Unlike existing baseline methods, our approach incorporates a fine-grained representation of semantic similarity, enabling nuanced differentiation among various semantic interpretations in model responses. Empirical evaluations demonstrate that Spectral Uncertainty outperforms state-of-the-art methods in estimating both aleatoric and total uncertainty across diverse models and benchmark datasets.'}, {'id': 'arxiv_2510.05566', 'title': 'Domain-Shift-Aware Conformal Prediction for Large Language Models', 'URL': 'http://arxiv.org/abs/2510.05566', 'extra_urls': ['http://arxiv.org/abs/2510.05566'], 'type': 'article', 'author': [{'family': 'Lin', 'given': 'Zhexiao'}, {'family': 'Li', 'given': 'Yuanyuan'}, {'family': 'Sarna', 'given': 'Neeraj'}, {'family': 'Gao', 'given': 'Yuanyuan'}, {'family': 'Gablenz', 'given': 'Michael von'}], 'publisher': 'arXiv', 'abstract': 'Large language models have achieved impressive performance across diverse tasks. However, their tendency to produce overconfident and factually incorrect outputs, known as hallucinations, poses risks in real world applications. Conformal prediction provides finite-sample, distribution-free coverage guarantees, but standard conformal prediction breaks down under domain shift, often leading to under-coverage and unreliable prediction sets. We propose a new framework called Domain-Shift-Aware Conformal Prediction (DS-CP). Our framework adapts conformal prediction to large language models under domain shift, by systematically reweighting calibration samples based on their proximity to the test prompt, thereby preserving validity while enhancing adaptivity. Our theoretical analysis and experiments on the MMLU benchmark demonstrate that the proposed method delivers more reliable coverage than standard conformal prediction, especially under substantial distribution shifts, while maintaining efficiency. This provides a practical step toward trustworthy uncertainty quantification for large language models in real-world deployment.'}, {'id': 'arxiv_2509.04439', 'title': 'ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory', 'URL': 'http://arxiv.org/abs/2509.04439', 'extra_urls': ['http://arxiv.org/abs/2509.04439'], 'type': 'article', 'author': [{'family': 'Ho', 'given': 'Matthew'}, {'family': 'Si', 'given': 'Chen'}, {'family': 'Feng', 'given': 'Zhaoxiang'}, {'family': 'Yu', 'given': 'Fangxu'}, {'family': 'Yang', 'given': 'Yichi'}, {'family': 'Liu', 'given': 'Zhijian'}, {'family': 'Hu', 'given': 'Zhiting'}, {'family': 'Qin', 'given': 'Lianhui'}], 'publisher': 'arXiv', 'abstract': 'While inference-time scaling enables LLMs to carry out increasingly long and capable reasoning traces, the patterns and insights uncovered during these traces are immediately discarded once the context window is reset for a new query. External memory is a natural way to persist these discoveries, and recent work has shown clear benefits for reasoning-intensive tasks. We see an opportunity to make such memories more broadly reusable and scalable by moving beyond instance-based memory entries (e.g. exact query/response pairs, or summaries tightly coupled with the original problem context) toward concept-level memory: reusable, modular abstractions distilled from solution traces and stored in natural language. For future queries, relevant concepts are selectively retrieved and integrated into the prompt, enabling test-time continual learning without weight updates. Our design introduces new strategies for abstracting takeaways from rollouts and retrieving entries for new queries, promoting reuse and allowing memory to expand with additional experiences. We evaluate on ARC-AGI, a benchmark that stresses compositional generalization and abstract reasoning, making it a natural fit for concept memory. Our method yields a 7.5% relative gain over a strong no-memory baseline with performance continuing to scale with inference compute. We find abstract concepts to be the most consistent memory design, outscoring the baseline at all tested inference compute scales. Moreover, dynamically updating memory during test-time outperforms fixed settings, supporting the hypothesis that accumulating and abstracting patterns enables further solutions in a form of self-improvement. Code is available at https://github.com/matt-seb-ho/arc_memo.'}, {'id': 'arxiv_2510.04851', 'title': 'LEGOMem: Modular Procedural Memory for Multi-agent LLM Systems for Workflow Automation', 'URL': 'http://arxiv.org/abs/2510.04851', 'extra_urls': ['http://arxiv.org/abs/2510.04851'], 'type': 'article', 'author': [{'family': 'Han', 'given': 'Dongge'}, {'family': 'Couturier', 'given': 'Camille'}, {'family': 'Diaz', 'given': 'Daniel Madrigal'}, {'family': 'Zhang', 'given': 'Xuchao'}, {'family': 'R\xfchle', 'given': 'Victor'}, {'family': 'Rajmohan', 'given': 'Saravan'}], 'publisher': 'arXiv', 'abstract': 'We introduce LEGOMem, a modular procedural memory framework for multi-agent large language model (LLM) systems in workflow automation. LEGOMem decomposes past task trajectories into reusable memory units and flexibly allocates them across orchestrators and task agents to support planning and execution. To explore the design space of memory in multi-agent systems, we use LEGOMem as a lens and conduct a systematic study of procedural memory in multi-agent systems, examining where memory should be placed, how it should be retrieved, and which agents benefit most. Experiments on the OfficeBench benchmark show that orchestrator memory is critical for effective task decomposition and delegation, while fine-grained agent memory improves execution accuracy. We find that even teams composed of smaller language models can benefit substantially from procedural memory, narrowing the performance gap with stronger agents by leveraging prior execution traces for more accurate planning and tool use. These results position LEGOMem as both a practical framework for memory-augmented agent systems and a research tool for understanding memory design in multi-agent workflow automation.'}, {'id': 'arxiv_2508.03341', 'title': 'Nemori: Self-Organizing Agent Memory Inspired by Cognitive Science', 'URL': 'http://arxiv.org/abs/2508.03341', 'extra_urls': ['http://arxiv.org/abs/2508.03341'], 'type': 'article', 'author': [{'family': 'Nan', 'given': 'Jiayan'}, {'family': 'Ma', 'given': 'Wenquan'}, {'family': 'Wu', 'given': 'Wenlong'}, {'family': 'Chen', 'given': 'Yize'}], 'publisher': 'arXiv', 'abstract': "Large Language Models (LLMs) demonstrate remarkable capabilities, yet their inability to maintain persistent memory in long contexts limits their effectiveness as autonomous agents in long-term interactions. While existing memory systems have made progress, their reliance on arbitrary granularity for defining the basic memory unit and passive, rule-based mechanisms for knowledge extraction limits their capacity for genuine learning and evolution. To address these foundational limitations, we present Nemori, a novel self-organizing memory architecture inspired by human cognitive principles. Nemori's core innovation is twofold: First, its Two-Step Alignment Principle, inspired by Event Segmentation Theory, provides a principled, top-down method for autonomously organizing the raw conversational stream into semantically coherent episodes, solving the critical issue of memory granularity. Second, its Predict-Calibrate Principle, inspired by the Free-energy Principle, enables the agent to proactively learn from prediction gaps, moving beyond pre-defined heuristics to achieve adaptive knowledge evolution. This offers a viable path toward handling the long-term, dynamic workflows of autonomous agents. Extensive experiments on the LoCoMo and LongMemEval benchmarks demonstrate that Nemori significantly outperforms prior state-of-the-art systems, with its advantage being particularly pronounced in longer contexts."}, {'id': 'arxiv_2510.07713', 'title': 'MemWeaver: A Hierarchical Memory from Textual Interactive Behaviors for Personalized Generation', 'URL': 'http://arxiv.org/abs/2510.07713', 'extra_urls': ['http://arxiv.org/abs/2510.07713'], 'type': 'article', 'author': [{'family': 'Yu', 'given': 'Shuo'}, {'family': 'Cheng', 'given': 'Mingyue'}, {'family': 'Wang', 'given': 'Daoyu'}, {'family': 'Liu', 'given': 'Qi'}, {'family': 'Liu', 'given': 'Zirui'}, {'family': 'Guo', 'given': 'Ze'}, {'family': 'Tao', 'given': 'Xiaoyu'}], 'publisher': 'arXiv', 'abstract': "The primary form of user-internet engagement is shifting from leveraging implicit feedback signals, such as browsing and clicks, to harnessing the rich explicit feedback provided by textual interactive behaviors. This shift unlocks a rich source of user textual history, presenting a profound opportunity for a deeper form of personalization. However, prevailing approaches offer only a shallow form of personalization, as they treat user history as a flat list of texts for retrieval and fail to model the rich temporal and semantic structures reflecting dynamic nature of user interests. In this work, we propose \\textbf{MemWeaver}, a framework that weaves the user's entire textual history into a hierarchical memory to power deeply personalized generation. The core innovation of our memory lies in its ability to capture both the temporal evolution of interests and the semantic relationships between different activities. To achieve this, MemWeaver builds two complementary memory components that both integrate temporal and semantic information, but at different levels of abstraction: behavioral memory, which captures specific user actions, and cognitive memory, which represents long-term preferences. This dual-component memory serves as a unified representation of the user, allowing large language models (LLMs) to reason over both concrete behaviors and abstracted traits. Experiments on the Language Model Personalization (LaMP) benchmark validate the efficacy of MemWeaver. Our code is available\\footnote{https://github.com/fishsure/MemWeaver}."}, {'id': 'arxiv_2509.13235', 'title': 'A Scenario-Driven Cognitive Approach to Next-Generation AI Memory', 'URL': 'http://arxiv.org/abs/2509.13235', 'extra_urls': ['http://arxiv.org/abs/2509.13235'], 'type': 'article', 'author': [{'family': 'Cai', 'given': 'Linyue'}, {'family': 'Cheng', 'given': 'Yuyang'}, {'family': 'Shao', 'given': 'Xiaoding'}, {'family': 'Wang', 'given': 'Huiming'}, {'family': 'Zhao', 'given': 'Yong'}, {'family': 'Zhang', 'given': 'Wei'}, {'family': 'Li', 'given': 'Kang'}], 'publisher': 'arXiv', 'abstract': 'As artificial intelligence advances toward artificial general intelligence (AGI), the need for robust and human-like memory systems has become increasingly evident. Current memory architectures often suffer from limited adaptability, insufficient multimodal integration, and an inability to support continuous learning. To address these limitations, we propose a scenario-driven methodology that extracts essential functional requirements from representative cognitive scenarios, leading to a unified set of design principles for next-generation AI memory systems. Based on this approach, we introduce the \\textbf{COgnitive Layered Memory Architecture (COLMA)}, a novel framework that integrates cognitive scenarios, memory processes, and storage mechanisms into a cohesive design. COLMA provides a structured foundation for developing AI systems capable of lifelong learning and human-like reasoning, thereby contributing to the pragmatic development of AGI.'}, {'id': 'arxiv_2510.11967', 'title': 'Scaling Long-Horizon LLM Agent via Context-Folding', 'URL': 'http://arxiv.org/abs/2510.11967', 'extra_urls': ['http://arxiv.org/abs/2510.11967'], 'type': 'article', 'author': [{'family': 'Sun', 'given': 'Weiwei'}, {'family': 'Lu', 'given': 'Miao'}, {'family': 'Ling', 'given': 'Zhan'}, {'family': 'Liu', 'given': 'Kang'}, {'family': 'Yao', 'given': 'Xuesong'}, {'family': 'Yang', 'given': 'Yiming'}, {'family': 'Chen', 'given': 'Jiecao'}], 'publisher': 'arXiv', 'abstract': 'Large language model (LLM) agents are fundamentally constrained by context length on long-horizon tasks. We introduce Context-Folding, a framework that empowers agents to actively manage their working context. An agent can procedurally branch into a sub-trajectory to handle a subtask and then fold it upon completion, collapsing the intermediate steps while retaining a concise summary of the outcome. To make this behavior learnable, we develop an end-to-end reinforcement learning framework FoldGRPO with specific process rewards to encourage effective task decomposition and context management. On complex long-horizon tasks (Deep Research and SWE), our folding agent matches or outperforms the ReAct baselines while using an active context 10$\\times$ smaller and significantly outperforms models that rely on summarization-based context management.'}, {'id': 'arxiv_2510.06727', 'title': 'Scaling LLM Multi-turn RL with End-to-end Summarization-based Context Management', 'URL': 'http://arxiv.org/abs/2510.06727', 'extra_urls': ['http://arxiv.org/abs/2510.06727'], 'type': 'article', 'author': [{'family': 'Lu', 'given': 'Miao'}, {'family': 'Sun', 'given': 'Weiwei'}, {'family': 'Du', 'given': 'Weihua'}, {'family': 'Ling', 'given': 'Zhan'}, {'family': 'Yao', 'given': 'Xuesong'}, {'family': 'Liu', 'given': 'Kang'}, {'family': 'Chen', 'given': 'Jiecao'}], 'publisher': 'arXiv', 'abstract': 'We study reinforcement learning (RL) fine-tuning of large language model (LLM) agents for long-horizon multi-turn tool use, where context length quickly becomes a fundamental bottleneck. Existing RL pipelines can suffer from degraded instruction following, excessive rollout costs, and most importantly, strict context limits. To address these challenges, we introduce summarization-based context management to training. In specific, it periodically compresses the tool using history by LLM-generated summaries that retain task-relevant information to keep a compact context while enabling the agent to scale beyond the fixed context window. Building on this formulation, we derive a policy gradient representation that seamlessly enables standard LLM RL infrastructures to optimize both tool-use behaviors as well as summarization strategies in an end-to-end fashion. We instantiate this framework with \\underline{SU}mmarization augmented \\underline{P}olicy \\underline{O}ptimization (\\texttt{SUPO}), an LLM RL algorithm that enables long-horizon training beyond a fixed context limit. Experiments on interactive function calling and searching tasks demonstrate that \\texttt{SUPO} significantly improves the success rate while maintaining the same or even lower working context length compared to baselines. We also demonstrate that for complex searching tasks, \\texttt{SUPO} can further improve the evaluation performance when scaling test-time maximum round of summarization beyond that of training time. Our results establish summarization-based context management as a principled and scalable approach for training RL agents beyond a fixed context length limit.'}, {'id': 'arxiv_2509.18970', 'title': 'LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions', 'URL': 'http://arxiv.org/abs/2509.18970', 'extra_urls': ['http://arxiv.org/abs/2509.18970'], 'type': 'article', 'author': [{'family': 'Lin', 'given': 'Xixun'}, {'family': 'Ning', 'given': 'Yucheng'}, {'family': 'Zhang', 'given': 'Jingwen'}, {'family': 'Dong', 'given': 'Yan'}, {'family': 'Liu', 'given': 'Yilong'}, {'family': 'Wu', 'given': 'Yongxuan'}, {'family': 'Qi', 'given': 'Xiaohua'}, {'family': 'Sun', 'given': 'Nan'}, {'family': 'Shang', 'given': 'Yanmin'}, {'family': 'Cao', 'given': 'Pengfei'}, {'family': 'Zou', 'given': 'Lixin'}, {'family': 'Chen', 'given': 'Xu'}, {'family': 'Zhou', 'given': 'Chuan'}, {'family': 'Wu', 'given': 'Jia'}, {'family': 'Pan', 'given': 'Shirui'}, {'family': 'Wang', 'given': 'Bin'}, {'family': 'Cao', 'given': 'Yanan'}, {'family': 'Chen', 'given': 'Kai'}, {'family': 'Hu', 'given': 'Songlin'}, {'family': 'Guo', 'given': 'Li'}], 'publisher': 'arXiv', 'abstract': 'Driven by the rapid advancements of Large Language Models (LLMs), LLM-based agents have emerged as powerful intelligent systems capable of human-like cognition, reasoning, and interaction. These agents are increasingly being deployed across diverse real-world applications, including student education, scientific research, and financial analysis. However, despite their remarkable potential, LLM-based agents remain vulnerable to hallucination issues, which can result in erroneous task execution and undermine the reliability of the overall system design. Addressing this critical challenge requires a deep understanding and a systematic consolidation of recent advances on LLM-based agents. To this end, we present the first comprehensive survey of hallucinations in LLM-based agents. By carefully analyzing the complete workflow of agents, we propose a new taxonomy that identifies different types of agent hallucinations occurring at different stages. Furthermore, we conduct an in-depth examination of eighteen triggering causes underlying the emergence of agent hallucinations. Through a detailed review of a large number of existing studies, we summarize approaches for hallucination mitigation and detection, and highlight promising directions for future research. We hope this survey will inspire further efforts toward addressing hallucinations in LLM-based agents, ultimately contributing to the development of more robust and reliable agent systems.'}, {'id': 'arxiv_2509.11914', 'title': 'EgoMem: Lifelong Memory Agent for Full-duplex Omnimodal Models', 'URL': 'http://arxiv.org/abs/2509.11914', 'extra_urls': ['http://arxiv.org/abs/2509.11914'], 'type': 'article', 'author': [{'family': 'Yao', 'given': 'Yiqun'}, {'family': 'Yu', 'given': 'Naitong'}, {'family': 'Li', 'given': 'Xiang'}, {'family': 'Jiang', 'given': 'Xin'}, {'family': 'Fang', 'given': 'Xuezhi'}, {'family': 'Ma', 'given': 'Wenjia'}, {'family': 'Meng', 'given': 'Xuying'}, {'family': 'Li', 'given': 'Jing'}, {'family': 'Sun', 'given': 'Aixin'}, {'family': 'Wang', 'given': 'Yequan'}], 'publisher': 'arXiv', 'abstract': "We introduce EgoMem, the first lifelong memory agent tailored for full-duplex models that process real-time omnimodal streams. EgoMem enables real-time models to recognize multiple users directly from raw audiovisual streams, to provide personalized response, and to maintain long-term knowledge of users' facts, preferences, and social relationships extracted from audiovisual history. EgoMem operates with three asynchronous processes: (i) a retrieval process that dynamically identifies user via face and voice, and gathers relevant context from a long-term memory; (ii) an omnimodal dialog process that generates personalized audio responses based on the retrieved context; and (iii) a memory management process that automatically detects dialog boundaries from omnimodal streams, and extracts necessary information to update the long-term memory. Unlike existing memory agents for LLMs, EgoMem relies entirely on raw audiovisual streams, making it especially suitable for lifelong, real-time, and embodied scenarios. Experimental results demonstrate that EgoMem's retrieval and memory management modules achieve over 95% accuracy on the test set. When integrated with a fine-tuned RoboEgo omnimodal chatbot, the system achieves fact-consistency scores above 87% in real-time personalized dialogs, establishing a strong baseline for future research."}, {'id': 'arxiv_2503.22458', 'title': 'Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey', 'URL': 'http://arxiv.org/abs/2503.22458', 'extra_urls': ['http://arxiv.org/abs/2503.22458'], 'type': 'article', 'author': [{'family': 'Guan', 'given': 'Shengyue'}, {'family': 'Xiong', 'given': 'Haoyi'}, {'family': 'Wang', 'given': 'Jindong'}, {'family': 'Bian', 'given': 'Jiang'}, {'family': 'Zhu', 'given': 'Bin'}, {'family': 'Lou', 'given': 'Jian-guang'}], 'publisher': 'arXiv', 'abstract': 'This survey examines evaluation methods for large language model (LLM)-based agents in multi-turn conversational settings. Using a PRISMA-inspired framework, we systematically reviewed nearly 250 scholarly sources, capturing the state of the art from various venues of publication, and establishing a solid foundation for our analysis. Our study offers a structured approach by developing two interrelated taxonomy systems: one that defines \\emph{what to evaluate} and another that explains \\emph{how to evaluate}. The first taxonomy identifies key components of LLM-based agents for multi-turn conversations and their evaluation dimensions, including task completion, response quality, user experience, memory and context retention, as well as planning and tool integration. These components ensure that the performance of conversational agents is assessed in a holistic and meaningful manner. The second taxonomy system focuses on the evaluation methodologies. It categorizes approaches into annotation-based evaluations, automated metrics, hybrid strategies that combine human assessments with quantitative measures, and self-judging methods utilizing LLMs. This framework not only captures traditional metrics derived from language understanding, such as BLEU and ROUGE scores, but also incorporates advanced techniques that reflect the dynamic, interactive nature of multi-turn dialogues.'}, {'id': 'arxiv_2510.07777', 'title': 'Drift No More? Context Equilibria in Multi-Turn LLM Interactions', 'URL': 'http://arxiv.org/abs/2510.07777', 'extra_urls': ['http://arxiv.org/abs/2510.07777'], 'type': 'article', 'author': [{'family': 'Dongre', 'given': 'Vardhan'}, {'family': 'Rossi', 'given': 'Ryan A.'}, {'family': 'Lai', 'given': 'Viet Dac'}, {'family': 'Yoon', 'given': 'David Seunghyun'}, {'family': 'Hakkani-T\xfcr', 'given': 'Dilek'}, {'family': 'Bui', 'given': 'Trung'}], 'publisher': 'arXiv', 'abstract': "Large Language Models (LLMs) excel at single-turn tasks such as instruction following and summarization, yet real-world deployments require sustained multi-turn interactions where user goals and conversational context persist and evolve. A recurring challenge in this setting is context drift: the gradual divergence of a model's outputs from goal-consistent behavior across turns. Unlike single-turn errors, drift unfolds temporally and is poorly captured by static evaluation metrics. In this work, we present a study of context drift in multi-turn interactions and propose a simple dynamical framework to interpret its behavior. We formalize drift as the turn-wise KL divergence between the token-level predictive distributions of the test model and a goal-consistent reference model, and propose a recurrence model that interprets its evolution as a bounded stochastic process with restoring forces and controllable interventions. We instantiate this framework in both synthetic long-horizon rewriting tasks and realistic user-agent simulations such as in $\\tau$-Bench, measuring drift for several open-weight LLMs that are used as user simulators. Our experiments consistently reveal stable, noise-limited equilibria rather than runaway degradation, and demonstrate that simple reminder interventions reliably reduce divergence in line with theoretical predictions. Together, these results suggest that multi-turn drift can be understood as a controllable equilibrium phenomenon rather than as inevitable decay, providing a foundation for studying and mitigating context drift in extended interactions."}, {'id': 'a_realistic', 'title': 'MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs', 'URL': 'https://aclanthology.org/2025.findings-acl.958/', 'type': 'article', 'author': [{'family': 'Deshpande', 'given': 'Kaustubh'}, {'family': 'Sirdeshmukh', 'given': 'Ved'}, {'family': 'Mols', 'given': 'Johannes Baptist'}, {'family': 'Jin', 'given': 'Lifeng'}, {'family': 'Hernandez-Cardona', 'given': 'Ed-Yeremai'}, {'family': 'Lee', 'given': 'Dean'}, {'family': 'Kritz', 'given': 'Jeremy'}, {'family': 'Primack', 'given': 'Willow E.'}, {'family': 'Yue', 'given': 'Summer'}, {'family': 'Xing', 'given': 'Chen'}], 'publisher': 'Association for Computational Linguistics', 'abstract': 'We present MultiChallenge, a pioneering benchmark evaluating large language models (LLMs) on conducting multi-turn conversations with human users, a crucial yet underexamined capability for their applications. MultiChallenge identifies four categories of challenges in multi-turn conversations that are not only common and realistic among current human-LLM interactions, but are also challenging to all current frontier LLMs. All 4 challenges require accurate instruction-following, context allocation, and in-context reasoning at the same time.We also develop LLM as judge with instance-level rubrics to facilitate an automatic evaluation method with fair agreement with experienced human raters. Despite achieving near perfect scores on existing multi-turn evaluation benchmarks, all frontier models have less than 50% accuracy on MultiChallenge, with the top-performing Claude 3.5 Sonnet (October 2024) achieving just a 41.4% average accuracy.'}, {'id': 'arxiv_2502.07077', 'title': 'Multi-turn Evaluation of Anthropomorphic Behaviours in Large Language Models', 'URL': 'http://arxiv.org/abs/2502.07077', 'extra_urls': ['http://arxiv.org/abs/2502.07077'], 'type': 'article', 'author': [{'family': 'Ibrahim', 'given': 'Lujain'}, {'family': 'Akbulut', 'given': 'Canfer'}, {'family': 'Elasmar', 'given': 'Rasmi'}, {'family': 'Rastogi', 'given': 'Charvi'}, {'family': 'Kahng', 'given': 'Minsuk'}, {'family': 'Morris', 'given': 'Meredith Ringel'}, {'family': 'McKee', 'given': 'Kevin R.'}, {'family': 'Rieser', 'given': 'Verena'}, {'family': 'Shanahan', 'given': 'Murray'}, {'family': 'Weidinger', 'given': 'Laura'}], 'publisher': 'arXiv', 'abstract': "The tendency of users to anthropomorphise large language models (LLMs) is of growing interest to AI developers, researchers, and policy-makers. Here, we present a novel method for empirically evaluating anthropomorphic LLM behaviours in realistic and varied settings. Going beyond single-turn static benchmarks, we contribute three methodological advances in state-of-the-art (SOTA) LLM evaluation. First, we develop a multi-turn evaluation of 14 anthropomorphic behaviours. Second, we present a scalable, automated approach by employing simulations of user interactions. Third, we conduct an interactive, large-scale human subject study (N=1101) to validate that the model behaviours we measure predict real users' anthropomorphic perceptions. We find that all SOTA LLMs evaluated exhibit similar behaviours, characterised by relationship-building (e.g., empathy and validation) and first-person pronoun use, and that the majority of behaviours only first occur after multiple turns. Our work lays an empirical foundation for investigating how design choices influence anthropomorphic model behaviours and for progressing the ethical debate on the desirability of these behaviours. It also showcases the necessity of multi-turn evaluations for complex social phenomena in human-AI interaction."}, {'id': 'arxiv_2504.04717', 'title': 'Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large Language Models', 'URL': 'http://arxiv.org/abs/2504.04717', 'extra_urls': ['http://arxiv.org/abs/2504.04717'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Yubo'}, {'family': 'Shen', 'given': 'Xiaobin'}, {'family': 'Yao', 'given': 'Xinyu'}, {'family': 'Ding', 'given': 'Xueying'}, {'family': 'Miao', 'given': 'Yidi'}, {'family': 'Krishnan', 'given': 'Ramayya'}, {'family': 'Padman', 'given': 'Rema'}], 'publisher': 'arXiv', 'abstract': 'Recent advancements in large language models (LLMs) have revolutionized their ability to handle single-turn tasks, yet real-world applications demand sophisticated multi-turn interactions. This survey provides a comprehensive review of recent advancements in evaluating and enhancing multi-turn interactions in LLMs. Focusing on task-specific scenarios, from instruction following in diverse domains such as math and coding to complex conversational engagements in roleplay, healthcare, education, and even adversarial jailbreak settings, we systematically examine the challenges of maintaining context, coherence, fairness, and responsiveness over prolonged dialogues. The paper organizes current benchmarks and datasets into coherent categories that reflect the evolving landscape of multi-turn dialogue evaluation. In addition, we review a range of enhancement methodologies under multi-turn settings, including model-centric strategies (contextual learning, supervised fine-tuning, reinforcement learning, and new architectures), external integration approaches (memory-augmented, retrieval-based methods, and knowledge graph), and agent-based techniques for collaborative interactions. Finally, we discuss open challenges and propose future directions for research to further advance the robustness and effectiveness of multi-turn interactions in LLMs. Related resources and papers are available at https://github.com/yubol-cmu/Awesome-Multi-Turn-LLMs.'}, {'id': 'how_do_microservice', 'title': 'How Do Microservice API Patterns Impact Understandability? A Controlled Experiment', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10592780', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10592780'], 'type': 'article', 'author': [{'family': 'Bogner', 'given': 'Justus'}, {'family': 'W\xf3jcik', 'given': 'Pawel'}, {'family': 'Zimmermann', 'given': 'Olaf'}], 'abstract': 'Microservices expose their functionality via remote Application Programming Interfaces (APIs), e.g., based on HTTP or asynchronous messaging technology. To solve recurring problems in this design space, Microservice API Patterns (MAPs) have emerged to capture the collective experience of the API design community. At present, there is a lack of empirical evidence for the effectiveness of these patterns, e.g., how they impact understandability and API usability. We therefore conducted a controlled experiment with 6 microservice patterns to evaluate their impact on understandability with 65 diverse participants. Additionally, we wanted to study how demographics like years of professional experience or experience with MAPs influence the effects of the patterns. Per pattern, we constructed two API examples, each in a pattern version P and a functionally equivalent non-pattern version N (24 in total). Based on a crossover design, participants had to answer comprehension Questions, while we measured the time. For five of the six patterns, we identified a significant positive impact on understandability, i.e., participants answered faster and / or more correctly for P. However, effect sizes were mostly small, with one pattern showing a medium effect. The correlations between performance and demographics seem to suggest that certain patterns may introduce additional complexity; people experienced with MAPs will profit more from their effects. This has important implications for training and education around MAPs and other patterns.'}, {'id': 'arxiv_2505.24716', 'title': 'Towards Scalable Schema Mapping using Large Language Models', 'URL': 'http://arxiv.org/abs/2505.24716', 'extra_urls': ['http://arxiv.org/abs/2505.24716'], 'type': 'article', 'author': [{'family': 'Buss', 'given': 'Christopher'}, {'family': 'Safari', 'given': 'Mahdis'}, {'family': 'Termehchy', 'given': 'Arash'}, {'family': 'Lee', 'given': 'Stefan'}, {'family': 'Maier', 'given': 'David'}], 'publisher': 'arXiv', 'abstract': 'The growing need to integrate information from a large number of diverse sources poses significant scalability challenges for data integration systems. These systems often rely on manually written schema mappings, which are complex, source-specific, and costly to maintain as sources evolve. While recent advances suggest that large language models (LLMs) can assist in automating schema matching by leveraging both structural and natural language cues, key challenges remain. In this paper, we identify three core issues with using LLMs for schema mapping: (1) inconsistent outputs due to sensitivity to input phrasing and structure, which we propose methods to address through sampling and aggregation techniques; (2) the need for more expressive mappings (e.g., GLaV), which strain the limited context windows of LLMs; and (3) the computational cost of repeated LLM calls, which we propose to mitigate through strategies like data type prefiltering.'}, {'id': 'arxiv_2406.04845', 'title': 'FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models', 'URL': 'http://arxiv.org/abs/2406.04845', 'extra_urls': ['http://arxiv.org/abs/2406.04845'], 'type': 'article', 'author': [{'family': 'Ye', 'given': 'Rui'}, {'family': 'Ge', 'given': 'Rui'}, {'family': 'Zhu', 'given': 'Xinyu'}, {'family': 'Chai', 'given': 'Jingyi'}, {'family': 'Du', 'given': 'Yaxin'}, {'family': 'Liu', 'given': 'Yang'}, {'family': 'Wang', 'given': 'Yanfeng'}, {'family': 'Chen', 'given': 'Siheng'}], 'publisher': 'arXiv', 'abstract': 'Federated learning has enabled multiple parties to collaboratively train large language models without directly sharing their data (FedLLM). Following this training paradigm, the community has put massive efforts from diverse aspects including framework, performance, and privacy. However, an unpleasant fact is that there are currently no realistic datasets and benchmarks for FedLLM and previous works all rely on artificially constructed datasets, failing to capture properties in real-world scenarios. Addressing this, we propose FedLLM-Bench, which involves 8 training methods, 4 training datasets, and 6 evaluation metrics, to offer a comprehensive testbed for the FedLLM community. FedLLM-Bench encompasses three datasets (e.g., user-annotated multilingual dataset) for federated instruction tuning and one dataset (e.g., user-annotated preference dataset) for federated preference alignment, whose scale of client number ranges from 38 to 747. Our datasets incorporate several representative diversities: language, quality, quantity, instruction, length, embedding, and preference, capturing properties in real-world scenarios. Based on FedLLM-Bench, we conduct experiments on all datasets to benchmark existing FL methods and provide empirical insights (e.g., multilingual collaboration). We believe that our FedLLM-Bench can benefit the FedLLM community by reducing required efforts, providing a practical testbed, and promoting fair comparisons. Code and datasets are available at https://github.com/rui-ye/FedLLM-Bench.'}, {'id': 'doi_10_1145_2674377_2674382', 'title': 'Improving Performance of Rural Supply Chains Using Mobile Phones: Reducing Information Asymmetry to Improve Stock Availability in Low-resource Environments', 'URL': 'https://doi.org/10.1145/2674377.2674382', 'type': 'article', 'author': [{'family': 'Ramanujapuram', 'given': 'Arun'}, {'family': 'Akkihal', 'given': 'Anup'}], 'issued': {'date-parts': [[2014]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Ensuring availability of essential goods, such as medicines or vaccines, at the point of care in the villages is a significant challenge in rural supply chains. The crux of the problem lies in information asymmetry of supply and demand, as well as ad hoc distribution practices. These supply chains are not managed efficiently, and often information flows upstream in the chain in an incomplete, incorrect and untimely manner. This ultimately affects procurement and distribution decisions, consequently leading to stock outs of important goods at the point of care.To address the problem of stock availability, we have implemented a "Bulletin Board" that digitally captures needs (demand) and availability (supply) of goods in real-time from any location using low-end mobile phones, and broadcasts this information to vendors and managers, upstream in the supply chain. We demonstrate that by reducing information asymmetry between supply and demand, the overall system "self-organizes" in a manner that stocks are appropriately re-distributed, thereby improving availability at the point of care. We demonstrate these concepts in the context of vaccine and medicine availability in a public health supply chain. In a study in Karnataka, India, we have observed vaccine stock availability increase to 99% and replenishment responsiveness improve by 64%. However, such an approach relies on obtaining high quality of data from the last mile, which is a big challenge in low-resource environments, where mobile networks are unreliable and human capacity is low. We describe the design of a mobile phone based service that leverages insights from information asymmetry theory and effective service design to achieve sustainable supply chain performance in low-resource environments.', 'DOI': '10.1145/2674377.2674382'}, {'id': 'arxiv_2504.18875', 'title': 'Generative to Agentic AI: Survey, Conceptualization, and Challenges', 'URL': 'http://arxiv.org/abs/2504.18875', 'extra_urls': ['http://arxiv.org/abs/2504.18875'], 'type': 'article', 'author': [{'family': 'Schneider', 'given': 'Johannes'}], 'publisher': 'arXiv', 'abstract': "Agentic Artificial Intelligence (AI) builds upon Generative AI (GenAI). It constitutes the next major step in the evolution of AI with much stronger reasoning and interaction capabilities that enable more autonomous behavior to tackle complex tasks. Since the initial release of ChatGPT (3.5), Generative AI has seen widespread adoption, giving users firsthand experience. However, the distinction between Agentic AI and GenAI remains less well understood. To address this gap, our survey is structured in two parts. In the first part, we compare GenAI and Agentic AI using existing literature, discussing their key characteristics, how Agentic AI remedies limitations of GenAI, and the major steps in GenAI's evolution toward Agentic AI. This section is intended for a broad audience, including academics in both social sciences and engineering, as well as industry professionals. It provides the necessary insights to comprehend novel applications that are possible with Agentic AI but not with GenAI. In the second part, we deep dive into novel aspects of Agentic AI, including recent developments and practical concerns such as defining agents. Finally, we discuss several challenges that could serve as a future research agenda, while cautioning against risks that can emerge when exceeding human intelligence."}, {'id': 'enhancing_digital_product', 'title': 'Enhancing Digital Product Passport Through Decentralized Digital Twins', 'URL': 'https://ieeexplore.ieee.org/document/11076730', 'extra_urls': ['https://ieeexplore.ieee.org/document/11076730'], 'type': 'article', 'author': [{'family': 'Kannappan', 'given': 'Ranjit'}, {'family': 'Hatin', 'given': 'Julien'}, {'family': 'Bertin', 'given': 'Emmanuel'}, {'family': 'Crespi', 'given': 'Noel'}], 'abstract': 'The Digital Product Passport (DPP) is a key enabler of the European Union\u2019s vision for a circular economy. Achieving the full potential of DPP requires addressing the challenges of traditional product lifecycle systems (PLM). Traditional PLM focuses on streamlining data management and decision making. However, their centralized architecture limits transparent, crossorganizational collaboration, impacting the circular economy efforts. This paper proposes a blockchain based framework, tailored to support DPP implementation by enabling the creation and sharing of lifecycle data using digital twin technology. The proposed architecture implements two types of digital twins - Component Digital Twin and Product Digital Twin modeled using the Asset Administration Shell (AAS) standard to ensure interoperability. The architecture leverages Ethereum smart contracts for blockchain interaction and IPFS for off-chain decentralized storage. Two approaches for secure data sharing are implemented: Direct and Signature-based data sharing. Performance evaluation shows low latency for key operations like twin creation (167 ms) and data sharing (64 ms). By leveraging decentralization in DPPs, the proposed framework fosters collaboration, transparency, and circular economy practices, empowering stakeholders to access and share critical product data throughout the lifecycle.'}, {'id': 'arxiv_2410.15758', 'title': 'Digital Product Passport Management with Decentralised Identifiers and Verifiable Credentials', 'URL': 'http://arxiv.org/abs/2410.15758', 'extra_urls': ['http://arxiv.org/abs/2410.15758'], 'type': 'article', 'author': [{'family': 'Garc\xeda', 'given': 'Ismael Ill\xe1n'}, {'family': 'Mu\xf1oz-Esco\xed', 'given': 'Francesc D.'}, {'family': 'Aroca', 'given': 'Jordi Arjona'}, {'family': 'Pe\xf1uela', 'given': 'F. Javier Fern\xe1ndez-Bravo'}], 'publisher': 'arXiv', 'abstract': 'Digital product passports (DPP) have been proposed in the European Ecodesign for Sustainable Products Regulation (ESPR) as a means to keep and provide product information that facilitates product reusage, reparation, and recycling. Thus, DPPs should provide a positive effect on the environmental impact of future manufactured products, preventing waste and promoting a circular economy (CE) model. ESPR settles a set of requirements in collecting and administering product-related data. Decentralised identifiers (DID) and verifiable credentials (VC) are two self-sovereign-identity-related elements that may help in that DPP management since they introduce a decentralised administration of identity that may enhance the overall scalability of the resulting system, improving also its reliability. This paper analyses the ESPR requirements and describes how they may be achieved using DIDs and VCs, assessing their performance in some scenarios.'}, {'id': 'doi_10_1007_978-3-030-01614-2_19', 'title': 'Digital Twin Requirements in the Context of Industry 4.0', 'URL': 'https://doi.org/10.1007/978-3-030-01614-2_19', 'type': 'article', 'author': [{'family': 'Dur\xe3o', 'given': 'Luiz Fernando C. S.'}, {'family': 'Haag', 'given': 'Sebastian'}, {'family': 'Anderl', 'given': 'Reiner'}, {'family': 'Sch\xfctzer', 'given': 'Klaus'}, {'family': 'Zancul', 'given': 'Eduardo'}], 'issued': {'date-parts': [[2018]]}, 'publisher': 'Springer International Publishing', 'abstract': 'Digital Twin (DT) is being considered a significant enabler for Industry 4.0 initiatives. Within Industry 4.0, the amount of digital product information generated and collected over the entire lifecycle has been growing. Current information and communication technologies, including data storage, data processing, and wireless data transmission, may be leveraged to digitally mirror the lifecycle of a corresponding physical product with increasing level of detail. A DT creates a link between physical products and their virtual models with more comprehensive data and accumulation of knowledge. Therefore, a DT may be applied to enhance simulation, traceability and to support the offering of value-added services along the lifecycle. However, the definition of a DT and its requirements are not yet fully established. The characteristics a DT model should possess to be widely used in manufacturing remains an open question in the literature. The concept is still broad and dependent on the lifecycle stage and industry sector of application. Therefore, the objective of this paper is to propose an initial synthesis of DT requirements based on a literature review and industry interviews. The literature review focuses on the content analysis of papers published from 2010 to 2018 and indexed in the ISI Web of Science database. The interviews were conducted with industry representatives in Brazil. The results show that DT requirements are related to real-time data, integration, and fidelity. Besides, it shows that industry requirements are close to literature and the actual implementation of DT is the future of research in this field.', 'DOI': '10.1007/978-3-030-01614-2_19'}, {'id': 'effective_vocabulary', 'title': 'VEEF-Multi-LLM: Effective Vocabulary Expansion and Parameter Efficient Finetuning Towards Multilingual Large Language Models', 'URL': 'https://aclanthology.org/2025.coling-main.533/', 'extra_urls': ['https://aclanthology.org/2025.coling-main.533/'], 'type': 'article', 'author': [{'family': 'Sha', 'given': 'Jiu'}, {'family': 'Zhu', 'given': 'Mengxiao'}, {'family': 'Feng', 'given': 'Chong'}, {'family': 'Shang', 'given': 'Yuming'}], 'publisher': 'Association for Computational Linguistics', 'abstract': 'Large Language Models(LLMs) have brought significant transformations to various aspects of human life and productivity. However, the heavy reliance on vast amounts of data in developing these models has resulted in a notable disadvantage for low-resource languages, such as Nuosu and others, which lack large datasets. Moreover, many LLMs exhibit significant performance discrepancies between high-and lowresource languages, thereby restricting equitable access to technological advances for all linguistic communities. To address these challenges, this paper propose a low-resource multilingual large language model, termed VEEF-Multi-LLM, constructed through effective vocabulary expansion and parameter-efficient fine-tuning. We introduce a series of innovative methods to address challenges in low-resource languages. First, we adopt Byte-level Byte-Pair Encoding to expand the vocabulary for broader multilingual support. We separate input and output embedding weights to boost performance, and apply RoPE for long-context handling, as well as RMSNorm for efficient training. To generate high-quality supervised fine-tuning (SFT) data, we use self-training and selective translation, and refine the resulting dataset with the assistance of native speakers to ensure cultural and linguistic accuracy. Our model, VEEF-Multi-LLM-8B, is trained on 600 billion tokens across 50 natural and 16 programming languages. Experimental results show that the model excels in multilingual instruction-following tasks, particularly in translation, outperforming competing models in benchmarks such as XCOPA and XStoryCloze. Although it lags slightly behind English-centric models in some tasks (e.g., m-MMLU), it prioritizes safety, reliability, and inclusivity, making it valuable for diverse linguistic communities. We open-source our models on GitHub and Huggingface.'}, {'id': 'arxiv_2502.08650', 'title': 'Who is Responsible? The Data, Models, Users or Regulations? A Comprehensive Survey on Responsible Generative AI for a Sustainable Future', 'URL': 'http://arxiv.org/abs/2502.08650', 'extra_urls': ['http://arxiv.org/abs/2502.08650'], 'type': 'article', 'author': [{'family': 'Raza', 'given': 'Shaina'}, {'family': 'Qureshi', 'given': 'Rizwan'}, {'family': 'Zahid', 'given': 'Anam'}, {'family': 'Kamawal', 'given': 'Safiullah'}, {'family': 'Sadak', 'given': 'Ferhat'}, {'family': 'Fioresi', 'given': 'Joseph'}, {'family': 'Saeed', 'given': 'Muhammaed'}, {'family': 'Sapkota', 'given': 'Ranjan'}, {'family': 'Jain', 'given': 'Aditya'}, {'family': 'Zafar', 'given': 'Anas'}, {'family': 'Hassan', 'given': 'Muneeb Ul'}, {'family': 'Zafar', 'given': 'Aizan'}, {'family': 'Maqbool', 'given': 'Hasan'}, {'family': 'Vayani', 'given': 'Ashmal'}, {'family': 'Wu', 'given': 'Jia'}, {'family': 'Shoman', 'given': 'Maged'}], 'publisher': 'arXiv', 'abstract': 'Generative AI is moving rapidly from research into real world deployment across sectors, which elevates the need for responsible development, deployment, evaluation, and governance. To address this pressing challenge, in this study, we synthesize the landscape of responsible generative AI across methods, benchmarks, and policies, and connects governance expectations to concrete engineering practice. We follow a prespecified search and screening protocol focused on post-ChatGPT era with selective inclusion of foundational work for definitions, and we conduct a narrative and thematic synthesis. Three findings emerge; First, benchmark and practice coverage is dense for bias and toxicity but relatively sparse for privacy and provenance, deepfake and media integrity risk, and system level failure in tool using and agentic settings. Second, many evaluations remain static and task local, which limits evidence portability for audit and lifecycle assurance. Third, documentation and metric validity are inconsistent, which complicates comparison across releases and domains. We outline a research and practice agenda that prioritizes adaptive and multimodal evaluation, privacy and provenance testing, deepfake risk assessment, calibration and uncertainty reporting, versioned and documented artifacts, and continuous monitoring. Limitations include reliance on public artifacts and the focus period, which may under represent capabilities reported later. The survey offers a path to align development and evaluation with governance needs and to support safe, transparent, and accountable deployment across domains. Project page: https://anas-zafar.github.io/responsible-ai.github.io , GitHub: https://github.com/anas-zafar/Responsible-AI'}, {'id': 'business_simulation', 'title': 'AI-Enhanced Business Simulation Models for Strategic Decision-Making in Uncertain Environments', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11156362', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11156362'], 'type': 'article', 'author': [{'family': 'Lahoti', 'given': 'Yuvraj'}, {'family': 'Kalshetti', 'given': 'Prashant'}, {'family': 'Anute', 'given': 'Nilesh'}, {'family': 'Limbore', 'given': 'Nilesh Vitthal'}], 'abstract': "Uncertainty and complexity make it hard to make effective decisions in today's business world, which changes quickly. Even though traditional business computer models can teach us a lot, they don't always capture how dynamic and unclear real-life situations are. This article talks about a new AI-enhanced business exercise system that is meant to help people make smart decisions when they don't know what will happen. By adding advanced AI methods like machine learning and reinforcement learning to business models, the framework makes it possible for data-driven, adaptable decision support that learns and changes as market conditions do. The suggested method uses random processes and scenario analysis to model unpredictability. This lets decision-makers look at a range of possible futures and see how well tactics work when faced with different risks and problems. To show what the framework can do, a sample simulation model was made using carefully chosen AI algorithms that are best at making predictions and using computers quickly. The modeling setting was set up to look like complicated business situations, including important organizational and market factors that affect the results. The results of the experiments show that the framework can improve the quality of decisions by giving us practical insights, making risk assessment better, and letting us evaluate strategies in a variety of situations. This work adds to management study by connecting new developments in AI with real-world business simulations. This makes strategy planning more adaptable and well-informed. The approach could be used in multi-agent systems, and real-time data merging could help with ongoing learning in the future. This AI-based method looks like it could help leaders and researchers deal with uncertainty and improve business success in unstable markets."}, {'id': 'arxiv_2507.00951', 'title': 'Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact', 'URL': 'http://arxiv.org/abs/2507.00951', 'extra_urls': ['http://arxiv.org/abs/2507.00951'], 'type': 'article', 'author': [{'family': 'Qureshi', 'given': 'Rizwan'}, {'family': 'Sapkota', 'given': 'Ranjan'}, {'family': 'Shah', 'given': 'Abbas'}, {'family': 'Muneer', 'given': 'Amgad'}, {'family': 'Zafar', 'given': 'Anas'}, {'family': 'Vayani', 'given': 'Ashmal'}, {'family': 'Shoman', 'given': 'Maged'}, {'family': 'Eldaly', 'given': 'Abdelrahman B. M.'}, {'family': 'Zhang', 'given': 'Kai'}, {'family': 'Sadak', 'given': 'Ferhat'}, {'family': 'Raza', 'given': 'Shaina'}, {'family': 'Fan', 'given': 'Xinqi'}, {'family': 'Shwartz-Ziv', 'given': 'Ravid'}, {'family': 'Yan', 'given': 'Hong'}, {'family': 'Jain', 'given': 'Vinjia'}, {'family': 'Chadha', 'given': 'Aman'}, {'family': 'Karkee', 'given': 'Manoj'}, {'family': 'Wu', 'given': 'Jia'}, {'family': 'Mirjalili', 'given': 'Seyedali'}], 'publisher': 'arXiv', 'abstract': 'Can machines truly think, reason and act in domains like humans? This enduring question continues to shape the pursuit of Artificial General Intelligence (AGI). Despite the growing capabilities of models such as GPT-4.5, DeepSeek, Claude 3.5 Sonnet, Phi-4, and Grok 3, which exhibit multimodal fluency and partial reasoning, these systems remain fundamentally limited by their reliance on token-level prediction and lack of grounded agency. This paper offers a cross-disciplinary synthesis of AGI development, spanning artificial intelligence, cognitive neuroscience, psychology, generative models, and agent-based systems. We analyze the architectural and cognitive foundations of general intelligence, highlighting the role of modular reasoning, persistent memory, and multi-agent coordination. In particular, we emphasize the rise of Agentic RAG frameworks that combine retrieval, planning, and dynamic tool use to enable more adaptive behavior. We discuss generalization strategies, including information compression, test-time adaptation, and training-free methods, as critical pathways toward flexible, domain-agnostic intelligence. Vision-Language Models (VLMs) are reexamined not just as perception modules but as evolving interfaces for embodied understanding and collaborative task completion. We also argue that true intelligence arises not from scale alone but from the integration of memory and reasoning: an orchestration of modular, interactive, and self-improving components where compression enables adaptive behavior. Drawing on advances in neurosymbolic systems, reinforcement learning, and cognitive scaffolding, we explore how recent architectures begin to bridge the gap between statistical learning and goal-directed cognition. Finally, we identify key scientific, technical, and ethical challenges on the path to AGI.'}, {'id': 'how_to_choose', 'title': 'How to Choose Among Technologies With Learning Curves: Making Better Investment Decisions', 'URL': 'https://papers.ssrn.com/abstract=5168106', 'extra_urls': ['https://papers.ssrn.com/abstract=5168106'], 'type': 'article', 'author': [{'family': 'Kaps', 'given': 'Christian'}, {'family': 'Anderer', 'given': 'Arielle'}], 'publisher': 'Social Science Research Network', 'abstract': 'Learning curves, the fact that technologies improve as a function of cumulative experience or investment, are desirable-think inexpensive solar panels or higher performing semiconductors. But, for firms that need to pick one technology among several candidates, such as R&amp;D labs or venture capital firms, learning curves make it hard to make the optimal technology investment choice. This paper addresses this challenge and provides the first formal analysis of how to invest in a set of technologies over multiple periods if (i) the cost of a technology decreases with cumulative investment and (ii) the decision maker only benefits from the estimated lowest-cost technology at the end of the investment horizon. We develop a dynamic programming framework to model this problem and, for a 2-technology case, are able to identify a closed-form ratio that managers can compute to choose the optimal technology to invest in. We then leverage these insights to develop a policy that can be employed to find the best investment choice for settings with any number of technologies and decision periods. Our policy has the added benefit of making the value of exploration versus exploitation visible to the decision-maker. We provide detailed numerical comparisons of our Technology Learning Curve Optimization (TELCO) policy and find it performs, on average, 8% better than the second-best policy across 1200 different scenarios. Additionally, we apply our methodology to the real-world problem of lithium-ion chemistries for battery production, demonstrating its robustness and effectiveness.'}, {'id': 'arxiv_2510.03469', 'title': 'Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification', 'URL': 'http://arxiv.org/abs/2510.03469', 'extra_urls': ['http://arxiv.org/abs/2510.03469'], 'type': 'article', 'author': [{'family': 'Ramani', 'given': 'Keshav'}, {'family': 'Tawosi', 'given': 'Vali'}, {'family': 'Alamir', 'given': 'Salwa'}, {'family': 'Borrajo', 'given': 'Daniel'}], 'publisher': 'arXiv', 'abstract': 'We introduce a novel framework for evaluating the alignment between natural language plans and their expected behavior by converting them into Kripke structures and Linear Temporal Logic (LTL) using Large Language Models (LLMs) and performing model checking. We systematically evaluate this framework on a simplified version of the PlanBench plan verification dataset and report on metrics like Accuracy, Precision, Recall and F1 scores. Our experiments demonstrate that GPT-5 achieves excellent classification performance (F1 score of 96.3%) while almost always producing syntactically perfect formal representations that can act as guarantees. However, the synthesis of semantically perfect formal models remains an area for future exploration.'}, {'id': 'arxiv_2509.23864', 'title': 'AgentGuard: Runtime Verification of AI Agents', 'URL': 'http://arxiv.org/abs/2509.23864', 'extra_urls': ['http://arxiv.org/abs/2509.23864'], 'type': 'article', 'author': [{'family': 'Koohestani', 'given': 'Roham'}], 'publisher': 'arXiv', 'abstract': "The rapid evolution to autonomous, agentic AI systems introduces significant risks due to their inherent unpredictability and emergent behaviors; this also renders traditional verification methods inadequate and necessitates a shift towards probabilistic guarantees where the question is no longer if a system will fail, but the probability of its failure within given constraints. This paper presents AgentGuard, a framework for runtime verification of Agentic AI systems that provides continuous, quantitative assurance through a new paradigm called Dynamic Probabilistic Assurance. AgentGuard operates as an inspection layer that observes an agent's raw I/O and abstracts it into formal events corresponding to transitions in a state model. It then uses online learning to dynamically build and update a Markov Decision Process (MDP) that formally models the agent's emergent behavior. Using probabilistic model checking, the framework then verifies quantitative properties in real-time."}, {'id': 'arxiv_2509.20364', 'title': 'An Approach to Checking Correctness for Agentic Systems', 'URL': 'http://arxiv.org/abs/2509.20364', 'extra_urls': ['http://arxiv.org/abs/2509.20364'], 'type': 'article', 'author': [{'family': 'Sheffler', 'given': 'Thomas J.'}], 'publisher': 'arXiv', 'abstract': "This paper presents a temporal expression language for monitoring AI agent behavior, enabling systematic error-detection of LLM-based agentic systems that exhibit variable outputs due to stochastic generation processes. Drawing from temporal logic techniques used in hardware verification, this approach monitors execution traces of agent tool calls and state transitions to detect deviations from expected behavioral patterns. Current error-detection approaches rely primarily on text matching of inputs and outputs, which proves fragile due to the natural language variability inherent in LLM responses. The proposed method instead focuses on the sequence of agent actions -- such as tool invocations and inter-agent communications -- allowing verification of system behavior independent of specific textual outputs. The temporal expression language provides assertions that capture correct behavioral patterns across multiple execution scenarios. These assertions serve dual purposes: validating prompt engineering and guardrail effectiveness during development, and providing regression testing when agents are updated with new LLMs or modified logic. The approach is demonstrated using a three-agent system, where agents coordinate to solve multi-step reasoning tasks. When powered by large, capable models, all temporal assertions were satisfied across many test runs. However, when smaller models were substituted in two of the three agents, executions violated behavioral assertions, primarily due to improper tool sequencing and failed coordination handoffs. The temporal expressions successfully flagged these anomalies, demonstrating the method's effectiveness for detecting behavioral regressions in production agentic systems. This approach provides a foundation for systematic monitoring of AI agent reliability as these systems become increasingly deployed in critical applications."}, {'id': 'verifying', 'title': 'LLMV-AgE: Verifying LLM-Guided Planning for Agentic Exploration in Open-World RL', 'URL': 'https://openreview.net/forum?id=dA7a3eKkKg', 'extra_urls': ['https://openreview.net/forum?id=dA7a3eKkKg'], 'type': 'article', 'author': [{'family': 'Chi', 'given': 'Haotian'}, {'family': 'Zhao', 'given': 'Songwei'}, {'family': 'Tsang', 'given': 'Ivor'}, {'family': 'Ong', 'given': 'Yew-Soon'}, {'family': 'Chen', 'given': 'Hechang'}, {'family': 'Chang', 'given': 'Yi'}, {'family': 'Yin', 'given': 'Haiyan'}], 'abstract': 'Large language models (LLMs) have shown promise in enhancing reinforcement learning (RL) through task decomposition, yet their generated subgoals often lack reliability, leading to inefficient exploration and suboptimal policy learning. In this paper, we propose LLMV-AgE (Verification of LLM-guided planning for Agentic Exploration), an RL framework that integrates LLM-guided subgoal planning with a hierarchical verification process to ensure both semantic validity and environmental feasibility. LLMV-AgE systematically assesses subgoal coherence, corrects invalid plans through iterative refinement, and aligns policy learning with reliable, goal-driven objectives. Empirical results on the procedurally generated Crafter benchmark demonstrate that LLMV-AgE significantly improves exploration efficiency and policy robustness by mitigating the impact of hallucinated subgoals and guiding agents toward more achievable goals.'}, {'id': 'arxiv_2502.16662', 'title': 'Saarthi: The First AI Formal Verification Engineer', 'URL': 'http://arxiv.org/abs/2502.16662', 'extra_urls': ['http://arxiv.org/abs/2502.16662'], 'type': 'article', 'author': [{'family': 'Kumar', 'given': 'Aman'}, {'family': 'Gadde', 'given': 'Deepak Narayan'}, {'family': 'Radhakrishna', 'given': 'Keerthan Kopparam'}, {'family': 'Lettnin', 'given': 'Djones'}], 'publisher': 'arXiv', 'abstract': "Recently, Devin has made a significant buzz in the Artificial Intelligence (AI) community as the world's first fully autonomous AI software engineer, capable of independently developing software code. Devin uses the concept of agentic workflow in Generative AI (GenAI), which empowers AI agents to engage in a more dynamic, iterative, and self-reflective process. In this paper, we present a similar fully autonomous AI formal verification engineer, Saarthi, capable of verifying a given RTL design end-to-end using an agentic workflow. With Saarthi, verification engineers can focus on more complex problems, and verification teams can strive for more ambitious goals. The domain-agnostic implementation of Saarthi makes it scalable for use across various domains such as RTL design, UVM-based verification, and others."}, {'id': 'arxiv_2510.03463', 'title': 'ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering Framework', 'URL': 'http://arxiv.org/abs/2510.03463', 'extra_urls': ['http://arxiv.org/abs/2510.03463'], 'type': 'article', 'author': [{'family': 'Tawosi', 'given': 'Vali'}, {'family': 'Ramani', 'given': 'Keshav'}, {'family': 'Alamir', 'given': 'Salwa'}, {'family': 'Liu', 'given': 'Xiaomo'}], 'publisher': 'arXiv', 'abstract': 'Multi-agent Large Language Model (LLM) systems have been leading the way in applied LLM research across a number of fields. One notable area is software development, where researchers have advanced the automation of code implementation, code testing, code maintenance, inter alia, using LLM agents. However, software development is a multifaceted environment that extends beyond just code. As such, a successful LLM system must factor in multiple stages of the software development life-cycle (SDLC). In this paper, we propose a vision for ALMAS, an Autonomous LLM-based Multi-Agent Software Engineering framework, which follows the above SDLC philosophy such that it may work within an agile software development team to perform several tasks end-to-end. ALMAS aligns its agents with agile roles, and can be used in a modular fashion to seamlessly integrate with human developers and their development environment. We showcase the progress towards ALMAS through our published works and a use case demonstrating the framework, where ALMAS is able to seamlessly generate an application and add a new feature.'}, {'id': 'arxiv_2506.09755', 'title': 'Intelligent Design 4.0: Paradigm Evolution Toward the Agentic AI Era', 'URL': 'http://arxiv.org/abs/2506.09755', 'extra_urls': ['http://arxiv.org/abs/2506.09755'], 'type': 'article', 'author': [{'family': 'Jiang', 'given': 'Shuo'}, {'family': 'Xie', 'given': 'Min'}, {'family': 'Chen', 'given': 'Frank Youhua'}, {'family': 'Ma', 'given': 'Jian'}, {'family': 'Luo', 'given': 'Jianxi'}], 'publisher': 'arXiv', 'abstract': "Research and practice in Intelligent Design (ID) have significantly enhanced engineering innovation, efficiency, quality, and productivity over recent decades, fundamentally reshaping how engineering designers think, behave, and interact with design processes. The recent emergence of Foundation Models (FMs), particularly Large Language Models (LLMs), has demonstrated general knowledge-based reasoning capabilities, and open new paths and avenues for further transformation in engineering design. In this context, this paper introduces Intelligent Design 4.0 (ID 4.0) as an emerging paradigm empowered by agentic AI systems. We review the historical evolution of ID across four distinct stages: rule-based expert systems, task-specific machine learning models, large-scale foundation AI models, and the recent emerging paradigm of multi-agent collaboration. We propose a conceptual framework for ID 4.0 and discuss its potential to support end-to-end automation of engineering design processes through coordinated, autonomous multi-agent-based systems. Furthermore, we discuss future perspectives to enhance and fully realize ID 4.0's potential, including more complex design scenarios, more practical design implementations, novel agent coordination mechanisms, and autonomous design goal-setting with better human value alignment. In sum, these insights lay a foundation for advancing Intelligent Design toward greater adaptivity, autonomy, and effectiveness in addressing increasingly complex design challenges."}, {'id': 'arxiv_2505.08137', 'title': 'Large Language Models for Computer-Aided Design: A Survey', 'URL': 'http://arxiv.org/abs/2505.08137', 'extra_urls': ['http://arxiv.org/abs/2505.08137'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Licheng'}, {'family': 'Le', 'given': 'Bach'}, {'family': 'Akhtar', 'given': 'Naveed'}, {'family': 'Lam', 'given': 'Siew-Kei'}, {'family': 'Ngo', 'given': 'Tuan'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) have seen rapid advancements in recent years, with models like ChatGPT and DeepSeek, showcasing their remarkable capabilities across diverse domains. While substantial research has been conducted on LLMs in various fields, a comprehensive review focusing on their integration with Computer-Aided Design (CAD) remains notably absent. CAD is the industry standard for 3D modeling and plays a vital role in the design and development of products across different industries. As the complexity of modern designs increases, the potential for LLMs to enhance and streamline CAD workflows presents an exciting frontier. This article presents the first systematic survey exploring the intersection of LLMs and CAD. We begin by outlining the industrial significance of CAD, highlighting the need for AI-driven innovation. Next, we provide a detailed overview of the foundation of LLMs. We also examine both closed-source LLMs as well as publicly available models. The core of this review focuses on the various applications of LLMs in CAD, providing a taxonomy of six key areas where these models are making considerable impact. Finally, we propose several promising future directions for further advancements, which offer vast opportunities for innovation and are poised to shape the future of CAD technology. Github: https://github.com/lichengzhanguom/LLMs-CAD-Survey-Taxonomy'}, {'id': 'arxiv_2501.12202', 'title': 'Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D Assets Generation', 'URL': 'http://arxiv.org/abs/2501.12202', 'extra_urls': ['http://arxiv.org/abs/2501.12202'], 'type': 'article', 'author': [{'family': 'Zhao', 'given': 'Zibo'}, {'family': 'Lai', 'given': 'Zeqiang'}, {'family': 'Lin', 'given': 'Qingxiang'}, {'family': 'Zhao', 'given': 'Yunfei'}, {'family': 'Liu', 'given': 'Haolin'}, {'family': 'Yang', 'given': 'Shuhui'}, {'family': 'Feng', 'given': 'Yifei'}, {'family': 'Yang', 'given': 'Mingxin'}, {'family': 'Zhang', 'given': 'Sheng'}, {'family': 'Yang', 'given': 'Xianghui'}, {'family': 'Shi', 'given': 'Huiwen'}, {'family': 'Liu', 'given': 'Sicong'}, {'family': 'Wu', 'given': 'Junta'}, {'family': 'Lian', 'given': 'Yihang'}, {'family': 'Yang', 'given': 'Fan'}, {'family': 'Tang', 'given': 'Ruining'}, {'family': 'He', 'given': 'Zebin'}, {'family': 'Wang', 'given': 'Xinzhou'}, {'family': 'Liu', 'given': 'Jian'}, {'family': 'Zuo', 'given': 'Xuhui'}, {'family': 'Chen', 'given': 'Zhuo'}, {'family': 'Lei', 'given': 'Biwen'}, {'family': 'Weng', 'given': 'Haohan'}, {'family': 'Xu', 'given': 'Jing'}, {'family': 'Zhu', 'given': 'Yiling'}, {'family': 'Liu', 'given': 'Xinhai'}, {'family': 'Xu', 'given': 'Lixin'}, {'family': 'Hu', 'given': 'Changrong'}, {'family': 'Yang', 'given': 'Shaoxiong'}, {'family': 'Zhang', 'given': 'Song'}, {'family': 'Liu', 'given': 'Yang'}, {'family': 'Huang', 'given': 'Tianyu'}, {'family': 'Wang', 'given': 'Lifu'}, {'family': 'Zhang', 'given': 'Jihong'}, {'family': 'Chen', 'given': 'Meng'}, {'family': 'Dong', 'given': 'Liang'}, {'family': 'Jia', 'given': 'Yiwen'}, {'family': 'Cai', 'given': 'Yulin'}, {'family': 'Yu', 'given': 'Jiaao'}, {'family': 'Tang', 'given': 'Yixuan'}, {'family': 'Zhang', 'given': 'Hao'}, {'family': 'Ye', 'given': 'Zheng'}, {'family': 'He', 'given': 'Peng'}, {'family': 'Wu', 'given': 'Runzhou'}, {'family': 'Zhang', 'given': 'Chao'}, {'family': 'Tan', 'given': 'Yonghao'}, {'family': 'Xiao', 'given': 'Jie'}, {'family': 'Tao', 'given': 'Yangyu'}, {'family': 'Zhu', 'given': 'Jianchen'}, {'family': 'Xue', 'given': 'Jinbao'}, {'family': 'Liu', 'given': 'Kai'}, {'family': 'Zhao', 'given': 'Chongqing'}, {'family': 'Wu', 'given': 'Xinming'}, {'family': 'Hu', 'given': 'Zhichao'}, {'family': 'Qin', 'given': 'Lei'}, {'family': 'Peng', 'given': 'Jianbing'}, {'family': 'Li', 'given': 'Zhan'}, {'family': 'Chen', 'given': 'Minghui'}, {'family': 'Zhang', 'given': 'Xipeng'}, {'family': 'Niu', 'given': 'Lin'}, {'family': 'Wang', 'given': 'Paige'}, {'family': 'Wang', 'given': 'Yingkai'}, {'family': 'Kuang', 'given': 'Haozhao'}, {'family': 'Fan', 'given': 'Zhongyi'}, {'family': 'Zheng', 'given': 'Xu'}, {'family': 'Zhuang', 'given': 'Weihao'}, {'family': 'He', 'given': 'YingPing'}, {'family': 'Liu', 'given': 'Tian'}, {'family': 'Yang', 'given': 'Yong'}, {'family': 'Wang', 'given': 'Di'}, {'family': 'Liu', 'given': 'Yuhong'}, {'family': 'Jiang', 'given': 'Jie'}, {'family': 'Huang', 'given': 'Jingwei'}, {'family': 'Guo', 'given': 'Chunchao'}], 'publisher': 'arXiv', 'abstract': 'We present Hunyuan3D 2.0, an advanced large-scale 3D synthesis system for generating high-resolution textured 3D assets. This system includes two foundation components: a large-scale shape generation model -- Hunyuan3D-DiT, and a large-scale texture synthesis model -- Hunyuan3D-Paint. The shape generative model, built on a scalable flow-based diffusion transformer, aims to create geometry that properly aligns with a given condition image, laying a solid foundation for downstream applications. The texture synthesis model, benefiting from strong geometric and diffusion priors, produces high-resolution and vibrant texture maps for either generated or hand-crafted meshes. Furthermore, we build Hunyuan3D-Studio -- a versatile, user-friendly production platform that simplifies the re-creation process of 3D assets. It allows both professional and amateur users to manipulate or even animate their meshes efficiently. We systematically evaluate our models, showing that Hunyuan3D 2.0 outperforms previous state-of-the-art models, including the open-source models and closed-source models in geometry details, condition alignment, texture quality, and etc. Hunyuan3D 2.0 is publicly released in order to fill the gaps in the open-source 3D community for large-scale foundation generative models. The code and pre-trained weights of our models are available at: https://github.com/Tencent/Hunyuan3D-2'}, {'id': 'arxiv_2411.04954', 'title': 'CAD-MLLM: Unifying Multimodality-Conditioned CAD Generation With MLLM', 'URL': 'http://arxiv.org/abs/2411.04954', 'extra_urls': ['http://arxiv.org/abs/2411.04954'], 'type': 'article', 'author': [{'family': 'Xu', 'given': 'Jingwei'}, {'family': 'Wang', 'given': 'Chenyu'}, {'family': 'Zhao', 'given': 'Zibo'}, {'family': 'Liu', 'given': 'Wen'}, {'family': 'Ma', 'given': 'Yi'}, {'family': 'Gao', 'given': 'Shenghua'}], 'publisher': 'arXiv', 'abstract': "This paper aims to design a unified Computer-Aided Design (CAD) generation system that can easily generate CAD models based on the user's inputs in the form of textual description, images, point clouds, or even a combination of them. Towards this goal, we introduce the CAD-MLLM, the first system capable of generating parametric CAD models conditioned on the multimodal input. Specifically, within the CAD-MLLM framework, we leverage the command sequences of CAD models and then employ advanced large language models (LLMs) to align the feature space across these diverse multi-modalities data and CAD models' vectorized representations. To facilitate the model training, we design a comprehensive data construction and annotation pipeline that equips each CAD model with corresponding multimodal data. Our resulting dataset, named Omni-CAD, is the first multimodal CAD dataset that contains textual description, multi-view images, points, and command sequence for each CAD model. It contains approximately 450K instances and their CAD construction sequences. To thoroughly evaluate the quality of our generated CAD models, we go beyond current evaluation metrics that focus on reconstruction quality by introducing additional metrics that assess topology quality and surface enclosure extent. Extensive experimental results demonstrate that CAD-MLLM significantly outperforms existing conditional generative methods and remains highly robust to noises and missing points. The project page and more visualizations can be found at: https://cad-mllm.github.io/"}, {'id': 'arxiv_2405.02580', 'title': 'PropertyGPT: LLM-driven Formal Verification of Smart Contracts through Retrieval-Augmented Property Generation', 'URL': 'http://arxiv.org/abs/2405.02580', 'extra_urls': ['http://arxiv.org/abs/2405.02580'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Ye'}, {'family': 'Xue', 'given': 'Yue'}, {'family': 'Wu', 'given': 'Daoyuan'}, {'family': 'Sun', 'given': 'Yuqiang'}, {'family': 'Li', 'given': 'Yi'}, {'family': 'Shi', 'given': 'Miaolei'}, {'family': 'Liu', 'given': 'Yang'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'With recent advances in large language models (LLMs), this paper explores the potential of leveraging state-of-the-art LLMs,such as GPT-4, to transfer existing human-written properties (e.g.,those from Certora auditing reports) and automatically generate customized properties for unknown code. To this end, we embed existing properties into a vector database and retrieve a reference property for LLM-based in-context learning to generate a new property for a given code. While this basic process is relatively straightforward, ensuring that the generated properties are (i) compilable, (ii) appropriate, and (iii) verifiable presents challenges. To address (i), we use the compilation and static analysis feedback as an external oracle to guide LLMs in iteratively revising the generated properties. For (ii), we consider multiple dimensions of similarity to rank the properties and employ a weighted algorithm to identify the top-K properties as the final result. For (iii), we design a dedicated prover to formally verify the correctness of the generated properties. We have implemented these strategies into a novel LLM-based property generation tool called PropertyGPT. Our experiments show that PropertyGPT can generate comprehensive and high-quality properties, achieving an 80% recall compared to the ground truth. It successfully detected 26 CVEs/attack incidents out of 37 tested and also uncovered 12 zero-day vulnerabilities, leading to $8,256 in bug bounty rewards.'}, {'id': 'arxiv_2508.19870', 'title': 'Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey', 'URL': 'http://arxiv.org/abs/2508.19870', 'extra_urls': ['http://arxiv.org/abs/2508.19870'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Yinqiu'}, {'family': 'Zhang', 'given': 'Ruichen'}, {'family': 'Luo', 'given': 'Haoxiang'}, {'family': 'Lin', 'given': 'Yijing'}, {'family': 'Sun', 'given': 'Geng'}, {'family': 'Niyato', 'given': 'Dusit'}, {'family': 'Du', 'given': 'Hongyang'}, {'family': 'Xiong', 'given': 'Zehui'}, {'family': 'Wen', 'given': 'Yonggang'}, {'family': 'Jamalipour', 'given': 'Abbas'}, {'family': 'Kim', 'given': 'Dong In'}, {'family': 'Zhang', 'given': 'Ping'}], 'publisher': 'arXiv', 'abstract': "Agentification serves as a critical enabler of Edge General Intelligence (EGI), transforming massive edge devices into cognitive agents through integrating Large Language Models (LLMs) and perception, reasoning, and acting modules. These agents collaborate across heterogeneous edge infrastructures, forming multi-LLM agentic AI systems that leverage collective intelligence and specialized capabilities to tackle complex, multi-step tasks. However, the collaborative nature of multi-LLM systems introduces critical security vulnerabilities, including insecure inter-LLM communications, expanded attack surfaces, and cross-domain data leakage that traditional perimeter-based security cannot adequately address. To this end, this survey introduces zero-trust security of multi-LLM in EGI, a paradigmatic shift following the ``never trust, always verify'' principle. We begin by systematically analyzing the security risks in multi-LLM systems within EGI contexts. Subsequently, we present the vision of a zero-trust multi-LLM framework in EGI. We then survey key technical progress to facilitate zero-trust multi-LLM systems in EGI. Particularly, we categorize zero-trust security mechanisms into model- and system-level approaches. The former and latter include strong identification, context-aware access control, etc., and proactive maintenance, blockchain-based management, etc., respectively. Finally, we identify critical research directions. This survey serves as the first systematic treatment of zero-trust applied to multi-LLM systems, providing both theoretical foundations and practical strategies."}, {'id': 'arxiv_2508.01351', 'title': 'NATLM: Detecting Defects in NFT Smart Contracts Leveraging LLM', 'URL': 'http://arxiv.org/abs/2508.01351', 'extra_urls': ['http://arxiv.org/abs/2508.01351'], 'type': 'article', 'author': [{'family': 'Niu', 'given': 'Yuanzheng'}, {'family': 'Li', 'given': 'Xiaoqi'}, {'family': 'Li', 'given': 'Wenkai'}], 'publisher': 'arXiv', 'abstract': 'Security issues are becoming increasingly significant with the rapid evolution of Non-fungible Tokens (NFTs). As NFTs are traded as digital assets, they have emerged as prime targets for cyber attackers. In the development of NFT smart contracts, there may exist undiscovered defects that could lead to substantial financial losses if exploited. To tackle this issue, this paper presents a framework called NATLM(NFT Assistant LLM), designed to detect potential defects in NFT smart contracts. The framework effectively identifies four common types of vulnerabilities in NFT smart contracts: ERC-721 Reentrancy, Public Burn, Risky Mutable Proxy, and Unlimited Minting. Relying exclusively on large language models (LLMs) for defect detection can lead to a high false-positive rate. To enhance detection performance, NATLM integrates static analysis with LLMs, specifically Gemini Pro 1.5. Initially, NATLM employs static analysis to extract structural, syntactic, and execution flow information from the code, represented through Abstract Syntax Trees (AST) and Control Flow Graphs (CFG). These extracted features are then combined with vectors of known defect examples to create a matrix for input into the knowledge base. Subsequently, the feature vectors and code vectors of the analyzed contract are compared with the contents of the knowledge base. Finally, the LLM performs deep semantic analysis to enhance detection capabilities, providing a more comprehensive and accurate identification of potential security issues. Experimental results indicate that NATLM analyzed 8,672 collected NFT smart contracts, achieving an overall precision of 87.72%, a recall of 89.58%, and an F1 score of 88.94%. The results outperform other baseline experiments, successfully identifying four common types of defects.'}, {'id': 'arxiv_2508.05188', 'title': 'Incident Response Planning Using a Lightweight Large Language Model with Reduced Hallucination', 'URL': 'http://arxiv.org/abs/2508.05188', 'extra_urls': ['http://arxiv.org/abs/2508.05188'], 'type': 'article', 'author': [{'family': 'Hammar', 'given': 'Kim'}, {'family': 'Alpcan', 'given': 'Tansu'}, {'family': 'Lupu', 'given': 'Emil C.'}], 'publisher': 'arXiv', 'abstract': 'Timely and effective incident response is key to managing the growing frequency of cyberattacks. However, identifying the right response actions for complex systems is a major technical challenge. A promising approach to mitigate this challenge is to use the security knowledge embedded in large language models (LLMs) to assist security operators during incident handling. Recent research has demonstrated the potential of this approach, but current methods are mainly based on prompt engineering of frontier LLMs, which is costly and prone to hallucinations. We address these limitations by presenting a novel way to use an LLM for incident response planning with reduced hallucination. Our method includes three steps: fine-tuning, information retrieval, and lookahead planning. We prove that our method generates response plans with a bounded probability of hallucination and that this probability can be made arbitrarily small at the expense of increased planning time under certain assumptions. Moreover, we show that our method is lightweight and can run on commodity hardware. We evaluate our method on logs from incidents reported in the literature. The experimental results show that our method a) achieves up to 22% shorter recovery times than frontier LLMs and b) generalizes to a broad range of incident types and response actions.'}, {'id': 'arxiv_2509.24698', 'title': 'LISA Technical Report: An Agentic Framework for Smart Contract Auditing', 'URL': 'http://arxiv.org/abs/2509.24698', 'extra_urls': ['http://arxiv.org/abs/2509.24698'], 'type': 'article', 'author': [{'family': 'Sun', 'given': 'Izaiah'}, {'family': 'Tan', 'given': 'Daniel'}, {'family': 'Deng', 'given': 'Andy'}], 'publisher': 'arXiv', 'abstract': 'We present LISA, an agentic smart contract vulnerability detection framework that combines rule-based and logic-based methods to address a broad spectrum of vulnerabilities in smart contracts. LISA leverages data from historical audit reports to learn the detection experience (without model fine-tuning), enabling it to generalize learned patterns to unseen projects and evolving threat profiles. In our evaluation, LISA significantly outperforms both LLM-based approaches and traditional static analysis tools, achieving superior coverage of vulnerability types and higher detection accuracy. Our results suggest that LISA offers a compelling solution for industry: delivering more reliable and comprehensive vulnerability detection while reducing the dependence on manual effort.'}, {'id': 'framework', 'title': 'Knowledge-Based Multi-Agent Framework for Automated Software Architecture Design', 'URL': 'https://dl.acm.org/doi/10.1145/3696630.3728493', 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Yiran'}, {'family': 'Li', 'given': 'Ruiyin'}, {'family': 'Liang', 'given': 'Peng'}, {'family': 'Sun', 'given': 'Weisong'}, {'family': 'Liu', 'given': 'Yang'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Architecture design is a critical step in software development. However, creating a high-quality architecture is often costly due to the significant need for human expertise and manual effort. Recently, agents built upon Large Language Models (LLMs) have achieved remarkable success in various software engineering tasks. Despite this progress, the use of agents to automate the architecture design process remains largely unexplored. To address this gap, we envision a Knowledge-based Multi-Agent Architecture Design (MAAD) framework. MAAD uses agents to simulate human roles in the traditional software architecture design process, thereby automating the design process. To empower these agents, MAAD incorporates knowledge extracted from three key sources: 1) existing system designs, 2) authoritative literature, and 3) architecture experts. By envisioning the MAAD framework, we aim to advance the full automation of application-level system development.'}, {'id': 'arxiv_2507.15822', 'title': 'Do AI models help produce verified bug fixes?', 'URL': 'http://arxiv.org/abs/2507.15822', 'extra_urls': ['http://arxiv.org/abs/2507.15822'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Li'}, {'family': 'Mustafin', 'given': 'Ilgiz'}, {'family': 'Piccioni', 'given': 'Marco'}, {'family': 'Schena', 'given': 'Alessandro'}, {'family': 'Weber', 'given': 'Reto'}, {'family': 'Meyer', 'given': 'Bertrand'}], 'publisher': 'arXiv', 'abstract': 'Among areas of software engineering where AI techniques -- particularly, Large Language Models -- seem poised to yield dramatic improvements, an attractive candidate is Automatic Program Repair (APR), the production of satisfactory corrections to software bugs. Does this expectation materialize in practice? How do we find out, making sure that proposed corrections actually work? If programmers have access to LLMs, how do they actually use them to complement their own skills? To answer these questions, we took advantage of the availability of a program-proving environment, which formally determines the correctness of proposed fixes, to conduct a study of program debugging with two randomly assigned groups of programmers, one with access to LLMs and the other without, both validating their answers through the proof tools. The methodology relied on a division into general research questions (Goals in the Goal-Query-Metric approach), specific elements admitting specific answers (Queries), and measurements supporting these answers (Metrics). While applied so far to a limited sample size, the results are a first step towards delineating a proper role for AI and LLMs in providing guaranteed-correct fixes to program bugs. These results caused surprise as compared to what one might expect from the use of AI for debugging and APR. The contributions also include: a detailed methodology for experiments in the use of LLMs for debugging, which other projects can reuse; a fine-grain analysis of programmer behavior, made possible by the use of full-session recording; a definition of patterns of use of LLMs, with 7 distinct categories; and validated advice for getting the best of LLMs for debugging and Automatic Program Repair.'}, {'id': 'arxiv_2503.10784', 'title': 'Vulnerability Detection: From Formal Verification to Large Language Models and Hybrid Approaches: A Comprehensive Overview', 'URL': 'http://arxiv.org/abs/2503.10784', 'extra_urls': ['http://arxiv.org/abs/2503.10784'], 'type': 'article', 'author': [{'family': 'Tihanyi', 'given': 'Norbert'}, {'family': 'Bisztray', 'given': 'Tamas'}, {'family': 'Ferrag', 'given': 'Mohamed Amine'}, {'family': 'Cherif', 'given': 'Bilel'}, {'family': 'Dubniczky', 'given': 'Richard A.'}, {'family': 'Jain', 'given': 'Ridhi'}, {'family': 'Cordeiro', 'given': 'Lucas C.'}], 'publisher': 'arXiv', 'abstract': "Software testing and verification are critical for ensuring the reliability and security of modern software systems. Traditionally, formal verification techniques, such as model checking and theorem proving, have provided rigorous frameworks for detecting bugs and vulnerabilities. However, these methods often face scalability challenges when applied to complex, real-world programs. Recently, the advent of Large Language Models (LLMs) has introduced a new paradigm for software analysis, leveraging their ability to understand insecure coding practices. Although LLMs demonstrate promising capabilities in tasks such as bug prediction and invariant generation, they lack the formal guarantees of classical methods. This paper presents a comprehensive study of state-of-the-art software testing and verification, focusing on three key approaches: classical formal methods, LLM-based analysis, and emerging hybrid techniques, which combine their strengths. We explore each approach's strengths, limitations, and practical applications, highlighting the potential of hybrid systems to address the weaknesses of standalone methods. We analyze whether integrating formal rigor with LLM-driven insights can enhance the effectiveness and scalability of software verification, exploring their viability as a pathway toward more robust and adaptive testing frameworks."}, {'id': 'arxiv_2509.18934', 'title': 'Generic Adversarial Smart Contract Detection with Semantics and Uncertainty-Aware LLM', 'URL': 'http://arxiv.org/abs/2509.18934', 'extra_urls': ['http://arxiv.org/abs/2509.18934'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Yating'}, {'family': 'Su', 'given': 'Xing'}, {'family': 'Wu', 'given': 'Hao'}, {'family': 'Li', 'given': 'Sijin'}, {'family': 'Cheng', 'given': 'Yuxi'}, {'family': 'Xu', 'given': 'Fengyuan'}, {'family': 'Zhong', 'given': 'Sheng'}], 'publisher': 'arXiv', 'abstract': "Adversarial smart contracts, mostly on EVM-compatible chains like Ethereum and BSC, are deployed as EVM bytecode to exploit vulnerable smart contracts typically for financial gains. Detecting such malicious contracts at the time of deployment is an important proactive strategy preventing loss from victim contracts. It offers a better cost-benefit than detecting vulnerabilities on diverse potential victims. However, existing works are not generic with limited detection types and effectiveness due to imbalanced samples, while the emerging LLM technologies, which show its potentials in generalization, have two key problems impeding its application in this task: hard digestion of compiled-code inputs, especially those with task-specific logic, and hard assessment of LLMs' certainty in their binary answers, i.e., yes-or-no answers. Therefore, we propose a generic adversarial smart contracts detection framework FinDet, which leverages LLMs with two enhancements addressing above two problems. FinDet takes as input only the EVM-bytecode contracts and identifies adversarial ones among them with high balanced accuracy. The first enhancement extracts concise semantic intentions and high-level behavioral logic from the low-level bytecode inputs, unleashing the LLM reasoning capability restricted by the task input. The second enhancement probes and measures the LLM uncertainty to its multi-round answering to the same query, improving the LLM answering robustness for binary classifications required by the task output. Our comprehensive evaluation shows that FinDet achieves a BAC of 0.9223 and a TPR of 0.8950, significantly outperforming existing baselines. It remains robust under challenging conditions including unseen attack patterns, low-data settings, and feature obfuscation. FinDet detects all 5 public and 20+ unreported adversarial contracts in a 10-day real-world test, confirmed manually."}, {'id': 'arxiv_2506.10998', 'title': 'Towards Automated Formal Verification of Backend Systems with LLMs', 'URL': 'http://arxiv.org/abs/2506.10998', 'extra_urls': ['http://arxiv.org/abs/2506.10998'], 'type': 'article', 'author': [{'family': 'Xu', 'given': 'Kangping'}, {'family': 'Luo', 'given': 'Yifan'}, {'family': 'Yuan', 'given': 'Yang'}, {'family': 'Yao', 'given': 'Andrew Chi-Chih'}], 'publisher': 'arXiv', 'abstract': "Software testing plays a critical role in ensuring that systems behave as intended. However, existing automated testing approaches struggle to match the capabilities of human engineers due to key limitations such as test locality, lack of general reliability, and business logic blindness. In this work, we propose a novel framework that leverages functional programming and type systems to translate Scala backend code into formal Lean representations. Our pipeline automatically generates theorems that specify the intended behavior of APIs and database operations, and uses LLM-based provers to verify them. When a theorem is proved, the corresponding logic is guaranteed to be correct and no further testing is needed. If the negation of a theorem is proved instead, it confirms a bug. In cases where neither can be proved, human intervention is required. We evaluate our method on realistic backend systems and find that it can formally verify over 50% of the test requirements, which suggests that half of a testing engineer's workload can be automated. Additionally, with an average cost of only $2.19 per API, LLM-based verification is significantly more cost-effective than manual testing and can be scaled easily through parallel execution. Our results indicate a promising direction for scalable, AI-powered software testing, with the potential to greatly improve engineering productivity as models continue to advance."}, {'id': 'arxiv_2508.17329', 'title': 'Risk Assessment and Security Analysis of Large Language Models', 'URL': 'http://arxiv.org/abs/2508.17329', 'extra_urls': ['http://arxiv.org/abs/2508.17329'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Xiaoyan'}, {'family': 'Lyu', 'given': 'Dongyang'}, {'family': 'Li', 'given': 'Xiaoqi'}], 'publisher': 'arXiv', 'abstract': 'As large language models (LLMs) expose systemic security challenges in high risk applications, including privacy leaks, bias amplification, and malicious abuse, there is an urgent need for a dynamic risk assessment and collaborative defence framework that covers their entire life cycle. This paper focuses on the security problems of large language models (LLMs) in critical application scenarios, such as the possibility of disclosure of user data, the deliberate input of harmful instructions, or the models bias. To solve these problems, we describe the design of a system for dynamic risk assessment and a hierarchical defence system that allows different levels of protection to cooperate. This paper presents a risk assessment system capable of evaluating both static and dynamic indicators simultaneously. It uses entropy weighting to calculate essential data, such as the frequency of sensitive words, whether the API call is typical, the realtime risk entropy value is significant, and the degree of context deviation. The experimental results show that the system is capable of identifying concealed attacks, such as role escape, and can perform rapid risk evaluation. The paper uses a hybrid model called BERT-CRF (Bidirectional Encoder Representation from Transformers) at the input layer to identify and filter malicious commands. The model layer uses dynamic adversarial training and differential privacy noise injection technology together. The output layer also has a neural watermarking system that can track the source of the content. In practice, the quality of this method, especially important in terms of customer service in the financial industry.'}, {'id': 'arxiv_2510.03819', 'title': 'Security Analysis of Ponzi Schemes in Ethereum Smart Contracts', 'URL': 'http://arxiv.org/abs/2510.03819', 'extra_urls': ['http://arxiv.org/abs/2510.03819'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Chunyi'}, {'family': 'Wei', 'given': 'Qinghong'}, {'family': 'Li', 'given': 'Xiaoqi'}], 'publisher': 'arXiv', 'abstract': 'The rapid advancement of blockchain technology has precipitated the widespread adoption of Ethereum and smart contracts across a variety of sectors. However, this has also given rise to numerous fraudulent activities, with many speculators embedding Ponzi schemes within smart contracts, resulting in significant financial losses for investors. Currently, there is a lack of effective methods for identifying and analyzing such new types of fraudulent activities. This paper categorizes these scams into four structural types and explores the intrinsic characteristics of Ponzi scheme contract source code from a program analysis perspective. The Mythril tool is employed to conduct static and dynamic analyses of representative cases, thereby revealing their vulnerabilities and operational mechanisms. Furthermore, this paper employs shell scripts and command patterns to conduct batch detection of open-source smart contract code, thereby unveiling the common characteristics of Ponzi scheme smart contracts.'}, {'id': 'arxiv_2508.14385', 'title': 'Online Incident Response Planning under Model Misspecification through Bayesian Learning and Belief Quantization', 'URL': 'http://arxiv.org/abs/2508.14385', 'extra_urls': ['http://arxiv.org/abs/2508.14385'], 'type': 'article', 'author': [{'family': 'Hammar', 'given': 'Kim'}, {'family': 'Li', 'given': 'Tao'}], 'abstract': 'Effective responses to cyberattacks require fast decisions, even when information about the attack is incomplete or inaccurate. However, most decision-support frameworks for incident response rely on a detailed system model that describes the incident, which restricts their practical utility. In this paper, we address this limitation and present an online method for incident response planning under model misspecification, which we call MOBAL: Misspecified Online Bayesian Learning. MOBAL iteratively refines a conjecture about the model through Bayesian learning as new information becomes available, which facilitates model adaptation as the incident unfolds. To determine effective responses online, we quantize the conjectured model into a finite Markov model, which enables efficient response planning through dynamic programming. We prove that Bayesian learning is asymptotically consistent with respect to the information feedback. Additionally, we establish bounds on misspecification and quantization errors. Experiments on the CAGE-2 benchmark show that MOBAL outperforms the state of the art in terms of adaptability and robustness to model misspecification.'}, {'id': 'arxiv_2507.13081', 'title': 'iReDev: A Knowledge-Driven Multi-Agent Framework for Intelligent Requirements Development', 'URL': 'http://arxiv.org/abs/2507.13081', 'extra_urls': ['http://arxiv.org/abs/2507.13081'], 'type': 'article', 'author': [{'family': 'Jin', 'given': 'Dongming'}, {'family': 'Sun', 'given': 'Weisong'}, {'family': 'Huang', 'given': 'Jiangping'}, {'family': 'Liang', 'given': 'Peng'}, {'family': 'Xuan', 'given': 'Jifeng'}, {'family': 'Liu', 'given': 'Yang'}, {'family': 'Jin', 'given': 'Zhi'}], 'publisher': 'arXiv', 'abstract': 'Requirements development is a critical phase as it is responsible for providing a clear understanding of what stakeholders need. It involves collaboration among stakeholders to extract explicit requirements and address potential conflicts, which is time-consuming and labor-intensive. Recently, multi-agent systems for software development have attracted much attention. However, existing research provides limited support for requirements development and overlooks the injection of human knowledge into agents and the human-agent collaboration. % To address these issues, this paper proposes a knowledge-driven multi-agent framework for intelligent requirement development, named iReDev. iReDev features: iReDev consists of six knowledge-driven agents to support the entire requirements development. They collaboratively perform various tasks to produce a software requirements specification. iReDev focuses on integrating human knowledge for agents, enabling them to simulate real-world stakeholders. iReDev uses an event-driven communication mechanism based on an artifact pool. Agents continuously monitor the pool and autonomously trigger the next action based on its changes, enabling iReDev to handle new requirements quickly. iReDev introduces a human-in-the-loop mechanism to support human-agent collaboration, ensuring that the generated artifacts align with the expectations of stakeholders. We evaluated the generated artifacts and results show that iReDev outperforms existing baselines in multiple aspects. We further envision three key directions and hope this work can facilitate the development of intelligent requirements development.'}, {'id': 'arxiv_2508.18675', 'title': 'Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision', 'URL': 'http://arxiv.org/abs/2508.18675', 'extra_urls': ['http://arxiv.org/abs/2508.18675'], 'type': 'article', 'author': [{'family': 'Lu', 'given': 'Xu'}, {'family': 'Sun', 'given': 'Weisong'}, {'family': 'Zhang', 'given': 'Yiran'}, {'family': 'Hu', 'given': 'Ming'}, {'family': 'Tian', 'given': 'Cong'}, {'family': 'Jin', 'given': 'Zhi'}, {'family': 'Liu', 'given': 'Yang'}], 'publisher': 'arXiv', 'abstract': 'Automated code generation has long been considered the holy grail of software engineering. The emergence of Large Language Models (LLMs) has catalyzed a revolutionary breakthrough in this area. However, existing methods that only rely on LLMs remain inadequate in the quality of generated code, offering no guarantees of satisfying practical requirements. They lack a systematic strategy for requirements development and modeling. Recently, LLM-based agents typically possess powerful abilities and play an essential role in facilitating the alignment of LLM outputs with user requirements. In this paper, we envision the first multi-agent framework for reliable code generation based on \\textsc{re}quirements \\textsc{de}velopment and \\textsc{fo}rmalization, named \\textsc{ReDeFo}. This framework incorporates three agents, highlighting their augmentation with knowledge and techniques of formal methods, into the requirements-to-code generation pipeline to strengthen quality assurance. The core of \\textsc{ReDeFo} is the use of formal specifications to bridge the gap between potentially ambiguous natural language requirements and precise executable code. \\textsc{ReDeFo} enables rigorous reasoning about correctness, uncovering hidden bugs, and enforcing critical properties throughout the development process. In general, our framework aims to take a promising step toward realizing the long-standing vision of reliable, auto-generated software.'}, {'id': 'arxiv_2509.11238', 'title': 'UserTrace: User-Level Requirements Generation and Traceability Recovery from Software Project Repositories', 'URL': 'http://arxiv.org/abs/2509.11238', 'extra_urls': ['http://arxiv.org/abs/2509.11238'], 'type': 'article', 'author': [{'family': 'Jin', 'given': 'Dongming'}, {'family': 'Jin', 'given': 'Zhi'}, {'family': 'Zhang', 'given': 'Yiran'}, {'family': 'Fang', 'given': 'Zheng'}, {'family': 'Li', 'given': 'Linyu'}, {'family': 'He', 'given': 'Yuanpeng'}, {'family': 'Chen', 'given': 'Xiaohong'}, {'family': 'Sun', 'given': 'Weisong'}], 'publisher': 'arXiv', 'abstract': 'Software maintainability critically depends on high-quality requirements descriptions and explicit traceability between requirements and code. Although automated code summarization (ACS) and requirements traceability (RT) techniques have been widely studied, existing ACS methods mainly generate implementation-level (i.e., developer-oriented) requirements (IRs) for fine-grained units (e.g., methods), while RT techniques often overlook the impact of project evolution. As a result, user-level (i.e., end user-oriented) requirements (URs) and live trace links remain underexplored, despite their importance for supporting user understanding and for validating whether AI-generated software aligns with user intent. To address this gap, we propose UserTrace, a multi-agent system that automatically generates URs and recovers live trace links (from URs to IRs to code) from software repositories. UserTrace coordinates four specialized agents (i.e., Code Reviewer, Searcher, Writer, and Verifier) through a three-phase process: structuring repository dependencies, deriving IRs for code units, and synthesizing URs with domain-specific context. Our comparative evaluation shows that UserTrace produces URs with higher completeness, correctness, and helpfulness than an established baseline, and achieves superior precision in trace link recovery compared to five state-of-the-art RT approaches. A user study further demonstrates that UserTrace helps end users validate whether the AI-generated repositories align with their intent.'}, {'id': 'arxiv_2510.12399', 'title': 'A Survey of Vibe Coding with Large Language Models', 'URL': 'http://arxiv.org/abs/2510.12399', 'extra_urls': ['http://arxiv.org/abs/2510.12399'], 'type': 'article', 'author': [{'family': 'Ge', 'given': 'Yuyao'}, {'family': 'Mei', 'given': 'Lingrui'}, {'family': 'Duan', 'given': 'Zenghao'}, {'family': 'Li', 'given': 'Tianhao'}, {'family': 'Zheng', 'given': 'Yujia'}, {'family': 'Wang', 'given': 'Yiwei'}, {'family': 'Wang', 'given': 'Lexin'}, {'family': 'Yao', 'given': 'Jiayu'}, {'family': 'Liu', 'given': 'Tianyu'}, {'family': 'Cai', 'given': 'Yujun'}, {'family': 'Bi', 'given': 'Baolong'}, {'family': 'Guo', 'given': 'Fangda'}, {'family': 'Guo', 'given': 'Jiafeng'}, {'family': 'Liu', 'given': 'Shenghua'}, {'family': 'Cheng', 'given': 'Xueqi'}], 'publisher': 'arXiv', 'abstract': 'The advancement of large language models (LLMs) has catalyzed a paradigm shift from code generation assistance to autonomous coding agents, enabling a novel development methodology termed "Vibe Coding" where developers validate AI-generated implementations through outcome observation rather than line-by-line code comprehension. Despite its transformative potential, the effectiveness of this emergent paradigm remains under-explored, with empirical evidence revealing unexpected productivity losses and fundamental challenges in human-AI collaboration. To address this gap, this survey provides the first comprehensive and systematic review of Vibe Coding with large language models, establishing both theoretical foundations and practical frameworks for this transformative development approach. Drawing from systematic analysis of over 1000 research papers, we survey the entire vibe coding ecosystem, examining critical infrastructure components including LLMs for coding, LLM-based coding agent, development environment of coding agent, and feedback mechanisms. We first introduce Vibe Coding as a formal discipline by formalizing it through a Constrained Markov Decision Process that captures the dynamic triadic relationship among human developers, software projects, and coding agents. Building upon this theoretical foundation, we then synthesize existing practices into five distinct development models: Unconstrained Automation, Iterative Conversational Collaboration, Planning-Driven, Test-Driven, and Context-Enhanced Models, thus providing the first comprehensive taxonomy in this domain. Critically, our analysis reveals that successful Vibe Coding depends not merely on agent capabilities but on systematic context engineering, well-established development environments, and human-agent collaborative development models.'}, {'id': 'arxiv_2502.02533', 'title': 'Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies', 'URL': 'http://arxiv.org/abs/2502.02533', 'extra_urls': ['http://arxiv.org/abs/2502.02533'], 'type': 'article', 'author': [{'family': 'Zhou', 'given': 'Han'}, {'family': 'Wan', 'given': 'Xingchen'}, {'family': 'Sun', 'given': 'Ruoxi'}, {'family': 'Palangi', 'given': 'Hamid'}, {'family': 'Iqbal', 'given': 'Shariq'}, {'family': 'Vuli\u0107', 'given': 'Ivan'}, {'family': 'Korhonen', 'given': 'Anna'}, {'family': 'Ar\u0131k', 'given': 'Sercan \xd6'}], 'publisher': 'arXiv', 'abstract': 'Large language models, employed as multiple agents that interact and collaborate with each other, have excelled at solving complex tasks. The agents are programmed with prompts that declare their functionality, along with the topologies that orchestrate interactions across agents. Designing prompts and topologies for multi-agent systems (MAS) is inherently complex. To automate the entire design process, we first conduct an in-depth analysis of the design space aiming to understand the factors behind building effective MAS. We reveal that prompts together with topologies play critical roles in enabling more effective MAS design. Based on the insights, we propose Multi-Agent System Search (MASS), a MAS optimization framework that efficiently exploits the complex MAS design space by interleaving its optimization stages, from local to global, from prompts to topologies, over three stages: 1) block-level (local) prompt optimization; 2) workflow topology optimization; 3) workflow-level (global) prompt optimization, where each stage is conditioned on the iteratively optimized prompts/topologies from former stages. We show that MASS-optimized multi-agent systems outperform a spectrum of existing alternatives by a substantial margin. Based on the MASS-found systems, we finally propose design principles behind building effective multi-agent systems.'}, {'id': 'arxiv_2508.12683', 'title': 'A Taxonomy of Hierarchical Multi-Agent Systems: Design Patterns, Coordination Mechanisms, and Industrial Applications', 'URL': 'http://arxiv.org/abs/2508.12683', 'extra_urls': ['http://arxiv.org/abs/2508.12683'], 'type': 'article', 'author': [{'family': 'Moore', 'given': 'David J.'}], 'publisher': 'arXiv', 'abstract': 'Hierarchical multi-agent systems (HMAS) organize collections of agents into layered structures that help manage complexity and scale. These hierarchies can simplify coordination, but they also can introduce trade-offs that are not always obvious. This paper proposes a multi-dimensional taxonomy for HMAS along five axes: control hierarchy, information flow, role and task delegation, temporal layering, and communication structure. The intent is not to prescribe a single "best" design but to provide a lens for comparing different approaches. Rather than treating these dimensions in isolation, the taxonomy is connected to concrete coordination mechanisms - from the long-standing contract-net protocol for task allocation to more recent work in hierarchical reinforcement learning. Industrial contexts illustrate the framework, including power grids and oilfield operations, where agents at production, maintenance, and supply levels coordinate to diagnose well issues or balance energy demand. These cases suggest that hierarchical structures may achieve global efficiency while preserving local autonomy, though the balance is delicate. The paper closes by identifying open challenges: making hierarchical decisions explainable to human operators, scaling to very large agent populations, and assessing whether learning-based agents such as large language models can be safely integrated into layered frameworks. This paper presents what appears to be the first taxonomy that unifies structural, temporal, and communication dimensions of hierarchical MAS into a single design framework, bridging classical coordination mechanisms with modern reinforcement learning and large language model agents.'}, {'id': 'arxiv_2510.10991', 'title': 'A Survey on Agentic Multimodal Large Language Models', 'URL': 'http://arxiv.org/abs/2510.10991', 'extra_urls': ['http://arxiv.org/abs/2510.10991'], 'type': 'article', 'author': [{'family': 'Yao', 'given': 'Huanjin'}, {'family': 'Zhang', 'given': 'Ruifei'}, {'family': 'Huang', 'given': 'Jiaxing'}, {'family': 'Zhang', 'given': 'Jingyi'}, {'family': 'Wang', 'given': 'Yibo'}, {'family': 'Fang', 'given': 'Bo'}, {'family': 'Zhu', 'given': 'Ruolin'}, {'family': 'Jing', 'given': 'Yongcheng'}, {'family': 'Liu', 'given': 'Shunyu'}, {'family': 'Li', 'given': 'Guanbin'}, {'family': 'Tao', 'given': 'Dacheng'}], 'publisher': 'arXiv', 'abstract': "With the recent emergence of revolutionary autonomous agentic systems, research community is witnessing a significant shift from traditional static, passive, and domain-specific AI agents toward more dynamic, proactive, and generalizable agentic AI. Motivated by the growing interest in agentic AI and its potential trajectory toward AGI, we present a comprehensive survey on Agentic Multimodal Large Language Models (Agentic MLLMs). In this survey, we explore the emerging paradigm of agentic MLLMs, delineating their conceptual foundations and distinguishing characteristics from conventional MLLM-based agents. We establish a conceptual framework that organizes agentic MLLMs along three fundamental dimensions: (i) Agentic internal intelligence functions as the system's commander, enabling accurate long-horizon planning through reasoning, reflection, and memory; (ii) Agentic external tool invocation, whereby models proactively use various external tools to extend their problem-solving capabilities beyond their intrinsic knowledge; and (iii) Agentic environment interaction further situates models within virtual or physical environments, allowing them to take actions, adapt strategies, and sustain goal-directed behavior in dynamic real-world scenarios. To further accelerate research in this area for the community, we compile open-source training frameworks, training and evaluation datasets for developing agentic MLLMs. Finally, we review the downstream applications of agentic MLLMs and outline future research directions for this rapidly evolving field. To continuously track developments in this rapidly evolving field, we will also actively update a public repository at https://github.com/HJYao00/Awesome-Agentic-MLLMs."}, {'id': 'arxiv_2410.20199', 'title': 'Rethinking the Uncertainty: A Critical Review and Analysis in the Era of Large Language Models', 'URL': 'http://arxiv.org/abs/2410.20199', 'extra_urls': ['http://arxiv.org/abs/2410.20199'], 'type': 'article', 'author': [{'family': 'Beigi', 'given': 'Mohammad'}, {'family': 'Wang', 'given': 'Sijia'}, {'family': 'Shen', 'given': 'Ying'}, {'family': 'Lin', 'given': 'Zihao'}, {'family': 'Kulkarni', 'given': 'Adithya'}, {'family': 'He', 'given': 'Jianfeng'}, {'family': 'Chen', 'given': 'Feng'}, {'family': 'Jin', 'given': 'Ming'}, {'family': 'Cho', 'given': 'Jin-Hee'}, {'family': 'Zhou', 'given': 'Dawei'}, {'family': 'Lu', 'given': 'Chang-Tien'}, {'family': 'Huang', 'given': 'Lifu'}], 'publisher': 'arXiv', 'abstract': 'In recent years, Large Language Models (LLMs) have become fundamental to a broad spectrum of artificial intelligence applications. As the use of LLMs expands, precisely estimating the uncertainty in their predictions has become crucial. Current methods often struggle to accurately identify, measure, and address the true uncertainty, with many focusing primarily on estimating model confidence. This discrepancy is largely due to an incomplete understanding of where, when, and how uncertainties are injected into models. This paper introduces a comprehensive framework specifically designed to identify and understand the types and sources of uncertainty, aligned with the unique characteristics of LLMs. Our framework enhances the understanding of the diverse landscape of uncertainties by systematically categorizing and defining each type, establishing a solid foundation for developing targeted methods that can precisely quantify these uncertainties. We also provide a detailed introduction to key related concepts and examine the limitations of current methods in mission-critical and safety-sensitive applications. The paper concludes with a perspective on future directions aimed at enhancing the reliability and practical adoption of these methods in real-world scenarios.'}, {'id': 'arxiv_2507.03724', 'title': 'MemOS: A Memory OS for AI System', 'URL': 'http://arxiv.org/abs/2507.03724', 'extra_urls': ['http://arxiv.org/abs/2507.03724'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Zhiyu'}, {'family': 'Song', 'given': 'Shichao'}, {'family': 'Xi', 'given': 'Chenyang'}, {'family': 'Wang', 'given': 'Hanyu'}, {'family': 'Tang', 'given': 'Chen'}, {'family': 'Niu', 'given': 'Simin'}, {'family': 'Chen', 'given': 'Ding'}, {'family': 'Yang', 'given': 'Jiawei'}, {'family': 'Li', 'given': 'Chunyu'}, {'family': 'Yu', 'given': 'Qingchen'}, {'family': 'Zhao', 'given': 'Jihao'}, {'family': 'Wang', 'given': 'Yezhaohui'}, {'family': 'Liu', 'given': 'Peng'}, {'family': 'Lin', 'given': 'Zehao'}, {'family': 'Wang', 'given': 'Pengyuan'}, {'family': 'Huo', 'given': 'Jiahao'}, {'family': 'Chen', 'given': 'Tianyi'}, {'family': 'Chen', 'given': 'Kai'}, {'family': 'Li', 'given': 'Kehang'}, {'family': 'Tao', 'given': 'Zhen'}, {'family': 'Lai', 'given': 'Huayi'}, {'family': 'Wu', 'given': 'Hao'}, {'family': 'Tang', 'given': 'Bo'}, {'family': 'Wang', 'given': 'Zhenren'}, {'family': 'Fan', 'given': 'Zhaoxin'}, {'family': 'Zhang', 'given': 'Ningyu'}, {'family': 'Zhang', 'given': 'Linfeng'}, {'family': 'Yan', 'given': 'Junchi'}, {'family': 'Yang', 'given': 'Mingchuan'}, {'family': 'Xu', 'given': 'Tong'}, {'family': 'Xu', 'given': 'Wei'}, {'family': 'Chen', 'given': 'Huajun'}, {'family': 'Wang', 'given': 'Haofen'}, {'family': 'Yang', 'given': 'Hongkang'}, {'family': 'Zhang', 'given': 'Wentao'}, {'family': 'Xu', 'given': 'Zhi-Qin John'}, {'family': 'Chen', 'given': 'Siheng'}, {'family': 'Xiong', 'given': 'Feiyu'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) have become an essential infrastructure for Artificial General Intelligence (AGI), yet their lack of well-defined memory management systems hinders the development of long-context reasoning, continual personalization, and knowledge consistency.Existing models mainly rely on static parameters and short-lived contextual states, limiting their ability to track user preferences or update knowledge over extended periods.While Retrieval-Augmented Generation (RAG) introduces external knowledge in plain text, it remains a stateless workaround without lifecycle control or integration with persistent representations.Recent work has modeled the training and inference cost of LLMs from a memory hierarchy perspective, showing that introducing an explicit memory layer between parameter memory and external retrieval can substantially reduce these costs by externalizing specific knowledge. Beyond computational efficiency, LLMs face broader challenges arising from how information is distributed over time and context, requiring systems capable of managing heterogeneous knowledge spanning different temporal scales and sources. To address this challenge, we propose MemOS, a memory operating system that treats memory as a manageable system resource. It unifies the representation, scheduling, and evolution of plaintext, activation-based, and parameter-level memories, enabling cost-efficient storage and retrieval. As the basic unit, a MemCube encapsulates both memory content and metadata such as provenance and versioning. MemCubes can be composed, migrated, and fused over time, enabling flexible transitions between memory types and bridging retrieval with parameter-based learning. MemOS establishes a memory-centric system framework that brings controllability, plasticity, and evolvability to LLMs, laying the foundation for continual learning and personalized modeling.'}, {'id': 'arxiv_2504.15965', 'title': 'From Human Memory to AI Memory: A Survey on Memory Mechanisms in the Era of LLMs', 'URL': 'http://arxiv.org/abs/2504.15965', 'extra_urls': ['http://arxiv.org/abs/2504.15965'], 'type': 'article', 'author': [{'family': 'Wu', 'given': 'Yaxiong'}, {'family': 'Liang', 'given': 'Sheng'}, {'family': 'Zhang', 'given': 'Chen'}, {'family': 'Wang', 'given': 'Yichao'}, {'family': 'Zhang', 'given': 'Yongyue'}, {'family': 'Guo', 'given': 'Huifeng'}, {'family': 'Tang', 'given': 'Ruiming'}, {'family': 'Liu', 'given': 'Yong'}], 'publisher': 'arXiv', 'abstract': 'Memory is the process of encoding, storing, and retrieving information, allowing humans to retain experiences, knowledge, skills, and facts over time, and serving as the foundation for growth and effective interaction with the world. It plays a crucial role in shaping our identity, making decisions, learning from past experiences, building relationships, and adapting to changes. In the era of large language models (LLMs), memory refers to the ability of an AI system to retain, recall, and use information from past interactions to improve future responses and interactions. Although previous research and reviews have provided detailed descriptions of memory mechanisms, there is still a lack of a systematic review that summarizes and analyzes the relationship between the memory of LLM-driven AI systems and human memory, as well as how we can be inspired by human memory to construct more powerful memory systems. To achieve this, in this paper, we propose a comprehensive survey on the memory of LLM-driven AI systems. In particular, we first conduct a detailed analysis of the categories of human memory and relate them to the memory of AI systems. Second, we systematically organize existing memory-related work and propose a categorization method based on three dimensions (object, form, and time) and eight quadrants. Finally, we illustrate some open problems regarding the memory of current AI systems and outline possible future directions for memory in the era of large language models.'}, {'id': 'arxiv_2508.10824', 'title': 'Memory-Augmented Transformers: A Systematic Review from Neuroscience Principles to Enhanced Model Architectures', 'URL': 'http://arxiv.org/abs/2508.10824', 'extra_urls': ['http://arxiv.org/abs/2508.10824'], 'type': 'article', 'author': [{'family': 'Omidi', 'given': 'Parsa'}, {'family': 'Huang', 'given': 'Xingshuai'}, {'family': 'Laborieux', 'given': 'Axel'}, {'family': 'Nikpour', 'given': 'Bahareh'}, {'family': 'Shi', 'given': 'Tianyu'}, {'family': 'Eshaghi', 'given': 'Armaghan'}], 'publisher': 'arXiv', 'abstract': 'Memory is fundamental to intelligence, enabling learning, reasoning, and adaptability across biological and artificial systems. While Transformer architectures excel at sequence modeling, they face critical limitations in long-range context retention, continual learning, and knowledge integration. This review presents a unified framework bridging neuroscience principles, including dynamic multi-timescale memory, selective attention, and consolidation, with engineering advances in Memory-Augmented Transformers. We organize recent progress through three taxonomic dimensions: functional objectives (context extension, reasoning, knowledge integration, adaptation), memory representations (parameter-encoded, state-based, explicit, hybrid), and integration mechanisms (attention fusion, gated control, associative retrieval). Our analysis of core memory operations (reading, writing, forgetting, and capacity management) reveals a shift from static caches toward adaptive, test-time learning systems. We identify persistent challenges in scalability and interference, alongside emerging solutions including hierarchical buffering and surprise-gated updates. This synthesis provides a roadmap toward cognitively-inspired, lifelong-learning Transformer architectures.'}, {'id': 'arxiv_2509.18133', 'title': 'Self-Evolving LLMs via Continual Instruction Tuning', 'URL': 'http://arxiv.org/abs/2509.18133', 'extra_urls': ['http://arxiv.org/abs/2509.18133'], 'type': 'article', 'author': [{'family': 'Kang', 'given': 'Jiazheng'}, {'family': 'Huang', 'given': 'Le'}, {'family': 'Hou', 'given': 'Cheng'}, {'family': 'Zhao', 'given': 'Zhe'}, {'family': 'Yan', 'given': 'Zhenxiang'}, {'family': 'Shi', 'given': 'Chuan'}, {'family': 'Bai', 'given': 'Ting'}], 'publisher': 'arXiv', 'abstract': 'In real-world industrial settings, large language models (LLMs) must learn continually to keep pace with diverse and evolving tasks, requiring self-evolution to refine knowledge under dynamic data distributions. However, existing continual learning (CL) approaches, such as replay and parameter isolation, often suffer from catastrophic forgetting: training on new tasks degrades performance on earlier ones by overfitting to the new distribution and weakening generalization.We propose MoE-CL, a parameter-efficient adversarial mixture-of-experts framework for industrial-scale, self-evolving continual instruction tuning of LLMs. MoE-CL uses a dual-expert design: (1) a dedicated LoRA expert per task to preserve task-specific knowledge via parameter independence, mitigating forgetting; and (2) a shared LoRA expert to enable cross-task transfer. To prevent transferring task-irrelevant noise through the shared pathway, we integrate a task-aware discriminator within a GAN. The discriminator encourages the shared expert to pass only task-aligned information during sequential training. Through adversarial learning, the shared expert acquires generalized representations that mimic the discriminator, while dedicated experts retain task-specific details, balancing knowledge retention and cross-task generalization and thereby supporting self-evolution.Extensive experiments on the public MTL5 benchmark and an industrial Tencent3 benchmark validate the effectiveness of MoE-CL for continual instruction tuning. In real-world A/B testing for content compliance review on the Tencent Video platform, MoE-CL reduced manual review costs by 15.3%. These results demonstrate that MoE-CL is practical for large-scale industrial deployment where continual adaptation and stable transfer are critical.'}, {'id': 'arxiv_2502.06975', 'title': 'Position: Episodic Memory is the Missing Piece for Long-Term LLM Agents', 'URL': 'http://arxiv.org/abs/2502.06975', 'extra_urls': ['http://arxiv.org/abs/2502.06975'], 'type': 'article', 'author': [{'family': 'Pink', 'given': 'Mathis'}, {'family': 'Wu', 'given': 'Qinyuan'}, {'family': 'Vo', 'given': 'Vy Ai'}, {'family': 'Turek', 'given': 'Javier'}, {'family': 'Mu', 'given': 'Jianing'}, {'family': 'Huth', 'given': 'Alexander'}, {'family': 'Toneva', 'given': 'Mariya'}], 'publisher': 'arXiv', 'abstract': 'As Large Language Models (LLMs) evolve from text-completion tools into fully fledged agents operating in dynamic environments, they must address the challenge of continually learning and retaining long-term knowledge. Many biological systems solve these challenges with episodic memory, which supports single-shot learning of instance-specific contexts. Inspired by this, we present an episodic memory framework for LLM agents, centered around five key properties of episodic memory that underlie adaptive and context-sensitive behavior. With various research efforts already partially covering these properties, this position paper argues that now is the right time for an explicit, integrated focus on episodic memory to catalyze the development of long-term agents. To this end, we outline a roadmap that unites several research directions under the goal to support all five properties of episodic memory for more efficient long-term LLM agents.'}, {'id': 'arxiv_2507.22925', 'title': 'Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents', 'URL': 'http://arxiv.org/abs/2507.22925', 'extra_urls': ['http://arxiv.org/abs/2507.22925'], 'type': 'article', 'author': [{'family': 'Sun', 'given': 'Haoran'}, {'family': 'Zeng', 'given': 'Shaoning'}], 'publisher': 'arXiv', 'abstract': 'Long-term memory is one of the key factors influencing the reasoning capabilities of Large Language Model Agents (LLM Agents). Incorporating a memory mechanism that effectively integrates past interactions can significantly enhance decision-making and contextual coherence of LLM Agents. While recent works have made progress in memory storage and retrieval, such as encoding memory into dense vectors for similarity-based search or organizing knowledge in the form of graph, these approaches often fall short in structured memory organization and efficient retrieval. To address these limitations, we propose a Hierarchical Memory (H-MEM) architecture for LLM Agents that organizes and updates memory in a multi-level fashion based on the degree of semantic abstraction. Each memory vector is embedded with a positional index encoding pointing to its semantically related sub-memories in the next layer. During the reasoning phase, an index-based routing mechanism enables efficient, layer-by-layer retrieval without performing exhaustive similarity computations. We evaluate our method on five task settings from the LoCoMo dataset. Experimental results show that our approach consistently outperforms five baseline methods, demonstrating its effectiveness in long-term dialogue scenarios.'}, {'id': 'arxiv_2507.07957', 'title': 'MIRIX: Multi-Agent Memory System for LLM-Based Agents', 'URL': 'http://arxiv.org/abs/2507.07957', 'extra_urls': ['http://arxiv.org/abs/2507.07957'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Yu'}, {'family': 'Chen', 'given': 'Xi'}], 'publisher': 'arXiv', 'abstract': "Although memory capabilities of AI agents are gaining increasing attention, existing solutions remain fundamentally limited. Most rely on flat, narrowly scoped memory components, constraining their ability to personalize, abstract, and reliably recall user-specific information over time. To this end, we introduce MIRIX, a modular, multi-agent memory system that redefines the future of AI memory by solving the field's most critical challenge: enabling language models to truly remember. Unlike prior approaches, MIRIX transcends text to embrace rich visual and multimodal experiences, making memory genuinely useful in real-world scenarios. MIRIX consists of six distinct, carefully structured memory types: Core, Episodic, Semantic, Procedural, Resource Memory, and Knowledge Vault, coupled with a multi-agent framework that dynamically controls and coordinates updates and retrieval. This design enables agents to persist, reason over, and accurately retrieve diverse, long-term user data at scale. We validate MIRIX in two demanding settings. First, on ScreenshotVQA, a challenging multimodal benchmark comprising nearly 20,000 high-resolution computer screenshots per sequence, requiring deep contextual understanding and where no existing memory systems can be applied, MIRIX achieves 35% higher accuracy than the RAG baseline while reducing storage requirements by 99.9%. Second, on LOCOMO, a long-form conversation benchmark with single-modal textual input, MIRIX attains state-of-the-art performance of 85.4%, far surpassing existing baselines. These results show that MIRIX sets a new performance standard for memory-augmented LLM agents. To allow users to experience our memory system, we provide a packaged application powered by MIRIX. It monitors the screen in real time, builds a personalized memory base, and offers intuitive visualization and secure local storage to ensure privacy."}, {'id': 'arxiv_2506.01442', 'title': 'Agentic Episodic Control', 'URL': 'http://arxiv.org/abs/2506.01442', 'extra_urls': ['http://arxiv.org/abs/2506.01442'], 'type': 'article', 'author': [{'family': 'Yang', 'given': 'Xidong'}, {'family': 'Li', 'given': 'Wenhao'}, {'family': 'Sheng', 'given': 'Junjie'}, {'family': 'Shen', 'given': 'Chuyun'}, {'family': 'Hua', 'given': 'Yun'}, {'family': 'Wang', 'given': 'Xiangfeng'}], 'publisher': 'arXiv', 'abstract': 'Reinforcement learning (RL) has driven breakthroughs in AI, from game-play to scientific discovery and AI alignment. However, its broader applicability remains limited by challenges such as low data efficiency and poor generalizability. Recent advances suggest that large language models, with their rich world knowledge and reasoning capabilities, could complement RL by enabling semantic state modeling and task-agnostic planning. In this work, we propose the Agentic Episodic Control (AEC), a novel architecture that integrates RL with LLMs to enhance decision-making. The AEC can leverage a large language model (LLM) to map the observations into language-grounded embeddings, which further can be stored in an episodic memory for rapid retrieval of high-value experiences. Simultaneously, a World-Graph working memory module is utilized to capture structured environmental dynamics in order to enhance relational reasoning. Furthermore, a lightweight critical state detector dynamically arbitrates between the episodic memory recall and the world-model-guided exploration. On the whole, by combining the trial-and-error learning scheme with LLM-derived semantic priors, the proposed AEC can improve both data efficiency and generalizability in reinforcement learning. In experiments on BabyAI-Text benchmark tasks, AEC demonstrates substantial improvements over existing baselines, especially on complex and generalization tasks like FindObj, where it outperforms the best baseline by up to 76%. The proposed AEC framework bridges the strengths of numeric reinforcement learning and symbolic reasoning, which provides a pathway toward more adaptable and sample-efficient agents.'}, {'id': 'arxiv_2505.00472', 'title': 'UserCentrix: An Agentic Memory-augmented AI Framework for Smart Spaces', 'URL': 'http://arxiv.org/abs/2505.00472', 'extra_urls': ['http://arxiv.org/abs/2505.00472'], 'type': 'article', 'author': [{'family': 'Saleh', 'given': 'Alaa'}, {'family': 'Tarkoma', 'given': 'Sasu'}, {'family': 'Donta', 'given': 'Praveen Kumar'}, {'family': 'Motlagh', 'given': 'Naser Hossein'}, {'family': 'Dustdar', 'given': 'Schahram'}, {'family': 'Pirttikangas', 'given': 'Susanna'}, {'family': 'Lov\xe9n', 'given': 'Lauri'}], 'publisher': 'arXiv', 'abstract': 'Agentic AI, with its autonomous and proactive decision-making, has transformed smart environments. By integrating Generative AI (GenAI) and multi-agent systems, modern AI frameworks can dynamically adapt to user preferences, optimize data management, and improve resource allocation. This paper introduces UserCentrix, an agentic memory-augmented AI framework designed to enhance smart spaces through dynamic, context-aware decision-making. This framework integrates personalized Large Language Model (LLM) agents that leverage user preferences and LLM memory management to deliver proactive and adaptive assistance. Furthermore, it incorporates a hybrid hierarchical control system, balancing centralized and distributed processing to optimize real-time responsiveness while maintaining global situational awareness. UserCentrix achieves resource-efficient AI interactions by embedding memory-augmented reasoning, cooperative agent negotiation, and adaptive orchestration strategies. Our key contributions include (i) a self-organizing framework with proactive scaling based on task urgency, (ii) a Value of Information (VoI)-driven decision-making process, (iii) a meta-reasoning personal LLM agent, and (iv) an intelligent multi-agent coordination system for seamless environment adaptation. Experimental results across various models confirm the effectiveness of our approach in enhancing response accuracy, system efficiency, and computational resource management in real-world application.'}, {'id': 'procedural_memory_is', 'title': 'Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in LLM-Based Agents', 'URL': 'https://dl.acm.org/doi/10.1145/3708319.3734172', 'type': 'article', 'author': [{'family': 'Wheeler', 'given': 'Schaun'}, {'family': 'Jeunen', 'given': 'Olivier'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Large Language Models (LLMs) represent a landmark achievement in Artificial Intelligence (AI), demonstrating unprecedented proficiency in procedural tasks such as text generation, code completion, and conversational coherence. These capabilities stem from their architecture, which mirrors human procedural memory\u2014the brain\u2019s ability to automate repetitive, pattern-driven tasks through practice. However, as LLMs are increasingly deployed in real-world applications, it becomes impossible to ignore their limitations operating in complex, unpredictable environments. This paper argues that LLMs, while transformative, are fundamentally constrained by their reliance on procedural memory. To create agents capable of navigating \u201cwicked\u201d learning environments\u2014where rules shift, feedback is ambiguous, and novelty is the norm\u2014we must augment LLMs with semantic memory and associative learning systems. By adopting a modular architecture that decouples these cognitive functions, we can bridge the gap between narrow procedural expertise and the adaptive intelligence required for real-world problem-solving.'}, {'id': 'arxiv_2507.05257', 'title': 'Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions', 'URL': 'http://arxiv.org/abs/2507.05257', 'extra_urls': ['http://arxiv.org/abs/2507.05257'], 'type': 'article', 'author': [{'family': 'Hu', 'given': 'Yuanzhe'}, {'family': 'Wang', 'given': 'Yu'}, {'family': 'McAuley', 'given': 'Julian'}], 'publisher': 'arXiv', 'abstract': 'Recent benchmarks for Large Language Model (LLM) agents primarily focus on evaluating reasoning, planning, and execution capabilities, while another critical component-memory, encompassing how agents memorize, update, and retrieve long-term information-is under-evaluated due to the lack of benchmarks. We term agents with memory mechanisms as memory agents. In this paper, based on classic theories from memory science and cognitive science, we identify four core competencies essential for memory agents: accurate retrieval, test-time learning, long-range understanding, and selective forgetting. Existing benchmarks either rely on limited context lengths or are tailored for static, long-context settings like book-based QA, which do not reflect the interactive, multi-turn nature of memory agents that incrementally accumulate information. Moreover, no existing benchmarks cover all four competencies. We introduce MemoryAgentBench, a new benchmark specifically designed for memory agents. Our benchmark transforms existing long-context datasets and incorporates newly constructed datasets into a multi-turn format, effectively simulating the incremental information processing characteristic of memory agents. By carefully selecting and curating datasets, our benchmark provides comprehensive coverage of the four core memory competencies outlined above, thereby offering a systematic and challenging testbed for assessing memory quality. We evaluate a diverse set of memory agents, ranging from simple context-based and retrieval-augmented generation (RAG) systems to advanced agents with external memory modules and tool integration. Empirical results reveal that current methods fall short of mastering all four competencies, underscoring the need for further research into comprehensive memory mechanisms for LLM agents.'}, {'id': 'arxiv_2510.05520', 'title': 'CAM: A Constructivist View of Agentic Memory for LLM-Based Reading Comprehension', 'URL': 'http://arxiv.org/abs/2510.05520', 'extra_urls': ['http://arxiv.org/abs/2510.05520'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Rui'}, {'family': 'Zhang', 'given': 'Zeyu'}, {'family': 'Bo', 'given': 'Xiaohe'}, {'family': 'Tian', 'given': 'Zihang'}, {'family': 'Chen', 'given': 'Xu'}, {'family': 'Dai', 'given': 'Quanyu'}, {'family': 'Dong', 'given': 'Zhenhua'}, {'family': 'Tang', 'given': 'Ruiming'}], 'publisher': 'arXiv', 'abstract': "Current Large Language Models (LLMs) are confronted with overwhelming information volume when comprehending long-form documents. This challenge raises the imperative of a cohesive memory module, which can elevate vanilla LLMs into autonomous reading agents. Despite the emergence of some heuristic approaches, a systematic design principle remains absent. To fill this void, we draw inspiration from Jean Piaget's Constructivist Theory, illuminating three traits of the agentic memory -- structured schemata, flexible assimilation, and dynamic accommodation. This blueprint forges a clear path toward a more robust and efficient memory system for LLM-based reading comprehension. To this end, we develop CAM, a prototype implementation of Constructivist Agentic Memory that simultaneously embodies the structurality, flexibility, and dynamicity. At its core, CAM is endowed with an incremental overlapping clustering algorithm for structured memory development, supporting both coherent hierarchical summarization and online batch integration. During inference, CAM adaptively explores the memory structure to activate query-relevant information for contextual response, akin to the human associative process. Compared to existing approaches, our design demonstrates dual advantages in both performance and efficiency across diverse long-text reading comprehension tasks, including question answering, query-based summarization, and claim verification."}, {'id': 'arxiv_2509.09505', 'title': 'Combating the Memory Walls: Optimization Pathways for Long-Context Agentic LLM Inference', 'URL': 'http://arxiv.org/abs/2509.09505', 'extra_urls': ['http://arxiv.org/abs/2509.09505'], 'type': 'article', 'author': [{'family': 'Wu', 'given': 'Haoran'}, {'family': 'Xiao', 'given': 'Can'}, {'family': 'Nie', 'given': 'Jiayi'}, {'family': 'Guo', 'given': 'Xuan'}, {'family': 'Lou', 'given': 'Binglei'}, {'family': 'Wong', 'given': 'Jeffrey T. H.'}, {'family': 'Mo', 'given': 'Zhiwen'}, {'family': 'Zhang', 'given': 'Cheng'}, {'family': 'Forys', 'given': 'Przemyslaw'}, {'family': 'Luk', 'given': 'Wayne'}, {'family': 'Fan', 'given': 'Hongxiang'}, {'family': 'Cheng', 'given': 'Jianyi'}, {'family': 'Jones', 'given': 'Timothy M.'}, {'family': 'Antonova', 'given': 'Rika'}, {'family': 'Mullins', 'given': 'Robert'}, {'family': 'Zhao', 'given': 'Aaron'}], 'publisher': 'arXiv', 'abstract': 'LLMs now form the backbone of AI agents for a diverse array of applications, including tool use, command-line agents, and web or computer use agents. These agentic LLM inference tasks are fundamentally different from chatbot-focused inference -- they often have much larger context lengths to capture complex, prolonged inputs, such as entire webpage DOMs or complicated tool call trajectories. This, in turn, generates significant off-chip memory traffic for the underlying hardware at the inference stage and causes the workload to be constrained by two memory walls, namely the bandwidth and capacity memory walls, preventing the on-chip compute units from achieving high utilization. In this paper, we introduce PLENA, a hardware-software co-designed system that applies three core optimization pathways to tackle these challenges. PLENA includes an efficient hardware implementation of compute and memory units supporting an asymmetric quantization scheme. PLENA also features a novel flattened systolic array architecture that has native support for FlashAttention to tackle these memory walls in the scenario of inference serving for long-context LLMs. Additionally, PLENA is developed with a complete stack, including a custom ISA, a compiler, a cycle-emulated simulator, and an automated design space exploration flow. The simulated results show that PLENA achieves up to 8.5x higher utilization than existing accelerators, and delivers 2.24x higher throughput than the A100 GPU and 3.85x higher throughput than the TPU v6e, under the same multiplier count and memory settings. The full PLENA system will also be open-sourced.'}, {'id': 'arxiv_2502.12110', 'title': 'A-MEM: Agentic Memory for LLM Agents', 'URL': 'http://arxiv.org/abs/2502.12110', 'extra_urls': ['http://arxiv.org/abs/2502.12110'], 'type': 'article', 'author': [{'family': 'Xu', 'given': 'Wujiang'}, {'family': 'Liang', 'given': 'Zujie'}, {'family': 'Mei', 'given': 'Kai'}, {'family': 'Gao', 'given': 'Hang'}, {'family': 'Tan', 'given': 'Juntao'}, {'family': 'Zhang', 'given': 'Yongfeng'}], 'publisher': 'arXiv', 'abstract': "While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences. Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases. Moreover, these systems' fixed operations and structures limit their adaptability across diverse tasks. To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way. Following the basic principles of the Zettelkasten method, we designed our memory system to create interconnected knowledge networks through dynamic indexing and linking. When a new memory is added, we generate a comprehensive note containing multiple structured attributes, including contextual descriptions, keywords, and tags. The system then analyzes historical memories to identify relevant connections, establishing links where meaningful similarities exist. Additionally, this process enables memory evolution - as new memories are integrated, they can trigger updates to the contextual representations and attributes of existing historical memories, allowing the memory network to continuously refine its understanding. Our approach combines the structured organization principles of Zettelkasten with the flexibility of agent-driven decision making, allowing for more adaptive and context-aware memory management. Empirical experiments on six foundation models show superior improvement against existing SOTA baselines. The source code for evaluating performance is available at https://github.com/WujiangXu/A-mem, while the source code of the agentic memory system is available at https://github.com/WujiangXu/A-mem-sys."}, {'id': 'arxiv_2508.19828', 'title': 'Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning', 'URL': 'http://arxiv.org/abs/2508.19828', 'extra_urls': ['http://arxiv.org/abs/2508.19828'], 'type': 'article', 'author': [{'family': 'Yan', 'given': 'Sikuan'}, {'family': 'Yang', 'given': 'Xiufeng'}, {'family': 'Huang', 'given': 'Zuchao'}, {'family': 'Nie', 'given': 'Ercong'}, {'family': 'Ding', 'given': 'Zifeng'}, {'family': 'Li', 'given': 'Zonggen'}, {'family': 'Ma', 'given': 'Xiaowen'}, {'family': 'Kersting', 'given': 'Kristian'}, {'family': 'Pan', 'given': 'Jeff Z.'}, {'family': 'Sch\xfctze', 'given': 'Hinrich'}, {'family': 'Tresp', 'given': 'Volker'}, {'family': 'Ma', 'given': 'Yunpu'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) have demonstrated impressive capabilities across a wide range of NLP tasks, but they remain fundamentally stateless, constrained by limited context windows that hinder long-horizon reasoning. Recent efforts to address this limitation often augment LLMs with an external memory bank, yet most existing pipelines are static and heuristic-driven, lacking a learned mechanism for deciding what to store, update, or retrieve. We present Memory-R1, a reinforcement learning (RL) framework that equips LLMs with the ability to actively manage and utilize external memory through two specialized agents: a Memory Manager that learns structured operations, including ADD, UPDATE, DELETE, and NOOP; and an Answer Agent that pre-selects and reasons over relevant entries. Both agents are fine-tuned with outcome-driven RL (PPO and GRPO), enabling adaptive memory management with minimal supervision. With only 152 training QA pairs, Memory-R1 outperforms strong baselines and generalizes across diverse question types, three benchmarks (LoCoMo, MSC, LongMemEval), and multiple model scales (3B-14B).'}, {'id': '3d_scan_technology', 'title': '3D Scan Technology to Enhance Body to Pattern Theory: Comparing the Conventional Bespoke Jacket Method with a Novel Parametric Method', 'URL': 'urn:isbn:978-3-032-00839-8', 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Renhao'}, {'family': 'Gill', 'given': 'Simeon'}, {'family': 'Hayes', 'given': 'Steven G.'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Springer Nature Switzerland', 'abstract': 'The conventional pattern drafting methods rely on manual anthropometric approaches and fail to fit the diverse body forms. The 3D body scanning technologies provide the opportunity to optimise the pattern theory. Body scanning generates a digital model allowing a great depth of measurement data of human body dimensions for the drafting process. The bespoke jacket with body shaping function typically causes fit issues, following traditional manual drafts. Compared to the male, a women\u2019s upper body shows more varied contours. However, there is limited study focused on increasing the women bespoke jacket functionality through novel anthropometric technology with an engineering approach. This study starts to address this gap.'}, {'id': 'arxiv_2501.19329', 'title': 'Let Human Sketches Help: Empowering Challenging Image Segmentation Task with Freehand Sketches', 'URL': 'http://arxiv.org/abs/2501.19329', 'extra_urls': ['http://arxiv.org/abs/2501.19329'], 'type': 'article', 'author': [{'family': 'Zang', 'given': 'Ying'}, {'family': 'Cao', 'given': 'Runlong'}, {'family': 'Zhang', 'given': 'Jianqi'}, {'family': 'Han', 'given': 'Yidong'}, {'family': 'Cao', 'given': 'Ziyue'}, {'family': 'Hu', 'given': 'Wenjun'}, {'family': 'Zhu', 'given': 'Didi'}, {'family': 'Zhu', 'given': 'Lanyun'}, {'family': 'Li', 'given': 'Zejian'}, {'family': 'Ji', 'given': 'Deyi'}, {'family': 'Chen', 'given': 'Tianrun'}], 'publisher': 'arXiv', 'abstract': "Sketches, with their expressive potential, allow humans to convey the essence of an object through even a rough contour. For the first time, we harness this expressive potential to improve segmentation performance in challenging tasks like camouflaged object detection (COD). Our approach introduces an innovative sketch-guided interactive segmentation framework, allowing users to intuitively annotate objects with freehand sketches (drawing a rough contour of the object) instead of the traditional bounding boxes or points used in classic interactive segmentation models like SAM. We demonstrate that sketch input can significantly improve performance in existing iterative segmentation methods, outperforming text or bounding box annotations. Additionally, we introduce key modifications to network architectures and a novel sketch augmentation technique to fully harness the power of sketch input and further boost segmentation accuracy. Remarkably, our model' s output can be directly used to train other neural networks, achieving results comparable to pixel-by-pixel annotations--while reducing annotation time by up to 120 times, which shows great potential in democratizing the annotation process and enabling model training with less reliance on resource-intensive, laborious pixel-level annotations. We also present KOSCamo+, the first freehand sketch dataset for camouflaged object detection. The dataset, code, and the labeling tool will be open sourced."}, {'id': 'fast_modeling', 'title': 'Fast Physics-Based Modeling of Knots and Ties using Templates', 'URL': 'https://dl.acm.org/doi/10.1145/3721238.3730622', 'type': 'article', 'author': [{'family': 'Guo', 'given': 'Dewen'}, {'family': 'Wang', 'given': 'Zhendong'}, {'family': 'Liu', 'given': 'Zegao'}, {'family': 'Li', 'given': 'Sheng'}, {'family': 'Wang', 'given': 'Guoping'}, {'family': 'Yang', 'given': 'Yin'}, {'family': 'Wang', 'given': 'Huamin'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Knots and ties are captivating elements of digital garments and accessories, but they have been notoriously challenging and computationally expensive to model manually. In this paper, we propose a physics-based modeling system for knots and ties using templates. The primary challenge lies in transforming cloth pieces into desired knot and tie configurations in a controllable, penetration-free manner, particularly when interacting with surrounding meshes. To address this, we introduce a pipe-like parametric knot template representation, defined by a B\xe9zier curve as its medial axis and an adaptively adjustable radius for enhanced flexibility and variation. This representation enables customizable knot sizes, shapes, and styles while ensuring intersection-free results through robust collision detection techniques. Using the defined knot template, we present a mapping and penetration-free initialization method to transform selected cloth regions from UV space into the initial 3D knot shape. We further enable quasistatic simulation of knots and their surrounding meshes through a fast and reliable collision handling and simulation scheme. Our experiments demonstrate the system\u2019s effectiveness and efficiency in modeling a wide range of digital knots and ties with diverse styles and shapes, including configurations that were previously impractical to create manually.'}, {'id': 'learning_universal', 'title': 'SketchFusion: Learning Universal Sketch Features through Fusing Foundation Models', 'URL': 'https://openaccess.thecvf.com/content/CVPR2025/html/Koley_SketchFusion_Learning_Universal_Sketch_Features_through_Fusing_Foundation_Models_CVPR_2025_paper.html', 'extra_urls': ['https://openaccess.thecvf.com/content/CVPR2025/html/Koley_SketchFusion_Learning_Universal_Sketch_Features_through_Fusing_Foundation_Models_CVPR_2025_paper.html'], 'type': 'article', 'author': [{'family': 'Koley', 'given': 'Subhadeep'}, {'family': 'Dutta', 'given': 'Tapas Kumar'}, {'family': 'Sain', 'given': 'Aneeshan'}, {'family': 'Chowdhury', 'given': 'Pinaki Nath'}, {'family': 'Bhunia', 'given': 'Ayan Kumar'}, {'family': 'Song', 'given': 'Yi-Zhe'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'all_about', 'title': "It's All About Your Sketch: Democratising Sketch Control in Diffusion Models", 'URL': 'https://openaccess.thecvf.com/content/CVPR2024/html/Koley_Its_All_About_Your_Sketch_Democratising_Sketch_Control_in_Diffusion_CVPR_2024_paper.html', 'extra_urls': ['https://openaccess.thecvf.com/content/CVPR2024/html/Koley_Its_All_About_Your_Sketch_Democratising_Sketch_Control_in_Diffusion_CVPR_2024_paper.html'], 'type': 'article', 'author': [{'family': 'Koley', 'given': 'Subhadeep'}, {'family': 'Bhunia', 'given': 'Ayan Kumar'}, {'family': 'Sekhri', 'given': 'Deeptanshu'}, {'family': 'Sain', 'given': 'Aneeshan'}, {'family': 'Chowdhury', 'given': 'Pinaki Nath'}, {'family': 'Xiang', 'given': 'Tao'}, {'family': 'Song', 'given': 'Yi-Zhe'}], 'issued': {'date-parts': [[2024]]}}, {'id': 'garment_retargeting', 'title': 'Intersection-Free Garment Retargeting', 'URL': 'https://dl.acm.org/doi/10.1145/3721238.3730590', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3721238.3730590'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Zizhou'}, {'family': 'Ara\xfajo', 'given': 'Chrystiano'}, {'family': 'Kunz', 'given': 'Andrew'}, {'family': 'Zorin', 'given': 'Denis'}, {'family': 'Panozzo', 'given': 'Daniele'}, {'family': 'Zordan', 'given': 'Victor'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Manual design of garments for avatars requires a large effort. Garment retargeting methods can save manual efforts by automatically deforming an existing garment design from one avatar to another. Previous methods are limited to human avatars with small variations in body shapes, while non-human avatars with unrealistic characteristics widely appear in games and animations. In this paper, the goal is to retarget artist-designed garments on a standard mannequin to a more general class of avatars. While there is a lack of training data of various avatars wearing garments, we propose a training-free method that performs optimizations on the mesh representation of the garments, with a combination of loss functions that preserve the geometrical features in the original design, guarantee intersection-free, and fit the garment adaptively to the avatars. Our method produces simulation-ready garment models that can be used later in avatar animations.'}, {'id': 'computational_garment', 'title': 'Rags2Riches: Computational Garment Reuse', 'URL': 'https://dl.acm.org/doi/10.1145/3721238.3730703', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3721238.3730703'], 'type': 'article', 'author': [{'family': 'Qi', 'given': 'Anran'}, {'family': 'Pietroni', 'given': 'Nico'}, {'family': 'Korosteleva', 'given': 'Maria'}, {'family': 'Sorkine-Hornung', 'given': 'Olga'}, {'family': 'Bousseau', 'given': 'Adrien'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'We present the first algorithm to automatically compute sewing patterns for upcycling existing garments into new designs. Our algorithm takes as input two garment designs along with their corresponding sewing patterns and determines how to cut one of them to match the other by following garment reuse principles. Specifically, our algorithm favors the reuse of seams and hems present in the existing garment, thereby preserving the embedded value of these structural components and simplifying the fabrication of the new garment. Finding optimal reused pattern is computationally challenging because it involves both discrete and continuous quantities. Discrete decisions include the choice of existing panels to cut from and the choice of seams and hems to reuse. Continuous variables include the precise placement of the new panels along seams and hems, and potential deformations of these panels to maximize reuse. Our key idea for making this optimization tractable is quantizing the shape of garment panels. This allows us to frame the search for an optimal reused pattern as a discrete assignment problem, which we solve efficiently with an ILP solver. We showcase our proposed pipeline on several reuse examples, including comparisons with reused patterns crafted by a professional garment designer. Additionally, we manufacture a physical reused garment to demonstrate the practical effectiveness of our approach.'}, {'id': 'arxiv_1806.11335', 'title': 'Learning a Shared Shape Space for Multimodal Garment Design', 'URL': 'http://arxiv.org/abs/1806.11335', 'extra_urls': ['http://arxiv.org/abs/1806.11335'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Tuanfeng Y.'}, {'family': 'Ceylan', 'given': 'Duygu'}, {'family': 'Popovic', 'given': 'Jovan'}, {'family': 'Mitra', 'given': 'Niloy J.'}], 'publisher': 'arXiv', 'abstract': 'Designing real and virtual garments is becoming extremely demanding with rapidly changing fashion trends and increasing need for synthesizing realistic dressed digital humans for various applications. This necessitates creating simple and effective workflows to facilitate authoring sewing patterns customized to garment and target body shapes to achieve desired looks. Traditional workflow involves a trial-and-error procedure wherein a mannequin is draped to judge the resultant folds and the sewing pattern iteratively adjusted until the desired look is achieved. This requires time and experience. Instead, we present a data-driven approach wherein the user directly indicates desired fold patterns simply by sketching while our system estimates corresponding garment and body shape parameters at interactive rates. The recovered parameters can then be further edited and the updated draped garment previewed. Technically, we achieve this via a novel shared shape space that allows the user to seamlessly specify desired characteristics across multimodal input {\\em without} requiring to run garment simulation at design time. We evaluate our approach qualitatively via a user study and quantitatively against test datasets, and demonstrate how our system can generate a rich quality of on-body garments targeted for a range of body shapes while achieving desired fold characteristics.'}, {'id': 'arxiv_2501.16177', 'title': 'BAG: Body-Aligned 3D Wearable Asset Generation', 'URL': 'http://arxiv.org/abs/2501.16177', 'extra_urls': ['http://arxiv.org/abs/2501.16177'], 'type': 'article', 'author': [{'family': 'Luo', 'given': 'Zhongjin'}, {'family': 'Li', 'given': 'Yang'}, {'family': 'Zhang', 'given': 'Mingrui'}, {'family': 'Wang', 'given': 'Senbo'}, {'family': 'Yan', 'given': 'Han'}, {'family': 'Song', 'given': 'Xibin'}, {'family': 'Shang', 'given': 'Taizhang'}, {'family': 'Mao', 'given': 'Wei'}, {'family': 'Li', 'given': 'Hongdong'}, {'family': 'Han', 'given': 'Xiaoguang'}, {'family': 'Ji', 'given': 'Pan'}], 'publisher': 'arXiv', 'abstract': 'While recent advancements have shown remarkable progress in general 3D shape generation models, the challenge of leveraging these approaches to automatically generate wearable 3D assets remains unexplored. To this end, we present BAG, a Body-aligned Asset Generation method to output 3D wearable asset that can be automatically dressed on given 3D human bodies. This is achived by controlling the 3D generation process using human body shape and pose information. Specifically, we first build a general single-image to consistent multiview image diffusion model, and train it on the large Objaverse dataset to achieve diversity and generalizability. Then we train a Controlnet to guide the multiview generator to produce body-aligned multiview images. The control signal utilizes the multiview 2D projections of the target human body, where pixel values represent the XYZ coordinates of the body surface in a canonical space. The body-conditioned multiview diffusion generates body-aligned multiview images, which are then fed into a native 3D diffusion model to produce the 3D shape of the asset. Finally, by recovering the similarity transformation using multiview silhouette supervision and addressing asset-body penetration with physics simulators, the 3D asset can be accurately fitted onto the target human body. Experimental results demonstrate significant advantages over existing methods in terms of image prompt-following capability, shape diversity, and shape quality. Our project page is available at https://bag-3d.github.io/.'}, {'id': 'raster_encoding', 'title': 'GarmentImage: Raster Encoding of Garment Sewing Patterns with Diverse Topologies', 'URL': 'https://dl.acm.org/doi/10.1145/3721238.3730632', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3721238.3730632'], 'type': 'article', 'author': [{'family': 'Tatsukawa', 'given': 'Yuki'}, {'family': 'Qi', 'given': 'Anran'}, {'family': 'Shen', 'given': 'I-Chao'}, {'family': 'Igarashi', 'given': 'Takeo'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Garment sewing patterns are the design language behind clothing, yet their current vector-based digital representations weren\u2019t built with machine learning in mind. Vector-based representation encodes a sewing pattern as a discrete set of panels, each defined as a sequence of lines and curves, stitching information between panels and the placement of each panel around a body. However, this representation causes two major challenges for neural networks: discontinuity in latent space between patterns with different topologies and limited generalization to garments with unseen topologies in the training data. In this work, we introduce GarmentImage, a unified raster-based sewing pattern representation. GarmentImage encodes a garment sewing pattern\u2019s geometry, topology and placement into multi-channel regular grids. Machine learning models trained on GarmentImage achieve seamless transitions between patterns with different topologies and show better generalization capabilities compared to models trained on vector-based representation. We demonstrate the effectiveness of GarmentImage across three applications: pattern exploration in latent space, text-based pattern editing, and image-to-pattern prediction. The results show that GarmentImage achieves superior performance on these applications using only simple convolutional networks.'}, {'id': 'computational_for', 'title': 'Computational Tailor-Making for Personalized, Shape-changing, and Sustainable Fabrics', 'URL': 'https://dl.acm.org/doi/10.1145/3746058.3758470', 'type': 'article', 'author': [{'family': 'Narumi', 'given': 'Koya'}, {'family': 'Hirose', 'given': 'Yuichi'}, {'family': 'Lee', 'given': 'Hsuanling'}, {'family': 'Larsson', 'given': 'Maria'}, {'family': 'He', 'given': 'Liang'}, {'family': 'Leake', 'given': 'Mackenzie'}, {'family': 'Forman', 'given': 'Jack'}, {'family': 'Farahi', 'given': 'Behnaz'}, {'family': 'Yao', 'given': 'Lining'}, {'family': 'Igarashi', 'given': 'Takeo'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Fabrics are fundamental elements of our daily lives, which are woven, knitted, or embroidered into diverse products like clothing and furniture. Recent advances in materials science and digital fabrication have enabled us to fabricate personalized and responsive fabric products computationally and interactively, which we call \u201ccomputational tailor-making.\u201d In this workshop, we will build an interdisciplinary network of researchers on computational tailor-making and discuss (1) computational fabric design, (2) novel fabric fabrication tools, (3) shape-changing fabrics, and (4) sustainable fabric production, from the viewpoint of HCI. The workshop session will help attendees build a shared vision, recognize potential challenges, find unexpected solutions and ideas, collaborate beyond disciplines, and explore the possible connection to industries.'}, {'id': 'arxiv_2509.05030', 'title': 'LUIVITON: Learned Universal Interoperable VIrtual Try-ON', 'URL': 'http://arxiv.org/abs/2509.05030', 'extra_urls': ['http://arxiv.org/abs/2509.05030'], 'type': 'article', 'author': [{'family': 'Cao', 'given': 'Cong'}, {'family': 'Cheng', 'given': 'Xianhang'}, {'family': 'Liu', 'given': 'Jingyuan'}, {'family': 'Zheng', 'given': 'Yujian'}, {'family': 'Lin', 'given': 'Zhenhui'}, {'family': 'Chkir', 'given': 'Meriem'}, {'family': 'Li', 'given': 'Hao'}], 'publisher': 'arXiv', 'abstract': 'We present LUIVITON, an end-to-end system for fully automated virtual try-on, capable of draping complex, multi-layer clothing onto diverse and arbitrarily posed humanoid characters. To address the challenge of aligning complex garments with arbitrary and highly diverse body shapes, we use SMPL as a proxy representation and separate the clothing-to-body draping problem into two correspondence tasks: 1) clothing-to-SMPL and 2) body-to-SMPL correspondence, where each has its unique challenges. While we address the clothing-to-SMPL fitting problem using a geometric learning-based approach for partial-to-complete shape correspondence prediction, we introduce a diffusion model-based approach for body-to-SMPL correspondence using multi-view consistent appearance features and a pre-trained 2D foundation model. Our method can handle complex geometries, non-manifold meshes, and generalizes effectively to a wide range of humanoid characters -- including humans, robots, cartoon subjects, creatures, and aliens, while maintaining computational efficiency for practical adoption. In addition to offering a fully automatic fitting solution, LUIVITON supports fast customization of clothing size, allowing users to adjust clothing sizes and material properties after they have been draped. We show that our system can produce high-quality 3D clothing fittings without any human labor, even when 2D clothing sewing patterns are not available.'}, {'id': 'arxiv_2506.05210', 'title': 'Towards Vision-Language-Garment Models for Web Knowledge Garment Understanding and Generation', 'URL': 'http://arxiv.org/abs/2506.05210', 'extra_urls': ['http://arxiv.org/abs/2506.05210'], 'type': 'article', 'author': [{'family': 'Ackermann', 'given': 'Jan'}, {'family': 'Nakayama', 'given': 'Kiyohiro'}, {'family': 'Yang', 'given': 'Guandao'}, {'family': 'Wu', 'given': 'Tong'}, {'family': 'Wetzstein', 'given': 'Gordon'}], 'publisher': 'arXiv', 'abstract': "Multimodal foundation models have demonstrated strong generalization, yet their ability to transfer knowledge to specialized domains such as garment generation remains underexplored. We introduce VLG, a vision-language-garment model that synthesizes garments from textual descriptions and visual imagery. Our experiments assess VLG's zero-shot generalization, investigating its ability to transfer web-scale reasoning to unseen garment styles and prompts. Preliminary results indicate promising transfer capabilities, highlighting the potential for multimodal foundation models to adapt effectively to specialized domains like fashion design."}, {'id': 'doi_10_36227_techrxiv_175790711_13089436_v1', 'title': 'CuttingEdgeAI RL for Unique 2D Cutting Stock Problems', 'URL': 'https://doi.org/10.36227/techrxiv.175790711.13089436/v1', 'extra_urls': ['https://doi.org/10.36227/techrxiv.175790711.13089436/v1'], 'type': 'article', 'author': [{'family': 'Bateham', 'given': 'Greg'}, {'family': 'Acharya', 'given': 'Sunim'}, {'family': 'Thakur', 'given': 'Satyam'}, {'family': 'Champie', 'given': 'Joyce'}, {'family': 'Dmytryk', 'given': 'Anastasiya'}, {'family': 'Karaman', 'given': 'Bayazit'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Fashion manufacturing, in the case of small businesses and solo seamstresses, typically remains muddled in labor-consuming, time-wasting techniques that suppress creativity and encourage material waste. This project considers the cutting stock problem', 'DOI': '10.36227/techrxiv.175790711.13089436/v1'}, {'id': 'hidden_layer', 'title': 'Hidden Layer Interaction: A Technique to Explore the Material of Generative AI', 'URL': 'https://dl.acm.org/doi/10.1145/3715336.3735437', 'type': 'article', 'author': [{'family': 'Grabe', 'given': 'Imke'}, {'family': 'Jenkins', 'given': 'Tom'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'This pictorial describes the process of developing an interaction technique for directly engaging with the hidden layers of a generative AI model for image synthesis. First, we give some background to generative AI in HCI, arguing that current interaction techniques prevent us from directly interacting with the material of AI, foreclosing its use in design. Drawing on inspiration from the Computer Science field of feature visualization, we investigate the materiality of our prototype, a GAN model trained to generate fashion imagery, and show how Hidden Layer Interaction offers an alternative to standard prompting. In doing so, we illustrate how this change in approach leads to new forms of interaction with the internal semantics of generative AI, and demonstrate how one might use Hidden Layer Interaction to engage with AI as a material in design.'}, {'id': 'arxiv_2509.04705', 'title': 'Transforming Fashion with AI: A Comparative Study of Large Language Models in Apparel Design', 'URL': 'http://arxiv.org/abs/2509.04705', 'extra_urls': ['http://arxiv.org/abs/2509.04705'], 'type': 'article', 'author': [{'family': 'Lamia', 'given': 'Nusrat Jahan'}, {'family': 'Mim', 'given': 'Sadia Afrin'}], 'publisher': 'arXiv', 'abstract': "Fashion has evolved from handcrafted designs to automated production over the years, where AI has added another dimension to it. Nowadays, practically every industry uses artificial models to automate their operations. To explore their role, we examined three prominent LLMs (OpenAI, GeminiAI, Deepseek) in multiple stages of textile manufacturing (e.g., sustainable choice, cost effectiveness, production planning, etc.). We assessed the models' ability to replicate garment design using certain parameters (fabric construction, shade, weave, silhouette, etc.). We compared the models in terms of different body types and functional purposes (e.g., fashionwear, sportswear) so that designers could evaluate effectiveness before developing actual patterns, make necessary modifications, and conduct fashion forecasting beforehand. To facilitate deeper analysis, we created a custom dataset specifically for fabric image generation and classification. Our analysis revealed that, in terms of fabric construction, the OpenAI DALL-E model integrated with ChatGPT outperformed other models, achieving a lower LPIPS (Learned Perceptual Image Patch Similarity) score of approximately $0.2$. In fabric classification from images, we found OpenAI offered the best results by breaking down certain factors (e.g., breathability, moisture-wicking, and tactile comfort), achieving approximately $80\\%$ accuracy for base construction and $55\\%$ for detailed construction. However, our results indicate that Deepseek faced significant challenges in generating and recognizing fabric images. Overall, all the models struggled to recognize complex fabric constructions and intricate designs from images, and relying too much on AI might hinder human creativity. We also observed that all three models performed effectively in providing recommendations and insights for fabric design in textual form."}, {'id': 'a_group', 'title': 'GDE-TP: a group design evaluation method based on triplet-based preference handling the uncertainty of group-level preference data', 'URL': 'https://papers.ssrn.com/abstract=5545480', 'extra_urls': ['https://papers.ssrn.com/abstract=5545480'], 'type': 'article', 'author': [{'family': 'Qi', 'given': 'Jin'}, {'family': 'Huang', 'given': 'Haiqing'}, {'family': 'Hu', 'given': 'Jie'}, {'family': 'Peng', 'given': 'Yinhong'}], 'publisher': 'Social Science Research Network', 'abstract': 'The use of AI-generated design has resulted in a large number of design candidates, which in turn has driven the development of more efficient design evaluation method that involves multiple decision-makers (DMs). Traditional uncertain information treatment methods have been employed into group design evaluation (GDE) to handle the uncertainty of DM\u2019s individual linguistic preference opinion, but overlooked the uncertainty hidden in a group of preferences given by different DMs. To address this problem, this study attempts to characterize such uncertainty as the fuzziness of group-level preference data. Based on linguistic D-number (LDN) theory, we propose a new triplet-based preference (T-preference) that consists of preference, reliability and fuzziness information. Accordingly, the T-preference generation method and T-preference-based GDE method (GDE-TP) are presented as well. The objective of GDE-TP is to make the design evaluation more rational by comprehensively considering the preference, reliability, and fuzziness factors. Under the principle of GDE-TP, the optimal design candidate is the one with high and reliable preference, while maintaining low fuzziness. Actual example and four empirical comparisons have been carried out in this paper, which prove the feasibility of GDE-TP as well as its superiority by comparing with i) different evaluation factors, ii) different decision-making models, iii) different uncertain information treatment methods and iv) different design attributes.'}, {'id': 'arxiv_2508.18733', 'title': 'Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vector Drawings', 'URL': 'http://arxiv.org/abs/2508.18733', 'extra_urls': ['http://arxiv.org/abs/2508.18733'], 'type': 'article', 'author': [{'family': 'Qin', 'given': 'Feiwei'}, {'family': 'Lu', 'given': 'Shichao'}, {'family': 'Hou', 'given': 'Junhao'}, {'family': 'Wang', 'given': 'Changmiao'}, {'family': 'Fang', 'given': 'Meie'}, {'family': 'Liu', 'given': 'Ligang'}], 'publisher': 'arXiv', 'abstract': 'Computer-Aided Design (CAD) generative modeling is driving significant innovations across industrial applications. Recent works have shown remarkable progress in creating solid models from various inputs such as point clouds, meshes, and text descriptions. However, these methods fundamentally diverge from traditional industrial workflows that begin with 2D engineering drawings. The automatic generation of parametric CAD models from these 2D vector drawings remains underexplored despite being a critical step in engineering design. To address this gap, our key insight is to reframe CAD generation as a sequence-to-sequence learning problem where vector drawing primitives directly inform the generation of parametric CAD operations, preserving geometric precision and design intent throughout the transformation process. We propose Drawing2CAD, a framework with three key technical components: a network-friendly vector primitive representation that preserves precise geometric information, a dual-decoder transformer architecture that decouples command type and parameter generation while maintaining precise correspondence, and a soft target distribution loss function accommodating inherent flexibility in CAD parameters. To train and evaluate Drawing2CAD, we create CAD-VGDrawing, a dataset of paired engineering drawings and parametric CAD models, and conduct thorough experiments to demonstrate the effectiveness of our method. Code and dataset are available at https://github.com/lllssc/Drawing2CAD.'}, {'id': 'arxiv_2504.13893', 'title': 'Semantic Direct Modeling', 'URL': 'http://arxiv.org/abs/2504.13893', 'extra_urls': ['http://arxiv.org/abs/2504.13893'], 'type': 'article', 'author': [{'family': 'Zou', 'given': 'Qiang'}, {'family': 'Liu', 'given': 'Shuo'}], 'publisher': 'arXiv', 'abstract': 'Current direct modeling systems limit users to low-level interactions with vertices, edges, and faces, forcing designers to manage detailed geometric elements rather than focusing on high-level design intent. This paper introduces semantic direct modeling (SDM), a novel approach that lifts direct modeling from low-level geometric modifications to high-level semantic interactions. This is achieved by utilizing a large language model (LLM) fine-tuned with CAD-specific prompts, which can guide the LLM to reason through design intent and accurately interpret CAD commands, thereby allowing designers to express their intent using natural language. Additionally, SDM maps design intent to the corresponding geometric features in the CAD model through a new conditional, context-sensitive feature recognition method, which uses generative AI to dynamically assign feature labels based on design intent. Together, they enable a seamless flow from high-level design intent to low-level geometric modifications, bypassing tedious software interactions. The effectiveness of SDM has been validated through real mechanical design cases.'}, {'id': 'arxiv_2505.17702', 'title': 'Seek-CAD: A Self-refined Generative Modeling for 3D Parametric CAD Using Local Inference via DeepSeek', 'URL': 'http://arxiv.org/abs/2505.17702', 'extra_urls': ['http://arxiv.org/abs/2505.17702'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Xueyang'}, {'family': 'Li', 'given': 'Jiahao'}, {'family': 'Song', 'given': 'Yu'}, {'family': 'Lou', 'given': 'Yunzhong'}, {'family': 'Zhou', 'given': 'Xiangdong'}], 'publisher': 'arXiv', 'abstract': 'The advent of Computer-Aided Design (CAD) generative modeling will significantly transform the design of industrial products. The recent research endeavor has extended into the realm of Large Language Models (LLMs). In contrast to fine-tuning methods, training-free approaches typically utilize the advanced closed-source LLMs, thereby offering enhanced flexibility and efficiency in the development of AI agents for generating CAD parametric models. However, the substantial cost and limitations of local deployment of the top-tier closed-source LLMs pose challenges in practical applications. The Seek-CAD is the pioneer exploration of locally deployed open-source inference LLM DeepSeek-R1 for CAD parametric model generation with a training-free methodology. This study is the first investigation to incorporate both visual and Chain-of-Thought (CoT) feedback within the self-refinement mechanism for generating CAD models. Specifically, the initial generated parametric CAD model is rendered into a sequence of step-wise perspective images, which are subsequently processed by a Vision Language Model (VLM) alongside the corresponding CoTs derived from DeepSeek-R1 to assess the CAD model generation. Then, the feedback is utilized by DeepSeek-R1 to refine the initial generated model for the next round of generation. Moreover, we present an innovative 3D CAD model dataset structured around the SSR (Sketch, Sketch-based feature, and Refinements) triple design paradigm. This dataset encompasses a wide range of CAD commands, thereby aligning effectively with industrial application requirements and proving suitable for the generation of LLMs. Extensive experiments validate the effectiveness of Seek-CAD under various metrics.'}, {'id': 'arxiv_2508.04002', 'title': 'CAD-Judge: Toward Efficient Morphological Grading and Verification for Text-to-CAD Generation', 'URL': 'http://arxiv.org/abs/2508.04002', 'extra_urls': ['http://arxiv.org/abs/2508.04002'], 'type': 'article', 'author': [{'family': 'Zhou', 'given': 'Zheyuan'}, {'family': 'Han', 'given': 'Jiayi'}, {'family': 'Du', 'given': 'Liang'}, {'family': 'Fang', 'given': 'Naiyu'}, {'family': 'Qiu', 'given': 'Lemiao'}, {'family': 'Zhang', 'given': 'Shuyou'}], 'publisher': 'arXiv', 'abstract': 'Computer-Aided Design (CAD) models are widely used across industrial design, simulation, and manufacturing processes. Text-to-CAD systems aim to generate editable, general-purpose CAD models from textual descriptions, significantly reducing the complexity and entry barrier associated with traditional CAD workflows. However, rendering CAD models can be slow, and deploying VLMs to review CAD models can be expensive and may introduce reward hacking that degrades the systems. To address these challenges, we propose CAD-Judge, a novel, verifiable reward system for efficient and effective CAD preference grading and grammatical validation. We adopt the Compiler-as-a-Judge Module (CJM) as a fast, direct reward signal, optimizing model alignment by maximizing generative utility through prospect theory. To further improve the robustness of Text-to-CAD in the testing phase, we introduce a simple yet effective agentic CAD generation approach and adopt the Compiler-as-a-Review Module (CRM), which efficiently verifies the generated CAD models, enabling the system to refine them accordingly. Extensive experiments on challenging CAD datasets demonstrate that our method achieves state-of-the-art performance while maintaining superior efficiency.'}, {'id': 'arxiv_2502.03997', 'title': 'CAD-Editor: A Locate-then-Infill Framework with Automated Training Data Synthesis for Text-Based CAD Editing', 'URL': 'http://arxiv.org/abs/2502.03997', 'extra_urls': ['http://arxiv.org/abs/2502.03997'], 'type': 'article', 'author': [{'family': 'Yuan', 'given': 'Yu'}, {'family': 'Sun', 'given': 'Shizhao'}, {'family': 'Liu', 'given': 'Qi'}, {'family': 'Bian', 'given': 'Jiang'}], 'publisher': 'arXiv', 'abstract': 'Computer Aided Design (CAD) is indispensable across various industries. \\emph{Text-based CAD editing}, which automates the modification of CAD models based on textual instructions, holds great potential but remains underexplored. Existing methods primarily focus on design variation generation or text-based CAD generation, either lacking support for text-based control or neglecting existing CAD models as constraints. We introduce \\emph{CAD-Editor}, the first framework for text-based CAD editing. To address the challenge of demanding triplet data with accurate correspondence for training, we propose an automated data synthesis pipeline. This pipeline utilizes design variation models to generate pairs of original and edited CAD models and employs Large Vision-Language Models (LVLMs) to summarize their differences into editing instructions. To tackle the composite nature of text-based CAD editing, we propose a locate-then-infill framework that decomposes the task into two focused sub-tasks: locating regions requiring modification and infilling these regions with appropriate edits. Large Language Models (LLMs) serve as the backbone for both sub-tasks, leveraging their capabilities in natural language understanding and CAD knowledge. Experiments show that CAD-Editor achieves superior performance both quantitatively and qualitatively. The code is available at \\url {https://github.com/microsoft/CAD-Editor}.'}, {'id': 'arxiv_2509.01350', 'title': 'Error Notebook-Guided, Training-Free Part Retrieval in 3D CAD Assemblies via Vision-Language Models', 'URL': 'http://arxiv.org/abs/2509.01350', 'extra_urls': ['http://arxiv.org/abs/2509.01350'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Yunqing'}, {'family': 'Zhang', 'given': 'Nan'}, {'family': 'Tan', 'given': 'Zhiming'}], 'publisher': 'arXiv', 'abstract': "Effective specification-aware part retrieval within complex CAD assemblies is essential for automated design verification and downstream engineering tasks. However, directly using LLMs/VLMs to this task presents some challenges: the input sequences may exceed model token limits, and even after processing, performance remains unsatisfactory. Moreover, fine-tuning LLMs/VLMs requires significant computational resources, and for many high-performing general-use proprietary models (e.g., GPT or Gemini), fine-tuning access is not available. In this paper, we propose a novel part retrieval framework that requires no extra training, but using Error Notebooks + RAG for refined prompt engineering to help improve the existing general model's retrieval performance. The construction of Error Notebooks consists of two steps: (1) collecting historical erroneous CoTs and their incorrect answers, and (2) connecting these CoTs through reflective corrections until the correct solutions are obtained. As a result, the Error Notebooks serve as a repository of tasks along with their corrected CoTs and final answers. RAG is then employed to retrieve specification-relevant records from the Error Notebooks and incorporate them into the inference process. Another major contribution of our work is a human-in-the-loop CAD dataset, which is used to evaluate our method. In addition, the engineering value of our novel framework lies in its ability to effectively handle 3D models with lengthy, non-natural language metadata. Experiments with proprietary models, including GPT-4o and the Gemini series, show substantial gains, with GPT-4o (Omni) achieving up to a 23.4% absolute accuracy improvement on the human preference dataset. Moreover, ablation studies confirm that CoT reasoning provides benefits especially in challenging cases with higher part counts (&gt;10)."}, {'id': 'leveraging_large', 'title': 'CAD-Llama: Leveraging Large Language Models for Computer-Aided Design Parametric 3D Model Generation', 'URL': 'https://openaccess.thecvf.com/content/CVPR2025/html/Li_CAD-Llama_Leveraging_Large_Language_Models_for_Computer-Aided_Design_Parametric_3D_CVPR_2025_paper.html', 'extra_urls': ['https://openaccess.thecvf.com/content/CVPR2025/html/Li_CAD-Llama_Leveraging_Large_Language_Models_for_Computer-Aided_Design_Parametric_3D_CVPR_2025_paper.html'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Jiahao'}, {'family': 'Ma', 'given': 'Weijian'}, {'family': 'Li', 'given': 'Xueyang'}, {'family': 'Lou', 'given': 'Yunzhong'}, {'family': 'Zhou', 'given': 'Guichun'}, {'family': 'Zhou', 'given': 'Xiangdong'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'arxiv_2501.19054', 'title': 'Text-to-CAD Generation Through Infusing Visual Feedback in Large Language Models', 'URL': 'http://arxiv.org/abs/2501.19054', 'extra_urls': ['http://arxiv.org/abs/2501.19054'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Ruiyu'}, {'family': 'Yuan', 'given': 'Yu'}, {'family': 'Sun', 'given': 'Shizhao'}, {'family': 'Bian', 'given': 'Jiang'}], 'publisher': 'arXiv', 'abstract': 'Creating Computer-Aided Design (CAD) models requires significant expertise and effort. Text-to-CAD, which converts textual descriptions into CAD parametric sequences, is crucial in streamlining this process. Recent studies have utilized ground-truth parametric sequences, known as sequential signals, as supervision to achieve this goal. However, CAD models are inherently multimodal, comprising parametric sequences and corresponding rendered visual objects. Besides,the rendering process from parametric sequences to visual objects is many-to-one. Therefore, both sequential and visual signals are critical for effective training. In this work, we introduce CADFusion, a framework that uses Large Language Models (LLMs) as the backbone and alternates between two training stages: the sequential learning (SL) stage and the visual feedback (VF) stage. In the SL stage, we train LLMs using ground-truth parametric sequences, enabling the generation of logically coherent parametric sequences. In the VF stage, we reward parametric sequences that render into visually preferred objects and penalize those that do not, allowing LLMs to learn how rendered visual objects are perceived and evaluated. These two stages alternate throughout the training, ensuring balanced learning and preserving benefits of both signals. Experiments demonstrate that CADFusion significantly improves performance, both qualitatively and quantitatively.'}, {'id': 'arxiv_2509.21150', 'title': 'CAD-Tokenizer: Towards Text-based CAD Prototyping via Modality-Specific Tokenization', 'URL': 'http://arxiv.org/abs/2509.21150', 'extra_urls': ['http://arxiv.org/abs/2509.21150'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Ruiyu'}, {'family': 'Sun', 'given': 'Shizhao'}, {'family': 'Ma', 'given': 'Weijian'}, {'family': 'Bian', 'given': 'Jiang'}], 'publisher': 'arXiv', 'abstract': "Computer-Aided Design (CAD) is a foundational component of industrial prototyping, where models are defined not by raw coordinates but by construction sequences such as sketches and extrusions. This sequential structure enables both efficient prototype initialization and subsequent editing. Text-guided CAD prototyping, which unifies Text-to-CAD generation and CAD editing, has the potential to streamline the entire design pipeline. However, prior work has not explored this setting, largely because standard large language model (LLM) tokenizers decompose CAD sequences into natural-language word pieces, failing to capture primitive-level CAD semantics and hindering attention modules from modeling geometric structure. We conjecture that a multimodal tokenization strategy, aligned with CAD's primitive and structural nature, can provide more effective representations. To this end, we propose CAD-Tokenizer, a framework that represents CAD data with modality-specific tokens using a sequence-based VQ-VAE with primitive-level pooling and constrained decoding. This design produces compact, primitive-aware representations that align with CAD's structural nature. Applied to unified text-guided CAD prototyping, CAD-Tokenizer significantly improves instruction following and generation quality, achieving better quantitative and qualitative performance over both general-purpose LLMs and task-specific baselines."}, {'id': 'arxiv_2503.05161', 'title': 'GaussianCAD: Robust Self-Supervised CAD Reconstruction from Three Orthographic Views Using 3D Gaussian Splatting', 'URL': 'http://arxiv.org/abs/2503.05161', 'extra_urls': ['http://arxiv.org/abs/2503.05161'], 'type': 'article', 'author': [{'family': 'Zhou', 'given': 'Zheng'}, {'family': 'Li', 'given': 'Zhe'}, {'family': 'Yu', 'given': 'Bo'}, {'family': 'Hu', 'given': 'Lina'}, {'family': 'Dong', 'given': 'Liang'}, {'family': 'Yang', 'given': 'Zijian'}, {'family': 'Liu', 'given': 'Xiaoli'}, {'family': 'Xu', 'given': 'Ning'}, {'family': 'Wang', 'given': 'Ziwei'}, {'family': 'Dang', 'given': 'Yonghao'}, {'family': 'Yin', 'given': 'Jianqin'}], 'publisher': 'arXiv', 'abstract': 'The automatic reconstruction of 3D computer-aided design (CAD) models from CAD sketches has recently gained significant attention in the computer vision community. Most existing methods, however, rely on vector CAD sketches and 3D ground truth for supervision, which are often difficult to be obtained in industrial applications and are sensitive to noise inputs. We propose viewing CAD reconstruction as a specific instance of sparse-view 3D reconstruction to overcome these limitations. While this reformulation offers a promising perspective, existing 3D reconstruction methods typically require natural images and corresponding camera poses as inputs, which introduces two major significant challenges: (1) modality discrepancy between CAD sketches and natural images, and (2) difficulty of accurate camera pose estimation for CAD sketches. To solve these issues, we first transform the CAD sketches into representations resembling natural images and extract corresponding masks. Next, we manually calculate the camera poses for the orthographic views to ensure accurate alignment within the 3D coordinate system. Finally, we employ a customized sparse-view 3D reconstruction method to achieve high-quality reconstructions from aligned orthographic views. By leveraging raster CAD sketches for self-supervision, our approach eliminates the reliance on vector CAD sketches and 3D ground truth. Experiments on the Sub-Fusion360 dataset demonstrate that our proposed method significantly outperforms previous approaches in CAD reconstruction performance and exhibits strong robustness to noisy inputs.'}, {'id': 'arxiv_2504.13178', 'title': 'Aligning Constraint Generation with Design Intent in Parametric CAD', 'URL': 'http://arxiv.org/abs/2504.13178', 'extra_urls': ['http://arxiv.org/abs/2504.13178'], 'type': 'article', 'author': [{'family': 'Casey', 'given': 'Evan'}, {'family': 'Zhang', 'given': 'Tianyu'}, {'family': 'Ishida', 'given': 'Shu'}, {'family': 'McCarthy', 'given': 'William P.'}, {'family': 'Thompson', 'given': 'John Roger'}, {'family': 'Khasahmadi', 'given': 'Amir'}, {'family': 'Lambourne', 'given': 'Joseph George'}, {'family': 'Jayaraman', 'given': 'Pradeep Kumar'}, {'family': 'Willis', 'given': 'Karl D. D.'}], 'publisher': 'arXiv', 'abstract': "We adapt alignment techniques from reasoning LLMs to the task of generating engineering sketch constraints found in computer-aided design (CAD) models. Engineering sketches consist of geometric primitives (e.g. points, lines) connected by constraints (e.g. perpendicular, tangent) that define the relationships between them. For a design to be easily editable, the constraints must effectively capture design intent, ensuring the geometry updates predictably when parameters change. Although current approaches can generate CAD designs, an open challenge remains to align model outputs with design intent, we label this problem 'design alignment'. A critical first step towards aligning generative CAD models is to generate constraints which fully-constrain all geometric primitives, without over-constraining or distorting sketch geometry. Using alignment techniques to train an existing constraint generation model with feedback from a constraint solver, we are able to fully-constrain 93% of sketches compared to 34% when using a naive supervised fine-tuning (SFT) baseline and only 8.9% without SFT. Our approach can be applied to any existing constraint generation model and sets the stage for further research bridging alignment strategies between the language and design domains. Additional results can be found at https://autodeskailab.github.io/aligning-constraint-generation/."}, {'id': 'a', 'title': 'PICASSO: A Feed-Forward Framework for Parametric Inference of CAD Sketches via Rendering Self-Supervision', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10943515', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10943515'], 'type': 'article', 'author': [{'family': 'Karadeniz', 'given': 'Ahmet Serdar'}, {'family': 'Mallis', 'given': 'Dimitrios'}, {'family': 'Mejri', 'given': 'Nesryne'}, {'family': 'Cherenkova', 'given': 'Kseniya'}, {'family': 'Kacem', 'given': 'Anis'}, {'family': 'Aouada', 'given': 'Djamila'}], 'abstract': 'This work introduces PICASSO, a framework for the parameterization of 2D CAD sketches from hand-drawn and precise sketch images. PICASSO converts a given CAD sketch image into parametric primitives that can be seamlessly integrated into CAD software. Our framework leverages rendering self-supervision to enable the pre-training of a CAD sketch parameterization network using sketch renderings only, thereby eliminating the need for corresponding CAD parameterization. Thus, we significantly reduce reliance on parameter-level annotations, which are often unavailable, particularly for hand-drawn sketches. The two primary components of PICASSO are (1) a Sketch Parameterization Network (SPN) that predicts a series of parametric primitives from CAD sketch images, and (2) a Sketch Rendering Network (SRN) that renders parametric CAD sketches in a differentiable manner and facilitates the computation of a rendering (image-level) loss for self-supervision. We demonstrate that the proposed PICASSO can achieve reasonable performance even when finetuned with only a small number of parametric CAD sketches. Extensive evaluation on the widely used SketchGraphs [37] and CAD as Language [14] datasets validates the effectiveness of the proposed approach on zero- and few-shot learning scenarios.'}, {'id': 'arxiv_2505.24838', 'title': 'VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and 3D Reasoning from CAD Software', 'URL': 'http://arxiv.org/abs/2505.24838', 'extra_urls': ['http://arxiv.org/abs/2505.24838'], 'type': 'article', 'author': [{'family': 'Man', 'given': 'Brandon'}, {'family': 'Nehme', 'given': 'Ghadi'}, {'family': 'Alam', 'given': 'Md Ferdous'}, {'family': 'Ahmed', 'given': 'Faez'}], 'publisher': 'arXiv', 'abstract': "Computer-Aided Design (CAD) is a time-consuming and complex process, requiring precise, long-horizon user interactions with intricate 3D interfaces. While recent advances in AI-driven user interface (UI) agents show promise, most existing datasets and methods focus on short, low-complexity tasks in mobile or web applications, failing to capture the demands of professional engineering tools. In this work, we introduce VideoCAD, the first attempt at engineering UI interaction learning for precision tasks. Specifically, VideoCAD is a large-scale synthetic dataset consisting of over 41K annotated video recordings of CAD operations, generated using an automated framework for collecting high-fidelity UI action data from human-made CAD designs. Compared to existing datasets, VideoCAD offers an order of magnitude higher complexity in UI interaction learning for real-world engineering tasks, having up to a 20x longer time horizon than other datasets. We show two important downstream applications of VideoCAD: learning UI interactions from professional precision 3D CAD tools and a visual question-answering (VQA) benchmark designed to evaluate multimodal large language models' (LLM) spatial reasoning and video understanding abilities. To learn the UI interactions, we propose VideoCADFormer - a state-of-the-art model in learning CAD interactions directly from video, which outperforms multiple behavior cloning baselines. Both VideoCADFormer and the VQA benchmark derived from VideoCAD reveal key challenges in the current state of video-based UI understanding, including the need for precise action grounding, multi-modal and spatial reasoning, and long-horizon dependencies."}, {'id': 'arxiv_2505.22914', 'title': 'cadrille: Multi-modal CAD Reconstruction with Online Reinforcement Learning', 'URL': 'http://arxiv.org/abs/2505.22914', 'extra_urls': ['http://arxiv.org/abs/2505.22914'], 'type': 'article', 'author': [{'family': 'Kolodiazhnyi', 'given': 'Maksim'}, {'family': 'Tarasov', 'given': 'Denis'}, {'family': 'Zhemchuzhnikov', 'given': 'Dmitrii'}, {'family': 'Nikulin', 'given': 'Alexander'}, {'family': 'Zisman', 'given': 'Ilya'}, {'family': 'Vorontsova', 'given': 'Anna'}, {'family': 'Konushin', 'given': 'Anton'}, {'family': 'Kurenkov', 'given': 'Vladislav'}, {'family': 'Rukhovich', 'given': 'Danila'}], 'publisher': 'arXiv', 'abstract': 'Computer-Aided Design (CAD) plays a central role in engineering and manufacturing, making it possible to create precise and editable 3D models. Using a variety of sensor or user-provided data as inputs for CAD reconstruction can democratize access to design applications. However, existing methods typically focus on a single input modality, such as point clouds, images, or text, which limits their generalizability and robustness. Leveraging recent advances in vision-language models (VLM), we propose a multi-modal CAD reconstruction model that simultaneously processes all three input modalities. Inspired by large language model (LLM) training paradigms, we adopt a two-stage pipeline: supervised fine-tuning (SFT) on large-scale procedurally generated data, followed by reinforcement learning (RL) fine-tuning using online feedback, obtained programatically. Furthermore, we are the first to explore RL fine-tuning of LLMs for CAD tasks demonstrating that online RL algorithms such as Group Relative Preference Optimization (GRPO) outperform offline alternatives. In the DeepCAD benchmark, our SFT model outperforms existing single-modal approaches in all three input modalities simultaneously. More importantly, after RL fine-tuning, cadrille sets new state-of-the-art on three challenging datasets, including a real-world one.'}, {'id': 'arxiv_2412.13810', 'title': 'CAD-Assistant: Tool-Augmented VLLMs as Generic CAD Task Solvers', 'URL': 'http://arxiv.org/abs/2412.13810', 'extra_urls': ['http://arxiv.org/abs/2412.13810'], 'type': 'article', 'author': [{'family': 'Mallis', 'given': 'Dimitrios'}, {'family': 'Karadeniz', 'given': 'Ahmet Serdar'}, {'family': 'Cavada', 'given': 'Sebastian'}, {'family': 'Rukhovich', 'given': 'Danila'}, {'family': 'Foteinopoulou', 'given': 'Niki'}, {'family': 'Cherenkova', 'given': 'Kseniya'}, {'family': 'Kacem', 'given': 'Anis'}, {'family': 'Aouada', 'given': 'Djamila'}], 'publisher': 'arXiv', 'abstract': 'We propose CAD-Assistant, a general-purpose CAD agent for AI-assisted design. Our approach is based on a powerful Vision and Large Language Model (VLLM) as a planner and a tool-augmentation paradigm using CAD-specific tools. CAD-Assistant addresses multimodal user queries by generating actions that are iteratively executed on a Python interpreter equipped with the FreeCAD software, accessed via its Python API. Our framework is able to assess the impact of generated CAD commands on geometry and adapts subsequent actions based on the evolving state of the CAD design. We consider a wide range of CAD-specific tools including a sketch image parameterizer, rendering modules, a 2D cross-section generator, and other specialized routines. CAD-Assistant is evaluated on multiple CAD benchmarks, where it outperforms VLLM baselines and supervised task-specific methods. Beyond existing benchmarks, we qualitatively demonstrate the potential of tool-augmented VLLMs as general-purpose CAD solvers across diverse workflows.'}, {'id': 'grounded_question', 'title': 'QueryCAD: Grounded Question Answering for CAD Models', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11128709', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11128709'], 'type': 'article', 'author': [{'family': 'Kienle', 'given': 'Claudius'}, {'family': 'Alt', 'given': 'Benjamin'}, {'family': 'Katic', 'given': 'Darko'}, {'family': 'J\xe4kel', 'given': 'Rainer'}, {'family': 'Peters', 'given': 'Jan'}], 'abstract': 'CAD models are widely used in industry and are essential for robotic automation processes. However, these models are rarely considered in novel AI-based approaches, such as the automatic synthesis of robot programs, as there are no readily available methods that would allow CAD models to be incorporated for the analysis, interpretation, or extraction of information. To address these limitations, we propose QueryCAD, the first system designed for CAD question answering, enabling the extraction of precise information from CAD models using natural language queries. QueryCAD incorporates SegCAD, an open-vocabulary instance segmentation model we developed to identify and select specific parts of the CAD model based on part descriptions. We further propose a CAD question answering benchmark to evaluate QueryCAD and establish a foundation for future research. Lastly, we integrate QueryCAD within an automatic robot program synthesis framework, validating its ability to enhance deep-learning solutions for robotics by enabling them to process CAD models. https://claudius-kienle.github.com/querycad.'}, {'id': 'arxiv_2503.19990', 'title': 'LEGO-Puzzles: How Good Are MLLMs at Multi-Step Spatial Reasoning?', 'URL': 'http://arxiv.org/abs/2503.19990', 'extra_urls': ['http://arxiv.org/abs/2503.19990'], 'type': 'article', 'author': [{'family': 'Tang', 'given': 'Kexian'}, {'family': 'Gao', 'given': 'Junyao'}, {'family': 'Zeng', 'given': 'Yanhong'}, {'family': 'Duan', 'given': 'Haodong'}, {'family': 'Sun', 'given': 'Yanan'}, {'family': 'Xing', 'given': 'Zhening'}, {'family': 'Liu', 'given': 'Wenran'}, {'family': 'Lyu', 'given': 'Kaifeng'}, {'family': 'Chen', 'given': 'Kai'}], 'publisher': 'arXiv', 'abstract': "Multi-step spatial reasoning entails understanding and reasoning about spatial relationships across multiple sequential steps, which is crucial for tackling complex real-world applications, such as robotic manipulation, autonomous navigation, and automated assembly. To assess how well current Multimodal Large Language Models (MLLMs) have acquired this fundamental capability, we introduce LEGO-Puzzles, a scalable benchmark designed to evaluate both spatial understanding and sequential reasoning in MLLMs through LEGO-based tasks. LEGO-Puzzles consists of 1,100 carefully curated visual question-answering (VQA) samples spanning 11 distinct tasks, ranging from basic spatial understanding to complex multi-step reasoning. Based on LEGO-Puzzles, we conduct a comprehensive evaluation of 20 state-of-the-art MLLMs and uncover significant limitations in their spatial reasoning capabilities: even the most powerful MLLMs can answer only about half of the test cases, whereas human participants achieve over 90% accuracy. Furthermore, based on LEGO-Puzzles, we design generation tasks to investigate whether MLLMs can transfer their spatial understanding and reasoning abilities to image generation. Our experiments show that only GPT-4o and Gemini-2.0-Flash exhibit a limited ability to follow these instructions, while other MLLMs either replicate the input image or generate completely irrelevant outputs. Overall, LEGO-Puzzles exposes critical deficiencies in existing MLLMs' spatial understanding and sequential reasoning capabilities, and underscores the need for further advancements in multimodal spatial reasoning."}, {'id': 'arxiv_2507.04293', 'title': 'AutoLayout: Closed-Loop Layout Synthesis via Slow-Fast Collaborative Reasoning', 'URL': 'http://arxiv.org/abs/2507.04293', 'extra_urls': ['http://arxiv.org/abs/2507.04293'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Weixing'}, {'family': 'Chi', 'given': 'Dafeng'}, {'family': 'Liu', 'given': 'Yang'}, {'family': 'Yang', 'given': 'Yuxi'}, {'family': 'Zhang', 'given': 'Yexin'}, {'family': 'Zhuang', 'given': 'Yuzheng'}, {'family': 'Quan', 'given': 'Xingyue'}, {'family': 'Hao', 'given': 'Jianye'}, {'family': 'Li', 'given': 'Guanbin'}, {'family': 'Lin', 'given': 'Liang'}], 'publisher': 'arXiv', 'abstract': 'The automated generation of layouts is vital for embodied intelligence and autonomous systems, supporting applications from virtual environment construction to home robot deployment. Current approaches, however, suffer from spatial hallucination and struggle with balancing semantic fidelity and physical plausibility, often producing layouts with deficits such as floating or overlapping objects and misaligned stacking relation. In this paper, we propose AutoLayout, a fully automated method that integrates a closed-loop self-validation process within a dual-system framework. Specifically, a slow system harnesses detailed reasoning with a Reasoning-Reflection-Generation (RRG) pipeline to extract object attributes and spatial constraints. Then, a fast system generates discrete coordinate sets and a topological relation set that are jointly validated. To mitigate the limitations of handcrafted rules, we further introduce an LLM-based Adaptive Relation Library (ARL) for generating and evaluating layouts. Through the implementation of Slow-Fast Collaborative Reasoning, the AutoLayout efficiently generates layouts after thorough deliberation, effectively mitigating spatial hallucination. Its self-validation mechanism establishes a closed-loop process that iteratively corrects potential errors, achieving a balance between physical stability and semantic consistency. The effectiveness of AutoLayout was validated across 8 distinct scenarios, where it demonstrated a significant 10.1% improvement over SOTA methods in terms of physical plausibility, semantic consistency, and functional completeness.'}, {'id': 'arxiv_2505.19713', 'title': 'CAD-Coder: Text-to-CAD Generation with Chain-of-Thought and Geometric Reward', 'URL': 'http://arxiv.org/abs/2505.19713', 'extra_urls': ['http://arxiv.org/abs/2505.19713'], 'type': 'article', 'author': [{'family': 'Guan', 'given': 'Yandong'}, {'family': 'Wang', 'given': 'Xilin'}, {'family': 'Ming', 'given': 'Xingxi'}, {'family': 'Zhang', 'given': 'Jing'}, {'family': 'Xu', 'given': 'Dong'}, {'family': 'Yu', 'given': 'Qian'}], 'publisher': 'arXiv', 'abstract': 'In this work, we introduce CAD-Coder, a novel framework that reformulates text-to-CAD as the generation of CadQuery scripts - a Python-based, parametric CAD language. This representation enables direct geometric validation, a richer modeling vocabulary, and seamless integration with existing LLMs. To further enhance code validity and geometric fidelity, we propose a two-stage learning pipeline: (1) supervised fine-tuning on paired text-CadQuery data, and (2) reinforcement learning with Group Reward Policy Optimization (GRPO), guided by a CAD-specific reward comprising both a geometric reward (Chamfer Distance) and a format reward. We also introduce a chain-of-thought (CoT) planning process to improve model reasoning, and construct a large-scale, high-quality dataset of 110K text-CadQuery-3D model triplets and 1.5K CoT samples via an automated pipeline. Extensive experiments demonstrate that CAD-Coder enables LLMs to generate diverse, valid, and complex CAD models directly from natural language, advancing the state of the art of text-to-CAD generation and geometric reasoning.'}, {'id': 'material_transfer', 'title': 'MTScan: Material Transfer from\xa0Partial Scans to\xa0CAD Models', 'URL': 'urn:isbn:978-981-96-5812-1', 'type': 'article', 'author': [{'family': 'Su', 'given': 'Xiangyu'}, {'family': 'Peng', 'given': 'Sida'}, {'family': 'van Kaick', 'given': 'Oliver'}, {'family': 'Huang', 'given': 'Hui'}, {'family': 'Hu', 'given': 'Ruizhen'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Springer Nature', 'abstract': 'We introduce a method for transferring material information from a partial scan to a CAD model by establishing a dense correspondence between the scan and the CAD model. Our method is enabled by a pipeline composed of a material decomposition network, a geometry mapping network, and material completion networks. Specifically, given a single RGB-D source image and a target CAD model aligned to the scan, we employ a material decomposition network to extract material and illumination parameters from the image. Next, we sample point clouds from the image and CAD model, and establish a dense correspondence between the two point clouds with a geometry mapping network, which maps the point clouds to a shared template space where correspondences can be derived from closest points and aligned UV maps can be obtained. Finally, based on the established correspondence, we transfer the decomposed material information from the source to the target, and further perform material completion via diffusion on the point clouds and in the UV space. We demonstrate with qualitative and quantitative evaluations that our method is able to obtain more accurate material transfers than previous work in challenging input cases with imperfect shape alignment, so that the shapes with transferred materials better resemble the scanned shapes.'}, {'id': 'generating', 'title': 'CADCrafter: Generating Computer-Aided Design Models from Unconstrained Images', 'URL': 'https://openaccess.thecvf.com/content/CVPR2025/html/Chen_CADCrafter_Generating_Computer-Aided_Design_Models_from_Unconstrained_Images_CVPR_2025_paper.html', 'extra_urls': ['https://openaccess.thecvf.com/content/CVPR2025/html/Chen_CADCrafter_Generating_Computer-Aided_Design_Models_from_Unconstrained_Images_CVPR_2025_paper.html'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Cheng'}, {'family': 'Wei', 'given': 'Jiacheng'}, {'family': 'Chen', 'given': 'Tianrun'}, {'family': 'Zhang', 'given': 'Chi'}, {'family': 'Yang', 'given': 'Xiaofeng'}, {'family': 'Zhang', 'given': 'Shangzhan'}, {'family': 'Yang', 'given': 'Bingchen'}, {'family': 'Foo', 'given': 'Chuan-Sheng'}, {'family': 'Lin', 'given': 'Guosheng'}, {'family': 'Huang', 'given': 'Qixing'}, {'family': 'Liu', 'given': 'Fayao'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'arxiv_2508.10118', 'title': 'From Intent to Execution: Multimodal Chain-of-Thought Reinforcement Learning for Precise CAD Code Generation', 'URL': 'http://arxiv.org/abs/2508.10118', 'extra_urls': ['http://arxiv.org/abs/2508.10118'], 'type': 'article', 'author': [{'family': 'Niu', 'given': 'Ke'}, {'family': 'Yu', 'given': 'Haiyang'}, {'family': 'Chen', 'given': 'Zhuofan'}, {'family': 'Zhao', 'given': 'Mengyang'}, {'family': 'Fu', 'given': 'Teng'}, {'family': 'Li', 'given': 'Bin'}, {'family': 'Xue', 'given': 'Xiangyang'}], 'publisher': 'arXiv', 'abstract': 'Computer-Aided Design (CAD) plays a vital role in engineering and manufacturing, yet current CAD workflows require extensive domain expertise and manual modeling effort. Recent advances in large language models (LLMs) have made it possible to generate code from natural language, opening new opportunities for automating parametric 3D modeling. However, directly translating human design intent into executable CAD code remains highly challenging, due to the need for logical reasoning, syntactic correctness, and numerical precision. In this work, we propose CAD-RL, a multimodal Chain-of-Thought (CoT) guided reinforcement learning post training framework for CAD modeling code generation. Our method combines CoT-based Cold Start with goal-driven reinforcement learning post training using three task-specific rewards: executability reward, geometric accuracy reward, and external evaluation reward. To ensure stable policy learning under sparse and high-variance reward conditions, we introduce three targeted optimization strategies: Trust Region Stretch for improved exploration, Precision Token Loss for enhanced dimensions parameter accuracy, and Overlong Filtering to reduce noisy supervision. To support training and benchmarking, we release ExeCAD, a noval dataset comprising 16,540 real-world CAD examples with paired natural language and structured design language descriptions, executable CADQuery scripts, and rendered 3D models. Experiments demonstrate that CAD-RL achieves significant improvements in reasoning quality, output precision, and code executability over existing VLMs.'}, {'id': 'arxiv_2505.14646', 'title': 'CAD-Coder: An Open-Source Vision-Language Model for Computer-Aided Design Code Generation', 'URL': 'http://arxiv.org/abs/2505.14646', 'extra_urls': ['http://arxiv.org/abs/2505.14646'], 'type': 'article', 'author': [{'family': 'Doris', 'given': 'Anna C.'}, {'family': 'Alam', 'given': 'Md Ferdous'}, {'family': 'Nobari', 'given': 'Amin Heyrani'}, {'family': 'Ahmed', 'given': 'Faez'}], 'publisher': 'arXiv', 'abstract': 'Efficient creation of accurate and editable 3D CAD models is critical in engineering design, significantly impacting cost and time-to-market in product innovation. Current manual workflows remain highly time-consuming and demand extensive user expertise. While recent developments in AI-driven CAD generation show promise, existing models are limited by incomplete representations of CAD operations, inability to generalize to real-world images, and low output accuracy. This paper introduces CAD-Coder, an open-source Vision-Language Model (VLM) explicitly fine-tuned to generate editable CAD code (CadQuery Python) directly from visual input. Leveraging a novel dataset that we created--GenCAD-Code, consisting of over 163k CAD-model image and code pairs--CAD-Coder outperforms state-of-the-art VLM baselines such as GPT-4.5 and Qwen2.5-VL-72B, achieving a 100% valid syntax rate and the highest accuracy in 3D solid similarity. Notably, our VLM demonstrates some signs of generalizability, successfully generating CAD code from real-world images and executing CAD operations unseen during fine-tuning. The performance and adaptability of CAD-Coder highlights the potential of VLMs fine-tuned on code to streamline CAD workflows for engineers and designers. CAD-Coder is publicly available at: https://github.com/anniedoris/CAD-Coder.'}, {'id': 'learning', 'title': 'Stitch-A-Shape: Bottom-up Learning for B-Rep Generation', 'URL': 'https://dl.acm.org/doi/10.1145/3721238.3730661', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3721238.3730661'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Pu'}, {'family': 'Zhang', 'given': 'Wenhao'}, {'family': 'Chen', 'given': 'Jinglu'}, {'family': 'Yan', 'given': 'Dongming'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Boundary representation (B-Rep) models serve as the primary representation format in modern CAD systems for describing 3D shapes. While deep learning has achieved success with various geometric representations, B-Reps remain challenging due to their hybrid nature of combining continuous geometry with discrete topological relationships. In this paper, we present Stitch-A-Shape, a B-Rep generation framework that directly models both topology and geometry. This strategy departs from prior work that focuses on either topology or geometry while recovering the other through post-processing. Our method consists of a geometry module that determines the spatial configuration of geometric elements (vertices, curves, and surface control points) and a topology module that establishes connectivity relationships and identifies boundary structures, including outer and inner loops. Our approach leverages a sequential "stitching" representation that mirrors the native data structure and inherent bottom-up organization of B-Rep, assembling geometric entities from vertices through curves to faces. We validate that our framework can handle topological and geometric ambiguities, as well as open surfaces and compound solids. Experiments show that Stitch-A-Shape achieves superior generation quality and computational efficiency compared to existing approaches in unconditional generation tasks, while exhibiting effective capabilities in class-conditional generation and B-Rep autocompletion applications.'}, {'id': 'arxiv_2504.04000', 'title': 'View2CAD: Reconstructing View-Centric CAD Models from Single RGB-D Scans', 'URL': 'http://arxiv.org/abs/2504.04000', 'extra_urls': ['http://arxiv.org/abs/2504.04000'], 'type': 'article', 'author': [{'family': 'Noeckel', 'given': 'James'}, {'family': 'Jones', 'given': 'Benjamin'}, {'family': 'Schulz', 'given': 'Adriana'}, {'family': 'Curless', 'given': 'Brian'}], 'publisher': 'arXiv', 'abstract': 'Parametric CAD models, represented as Boundary Representations (B-reps), are foundational to modern design and manufacturing workflows, offering the precision and topological breakdown required for downstream tasks such as analysis, editing, and fabrication. However, B-Reps are often inaccessible due to conversion to more standardized, less expressive geometry formats. Existing methods to recover B-Reps from measured data require complete, noise-free 3D data, which are laborious to obtain. We alleviate this difficulty by enabling the precise reconstruction of CAD shapes from a single RGB-D image. We propose a method that addresses the challenge of reconstructing only the observed geometry from a single view. To allow for these partial observations, and to avoid hallucinating incorrect geometry, we introduce a novel view-centric B-rep (VB-Rep) representation, which incorporates structures to handle visibility limits and encode geometric uncertainty. We combine panoptic image segmentation with iterative geometric optimization to refine and improve the reconstruction process. Our results demonstrate high-quality reconstruction on synthetic and real RGB-D data, showing that our method can bridge the reality gap.'}, {'id': 'arxiv_2505.06507', 'title': 'Text-to-CadQuery: A New Paradigm for CAD Generation with Scalable Large Model Capabilities', 'URL': 'http://arxiv.org/abs/2505.06507', 'extra_urls': ['http://arxiv.org/abs/2505.06507'], 'type': 'article', 'author': [{'family': 'Xie', 'given': 'Haoyang'}, {'family': 'Ju', 'given': 'Feng'}], 'publisher': 'arXiv', 'abstract': 'Computer-aided design (CAD) is fundamental to modern engineering and manufacturing, but creating CAD models still requires expert knowledge and specialized software. Recent advances in large language models (LLMs) open up the possibility of generative CAD, where natural language is directly translated into parametric 3D models. However, most existing methods generate task-specific command sequences that pretrained models cannot directly handle. These sequences must be converted into CAD representations such as CAD vectors before a 3D model can be produced, which requires training models from scratch and adds unnecessary complexity. To tackle this issue, we propose generating CadQuery code directly from text, leveraging the strengths of pretrained LLMs to produce 3D models without intermediate representations, using this Python-based scripting language. Since LLMs already excel at Python generation and spatial reasoning, fine-tuning them on Text-to-CadQuery data proves highly effective. Given that these capabilities typically improve with scale, we hypothesize that larger models will perform better after fine-tuning. To enable this, we augment the Text2CAD dataset with 170,000 CadQuery annotations. We fine-tune six open-source LLMs of varying sizes and observe consistent improvements. Our best model achieves a top-1 exact match of 69.3%, up from 58.8%, and reduces Chamfer Distance by 48.6%. Project page: https://github.com/Text-to-CadQuery/Text-to-CadQuery.'}, {'id': 'from_cad_data', 'title': 'From CAD Data to Semantic Graphs: A Framework for Classification', 'URL': 'https://www.computer.org/csdl/proceedings-article/icsc/2025/242600a144/27FQH13dPMI', 'type': 'article', 'author': [{'family': 'Taba', 'given': 'Robin'}, {'family': 'Schonlau', 'given': 'Anna Liza'}, {'family': 'Falkenhain', 'given': 'Joshua'}, {'family': 'Maas', 'given': 'Patrick'}, {'family': 'Koster', 'given': 'Frank'}], 'publisher': 'IEEE Computer Society', 'abstract': 'The growing complexity of digital assemblies presents significant challenges, particularly in understanding their characteristics and interdependencies. Traditional approaches, which focus largely on geometric properties, fall short in capturing the functional dependencies between components. This research introduces a novel approach using semantic enrichment of CAD components and Graph Neural Networks (GNNs) to classify mechanical parts and analyze their interconnections. By leveraging open-source gearbox designs which are based on native CAD data in addition to STEP data, the methodology showcases the ability of graph-based structures to account for both geometric and functional relationships, providing a more comprehensive digital understanding of assemblies.'}, {'id': 'arxiv_2411.10848', 'title': 'NeuroNURBS: Learning Efficient Surface Representations for 3D Solids', 'URL': 'http://arxiv.org/abs/2411.10848', 'extra_urls': ['http://arxiv.org/abs/2411.10848'], 'type': 'article', 'author': [{'family': 'Fan', 'given': 'Jiajie'}, {'family': 'Gholami', 'given': 'Babak'}, {'family': 'B\xe4ck', 'given': 'Thomas'}, {'family': 'Wang', 'given': 'Hao'}], 'publisher': 'arXiv', 'abstract': 'Boundary Representation (B-Rep) is the de facto representation of 3D solids in Computer-Aided Design (CAD). B-Rep solids are defined with a set of NURBS (Non-Uniform Rational B-Splines) surfaces forming a closed volume. To represent a surface, current works often employ the UV-grid approximation, i.e., sample points uniformly on the surface. However, the UV-grid method is not efficient in surface representation and sometimes lacks precision and regularity. In this work, we propose NeuroNURBS, a representation learning method to directly encode the parameters of NURBS surfaces. Our evaluation in solid generation and segmentation tasks indicates that the NeuroNURBS performs comparably and, in some cases, superior to UV-grids, but with a significantly improved efficiency: for training the surface autoencoder, GPU consumption is reduced by 86.7%; memory requirement drops by 79.9% for storing 3D solids. Moreover, adapting BrepGen for solid generation with our NeuroNURBS improves the FID from 30.04 to 27.24, and resolves the undulating issue in generated surfaces.'}, {'id': 'cad_object', 'title': 'CADDreamer: CAD Object Generation from Single-view Images', 'URL': 'https://openaccess.thecvf.com/content/CVPR2025/html/Li_CADDreamer_CAD_Object_Generation_from_Single-view_Images_CVPR_2025_paper.html', 'extra_urls': ['https://openaccess.thecvf.com/content/CVPR2025/html/Li_CADDreamer_CAD_Object_Generation_from_Single-view_Images_CVPR_2025_paper.html'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Yuan'}, {'family': 'Lin', 'given': 'Cheng'}, {'family': 'Liu', 'given': 'Yuan'}, {'family': 'Long', 'given': 'Xiaoxiao'}, {'family': 'Zhang', 'given': 'Chenxu'}, {'family': 'Wang', 'given': 'Ningna'}, {'family': 'Li', 'given': 'Xin'}, {'family': 'Wang', 'given': 'Wenping'}, {'family': 'Guo', 'given': 'Xiaohu'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'arxiv_2508.08821', 'title': '3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs', 'URL': 'http://arxiv.org/abs/2508.08821', 'extra_urls': ['http://arxiv.org/abs/2508.08821'], 'type': 'article', 'author': [{'family': 'Ahmed', 'given': 'Noor'}, {'family': 'Braunstein', 'given': 'Cameron'}, {'family': 'Eger', 'given': 'Steffen'}, {'family': 'Ilg', 'given': 'Eddy'}], 'publisher': 'arXiv', 'abstract': 'Recent Multi-Modal Large Language Models (MLLMs) have demonstrated strong capabilities in learning joint representations from text and images. However, their spatial reasoning remains limited. We introduce 3DFroMLLM, a novel framework that enables the generation of 3D object prototypes directly from MLLMs, including geometry and part labels. Our pipeline is agentic, comprising a designer, coder, and visual inspector operating in a refinement loop. Notably, our approach requires no additional training data or detailed user instructions. Building on prior work in 2D generation, we demonstrate that rendered images produced by our framework can be effectively used for image classification pretraining tasks and outperforms previous methods by 15%. As a compelling real-world use case, we show that the generated prototypes can be leveraged to improve fine-grained vision-language models by using the rendered, part-labeled prototypes to fine-tune CLIP for part segmentation and achieving a 55% accuracy improvement without relying on any additional human-labeled data.'}, {'id': 'arxiv_2505.19490', 'title': 'Automated CAD Modeling Sequence Generation from Text Descriptions via Transformer-Based Large Language Models', 'URL': 'http://arxiv.org/abs/2505.19490', 'extra_urls': ['http://arxiv.org/abs/2505.19490'], 'type': 'article', 'author': [{'family': 'Liao', 'given': 'Jianxing'}, {'family': 'Xu', 'given': 'Junyan'}, {'family': 'Sun', 'given': 'Yatao'}, {'family': 'Tang', 'given': 'Maowen'}, {'family': 'He', 'given': 'Sicheng'}, {'family': 'Liao', 'given': 'Jingxian'}, {'family': 'Yu', 'given': 'Shui'}, {'family': 'Li', 'given': 'Yun'}, {'family': 'Xiao', 'given': 'Hongguan'}], 'publisher': 'arXiv', 'abstract': 'Designing complex computer-aided design (CAD) models is often time-consuming due to challenges such as computational inefficiency and the difficulty of generating precise models. We propose a novel language-guided framework for industrial design automation to address these issues, integrating large language models (LLMs) with computer-automated design (CAutoD).Through this framework, CAD models are automatically generated from parameters and appearance descriptions, supporting the automation of design tasks during the detailed CAD design phase. Our approach introduces three key innovations: (1) a semi-automated data annotation pipeline that leverages LLMs and vision-language large models (VLLMs) to generate high-quality parameters and appearance descriptions; (2) a Transformer-based CAD generator (TCADGen) that predicts modeling sequences via dual-channel feature aggregation; (3) an enhanced CAD modeling generation model, called CADLLM, that is designed to refine the generated sequences by incorporating the confidence scores from TCADGen. Experimental results demonstrate that the proposed approach outperforms traditional methods in both accuracy and efficiency, providing a powerful tool for automating industrial workflows and generating complex CAD models from textual prompts. The code is available at https://jianxliao.github.io/cadllm-page/'}, {'id': 'arxiv_2506.10337', 'title': 'GeoCAD: Local Geometry-Controllable CAD Generation', 'URL': 'http://arxiv.org/abs/2506.10337', 'extra_urls': ['http://arxiv.org/abs/2506.10337'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Zhanwei'}, {'family': 'Liu', 'given': 'Kaiyuan'}, {'family': 'Liu', 'given': 'Junjie'}, {'family': 'Wang', 'given': 'Wenxiao'}, {'family': 'Lin', 'given': 'Binbin'}, {'family': 'Xie', 'given': 'Liang'}, {'family': 'Shen', 'given': 'Chen'}, {'family': 'Cai', 'given': 'Deng'}], 'publisher': 'arXiv', 'abstract': 'Local geometry-controllable computer-aided design (CAD) generation aims to modify local parts of CAD models automatically, enhancing design efficiency. It also ensures that the shapes of newly generated local parts follow user-specific geometric instructions (e.g., an isosceles right triangle or a rectangle with one corner cut off). However, existing methods encounter challenges in achieving this goal. Specifically, they either lack the ability to follow textual instructions or are unable to focus on the local parts. To address this limitation, we introduce GeoCAD, a user-friendly and local geometry-controllable CAD generation method. Specifically, we first propose a complementary captioning strategy to generate geometric instructions for local parts. This strategy involves vertex-based and VLLM-based captioning for systematically annotating simple and complex parts, respectively. In this way, we caption $\\sim$221k different local parts in total. In the training stage, given a CAD model, we randomly mask a local part. Then, using its geometric instruction and the remaining parts as input, we prompt large language models (LLMs) to predict the masked part. During inference, users can specify any local part for modification while adhering to a variety of predefined geometric instructions. Extensive experiments demonstrate the effectiveness of GeoCAD in generation quality, validity and text-to-CAD consistency. Code will be available at https://github.com/Zhanwei-Z/GeoCAD.'}, {'id': 'arxiv_2506.00568', 'title': 'CReFT-CAD: Boosting Orthographic Projection Reasoning for CAD via Reinforcement Fine-Tuning', 'URL': 'http://arxiv.org/abs/2506.00568', 'extra_urls': ['http://arxiv.org/abs/2506.00568'], 'type': 'article', 'author': [{'family': 'Niu', 'given': 'Ke'}, {'family': 'Chen', 'given': 'Zhuofan'}, {'family': 'Yu', 'given': 'Haiyang'}, {'family': 'Chen', 'given': 'Yuwen'}, {'family': 'Fu', 'given': 'Teng'}, {'family': 'Zhao', 'given': 'Mengyang'}, {'family': 'Li', 'given': 'Bin'}, {'family': 'Xue', 'given': 'Xiangyang'}], 'publisher': 'arXiv', 'abstract': 'Computer-Aided Design (CAD) plays a pivotal role in industrial manufacturing. Orthographic projection reasoning underpins the entire CAD workflow, encompassing design, manufacturing, and simulation. However, prevailing deep-learning approaches employ standard 3D reconstruction pipelines as an alternative, which often introduce imprecise dimensions and limit the parametric editability required for CAD workflows. Recently, some researchers adopt vision-language models (VLMs), particularly supervised fine-tuning (SFT), to tackle CAD-related challenges. SFT shows promise but often devolves into pattern memorization, yielding poor out-of-distribution performance on complex reasoning tasks. To address these gaps, we introduce CReFT-CAD, a two-stage fine-tuning paradigm that first employs a curriculum-driven reinforcement learning stage with difficulty-aware rewards to build reasoning ability steadily, and then applies supervised post-tuning to hone instruction following and semantic extraction. Complementing this, we release TriView2CAD, the first large-scale, open-source benchmark for orthographic projection reasoning, comprising 200,000 synthetic and 3,000 real-world orthographic projections with precise dimension annotations and six interoperable data modalities. We benchmark leading VLMs on orthographic projection reasoning and demonstrate that CReFT-CAD substantially improves reasoning accuracy and out-of-distribution generalizability in real-world scenarios, offering valuable insights for advancing CAD reasoning research.'}, {'id': 'arxiv_2503.06796', 'title': 'RoboDesign1M: A Large-scale Dataset for Robot Design Understanding', 'URL': 'http://arxiv.org/abs/2503.06796', 'extra_urls': ['http://arxiv.org/abs/2503.06796'], 'type': 'article', 'author': [{'family': 'Le', 'given': 'Tri'}, {'family': 'Nguyen', 'given': 'Toan'}, {'family': 'Tran', 'given': 'Quang'}, {'family': 'Nguyen', 'given': 'Quang'}, {'family': 'Huang', 'given': 'Baoru'}, {'family': 'Nguyen', 'given': 'Hoan'}, {'family': 'Vu', 'given': 'Minh Nhat'}, {'family': 'Ta', 'given': 'Tung D.'}, {'family': 'Nguyen', 'given': 'Anh'}], 'publisher': 'arXiv', 'abstract': 'Robot design is a complex and time-consuming process that requires specialized expertise. Gaining a deeper understanding of robot design data can enable various applications, including automated design generation, retrieving example designs from text, and developing AI-powered design assistants. While recent advancements in foundation models present promising approaches to addressing these challenges, progress in this field is hindered by the lack of large-scale design datasets. In this paper, we introduce RoboDesign1M, a large-scale dataset comprising 1 million samples. Our dataset features multimodal data collected from scientific literature, covering various robotics domains. We propose a semi-automated data collection pipeline, enabling efficient and diverse data acquisition. To assess the effectiveness of RoboDesign1M, we conduct extensive experiments across multiple tasks, including design image generation, visual question answering about designs, and design image retrieval. The results demonstrate that our dataset serves as a challenging new benchmark for design understanding tasks and has the potential to advance research in this field. RoboDesign1M will be released to support further developments in AI-driven robotic design automation.'}, {'id': 'arxiv_2508.17645', 'title': 'Generating Human-AI Collaborative Design Sequence for 3D Assets via Differentiable Operation Graph', 'URL': 'http://arxiv.org/abs/2508.17645', 'extra_urls': ['http://arxiv.org/abs/2508.17645'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Xiaoyang'}, {'family': 'Ni', 'given': 'Bingbing'}, {'family': 'Zhang', 'given': 'Wenjun'}], 'publisher': 'arXiv', 'abstract': "The emergence of 3D artificial intelligence-generated content (3D-AIGC) has enabled rapid synthesis of intricate geometries. However, a fundamental disconnect persists between AI-generated content and human-centric design paradigms, rooted in representational incompatibilities: conventional AI frameworks predominantly manipulate meshes or neural representations (\\emph{e.g.}, NeRF, Gaussian Splatting), while designers operate within parametric modeling tools. This disconnection diminishes the practical value of AI for 3D industry, undermining the efficiency of human-AI collaboration. To resolve this disparity, we focus on generating design operation sequences, which are structured modeling histories that comprehensively capture the step-by-step construction process of 3D assets and align with designers' typical workflows in modern 3D software. We first reformulate fundamental modeling operations (\\emph{e.g.}, \\emph{Extrude}, \\emph{Boolean}) into differentiable units, enabling joint optimization of continuous (\\emph{e.g.}, \\emph{Extrude} height) and discrete (\\emph{e.g.}, \\emph{Boolean} type) parameters via gradient-based learning. Based on these differentiable operations, a hierarchical graph with gating mechanism is constructed and optimized end-to-end by minimizing Chamfer Distance to target geometries. Multi-stage sequence length constraint and domain rule penalties enable unsupervised learning of compact design sequences without ground-truth sequence supervision. Extensive validation demonstrates that the generated operation sequences achieve high geometric fidelity, smooth mesh wiring, rational step composition and flexible editing capacity, with full compatibility within design industry."}, {'id': 'arxiv_2508.10201', 'title': 'B-repLer: Semantic B-rep Latent Editor using Large Language Models', 'URL': 'http://arxiv.org/abs/2508.10201', 'extra_urls': ['http://arxiv.org/abs/2508.10201'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Yilin'}, {'family': 'Dutt', 'given': 'Niladri Shekhar'}, {'family': 'Li', 'given': 'Changjian'}, {'family': 'Mitra', 'given': 'Niloy J.'}], 'publisher': 'arXiv', 'abstract': "Multimodal large language models (mLLMs), trained in a mixed modal setting as a universal model, have been shown to compete with or even outperform many specialized algorithms for imaging and graphics tasks. As demonstrated across many applications, mLLMs' ability to jointly process image and text data makes them suitable for zero-shot applications or efficient fine-tuning towards specialized tasks. However, they have had limited success in 3D analysis and editing tasks. This is due to both the lack of suitable (annotated) 3D data as well as the idiosyncrasies of 3D representations. In this paper, we investigate whether mLLMs can be adapted to support high-level editing of Boundary Representation (B-rep) CAD objects. B-reps remain the industry-standard for precisely encoding engineering objects, but are challenging as the representation is fragile (i.e. can easily lead to invalid CAD objects) and no publicly available data source exists with semantically-annotated B-reps or CAD construction history. We present B-repLer as a finetuned mLLM that can understand text prompts and make semantic edits on given B-Reps to produce valid outputs. We enable this via a novel multimodal architecture, specifically designed to handle B-rep models, and demonstrate how existing CAD tools, in conjunction with mLLMs, can be used to automatically generate the required reasoning dataset, without relying on external annotations. We extensively evaluate B-repLer and demonstrate several text-based B-rep edits of various complexity, which were not previously possible."}, {'id': 'arxiv_2507.09792', 'title': 'CADmium: Fine-Tuning Code Language Models for Text-Driven Sequential CAD Design', 'URL': 'http://arxiv.org/abs/2507.09792', 'extra_urls': ['http://arxiv.org/abs/2507.09792'], 'type': 'article', 'author': [{'family': 'Govindarajan', 'given': 'Prashant'}, {'family': 'Baldelli', 'given': 'Davide'}, {'family': 'Pathak', 'given': 'Jay'}, {'family': 'Fournier', 'given': 'Quentin'}, {'family': 'Chandar', 'given': 'Sarath'}], 'publisher': 'arXiv', 'abstract': 'Computer-aided design (CAD) is the digital construction of 2D and 3D objects, and is central to a wide range of engineering and manufacturing applications like automobile and aviation. Despite its importance, CAD modeling remains largely a time-intensive, manual task. Recent works have attempted to automate this process with small transformer-based models and handcrafted CAD sequence representations. However, there has been little effort to leverage the potential of large language models (LLMs) for sequential CAD design. In this work, we introduce a new large-scale dataset of more than 170k CAD models annotated with high-quality, human-like descriptions generated with our pipeline based on GPT-4.1. Using this dataset, we fine-tune powerful code-LLMs to generate CAD sequences represented in a JSON-based format from natural language descriptions, demonstrating the viability and effectiveness of this approach for text-conditioned CAD generation. Because simple metrics often fail to reflect the quality of generated objects, we introduce geometric and topological metrics based on sphericity, mean curvature, and Euler characteristic to provide richer structural insights. Our experiments and ablation studies on both synthetic and human-annotated data demonstrate that CADmium is able to automate CAD design, drastically speeding up the design of new objects. The dataset, code, and fine-tuned models are available online.'}, {'id': 'arxiv_2503.18549', 'title': 'RLCAD: Reinforcement Learning Training Gym for Revolution Involved CAD Command Sequence Generation', 'URL': 'http://arxiv.org/abs/2503.18549', 'extra_urls': ['http://arxiv.org/abs/2503.18549'], 'type': 'article', 'author': [{'family': 'Yin', 'given': 'Xiaolong'}, {'family': 'Lu', 'given': 'Xingyu'}, {'family': 'Shen', 'given': 'Jiahang'}, {'family': 'Ni', 'given': 'Jingzhe'}, {'family': 'Li', 'given': 'Hailong'}, {'family': 'Tong', 'given': 'Ruofeng'}, {'family': 'Tang', 'given': 'Min'}, {'family': 'Du', 'given': 'Peng'}], 'publisher': 'arXiv', 'abstract': 'A CAD command sequence is a typical parametric design paradigm in 3D CAD systems where a model is constructed by overlaying 2D sketches with operations such as extrusion, revolution, and Boolean operations. Although there is growing academic interest in the automatic generation of command sequences, existing methods and datasets only support operations such as 2D sketching, extrusion,and Boolean operations. This limitation makes it challenging to represent more complex geometries. In this paper, we present a reinforcement learning (RL) training environment (gym) built on a CAD geometric engine. Given an input boundary representation (B-Rep) geometry, the policy network in the RL algorithm generates an action. This action, along with previously generated actions, is processed within the gym to produce the corresponding CAD geometry, which is then fed back into the policy network. The rewards, determined by the difference between the generated and target geometries within the gym, are used to update the RL network. Our method supports operations beyond sketches, Boolean, and extrusion, including revolution operations. With this training gym, we achieve state-of-the-art (SOTA) quality in generating command sequences from B-Rep geometries.'}, {'id': 'arxiv_2509.11447', 'title': 'Large language model-empowered next-generation computer-aided engineering', 'URL': 'http://arxiv.org/abs/2509.11447', 'extra_urls': ['http://arxiv.org/abs/2509.11447'], 'type': 'article', 'author': [{'family': 'Guo', 'given': 'Jiachen'}, {'family': 'Park', 'given': 'Chanwook'}, {'family': 'Qian', 'given': 'Dong'}, {'family': 'Hughes', 'given': 'Thomas J. R.'}, {'family': 'Liu', 'given': 'Wing Kam'}], 'publisher': 'arXiv', 'abstract': 'Software development has entered a new era where large language models (LLMs) now serve as general-purpose reasoning engines, enabling natural language interaction and transformative applications across diverse domains. This paradigm is now extending into computer-aided engineering (CAE). Recent applications of LLMs in CAE have successfully automated routine tasks, including CAD model generation and FEM simulations. Nevertheless, these contributions, which primarily serve to reduce manual labor, are often insufficient for addressing the significant computational challenges posed by large-scale, high-dimensional systems. To this aim, we first introduce the concept of LLM-empowered CAE agent, where LLMs act as autonomous collaborators that plan, execute, and adapt CAE workflows. Then, we propose an LLM-empowered CAE agent for data-free model order reduction (MOR), a powerful yet underused approach for ultra-fast large-scale parametric analysis due to the intrusive nature and labor-intensive redevelopment of solvers. LLMs can alleviate this barrier by automating derivations, code restructuring, and implementation, making intrusive MOR both practical and broadly accessible. To demonstrate feasibility, we present an LLM-empowered CAE agent for solving ultra-large-scale space-parameter-time (S-P-T) physical problems using Tensor-decomposition-based A Priori Surrogates (TAPS). Our results show that natural language prompts describing parametric partial differential equations (PDEs) can be translated into efficient solver implementations, substantially reducing human effort while producing high-fidelity reduced-order models. Moreover, LLMs can synthesize novel MOR solvers for unseen cases such as nonlinear and high-dimensional parametric problems based on their internal knowledge base. This highlights the potential of LLMs to establish the foundation for next-generation CAE systems.'}, {'id': 'arxiv_2509.17283', 'title': 'Automated Facility Enumeration for Building Compliance Checking using Door Detection and Large Language Models', 'URL': 'http://arxiv.org/abs/2509.17283', 'extra_urls': ['http://arxiv.org/abs/2509.17283'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Licheng'}, {'family': 'Le', 'given': 'Bach'}, {'family': 'Akhtar', 'given': 'Naveed'}, {'family': 'Ngo', 'given': 'Tuan'}], 'publisher': 'arXiv', 'abstract': 'Building compliance checking (BCC) is a critical process for ensuring that constructed facilities meet regulatory standards. A core component of BCC is the accurate enumeration of facility types and their spatial distribution. Despite its importance, this problem has been largely overlooked in the literature, posing a significant challenge for BCC and leaving a critical gap in existing workflows. Performing this task manually is time-consuming and labor-intensive. Recent advances in large language models (LLMs) offer new opportunities to enhance automation by combining visual recognition with reasoning capabilities. In this paper, we introduce a new task for BCC: automated facility enumeration, which involves validating the quantity of each facility type against statutory requirements. To address it, we propose a novel method that integrates door detection with LLM-based reasoning. We are the first to apply LLMs to this task and further enhance their performance through a Chain-of-Thought (CoT) pipeline. Our approach generalizes well across diverse datasets and facility types. Experiments on both real-world and synthetic floor plan data demonstrate the effectiveness and robustness of our method.'}, {'id': 'an_approach', 'title': 'An Analytics-Driven Approach to Enhancing Supply Chain Visibility with   Graph Neural Networks and Federated Learning', 'URL': 'https://arxiv.org/html/2503.07231v1', 'extra_urls': ['https://arxiv.org/html/2503.07231v1'], 'type': 'article', 'author': [{'family': 'Zheng', 'given': 'Ge'}, {'family': 'Brintrup', 'given': 'Alexandra'}], 'publisher': 'arXiv', 'abstract': "In today's globalised trade, supply chains form complex networks spanning\nmultiple organisations and even countries, making them highly vulnerable to\ndisruptions. These vulnerabilities, highlighted by recent global crises,\nunderscore the urgent need for improved visibility and resilience of the supply\nchain. However, data-sharing limitations often hinder the achievement of\ncomprehensive visibility between organisations or countries due to privacy,\nsecurity, and regulatory concerns. Moreover, most existing research studies\nfocused on individual firm- or product-level networks, overlooking the\nmultifaceted interactions among diverse entities that characterise real-world\nsupply chains, thus limiting a holistic understanding of supply chain dynamics.\nTo address these challenges, we propose a novel approach that integrates\nFederated Learning (FL) and Graph Convolutional Neural Networks (GCNs) to\nenhance supply chain visibility through relationship prediction in supply chain\nknowledge graphs. FL enables collaborative model training across countries by\nfacilitating information sharing without requiring raw data exchange, ensuring\ncompliance with privacy regulations and maintaining data security. GCNs empower\nthe framework to capture intricate relational patterns within knowledge graphs,\nenabling accurate link prediction to uncover hidden connections and provide\ncomprehensive insights into supply chain networks. Experimental results\nvalidate the effectiveness of the proposed approach, demonstrating its ability\nto accurately predict relationships within country-level supply chain knowledge\ngraphs. This enhanced visibility supports actionable insights, facilitates\nproactive risk management, and contributes to the development of resilient and\nadaptive supply chain strategies, ensuring that supply chains are better\nequipped to navigate the complexities of the global economy."}, {'id': 'arxiv_2505.11154', 'title': 'MPMA: Preference Manipulation Attack Against Model Context Protocol', 'URL': 'http://arxiv.org/abs/2505.11154', 'extra_urls': ['http://arxiv.org/abs/2505.11154'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Zihan'}, {'family': 'Li', 'given': 'Hongwei'}, {'family': 'Zhang', 'given': 'Rui'}, {'family': 'Liu', 'given': 'Yu'}, {'family': 'Jiang', 'given': 'Wenbo'}, {'family': 'Fan', 'given': 'Wenshu'}, {'family': 'Zhao', 'given': 'Qingchuan'}, {'family': 'Xu', 'given': 'Guowen'}], 'publisher': 'arXiv', 'abstract': 'Model Context Protocol (MCP) standardizes interface mapping for large language models (LLMs) to access external data and tools, which revolutionizes the paradigm of tool selection and facilitates the rapid expansion of the LLM agent tool ecosystem. However, as the MCP is increasingly adopted, third-party customized versions of the MCP server expose potential security vulnerabilities. In this paper, we first introduce a novel security threat, which we term the MCP Preference Manipulation Attack (MPMA). An attacker deploys a customized MCP server to manipulate LLMs, causing them to prioritize it over other competing MCP servers. This can result in economic benefits for attackers, such as revenue from paid MCP services or advertising income generated from free servers. To achieve MPMA, we first design a Direct Preference Manipulation Attack ($\\mathtt{DPMA}$) that achieves significant effectiveness by inserting the manipulative word and phrases into the tool name and description. However, such a direct modification is obvious to users and lacks stealthiness. To address these limitations, we further propose Genetic-based Advertising Preference Manipulation Attack ($\\mathtt{GAPMA}$). $\\mathtt{GAPMA}$ employs four commonly used strategies to initialize descriptions and integrates a Genetic Algorithm (GA) to enhance stealthiness. The experiment results demonstrate that $\\mathtt{GAPMA}$ balances high effectiveness and stealthiness. Our study reveals a critical vulnerability of the MCP in open ecosystems, highlighting an urgent need for robust defense mechanisms to ensure the fairness of the MCP ecosystem.'}, {'id': 'arxiv_2403.14442', 'title': 'RoDLA: Benchmarking the Robustness of Document Layout Analysis Models', 'URL': 'https://arxiv.org/abs/2403.14442', 'extra_urls': ['https://arxiv.org/abs/2403.14442'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Yufan'}, {'family': 'Zhang', 'given': 'Jiaming'}, {'family': 'Peng', 'given': 'Kunyu'}, {'family': 'Zheng', 'given': 'Junwei'}, {'family': 'Liu', 'given': 'Ruiping'}, {'family': 'Torr', 'given': 'Philip'}, {'family': 'Stiefelhagen', 'given': 'Rainer'}], 'publisher': 'arXiv', 'abstract': 'Before developing a Document Layout Analysis (DLA) model in real-world\napplications, conducting comprehensive robustness testing is essential.\nHowever, the robustness of DLA models remains underexplored in the literature.\nTo address this, we are the first to introduce a robustness benchmark for DLA\nmodels, which includes 450K document images of three datasets. To cover\nrealistic corruptions, we propose a perturbation taxonomy with 36 common\ndocument perturbations inspired by real-world document processing.\nAdditionally, to better understand document perturbation impacts, we propose\ntwo metrics, Mean Perturbation Effect (mPE) for perturbation assessment and\nMean Robustness Degradation (mRD) for robustness evaluation. Furthermore, we\nintroduce a self-titled model, i.e., Robust Document Layout Analyzer (RoDLA),\nwhich improves attention mechanisms to boost extraction of robust features.\nExperiments on the proposed benchmarks (PubLayNet-P, DocLayNet-P, and\nM$^6$Doc-P) demonstrate that RoDLA obtains state-of-the-art mRD scores of\n115.7, 135.4, and 150.4, respectively. Compared to previous methods, RoDLA\nachieves notable improvements in mAP of +3.8%, +7.1% and +12.1%, respectively.'}, {'id': 'arxiv_2505.10609', 'title': 'Agent Name Service (ANS): A Universal Directory for Secure AI Agent   Discovery and Interoperability', 'URL': 'https://arxiv.org/abs/2505.10609', 'extra_urls': ['https://arxiv.org/abs/2505.10609'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Ken'}, {'family': 'Narajala', 'given': 'Vineeth Sai'}, {'family': 'Habler', 'given': 'Idan'}, {'family': 'Sheriff', 'given': 'Akram'}], 'publisher': 'arXiv', 'abstract': 'The proliferation of AI agents requires robust mechanisms for secure\ndiscovery. This paper introduces the Agent Name Service (ANS), a novel\narchitecture based on DNS addressing the lack of a public agent discovery\nframework. ANS provides a protocol-agnostic registry infrastructure that\nleverages Public Key Infrastructure (PKI) certificates for verifiable agent\nidentity and trust. The architecture features several key innovations: a\nformalized agent registration and renewal mechanism for lifecycle management;\nDNS-inspired naming conventions with capability-aware resolution; a modular\nProtocol Adapter Layer supporting diverse communication standards (A2A, MCP,\nACP etc.); and precisely defined algorithms for secure resolution. We implement\nstructured communication using JSON Schema and conduct a comprehensive threat\nanalysis of our proposal. The result is a foundational directory service\naddressing the core challenges of secured discovery and interaction in\nmulti-agent systems, paving the way for future interoperable, trustworthy, and\nscalable agent ecosystems.'}, {'id': 'arxiv_2508.03858', 'title': 'MI9 -- Agent Intelligence Protocol: Runtime Governance for Agentic AI   Systems', 'URL': 'https://arxiv.org/abs/2508.03858', 'extra_urls': ['https://arxiv.org/abs/2508.03858'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Charles L.'}, {'family': 'Singhal', 'given': 'Trisha'}, {'family': 'Kelkar', 'given': 'Ameya'}, {'family': 'Tuo', 'given': 'Jason'}], 'publisher': 'arXiv', 'abstract': "Agentic AI systems capable of reasoning, planning, and executing actions\npresent fundamentally distinct governance challenges compared to traditional AI\nmodels. Unlike conventional AI, these systems exhibit emergent and unexpected\nbehaviors during runtime, introducing novel agent-related risks that cannot be\nfully anticipated through pre-deployment governance alone. To address this\ncritical gap, we introduce MI9, the first fully integrated runtime governance\nframework designed specifically for safety and alignment of agentic AI systems.\nMI9 introduces real-time controls through six integrated components:\nagency-risk index, agent-semantic telemetry capture, continuous authorization\nmonitoring, Finite-State-Machine (FSM)-based conformance engines,\ngoal-conditioned drift detection, and graduated containment strategies.\nOperating transparently across heterogeneous agent architectures, MI9 enables\nthe systematic, safe, and responsible deployment of agentic systems in\nproduction environments where conventional governance approaches fall short,\nproviding the foundational infrastructure for safe agentic AI deployment at\nscale. Detailed analysis through a diverse set of scenarios demonstrates MI9's\nsystematic coverage of governance challenges that existing approaches fail to\naddress, establishing the technical foundation for comprehensive agentic AI\noversight."}, {'id': 'arxiv_2508.13220', 'title': 'MCPSecBench: A Systematic Security Benchmark and Playground for Testing   Model Context Protocols', 'URL': 'https://arxiv.org/abs/2508.13220', 'extra_urls': ['https://arxiv.org/abs/2508.13220'], 'type': 'article', 'author': [{'family': 'Yang', 'given': 'Yixuan'}, {'family': 'Wu', 'given': 'Daoyuan'}, {'family': 'Chen', 'given': 'Yufan'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) are increasingly integrated into real-world\napplications via the Model Context Protocol (MCP), a universal, open standard\nfor connecting AI agents with data sources and external tools. While MCP\nenhances the capabilities of LLM-based agents, it also introduces new security\nrisks and expands their attack surfaces. In this paper, we present the first\nsystematic taxonomy of MCP security, identifying 17 attack types across 4\nprimary attack surfaces. We introduce MCPSecBench, a comprehensive security\nbenchmark and playground that integrates prompt datasets, MCP servers, MCP\nclients, attack scripts, and protection mechanisms to evaluate these attacks\nacross three major MCP providers. Our benchmark is modular and extensible,\nallowing researchers to incorporate custom implementations of clients, servers,\nand transport protocols for systematic security assessment. Experimental\nresults show that over 85% of the identified attacks successfully compromise at\nleast one platform, with core vulnerabilities universally affecting Claude,\nOpenAI, and Cursor, while prompt-based and tool-centric attacks exhibit\nconsiderable variability across different hosts and models. In addition,\ncurrent protection mechanisms have little effect against these attacks.\nOverall, MCPSecBench standardizes the evaluation of MCP security and enables\nrigorous testing across all MCP layers.'}, {'id': 'arxiv_2508.12538', 'title': 'Systematic Analysis of MCP Security', 'URL': 'https://arxiv.org/abs/2508.12538', 'extra_urls': ['https://arxiv.org/abs/2508.12538'], 'type': 'article', 'author': [{'family': 'Guo', 'given': 'Yongjian'}, {'family': 'Liu', 'given': 'Puzhuo'}, {'family': 'Ma', 'given': 'Wanlun'}, {'family': 'Deng', 'given': 'Zehang'}, {'family': 'Zhu', 'given': 'Xiaogang'}, {'family': 'Di', 'given': 'Peng'}, {'family': 'Xiao', 'given': 'Xi'}, {'family': 'Wen', 'given': 'Sheng'}], 'publisher': 'arXiv', 'abstract': "The Model Context Protocol (MCP) has emerged as a universal standard that\nenables AI agents to seamlessly connect with external tools, significantly\nenhancing their functionality. However, while MCP brings notable benefits, it\nalso introduces significant vulnerabilities, such as Tool Poisoning Attacks\n(TPA), where hidden malicious instructions exploit the sycophancy of large\nlanguage models (LLMs) to manipulate agent behavior. Despite these risks,\ncurrent academic research on MCP security remains limited, with most studies\nfocusing on narrow or qualitative analyses that fail to capture the diversity\nof real-world threats. To address this gap, we present the MCP Attack Library\n(MCPLIB), which categorizes and implements 31 distinct attack methods under\nfour key classifications: direct tool injection, indirect tool injection,\nmalicious user attacks, and LLM inherent attack. We further conduct a\nquantitative analysis of the efficacy of each attack. Our experiments reveal\nkey insights into MCP vulnerabilities, including agents' blind reliance on tool\ndescriptions, sensitivity to file-based attacks, chain attacks exploiting\nshared context, and difficulty distinguishing external data from executable\ncommands. These insights, validated through attack experiments, underscore the\nurgency for robust defense strategies and informed MCP design. Our\ncontributions include 1) constructing a comprehensive MCP attack taxonomy, 2)\nintroducing a unified attack framework MCPLIB, and 3) conducting empirical\nvulnerability analysis to enhance MCP security mechanisms. This work provides a\nfoundational framework, supporting the secure evolution of MCP ecosystems."}, {'id': 'arxiv_2506.13590', 'title': 'Agent Capability Negotiation and Binding Protocol (ACNBP)', 'URL': 'https://arxiv.org/abs/2506.13590', 'extra_urls': ['https://arxiv.org/abs/2506.13590'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Ken'}, {'family': 'Sheriff', 'given': 'Akram'}, {'family': 'Narajala', 'given': 'Vineeth Sai'}, {'family': 'Habler', 'given': 'Idan'}], 'publisher': 'arXiv', 'abstract': "As multi-agent systems evolve to encompass increasingly diverse and\nspecialized agents, the challenge of enabling effective collaboration between\nheterogeneous agents has become paramount, with traditional agent communication\nprotocols often assuming homogeneous environments or predefined interaction\npatterns that limit their applicability in dynamic, open-world scenarios. This\npaper presents the Agent Capability Negotiation and Binding Protocol (ACNBP), a\nnovel framework designed to facilitate secure, efficient, and verifiable\ninteractions between agents in heterogeneous multi-agent systems through\nintegration with an Agent Name Service (ANS) infrastructure that provides\ncomprehensive discovery, negotiation, and binding mechanisms. The protocol\nintroduces a structured 10-step process encompassing capability discovery,\ncandidate pre-screening and selection, secure negotiation phases, and binding\ncommitment with built-in security measures including digital signatures,\ncapability attestation, and comprehensive threat mitigation strategies, while a\nkey innovation of ACNBP is its protocolExtension mechanism that enables\nbackward-compatible protocol evolution and supports diverse agent architectures\nwhile maintaining security and interoperability. We demonstrate ACNBP's\neffectiveness through a comprehensive security analysis using the MAESTRO\nthreat modeling framework, practical implementation considerations, and a\ndetailed example showcasing the protocol's application in a document\ntranslation scenario, with the protocol addressing critical challenges in agent\nautonomy, capability verification, secure communication, and scalable agent\necosystem management."}, {'id': 'arxiv_2210.03629', 'title': 'ReAct: Synergizing Reasoning and Acting in Language Models', 'URL': 'https://arxiv.org/abs/2210.03629', 'extra_urls': ['https://arxiv.org/abs/2210.03629'], 'type': 'article', 'author': [{'family': 'Yao', 'given': 'Shunyu'}, {'family': 'Zhao', 'given': 'Jeffrey'}, {'family': 'Yu', 'given': 'Dian'}, {'family': 'Du', 'given': 'Nan'}, {'family': 'Shafran', 'given': 'Izhak'}, {'family': 'Narasimhan', 'given': 'Karthik'}, {'family': 'Cao', 'given': 'Yuan'}], 'publisher': 'arXiv', 'abstract': 'While large language models (LLMs) have demonstrated impressive capabilities\nacross tasks in language understanding and interactive decision making, their\nabilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g.\naction plan generation) have primarily been studied as separate topics. In this\npaper, we explore the use of LLMs to generate both reasoning traces and\ntask-specific actions in an interleaved manner, allowing for greater synergy\nbetween the two: reasoning traces help the model induce, track, and update\naction plans as well as handle exceptions, while actions allow it to interface\nwith external sources, such as knowledge bases or environments, to gather\nadditional information. We apply our approach, named ReAct, to a diverse set of\nlanguage and decision making tasks and demonstrate its effectiveness over\nstate-of-the-art baselines, as well as improved human interpretability and\ntrustworthiness over methods without reasoning or acting components.\nConcretely, on question answering (HotpotQA) and fact verification (Fever),\nReAct overcomes issues of hallucination and error propagation prevalent in\nchain-of-thought reasoning by interacting with a simple Wikipedia API, and\ngenerates human-like task-solving trajectories that are more interpretable than\nbaselines without reasoning traces. On two interactive decision making\nbenchmarks (ALFWorld and WebShop), ReAct outperforms imitation and\nreinforcement learning methods by an absolute success rate of 34% and 10%\nrespectively, while being prompted with only one or two in-context examples.\nProject site with code: https://react-lm.github.io'}, {'id': 'arxiv_2504.16902', 'title': 'Building A Secure Agentic AI Application Leveraging A2A Protocol', 'URL': 'https://arxiv.org/abs/2504.16902', 'extra_urls': ['https://arxiv.org/abs/2504.16902'], 'type': 'article', 'author': [{'family': 'Habler', 'given': 'Idan'}, {'family': 'Huang', 'given': 'Ken'}, {'family': 'Narajala', 'given': 'Vineeth Sai'}, {'family': 'Kulkarni', 'given': 'Prashant'}], 'publisher': 'arXiv', 'abstract': "As Agentic AI systems evolve from basic workflows to complex multi agent\ncollaboration, robust protocols such as Google's Agent2Agent (A2A) become\nessential enablers. To foster secure adoption and ensure the reliability of\nthese complex interactions, understanding the secure implementation of A2A is\nessential. This paper addresses this goal by providing a comprehensive security\nanalysis centered on the A2A protocol. We examine its fundamental elements and\noperational dynamics, situating it within the framework of agent communication\ndevelopment. Utilizing the MAESTRO framework, specifically designed for AI\nrisks, we apply proactive threat modeling to assess potential security issues\nin A2A deployments, focusing on aspects such as Agent Card management, task\nexecution integrity, and authentication methodologies.\n  Based on these insights, we recommend practical secure development\nmethodologies and architectural best practices designed to build resilient and\neffective A2A systems. Our analysis also explores how the synergy between A2A\nand the Model Context Protocol (MCP) can further enhance secure\ninteroperability. This paper equips developers and architects with the\nknowledge and practical guidance needed to confidently leverage the A2A\nprotocol for building robust and secure next generation agentic applications."}, {'id': 'arxiv_2507.06323', 'title': 'Bridging AI and Software Security: A Comparative Vulnerability   Assessment of LLM Agent Deployment Paradigms', 'URL': 'https://arxiv.org/abs/2507.06323', 'extra_urls': ['https://arxiv.org/abs/2507.06323'], 'type': 'article', 'author': [{'family': 'Gasmi', 'given': 'Tarek'}, {'family': 'Guesmi', 'given': 'Ramzi'}, {'family': 'Belhadj', 'given': 'Ines'}, {'family': 'Bennaceur', 'given': 'Jihene'}], 'publisher': 'arXiv', 'abstract': 'Large Language Model (LLM) agents face security vulnerabilities spanning\nAI-specific and traditional software domains, yet current research addresses\nthese separately. This study bridges this gap through comparative evaluation of\nFunction Calling architecture and Model Context Protocol (MCP) deployment\nparadigms using a unified threat classification framework. We tested 3,250\nattack scenarios across seven language models, evaluating simple, composed, and\nchained attacks targeting both AI-specific threats (prompt injection) and\nsoftware vulnerabilities (JSON injection, denial-of-service). Function Calling\nshowed higher overall attack success rates (73.5% vs 62.59% for MCP), with\ngreater system-centric vulnerability while MCP exhibited increased LLM-centric\nexposure. Attack complexity dramatically amplified effectiveness, with chained\nattacks achieving 91-96% success rates. Counterintuitively, advanced reasoning\nmodels demonstrated higher exploitability despite better threat detection.\nResults demonstrate that architectural choices fundamentally reshape threat\nlandscapes. This work establishes methodological foundations for cross-domain\nLLM agent security assessment and provides evidence-based guidance for secure\ndeployment. Code and experimental materials are available at https: // github.\ncom/ theconsciouslab-ai/llm-agent-security.'}, {'id': 'arxiv_2408.10434', 'title': 'Insights on Microservice Architecture Through the Eyes of Industry   Practitioners', 'URL': 'https://www.arxiv.org/abs/2408.10434', 'extra_urls': ['https://www.arxiv.org/abs/2408.10434'], 'type': 'article', 'author': [{'family': 'Nogueira', 'given': 'Vinicius L.'}, {'family': 'Felizardo', 'given': 'Fernando S.'}, {'family': 'Amaral', 'given': 'Aline M. M. M.'}, {'family': 'Assuncao', 'given': 'Wesley K. G.'}, {'family': 'Colanzi', 'given': 'Thelma E.'}], 'publisher': 'arXiv', 'abstract': "The adoption of microservice architecture has seen a considerable upswing in\nrecent years, mainly driven by the need to modernize legacy systems and address\ntheir limitations. Legacy systems, typically designed as monolithic\napplications, often struggle with maintenance, scalability, and deployment\ninefficiencies. This study investigates the motivations, activities, and\nchallenges associated with migrating from monolithic legacy systems to\nmicroservices, aiming to shed light on common practices and challenges from a\npractitioner's point of view. We conducted a comprehensive study with 53\nsoftware practitioners who use microservices, expanding upon previous research\nby incorporating diverse international perspectives. Our mixed-methods approach\nincludes quantitative and qualitative analyses, focusing on four main aspects:\n(i) the driving forces behind migration, (ii) the activities to conduct the\nmigration, (iii) strategies for managing data consistency, and (iv) the\nprevalent challenges. Thus, our results reveal diverse practices and challenges\npractitioners face when migrating to microservices. Companies are interested in\ntechnical benefits, enhancing maintenance, scalability, and deployment\nprocesses. Testing in microservice environments remains complex, and extensive\nmonitoring is crucial to managing the dynamic nature of microservices. Database\nmanagement remains challenging. While most participants prefer decentralized\ndatabases for autonomy and scalability, challenges persist in ensuring data\nconsistency. Additionally, many companies leverage modern cloud technologies to\nmitigate network overhead, showcasing the importance of cloud infrastructure in\nfacilitating efficient microservice communication."}, {'id': 'arxiv_2508.17536', 'title': 'Debate or Vote: Which Yields Better Decisions in Multi-Agent Large   Language Models?', 'URL': 'https://arxiv.org/abs/2508.17536', 'extra_urls': ['https://arxiv.org/abs/2508.17536'], 'type': 'article', 'author': [{'family': 'Choi', 'given': 'Hyeong Kyu'}, {'family': 'Zhu', 'given': 'Xiaojin'}, {'family': 'Li', 'given': 'Sharon'}], 'publisher': 'arXiv', 'abstract': "Multi-Agent Debate~(MAD) has emerged as a promising paradigm for improving\nthe performance of large language models through collaborative reasoning.\nDespite recent advances, the key factors driving MAD's effectiveness remain\nunclear. In this work, we disentangle MAD into two key components--Majority\nVoting and inter-agent Debate--and assess their respective contributions.\nThrough extensive experiments across seven NLP benchmarks, we find that\nMajority Voting alone accounts for most of the performance gains typically\nattributed to MAD. To explain this, we propose a theoretical framework that\nmodels debate as a stochastic process. We prove that it induces a martingale\nover agents' belief trajectories, implying that debate alone does not improve\nexpected correctness. Guided by these insights, we demonstrate that targeted\ninterventions, by biasing the belief update toward correction, can meaningfully\nenhance debate effectiveness. Overall, our findings suggest that while MAD has\npotential, simple ensembling methods remain strong and more reliable\nalternatives in many practical settings. Code is released in\nhttps://github.com/deeplearning-wisc/debate-or-vote."}, {'id': 'arxiv_2510.01619', 'title': 'MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust   Physics-Based Dynamics', 'URL': 'https://arxiv.org/abs/2510.01619', 'extra_urls': ['https://arxiv.org/abs/2510.01619'], 'type': 'article', 'author': [{'family': 'Changmin Lee'}, {'family': 'Jihyun Lee'}, {'family': 'Tae-Kyun Kim'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2312.09228', 'title': '3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting', 'URL': 'https://arxiv.org/abs/2312.09228', 'extra_urls': ['https://arxiv.org/abs/2312.09228'], 'type': 'article', 'author': [{'family': 'Zhiyin Qian'}, {'family': 'Shaofei Wang'}, {'family': 'Marko Mihajlovic'}, {'family': 'Andreas Geiger'}, {'family': 'Siyu Tang'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2311.08581', 'title': 'Drivable 3D Gaussian Avatars', 'URL': 'https://arxiv.org/abs/2311.08581', 'extra_urls': ['https://arxiv.org/abs/2311.08581'], 'type': 'article', 'author': [{'family': 'Wojciech Zielonka'}, {'family': 'Timur Bagautdinov'}, {'family': 'Shunsuke Saito'}, {'family': 'Michael Zollh\xf6fer'}, {'family': 'Justus Thies'}, {'family': 'Javier Romero'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2409.08189', 'title': 'Gaussian Garments: Reconstructing Simulation-Ready Clothing with   Photorealistic Appearance from Multi-View Video', 'URL': 'https://arxiv.org/abs/2409.08189', 'extra_urls': ['https://arxiv.org/abs/2409.08189'], 'type': 'article', 'author': [{'family': 'Boxiang Rong'}, {'family': 'Artur Grigorev'}, {'family': 'Wenbo Wang'}, {'family': 'Michael J. Black'}, {'family': 'Bernhard Thomaszewski'}, {'family': 'Christina Tsalicoglou'}, {'family': 'Otmar Hilliges'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2508.19504', 'title': 'Aegis: Taxonomy and Optimizations for Overcoming Agent-Environment Failures in LLM Agents', 'URL': 'http://arxiv.org/abs/2508.19504', 'extra_urls': ['http://arxiv.org/abs/2508.19504'], 'type': 'article', 'author': [{'family': 'Song', 'given': 'Kevin'}, {'family': 'Jayarajan', 'given': 'Anand'}, {'family': 'Ding', 'given': 'Yaoyao'}, {'family': 'Su', 'given': 'Qidong'}, {'family': 'Zhu', 'given': 'Zhanda'}, {'family': 'Liu', 'given': 'Sihang'}, {'family': 'Pekhimenko', 'given': 'Gennady'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) agents augmented with domain tools promise to autonomously execute complex tasks requiring human-level intelligence, such as customer service and digital assistance. However, their practical deployment is often limited by their low success rates under complex real-world environments. To tackle this, prior research has primarily focused on improving the agents themselves, such as developing strong agentic LLMs, while overlooking the role of the system environment in which the agent operates. In this paper, we study a complementary direction: improving agent success rates by optimizing the system environment in which the agent operates. We collect 142 agent traces (3,656 turns of agent-environment interactions) across 5 state-of-the-art agentic benchmarks. By analyzing these agent failures, we propose a taxonomy for agent-environment interaction failures that includes 6 failure modes. Guided by these findings, we design Aegis, a set of targeted environment optimizations: 1) environment observability enhancement, 2) common computation offloading, and 3) speculative agentic actions. These techniques improve agent success rates on average by 6.7-12.5%, without any modifications to the agent and underlying LLM.'}, {'id': 'arxiv_2509.25370', 'title': 'Where LLM Agents Fail and How They can Learn From Failures', 'URL': 'http://arxiv.org/abs/2509.25370', 'extra_urls': ['http://arxiv.org/abs/2509.25370'], 'type': 'article', 'author': [{'family': 'Zhu', 'given': 'Kunlun'}, {'family': 'Liu', 'given': 'Zijia'}, {'family': 'Li', 'given': 'Bingxuan'}, {'family': 'Tian', 'given': 'Muxin'}, {'family': 'Yang', 'given': 'Yingxuan'}, {'family': 'Zhang', 'given': 'Jiaxun'}, {'family': 'Han', 'given': 'Pengrui'}, {'family': 'Xie', 'given': 'Qipeng'}, {'family': 'Cui', 'given': 'Fuyang'}, {'family': 'Zhang', 'given': 'Weijia'}, {'family': 'Ma', 'given': 'Xiaoteng'}, {'family': 'Yu', 'given': 'Xiaodong'}, {'family': 'Ramesh', 'given': 'Gowtham'}, {'family': 'Wu', 'given': 'Jialian'}, {'family': 'Liu', 'given': 'Zicheng'}, {'family': 'Lu', 'given': 'Pan'}, {'family': 'Zou', 'given': 'James'}, {'family': 'You', 'given': 'Jiaxuan'}], 'publisher': 'arXiv', 'abstract': 'Large Language Model (LLM) agents, which integrate planning, memory, reflection, and tool-use modules, have shown promise in solving complex, multi-step tasks. Yet their sophisticated architectures amplify vulnerability to cascading failures, where a single root-cause error propagates through subsequent decisions, leading to task failure. Current systems lack a framework that can comprehensively understand agent error in a modular and systemic way, and therefore fail to detect these errors accordingly. We address this gap with three contributions. First, we introduce the AgentErrorTaxonomy, a modular classification of failure modes spanning memory, reflection, planning, action, and system-level operations. Second, we construct AgentErrorBench, the first dataset of systematically annotated failure trajectories from ALFWorld, GAIA, and WebShop, grounding error analysis in real-world agent rollouts. Third, we propose AgentDebug, a debugging framework that isolates root-cause failures and provides corrective feedback, enabling agents to recover and iteratively improve. Experiments on AgentErrorBench show that AgentDebug achieves 24% higher all-correct accuracy and 17% higher step accuracy compared to the strongest baseline. Beyond detection, the targeted feedback generated by AgentDebug enables LLM agents to iteratively recover from failures, yielding up to 26% relative improvements in task success across ALFWorld, GAIA, and WebShop. These results establish principled debugging as a pathway to more reliable and adaptive LLM agents. The code and data will be available at https://github.com/ulab-uiuc/AgentDebug'}, {'id': 'arxiv_2504.06418', 'title': 'Releasing Differentially Private Event Logs Using Generative Models', 'URL': 'https://arxiv.org/abs/2504.06418', 'extra_urls': ['https://arxiv.org/abs/2504.06418'], 'type': 'article', 'author': [{'family': 'Frederik Wangelik'}, {'family': 'Majid Rafiei'}, {'family': 'Mahsa Pourbafrani'}, {'family': 'Wil M. P. van der Aalst'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2507.19550', 'title': 'Towards Multi-Agent Economies: Enhancing the A2A Protocol with   Ledger-Anchored Identities and x402 Micropayments for AI Agents', 'URL': 'https://arxiv.org/abs/2507.19550', 'extra_urls': ['https://arxiv.org/abs/2507.19550'], 'type': 'article', 'author': [{'family': 'Awid Vaziry'}, {'family': 'Sandro Rodriguez Garzon'}, {'family': 'Axel K\xfcpper'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.21594', 'title': 'Fast and Cost-effective Speculative Edge-Cloud Decoding with Early Exits', 'URL': 'https://arxiv.org/abs/2505.21594', 'extra_urls': ['https://arxiv.org/abs/2505.21594'], 'type': 'article', 'author': [{'family': 'Yeshwanth Venkatesha'}, {'family': 'Souvik Kundu'}, {'family': 'Priyadarshini Panda'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.19591', 'title': 'Multi-Agent Collaboration via Evolving Orchestration', 'URL': 'https://arxiv.org/abs/2505.19591', 'extra_urls': ['https://arxiv.org/abs/2505.19591'], 'type': 'article', 'author': [{'family': 'Yufan Dang'}, {'family': 'Chen Qian'}, {'family': 'Xueheng Luo'}, {'family': 'Jingru Fan'}, {'family': 'Zihao Xie'}, {'family': 'Ruijie Shi'}, {'family': 'Weize Chen'}, {'family': 'Cheng Yang'}, {'family': 'Xiaoyin Che'}, {'family': 'Ye Tian'}, {'family': 'Xuantang Xiong'}, {'family': 'Lei Han'}, {'family': 'Zhiyuan Liu'}, {'family': 'Maosong Sun'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2507.12311', 'title': 'An Ecosystem for Ontology Interoperability', 'URL': 'https://arxiv.org/abs/2507.12311', 'extra_urls': ['https://arxiv.org/abs/2507.12311'], 'type': 'article', 'author': [{'family': 'Zhangcheng Qiang'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.02861', 'title': 'Neural Orchestration for Multi-Agent Systems: A Deep Learning Framework   for Optimal Agent Selection in Multi-Domain Task Environments', 'URL': 'https://arxiv.org/abs/2505.02861', 'extra_urls': ['https://arxiv.org/abs/2505.02861'], 'type': 'article', 'author': [{'family': 'Kushagra Agrawal'}, {'family': 'Nisharg Nargund'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.05428', 'title': 'Empowering Scientific Workflows with Federated Agents', 'URL': 'https://arxiv.org/abs/2505.05428', 'extra_urls': ['https://arxiv.org/abs/2505.05428'], 'type': 'article', 'author': [{'family': 'J. Gregory Pauloski'}, {'family': 'Yadu Babuji'}, {'family': 'Ryan Chard'}, {'family': 'Mansi Sakarvadia'}, {'family': 'Kyle Chard'}, {'family': 'Ian Foster'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2509.05985', 'title': 'Operationalising AI Regulatory Sandboxes under the EU AI Act: The Triple   Challenge of Capacity, Coordination and Attractiveness to Providers', 'URL': 'https://arxiv.org/abs/2509.05985', 'extra_urls': ['https://arxiv.org/abs/2509.05985'], 'type': 'article', 'author': [{'family': 'Deirdre Ahern'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2406.08695', 'title': 'Global AI Governance in Healthcare: A Cross-Jurisdictional Regulatory   Analysis', 'URL': 'https://arxiv.org/abs/2406.08695', 'extra_urls': ['https://arxiv.org/abs/2406.08695'], 'type': 'article', 'author': [{'family': 'Attrayee Chakraborty'}, {'family': 'Mandar Karhade'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2507.02648', 'title': 'Recourse, Repair, Reparation, &amp; Prevention: A Stakeholder Analysis of AI   Supply Chains', 'URL': 'https://arxiv.org/abs/2507.02648', 'extra_urls': ['https://arxiv.org/abs/2507.02648'], 'type': 'article', 'author': [{'family': 'Aspen K. Hopkins'}, {'family': 'Isabella Struckman'}, {'family': 'Kevin Klyman'}, {'family': 'Susan S. Silbey'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2508.06760', 'title': 'Understanding Privacy Norms Around LLM-Based Chatbots: A Contextual   Integrity Perspective', 'URL': 'https://arxiv.org/abs/2508.06760', 'extra_urls': ['https://arxiv.org/abs/2508.06760'], 'type': 'article', 'author': [{'family': 'Sarah Tran'}, {'family': 'Hongfan Lu'}, {'family': 'Isaac Slaughter'}, {'family': 'Bernease Herman'}, {'family': 'Aayushi Dangol'}, {'family': 'Yue Fu'}, {'family': 'Lufei Chen'}, {'family': 'Biniyam Gebreyohannes'}, {'family': 'Bill Howe'}, {'family': 'Alexis Hiniker'}, {'family': 'Nicholas Weber'}, {'family': 'Robert Wolfe'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2409.00088', 'title': 'On-Device Language Models: A Comprehensive Review', 'URL': 'https://arxiv.org/abs/2409.00088', 'extra_urls': ['https://arxiv.org/abs/2409.00088'], 'type': 'article', 'author': [{'family': 'Jiajun Xu'}, {'family': 'Zhiyuan Li'}, {'family': 'Wei Chen'}, {'family': 'Qun Wang'}, {'family': 'Xin Gao'}, {'family': 'Qi Cai'}, {'family': 'Ziyuan Ling'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2502.17125', 'title': 'LettuceDetect: A Hallucination Detection Framework for RAG Applications', 'URL': 'https://arxiv.org/abs/2502.17125', 'extra_urls': ['https://arxiv.org/abs/2502.17125'], 'type': 'article', 'author': [{'family': '\xc1d\xe1m Kov\xe1cs'}, {'family': 'G\xe1bor Recski'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2401.10895', 'title': 'AI in Supply Chain Risk Assessment: A Systematic Literature Review and   Bibliometric Analysis', 'URL': 'https://arxiv.org/abs/2401.10895', 'extra_urls': ['https://arxiv.org/abs/2401.10895'], 'type': 'article', 'author': [{'family': 'Md Abrar Jahin'}, {'family': 'Saleh Akram Naife'}, {'family': 'Anik Kumar Saha'}, {'family': 'M. F. Mridha'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.15799', 'title': 'The Agentic Economy', 'URL': 'https://arxiv.org/abs/2505.15799', 'extra_urls': ['https://arxiv.org/abs/2505.15799'], 'type': 'article', 'author': [{'family': 'David M. Rothschild'}, {'family': 'Markus Mobius'}, {'family': 'Jake M. Hofman'}, {'family': 'Eleanor W. Dillon'}, {'family': 'Daniel G. Goldstein'}, {'family': 'Nicole Immorlica'}, {'family': 'Sonia Jaffe'}, {'family': 'Brendan Lucier'}, {'family': 'Aleksandrs Slivkins'}, {'family': 'Matthew Vogel'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2501.07913', 'title': 'Governing AI Agents', 'URL': 'https://arxiv.org/abs/2501.07913', 'extra_urls': ['https://arxiv.org/abs/2501.07913'], 'type': 'article', 'author': [{'family': 'Noam Kolt'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2509.01063', 'title': 'An Economy of AI Agents', 'URL': 'https://arxiv.org/abs/2509.01063', 'extra_urls': ['https://arxiv.org/abs/2509.01063'], 'type': 'article', 'author': [{'family': 'Gillian K. Hadfield'}, {'family': 'Andrew Koh'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2509.15366', 'title': 'Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context', 'URL': 'http://arxiv.org/abs/2509.15366', 'extra_urls': ['http://arxiv.org/abs/2509.15366'], 'type': 'article', 'author': [{'family': 'Sorstkins', 'given': 'Andrejs'}, {'family': 'Bailey', 'given': 'Josh'}, {'family': 'Baron', 'given': 'Dr Alistair'}], 'publisher': 'arXiv', 'abstract': 'The rapid evolution of neural architectures - from multilayer perceptrons to large-scale Transformer-based models - has enabled language models (LLMs) to exhibit emergent agentic behaviours when equipped with memory, planning, and external tool use. However, their inherent stochasticity and multi-step decision processes render classical evaluation methods inadequate for diagnosing agentic performance. This work introduces a diagnostic framework for expert systems that not only evaluates but also facilitates the transfer of expert behaviour into LLM-powered agents. The framework integrates (i) curated golden datasets of expert annotations, (ii) silver datasets generated through controlled behavioural mutation, and (iii) an LLM-based Agent Judge that scores and prescribes targeted improvements. These prescriptions are embedded into a vectorized recommendation map, allowing expert interventions to propagate as reusable improvement trajectories across multiple system instances. We demonstrate the framework on a multi-agent recruiter-assistant system, showing that it uncovers latent cognitive failures - such as biased phrasing, extraction drift, and tool misrouting - while simultaneously steering agents toward expert-level reasoning and style. The results establish a foundation for standardized, reproducible expert behaviour transfer in stochastic, tool-augmented LLM agents, moving beyond static evaluation to active expert system refinement.'}, {'id': 'arxiv_2508.02150', 'title': "Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models' Instruction Following", 'URL': 'http://arxiv.org/abs/2508.02150', 'extra_urls': ['http://arxiv.org/abs/2508.02150'], 'type': 'article', 'author': [{'family': 'Ren', 'given': 'Qingyu'}, {'family': 'He', 'given': 'Qianyu'}, {'family': 'Zhang', 'given': 'Bowei'}, {'family': 'Zeng', 'given': 'Jie'}, {'family': 'Liang', 'given': 'Jiaqing'}, {'family': 'Xiao', 'given': 'Yanghua'}, {'family': 'Zhou', 'given': 'Weikang'}, {'family': 'Sun', 'given': 'Zeye'}, {'family': 'Yu', 'given': 'Fei'}], 'publisher': 'arXiv', 'abstract': "Reasoning models excel in complex problem solving but exhibit a concerning trade off between reasoning capabilities and instruction following abilities. Existing approaches for improving instruction following rely on stronger external models, creating methodological bottlenecks and practical limitations including increased costs and accessibility constraints. We propose a self-supervised RL framework that leverages reasoning models' own internal signals to improve instruction following capabilities without external supervision. Extensive experiments demonstrate that our framework significantly improves instruction following capabilities while maintaining reasoning performance, offering a scalable and cost-effective approach to enhance instruction following in reasoning models. The data and code are publicly available at https://github.com/Rainier-rq/verl-if."}, {'id': 'arxiv_2510.11588', 'title': 'Analyzing and Internalizing Complex Policy Documents for LLM Agents', 'URL': 'http://arxiv.org/abs/2510.11588', 'extra_urls': ['http://arxiv.org/abs/2510.11588'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Jiateng'}, {'family': 'Wang', 'given': 'Zhenhailong'}, {'family': 'Huang', 'given': 'Xiaojiang'}, {'family': 'Li', 'given': 'Yingjie'}, {'family': 'Fan', 'given': 'Xing'}, {'family': 'Li', 'given': 'Xiang'}, {'family': 'Guo', 'given': 'Chenlei'}, {'family': 'Sarikaya', 'given': 'Ruhi'}, {'family': 'Ji', 'given': 'Heng'}], 'publisher': 'arXiv', 'abstract': "Large Language Model (LLM)-based agentic systems rely on in-context policy documents encoding diverse business rules. As requirements grow, these documents expand rapidly, causing high computational overhead. This motivates developing internalization methods that embed policy documents into model priors while preserving performance. Prior prompt compression work targets generic prompts, but agentic policy documents span multiple complexity levels and require deeper reasoning, making internalization harder. We introduce CC-Gen, an agentic benchmark generator with Controllable Complexity across four levels, enabling systematic evaluation of agents' ability to handle complexity and offering a unified framework for assessing policy internalization. Our analysis shows that complex policy specifications governing workflows pose major reasoning challenges. Supporting internalization with gold user agent interaction trajectories containing chain-of-thought (CoT) annotations via supervised fine-tuning (SFT) is data-intensive and degrades sharply as policy complexity increases. To mitigate data and reasoning burdens, we propose Category-Aware Policy Continued Pretraining (CAP-CPT). Our automated pipeline parses policy documents to extract key specifications, grouping them into factual, behavioral, and conditional categories, and isolating complex conditions that drive workflow complexity. This guides targeted data synthesis and enables agents to internalize policy information through an autoregressive pretraining loss. Experiments show CAP-CPT improves SFT baselines in all settings, with up to 41% and 22% gains on Qwen-3-32B, achieving 97.3% prompt length reduction on CC-Gen and further enhancing tau-Bench with minimal SFT data."}, {'id': 'arxiv_2510.14420', 'title': 'Instructions are all you need: Self-supervised Reinforcement Learning for Instruction Following', 'URL': 'http://arxiv.org/abs/2510.14420', 'extra_urls': ['http://arxiv.org/abs/2510.14420'], 'type': 'article', 'author': [{'family': 'Ren', 'given': 'Qingyu'}, {'family': 'He', 'given': 'Qianyu'}, {'family': 'Zhang', 'given': 'Bowei'}, {'family': 'Zeng', 'given': 'Jie'}, {'family': 'Liang', 'given': 'Jiaqing'}, {'family': 'Xiao', 'given': 'Yanghua'}, {'family': 'Zhou', 'given': 'Weikang'}, {'family': 'Sun', 'given': 'Zeye'}, {'family': 'Yu', 'given': 'Fei'}], 'publisher': 'arXiv', 'abstract': 'Language models often struggle to follow multi-constraint instructions that are crucial for real-world applications. Existing reinforcement learning (RL) approaches suffer from dependency on external supervision and sparse reward signals from multi-constraint tasks. We propose a label-free self-supervised RL framework that eliminates dependency on external supervision by deriving reward signals directly from instructions and generating pseudo-labels for reward model training. Our approach introduces constraint decomposition strategies and efficient constraint-wise binary classification to address sparse reward challenges while maintaining computational efficiency. Experiments show that our approach generalizes well, achieving strong improvements across 3 in-domain and 5 out-of-domain datasets, including challenging agentic and multi-turn instruction following. The data and code are publicly available at https://github.com/Rainier-rq/verl-if'}, {'id': 'arxiv_2505.16944', 'title': 'AGENTIF: Benchmarking Instruction Following of Large Language Models in Agentic Scenarios', 'URL': 'http://arxiv.org/abs/2505.16944', 'extra_urls': ['http://arxiv.org/abs/2505.16944'], 'type': 'article', 'author': [{'family': 'Qi', 'given': 'Yunjia'}, {'family': 'Peng', 'given': 'Hao'}, {'family': 'Wang', 'given': 'Xiaozhi'}, {'family': 'Xin', 'given': 'Amy'}, {'family': 'Liu', 'given': 'Youfeng'}, {'family': 'Xu', 'given': 'Bin'}, {'family': 'Hou', 'given': 'Lei'}, {'family': 'Li', 'given': 'Juanzi'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) have demonstrated advanced capabilities in real-world agentic applications. Growing research efforts aim to develop LLM-based agents to address practical demands, introducing a new challenge: agentic scenarios often involve lengthy instructions with complex constraints, such as extended system prompts and detailed tool specifications. While adherence to such instructions is crucial for agentic applications, whether LLMs can reliably follow them remains underexplored. In this paper, we introduce AgentIF, the first benchmark for systematically evaluating LLM instruction following ability in agentic scenarios. AgentIF features three key characteristics: (1) Realistic, constructed from 50 real-world agentic applications. (2) Long, averaging 1,723 words with a maximum of 15,630 words. (3) Complex, averaging 11.9 constraints per instruction, covering diverse constraint types, such as tool specifications and condition constraints. To construct AgentIF, we collect 707 human-annotated instructions across 50 agentic tasks from industrial application agents and open-source agentic systems. For each instruction, we annotate the associated constraints and corresponding evaluation metrics, including code-based evaluation, LLM-based evaluation, and hybrid code-LLM evaluation. We use AgentIF to systematically evaluate existing advanced LLMs. We observe that current models generally perform poorly, especially in handling complex constraint structures and tool specifications. We further conduct error analysis and analytical experiments on instruction length and meta constraints, providing some findings about the failure modes of existing LLMs. We have released the code and data to facilitate future research.'}, {'id': 'arxiv_2505.04260', 'title': 'Steerable Chatbots: Personalizing LLMs with Preference-Based Activation Steering', 'URL': 'http://arxiv.org/abs/2505.04260', 'extra_urls': ['http://arxiv.org/abs/2505.04260'], 'type': 'article', 'author': [{'family': 'Bo', 'given': 'Jessica Y.'}, {'family': 'Xu', 'given': 'Tianyu'}, {'family': 'Chatterjee', 'given': 'Ishan'}, {'family': 'Passarella-Ward', 'given': 'Katrina'}, {'family': 'Kulshrestha', 'given': 'Achin'}, {'family': 'Shin', 'given': 'D.'}], 'publisher': 'arXiv', 'abstract': 'As large language models (LLMs) improve in their capacity to serve as personal AI assistants, their ability to output uniquely tailored, personalized responses that align with the soft preferences of their users is essential for enhancing user satisfaction and retention. However, untrained lay users have poor prompt specification abilities and often struggle with conveying their latent preferences to AI assistants. To address this, we leverage activation steering to guide LLMs to align with interpretable preference dimensions during inference. In contrast to memory-based personalization methods that require longer user history, steering is extremely lightweight and can be easily controlled by the user via an linear strength factor. We embed steering into three different interactive chatbot interfaces and conduct a within-subjects user study (n=14) to investigate how end users prefer to personalize their conversations. The results demonstrate the effectiveness of preference-based steering for aligning real-world conversations with hidden user preferences, and highlight further insights on how diverse values around control, usability, and transparency lead users to prefer different interfaces.'}, {'id': 'arxiv_2505.16467', 'title': "Reading Between the Prompts: How Stereotypes Shape LLM's Implicit Personalization", 'URL': 'http://arxiv.org/abs/2505.16467', 'extra_urls': ['http://arxiv.org/abs/2505.16467'], 'type': 'article', 'author': [{'family': 'Neplenbroek', 'given': 'Vera'}, {'family': 'Bisazza', 'given': 'Arianna'}, {'family': 'Fern\xe1ndez', 'given': 'Raquel'}], 'publisher': 'arXiv', 'abstract': "Generative Large Language Models (LLMs) infer user's demographic information from subtle cues in the conversation -- a phenomenon called implicit personalization. Prior work has shown that such inferences can lead to lower quality responses for users assumed to be from minority groups, even when no demographic information is explicitly provided. In this work, we systematically explore how LLMs respond to stereotypical cues using controlled synthetic conversations, by analyzing the models' latent user representations through both model internals and generated answers to targeted user questions. Our findings reveal that LLMs do infer demographic attributes based on these stereotypical signals, which for a number of groups even persists when the user explicitly identifies with a different demographic group. Finally, we show that this form of stereotype-driven implicit personalization can be effectively mitigated by intervening on the model's internal representations using a trained linear probe to steer them toward the explicitly stated identity. Our results highlight the need for greater transparency and control in how LLMs represent user identity."}, {'id': 'arxiv_2509.19364', 'title': 'The Inadequacy of Offline LLM Evaluations: A Need to Account for Personalization in Model Behavior', 'URL': 'http://arxiv.org/abs/2509.19364', 'extra_urls': ['http://arxiv.org/abs/2509.19364'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Angelina'}, {'family': 'Ho', 'given': 'Daniel E.'}, {'family': 'Koyejo', 'given': 'Sanmi'}], 'publisher': 'arXiv', 'abstract': "Standard offline evaluations for language models -- a series of independent, state-less inferences made by models -- fail to capture how language models actually behave in practice, where personalization fundamentally alters model behavior. For instance, identical benchmark questions to the same language model can produce markedly different responses when prompted to a state-less system, in one user's chat session, or in a different user's chat session. In this work, we provide empirical evidence showcasing this phenomenon by comparing offline evaluations to field evaluations conducted by having 800 real users of ChatGPT and Gemini pose benchmark and other provided questions to their chat interfaces."}, {'id': 'arxiv_2509.18052', 'title': 'The PIMMUR Principles: Ensuring Validity in Collective Behavior of LLM Societies', 'URL': 'http://arxiv.org/abs/2509.18052', 'extra_urls': ['http://arxiv.org/abs/2509.18052'], 'type': 'article', 'author': [{'family': 'Zhou', 'given': 'Jiaxu'}, {'family': 'Huang', 'given': 'Jen-tse'}, {'family': 'Zhou', 'given': 'Xuhui'}, {'family': 'Lam', 'given': 'Man Ho'}, {'family': 'Wang', 'given': 'Xintao'}, {'family': 'Zhu', 'given': 'Hao'}, {'family': 'Wang', 'given': 'Wenxuan'}, {'family': 'Sap', 'given': 'Maarten'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) are increasingly used for social simulation, where populations of agents are expected to reproduce human-like collective behavior. However, we find that many recent studies adopt experimental designs that systematically undermine the validity of their claims. From a survey of over 40 papers, we identify six recurring methodological flaws: agents are often homogeneous (Profile), interactions are absent or artificially imposed (Interaction), memory is discarded (Memory), prompts tightly control outcomes (Minimal-Control), agents can infer the experimental hypothesis (Unawareness), and validation relies on simplified theoretical models rather than real-world data (Realism). For instance, GPT-4o and Qwen-3 correctly infer the underlying social experiment in 53.1% of cases when given instructions from prior work-violating the Unawareness principle. We formalize these six requirements as the PIMMUR principles and argue they are necessary conditions for credible LLM-based social simulation. To demonstrate their impact, we re-run five representative studies using a framework that enforces PIMMUR and find that the reported social phenomena frequently fail to emerge under more rigorous conditions. Our work establishes methodological standards for LLM-based multi-agent research and provides a foundation for more reliable and reproducible claims about "AI societies."'}, {'id': 'arxiv_2505.03961', 'title': 'The Power of Stories: Narrative Priming Shapes How LLM Agents Collaborate and Compete', 'URL': 'http://arxiv.org/abs/2505.03961', 'extra_urls': ['http://arxiv.org/abs/2505.03961'], 'type': 'article', 'author': [{'family': 'Gro\xdfmann', 'given': 'Gerrit'}, {'family': 'Ivanova', 'given': 'Larisa'}, {'family': 'Poduru', 'given': 'Sai Leela'}, {'family': 'Tabrizian', 'given': 'Mohaddeseh'}, {'family': 'Mesabah', 'given': 'Islam'}, {'family': 'Selby', 'given': 'David A.'}, {'family': 'Vollmer', 'given': 'Sebastian J.'}], 'publisher': 'arXiv', 'abstract': 'According to Yuval Noah Harari, large-scale human cooperation is driven by shared narratives that encode common beliefs and values. This study explores whether such narratives can similarly nudge LLM agents toward collaboration. We use a finitely repeated public goods game in which LLM agents choose either cooperative or egoistic spending strategies. We prime agents with stories highlighting teamwork to different degrees and test how this influences negotiation outcomes. Our experiments explore four questions:(1) How do narratives influence negotiation behavior? (2) What differs when agents share the same story versus different ones? (3) What happens when the agent numbers grow? (4) Are agents resilient against self-serving negotiators? We find that story-based priming significantly affects negotiation strategies and success rates. Common stories improve collaboration, benefiting each agent. By contrast, priming agents with different stories reverses this effect, and those agents primed toward self-interest prevail. We hypothesize that these results carry implications for multi-agent system design and AI alignment.'}, {'id': 'arxiv_2502.16320', 'title': 'Direct Alignment with Heterogeneous Preferences', 'URL': 'http://arxiv.org/abs/2502.16320', 'extra_urls': ['http://arxiv.org/abs/2502.16320'], 'type': 'article', 'author': [{'family': 'Shirali', 'given': 'Ali'}, {'family': 'Nasr-Esfahany', 'given': 'Arash'}, {'family': 'Alomar', 'given': 'Abdullah'}, {'family': 'Mirtaheri', 'given': 'Parsa'}, {'family': 'Abebe', 'given': 'Rediet'}, {'family': 'Procaccia', 'given': 'Ariel'}], 'publisher': 'arXiv', 'abstract': 'Alignment with human preferences is commonly framed using a universal reward function, even though human preferences are inherently heterogeneous. We formalize this heterogeneity by introducing user types and examine the limits of the homogeneity assumption. We show that aligning to heterogeneous preferences with a single policy is best achieved using the average reward across user types. However, this requires additional information about annotators. We examine improvements under different information settings, focusing on direct alignment methods. We find that minimal information can yield first-order improvements, while full feedback from each user type leads to consistent learning of the optimal policy. Surprisingly, however, no sample-efficient consistent direct loss exists in this latter setting. These results reveal a fundamental tension between consistency and sample efficiency in direct policy alignment.'}, {'id': 'arxiv_2501.11549', 'title': 'Whose Boat Does it Float? Improving Personalization in Preference Tuning via Inferred User Personas', 'URL': 'http://arxiv.org/abs/2501.11549', 'extra_urls': ['http://arxiv.org/abs/2501.11549'], 'type': 'article', 'author': [{'family': 'Balepur', 'given': 'Nishant'}, {'family': 'Padmakumar', 'given': 'Vishakh'}, {'family': 'Yang', 'given': 'Fumeng'}, {'family': 'Feng', 'given': 'Shi'}, {'family': 'Rudinger', 'given': 'Rachel'}, {'family': 'Boyd-Graber', 'given': 'Jordan Lee'}], 'publisher': 'arXiv', 'abstract': 'LLMs are aligned to follow input instructions by learning which of two responses users prefer for a prompt. However, such preference data do not convey why users prefer responses that are chosen or rejected, so LLMs trained on these datasets cannot tailor responses to varied user needs. To surface these parameters of personalization, we apply abductive reasoning to preference data, inferring needs and interests of users, i.e., personas, that may prefer either response. We test this idea in two steps: Persona Inference (PI), abductively inferring personas of users who prefer chosen or rejected outputs, and Persona Tailoring (PT), training models to tailor outputs to personas from PI. We show: 1) LLMs infer personas accurately explaining why different users may prefer both chosen or rejected outputs; 2) Training on preference data augmented with PI personas via PT boosts personalization and generalizes to supporting user-written personas; and 3) Rejected response personas form harder personalization evaluations, showing PT better aids users with uncommon preferences versus typical alignment methods. We argue for an abductive view of preferences for personalization, asking not only which response is better but when, why, and for whom.'}, {'id': 'arxiv_2410.05613', 'title': 'Stereotype or Personalization? User Identity Biases Chatbot Recommendations', 'URL': 'http://arxiv.org/abs/2410.05613', 'extra_urls': ['http://arxiv.org/abs/2410.05613'], 'type': 'article', 'author': [{'family': 'Kantharuban', 'given': 'Anjali'}, {'family': 'Milbauer', 'given': 'Jeremiah'}, {'family': 'Sap', 'given': 'Maarten'}, {'family': 'Strubell', 'given': 'Emma'}, {'family': 'Neubig', 'given': 'Graham'}], 'publisher': 'arXiv', 'abstract': "While personalized recommendations are often desired by users, it can be difficult in practice to distinguish cases of bias from cases of personalization: we find that models generate racially stereotypical recommendations regardless of whether the user revealed their identity intentionally through explicit indications or unintentionally through implicit cues. We demonstrate that when people use large language models (LLMs) to generate recommendations, the LLMs produce responses that reflect both what the user wants and who the user is. We argue that chatbots ought to transparently indicate when recommendations are influenced by a user's revealed identity characteristics, but observe that they currently fail to do so. Our experiments show that even though a user's revealed identity significantly influences model recommendations (p &lt; 0.001), model responses obfuscate this fact in response to user queries. This bias and lack of transparency occurs consistently across multiple popular consumer LLMs and for four American racial groups."}, {'id': 'arxiv_2509.23767', 'title': 'From Personal to Collective: On the Role of Local and Global Memory in LLM Personalization', 'URL': 'http://arxiv.org/abs/2509.23767', 'extra_urls': ['http://arxiv.org/abs/2509.23767'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Zehong'}, {'family': 'Wu', 'given': 'Junlin'}, {'family': 'Tan', 'given': 'ZHaoxuan'}, {'family': 'Li', 'given': 'Bolian'}, {'family': 'Zhong', 'given': 'Xianrui'}, {'family': 'Liu', 'given': 'Zheli'}, {'family': 'Zeng', 'given': 'Qingkai'}], 'publisher': 'arXiv', 'abstract': 'Large language model (LLM) personalization aims to tailor model behavior to individual users based on their historical interactions. However, its effectiveness is often hindered by two key challenges: the \\textit{cold-start problem}, where users with limited history provide insufficient context for accurate personalization, and the \\textit{biasing problem}, where users with abundant but skewed history cause the model to overfit to narrow preferences. We identify both issues as symptoms of a common underlying limitation, i.e., the inability to model collective knowledge across users. To address this, we propose a local-global memory framework (LoGo) that combines the personalized local memory with a collective global memory that captures shared interests across the population. To reconcile discrepancies between these two memory sources, we introduce a mediator module designed to resolve conflicts between local and global signals. Extensive experiments on multiple benchmarks demonstrate that LoGo consistently improves personalization quality by both warming up cold-start users and mitigating biased predictions. These results highlight the importance of incorporating collective knowledge to enhance LLM personalization.'}, {'id': 'arxiv_2504.00338', 'title': 'Agentic Multimodal AI for Hyperpersonalized B2B and B2C Advertising in Competitive Markets: An AI-Driven Competitive Advertising Framework', 'URL': 'http://arxiv.org/abs/2504.00338', 'extra_urls': ['http://arxiv.org/abs/2504.00338'], 'type': 'article', 'author': [{'family': 'Srinivas', 'given': 'Sakhinana Sagar'}, {'family': 'Das', 'given': 'Akash'}, {'family': 'Gupta', 'given': 'Shivam'}, {'family': 'Runkana', 'given': 'Venkataramana'}], 'publisher': 'arXiv', 'abstract': 'The growing use of foundation models (FMs) in real-world applications demands adaptive, reliable, and efficient strategies for dynamic markets. In the chemical industry, AI-discovered materials drive innovation, but commercial success hinges on market adoption, requiring FM-driven advertising frameworks that operate in-the-wild. We present a multilingual, multimodal AI framework for autonomous, hyper-personalized advertising in B2B and B2C markets. By integrating retrieval-augmented generation (RAG), multimodal reasoning, and adaptive persona-based targeting, our system generates culturally relevant, market-aware ads tailored to shifting consumer behaviors and competition. Validation combines real-world product experiments with a Simulated Humanistic Colony of Agents to model consumer personas, optimize strategies at scale, and ensure privacy compliance. Synthetic experiments mirror real-world scenarios, enabling cost-effective testing of ad strategies without risky A/B tests. Combining structured retrieval-augmented reasoning with in-context learning (ICL), the framework boosts engagement, prevents market cannibalization, and maximizes ROAS. This work bridges AI-driven innovation and market adoption, advancing multimodal FM deployment for high-stakes decision-making in commercial marketing.'}, {'id': 'arxiv_2505.00038', 'title': 'HyPerAlign: Interpretable Personalized LLM Alignment via Hypothesis Generation', 'URL': 'http://arxiv.org/abs/2505.00038', 'extra_urls': ['http://arxiv.org/abs/2505.00038'], 'type': 'article', 'author': [{'family': 'Garbacea', 'given': 'Cristina'}, {'family': 'Tan', 'given': 'Chenhao'}], 'publisher': 'arXiv', 'abstract': "Alignment algorithms are widely used to align large language models (LLMs) to human users based on preference annotations. Typically these (often divergent) preferences are aggregated over a diverse set of users, resulting in fine-tuned models that are aligned to the ``average-user'' preference. Nevertheless, current models are used by individual users in very specific contexts and situations, emphasizing the need for user-dependent preference control. In this work we address the problem of personalizing LLM outputs to their users. We aim to generate customized responses tailored to specific individuals instead of generic outputs that emulate the collective voices of diverse populations. We propose HyPerAlign, an interpretable and sample-efficient hypothesis-driven personalization approach for LLM models. Given few-shot examples written by a particular user, we first infer hypotheses about their communication strategies, personality, and writing style, then prompt LLM models with these hypotheses and user-specific attributes to generate customized outputs. We conduct experiments on two different personalization tasks, namely authorship attribution and deliberative alignment, with datasets from diverse domains (news articles, blog posts, emails, jailbreaking benchmarks). Results demonstrate the superiority of hypothesis-driven LLM personalization compared to preference-based fine-tuning methods. For authorship attribution, HyPerAlign generations have consistently high win-rates (commonly $&gt; 90\\%$) against state-of-the-art preference fine-tuning approaches across diverse user profiles and LLM models. For deliberative alignment, the helpfulness of LLM models is improved by up to $70\\%$ on average. Overall, HyPerAlign represents an interpretable and sample-efficient strategy for the personalization of LLM models to individual users."}, {'id': 'arxiv_2501.10685', 'title': 'Harnessing the Potential of Large Language Models in Modern Marketing Management: Applications, Future Directions, and Strategic Recommendations', 'URL': 'http://arxiv.org/abs/2501.10685', 'extra_urls': ['http://arxiv.org/abs/2501.10685'], 'type': 'article', 'author': [{'family': 'Aghaei', 'given': 'Raha'}, {'family': 'Kiaei', 'given': 'Ali A.'}, {'family': 'Boush', 'given': 'Mahnaz'}, {'family': 'Vahidi', 'given': 'Javad'}, {'family': 'Zavvar', 'given': 'Mohammad'}, {'family': 'Barzegar', 'given': 'Zeynab'}, {'family': 'Rofoosheh', 'given': 'Mahan'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) have revolutionized the process of customer engagement, campaign optimization, and content generation, in marketing management. In this paper, we explore the transformative potential of LLMs along with the current applications, future directions, and strategic recommendations for marketers. In particular, we focus on LLMs major business drivers such as personalization, real-time-interactive customer insights, and content automation, and how they enable customers and business outcomes. For instance, the ethical aspects of AI with respect to data privacy, transparency, and mitigation of bias are also covered, with the goal of promoting responsible use of the technology through best practices and the use of new technologies businesses can tap into the LLM potential, which help growth and stay one step ahead in the turmoil of digital marketing. This article is designed to give marketers the necessary guidance by using best industry practices to integrate these powerful LLMs into their marketing strategy and innovation without compromising on the ethos of their brand.'}, {'id': 'arxiv_2310.11689', 'title': 'Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs', 'URL': 'http://arxiv.org/abs/2310.11689', 'extra_urls': ['http://arxiv.org/abs/2310.11689'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Jiefeng'}, {'family': 'Yoon', 'given': 'Jinsung'}, {'family': 'Ebrahimi', 'given': 'Sayna'}, {'family': 'Arik', 'given': 'Sercan O.'}, {'family': 'Pfister', 'given': 'Tomas'}, {'family': 'Jha', 'given': 'Somesh'}], 'publisher': 'arXiv', 'abstract': 'Large language models (LLMs) have recently shown great advances in a variety of tasks, including natural language understanding and generation. However, their use in high-stakes decision-making scenarios is still limited due to the potential for errors. Selective prediction is a technique that can be used to improve the reliability of the LLMs by allowing them to abstain from making predictions when they are unsure of the answer. In this work, we propose a novel framework for adaptation with self-evaluation to improve the selective prediction performance of LLMs. Our framework is based on the idea of using parameter-efficient tuning to adapt the LLM to the specific task at hand while improving its ability to perform self-evaluation. We evaluate our method on a variety of question-answering (QA) datasets and show that it outperforms state-of-the-art selective prediction methods. For example, on the CoQA benchmark, our method improves the AUACC from 91.23% to 92.63% and improves the AUROC from 74.61% to 80.25%.'}, {'id': 'arxiv_2506.20178', 'title': 'COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees', 'URL': 'http://arxiv.org/abs/2506.20178', 'extra_urls': ['http://arxiv.org/abs/2506.20178'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Zhiyuan'}, {'family': 'Duan', 'given': 'Jinhao'}, {'family': 'Wang', 'given': 'Qingni'}, {'family': 'Zhu', 'given': 'Xiaofeng'}, {'family': 'Chen', 'given': 'Tianlong'}, {'family': 'Shi', 'given': 'Xiaoshuang'}, {'family': 'Xu', 'given': 'Kaidi'}], 'publisher': 'arXiv', 'abstract': "Uncertainty quantification (UQ) for foundation models is essential to identify and mitigate potential hallucinations in automatically generated text. However, heuristic UQ approaches lack formal guarantees for key metrics such as the false discovery rate (FDR) in selective prediction. Previous work adopts the split conformal prediction (SCP) framework to ensure desired coverage of admissible answers by constructing prediction sets, but these sets often contain incorrect candidates, limiting their practical utility. To address this, we propose COIN, an uncertainty-guarding selection framework that calibrates statistically valid thresholds to filter a single generated answer per question under user-specified FDR constraints. COIN estimates the empirical error rate on a calibration set and applies confidence interval methods such as Clopper-Pearson to establish a high-probability upper bound on the true error rate (i.e., FDR). This enables the selection of the largest uncertainty threshold that ensures FDR control on test data while significantly increasing sample retention. We demonstrate COIN's robustness in risk control, strong test-time power in retaining admissible answers, and predictive efficiency under limited calibration data across both general and multimodal text generation tasks. Furthermore, we show that employing alternative upper bound constructions and UQ strategies can further boost COIN's power performance, which underscores its extensibility and adaptability to diverse application scenarios."}, {'id': 'arxiv_2409.18645', 'title': 'The Craft of Selective Prediction: Towards Reliable Case Outcome Classification -- An Empirical Study on European Court of Human Rights Cases', 'URL': 'http://arxiv.org/abs/2409.18645', 'extra_urls': ['http://arxiv.org/abs/2409.18645'], 'type': 'article', 'author': [{'family': 'Santosh', 'given': 'T. Y. S. S.'}, {'family': 'Chowdhury', 'given': 'Irtiza'}, {'family': 'Xu', 'given': 'Shanshan'}, {'family': 'Grabmair', 'given': 'Matthias'}], 'publisher': 'arXiv', 'abstract': "In high-stakes decision-making tasks within legal NLP, such as Case Outcome Classification (COC), quantifying a model's predictive confidence is crucial. Confidence estimation enables humans to make more informed decisions, particularly when the model's certainty is low, or where the consequences of a mistake are significant. However, most existing COC works prioritize high task performance over model reliability. This paper conducts an empirical investigation into how various design choices including pre-training corpus, confidence estimator and fine-tuning loss affect the reliability of COC models within the framework of selective prediction. Our experiments on the multi-label COC task, focusing on European Court of Human Rights (ECtHR) cases, highlight the importance of a diverse yet domain-specific pre-training corpus for better calibration. Additionally, we demonstrate that larger models tend to exhibit overconfidence, Monte Carlo dropout methods produce reliable confidence estimates, and confident error regularization effectively mitigates overconfidence. To our knowledge, this is the first systematic exploration of selective prediction in legal NLP. Our findings underscore the need for further research on enhancing confidence measurement and improving the trustworthiness of models in the legal domain."}, {'id': 'arxiv_2506.23464', 'title': "The Confidence Paradox: Can LLM Know When It's Wrong", 'URL': 'http://arxiv.org/abs/2506.23464', 'extra_urls': ['http://arxiv.org/abs/2506.23464'], 'type': 'article', 'author': [{'family': 'Tripathi', 'given': 'Sahil'}, {'family': 'Nafis', 'given': 'Md Tabrez'}, {'family': 'Hussain', 'given': 'Imran'}, {'family': 'Gao', 'given': 'Jiechao'}], 'publisher': 'arXiv', 'abstract': 'Document Visual Question Answering (DocVQA) systems are increasingly deployed in real world applications, yet they remain ethically opaque-often producing overconfident answers to ambiguous questions or failing to communicate uncertainty in a trustworthy manner. This misalignment between model confidence and actual knowledge poses significant risks, particularly in domains requiring ethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUT have advanced SOTA performance by focusing on architectural sophistication and accuracy; however, they fall short in ethical responsiveness. To address these limitations, we introduce HonestVQA, a self-supervised honesty calibration framework for ethically aligned DocVQA. Our model-agnostic method quantifies uncertainty to identify knowledge gaps, aligns model confidence with actual correctness using weighted loss functions, and enforces ethical response behavior via contrastive learning. We further introduce two principled evaluation metrics--Honesty Score (H-Score) and Ethical Confidence Index (ECI)--to benchmark alignment between confidence, accuracy, and ethical communication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3% and F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reduces overconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. In cross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score, demonstrating strong generalization. Ablation shows a 3.8% drop in accuracy without alignment or contrastive loss.'}, {'id': 'arxiv_2508.07407', 'title': 'A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems', 'URL': 'http://arxiv.org/abs/2508.07407', 'extra_urls': ['http://arxiv.org/abs/2508.07407'], 'type': 'article', 'author': [{'family': 'Fang', 'given': 'Jinyuan'}, {'family': 'Peng', 'given': 'Yanwen'}, {'family': 'Zhang', 'given': 'Xi'}, {'family': 'Wang', 'given': 'Yingxu'}, {'family': 'Yi', 'given': 'Xinhao'}, {'family': 'Zhang', 'given': 'Guibin'}, {'family': 'Xu', 'given': 'Yi'}, {'family': 'Wu', 'given': 'Bin'}, {'family': 'Liu', 'given': 'Siwei'}, {'family': 'Li', 'given': 'Zihao'}, {'family': 'Ren', 'given': 'Zhaochun'}, {'family': 'Aletras', 'given': 'Nikos'}, {'family': 'Wang', 'given': 'Xi'}, {'family': 'Zhou', 'given': 'Han'}, {'family': 'Meng', 'given': 'Zaiqiao'}], 'publisher': 'arXiv', 'abstract': 'Recent advances in large language models have sparked growing interest in AI agents capable of solving complex, real-world tasks. However, most existing agent systems rely on manually crafted configurations that remain static after deployment, limiting their ability to adapt to dynamic and evolving environments. To this end, recent research has explored agent evolution techniques that aim to automatically enhance agent systems based on interaction data and environmental feedback. This emerging direction lays the foundation for self-evolving AI agents, which bridge the static capabilities of foundation models with the continuous adaptability required by lifelong agentic systems. In this survey, we provide a comprehensive review of existing techniques for self-evolving agentic systems. Specifically, we first introduce a unified conceptual framework that abstracts the feedback loop underlying the design of self-evolving agentic systems. The framework highlights four key components: System Inputs, Agent System, Environment, and Optimisers, serving as a foundation for understanding and comparing different strategies. Based on this framework, we systematically review a wide range of self-evolving techniques that target different components of the agent system. We also investigate domain-specific evolution strategies developed for specialised fields such as biomedicine, programming, and finance, where optimisation objectives are tightly coupled with domain constraints. In addition, we provide a dedicated discussion on the evaluation, safety, and ethical considerations for self-evolving agentic systems, which are critical to ensuring their effectiveness and reliability. This survey aims to provide researchers and practitioners with a systematic understanding of self-evolving AI agents, laying the foundation for the development of more adaptive, autonomous, and lifelong agentic systems.'}, {'id': 'arxiv_2509.14284', 'title': 'The Sum Leaks More Than Its Parts: Compositional Privacy Risks and Mitigations in Multi-Agent Collaboration', 'URL': 'http://arxiv.org/abs/2509.14284', 'extra_urls': ['http://arxiv.org/abs/2509.14284'], 'type': 'article', 'author': [{'family': 'Patil', 'given': 'Vaidehi'}, {'family': 'Stengel-Eskin', 'given': 'Elias'}, {'family': 'Bansal', 'given': 'Mohit'}], 'publisher': 'arXiv', 'abstract': "As large language models (LLMs) become integral to multi-agent systems, new privacy risks emerge that extend beyond memorization, direct inference, or single-turn evaluations. In particular, seemingly innocuous responses, when composed across interactions, can cumulatively enable adversaries to recover sensitive information, a phenomenon we term compositional privacy leakage. We present the first systematic study of such compositional privacy leaks and possible mitigation methods in multi-agent LLM systems. First, we develop a framework that models how auxiliary knowledge and agent interactions jointly amplify privacy risks, even when each response is benign in isolation. Next, to mitigate this, we propose and evaluate two defense strategies: (1) Theory-of-Mind defense (ToM), where defender agents infer a questioner's intent by anticipating how their outputs may be exploited by adversaries, and (2) Collaborative Consensus Defense (CoDef), where responder agents collaborate with peers who vote based on a shared aggregated state to restrict sensitive information spread. Crucially, we balance our evaluation across compositions that expose sensitive information and compositions that yield benign inferences. Our experiments quantify how these defense strategies differ in balancing the privacy-utility trade-off. We find that while chain-of-thought alone offers limited protection to leakage (~39% sensitive blocking rate), our ToM defense substantially improves sensitive query blocking (up to 97%) but can reduce benign task success. CoDef achieves the best balance, yielding the highest Balanced Outcome (79.8%), highlighting the benefit of combining explicit reasoning with defender collaboration. Together, our results expose a new class of risks in collaborative LLM deployments and provide actionable insights for designing safeguards against compositional, context-driven privacy leakage."}, {'id': 'arxiv_2508.06225', 'title': 'Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution', 'URL': 'http://arxiv.org/abs/2508.06225', 'extra_urls': ['http://arxiv.org/abs/2508.06225'], 'type': 'article', 'author': [{'family': 'Tian', 'given': 'Zailong'}, {'family': 'Han', 'given': 'Zhuoheng'}, {'family': 'Chen', 'given': 'Yanzhe'}, {'family': 'Xu', 'given': 'Haozhe'}, {'family': 'Yang', 'given': 'Xi'}, {'family': 'Xuan', 'given': 'Richeng'}, {'family': 'Wang', 'given': 'Houfeng'}, {'family': 'Liao', 'given': 'Lizi'}], 'publisher': 'arXiv', 'abstract': 'Large Language Models (LLMs) are widely used as automated judges, where practical value depends on both accuracy and trustworthy, risk-aware judgments. Existing approaches predominantly focus on accuracy, overlooking the necessity of well-calibrated confidence, which is vital for adaptive and reliable evaluation pipelines. In this work, we advocate a shift from accuracy-centric evaluation to confidence-driven, risk-aware LLM-as-a-Judge systems, emphasizing the necessity of well-calibrated confidence for trustworthy and adaptive evaluation. We systematically identify the Overconfidence Phenomenon in current LLM-as-a-Judges, where predicted confidence significantly overstates actual correctness, undermining reliability in practical deployment. To quantify this phenomenon, we introduce TH-Score, a novel metric measuring confidence-accuracy alignment. Furthermore, we propose LLM-as-a-Fuser, an ensemble framework that transforms LLMs into reliable, risk-aware evaluators. Extensive experiments demonstrate that our approach substantially improves calibration and enables adaptive, confidence-driven evaluation pipelines, achieving superior reliability and accuracy compared to existing baselines.'}, {'id': 'arxiv_2501.10970', 'title': 'The Alternative Annotator Test for LLM-as-a-Judge: How to Statistically Justify Replacing Human Annotators with LLMs', 'URL': 'http://arxiv.org/abs/2501.10970', 'extra_urls': ['http://arxiv.org/abs/2501.10970'], 'type': 'article', 'author': [{'family': 'Calderon', 'given': 'Nitay'}, {'family': 'Reichart', 'given': 'Roi'}, {'family': 'Dror', 'given': 'Rotem'}], 'publisher': 'arXiv', 'abstract': 'The "LLM-as-an-annotator" and "LLM-as-a-judge" paradigms employ Large Language Models (LLMs) as annotators, judges, and evaluators in tasks traditionally performed by humans. LLM annotations are widely used, not only in NLP research but also in fields like medicine, psychology, and social science. Despite their role in shaping study results and insights, there is no standard or rigorous procedure to determine whether LLMs can replace human annotators. In this paper, we propose a novel statistical procedure, the Alternative Annotator Test (alt-test), that requires only a modest subset of annotated examples to justify using LLM annotations. Additionally, we introduce a versatile and interpretable measure for comparing LLM annotators and judges. To demonstrate our procedure, we curated a diverse collection of ten datasets, consisting of language and vision-language tasks, and conducted experiments with six LLMs and four prompting techniques. Our results show that LLMs can sometimes replace humans with closed-source LLMs (such as GPT-4o), outperforming the open-source LLMs we examine, and that prompting techniques yield judges of varying quality. We hope this study encourages more rigorous and reliable practices.'}, {'id': 'arxiv_2410.15393', 'title': 'CalibraEval: Calibrating Prediction Distribution to Mitigate Selection Bias in LLMs-as-Judges', 'URL': 'http://arxiv.org/abs/2410.15393', 'extra_urls': ['http://arxiv.org/abs/2410.15393'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Haitao'}, {'family': 'Chen', 'given': 'Junjie'}, {'family': 'Ai', 'given': 'Qingyao'}, {'family': 'Chu', 'given': 'Zhumin'}, {'family': 'Zhou', 'given': 'Yujia'}, {'family': 'Dong', 'given': 'Qian'}, {'family': 'Liu', 'given': 'Yiqun'}], 'publisher': 'arXiv', 'abstract': 'The use of large language models (LLMs) as automated evaluation tools to assess the quality of generated natural language, known as LLMs-as-Judges, has demonstrated promising capabilities and is rapidly gaining widespread attention. However, when applied to pairwise comparisons of candidate responses, LLM-based evaluators often exhibit selection bias. Specifically, their judgments may become inconsistent when the option positions or ID tokens are swapped, compromising the effectiveness and fairness of the evaluation result. To address this challenge, we introduce CalibraEval, a novel label-free method for mitigating selection bias during inference. Specifically, CalibraEval reformulates debiasing as an optimization task aimed at adjusting observed prediction distributions to align with unbiased prediction distributions. To solve this optimization problem, we propose a non-parametric order-preserving algorithm (NOA). This algorithm leverages the partial order relationships between model prediction distributions, thereby eliminating the need for explicit labels and precise mathematical function modeling.Empirical evaluations of LLMs in multiple representative benchmarks demonstrate that CalibraEval effectively mitigates selection bias and improves performance compared to existing debiasing methods. This work marks a step toward building more robust and unbiased automated evaluation frameworks, paving the way for improved reliability in AI-driven assessments'}, {'id': 'arxiv_2508.18725', 'title': 'Toward Edge General Intelligence with Agentic AI and Agentification: Concepts, Technologies, and Future Directions', 'URL': 'http://arxiv.org/abs/2508.18725', 'extra_urls': ['http://arxiv.org/abs/2508.18725'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Ruichen'}, {'family': 'Liu', 'given': 'Guangyuan'}, {'family': 'Liu', 'given': 'Yinqiu'}, {'family': 'Zhao', 'given': 'Changyuan'}, {'family': 'Wang', 'given': 'Jiacheng'}, {'family': 'Xu', 'given': 'Yunting'}, {'family': 'Niyato', 'given': 'Dusit'}, {'family': 'Kang', 'given': 'Jiawen'}, {'family': 'Li', 'given': 'Yonghui'}, {'family': 'Mao', 'given': 'Shiwen'}, {'family': 'Sun', 'given': 'Sumei'}, {'family': 'Shen', 'given': 'Xuemin'}, {'family': 'Kim', 'given': 'Dong In'}], 'publisher': 'arXiv', 'abstract': "The rapid expansion of sixth-generation (6G) wireless networks and the Internet of Things (IoT) has catalyzed the evolution from centralized cloud intelligence towards decentralized edge general intelligence. However, traditional edge intelligence methods, characterized by static models and limited cognitive autonomy, fail to address the dynamic, heterogeneous, and resource-constrained scenarios inherent to emerging edge networks. Agentic artificial intelligence (Agentic AI) emerges as a transformative solution, enabling edge systems to autonomously perceive multimodal environments, reason contextually, and adapt proactively through continuous perception-reasoning-action loops. In this context, the agentification of edge intelligence serves as a key paradigm shift, where distributed entities evolve into autonomous agents capable of collaboration and continual adaptation. This paper presents a comprehensive survey dedicated to Agentic AI and agentification frameworks tailored explicitly for edge general intelligence. First, we systematically introduce foundational concepts and clarify distinctions from traditional edge intelligence paradigms. Second, we analyze important enabling technologies, including compact model compression, energy-aware computing strategies, robust connectivity frameworks, and advanced knowledge representation and reasoning mechanisms. Third, we provide representative case studies demonstrating Agentic AI's capabilities in low-altitude economy networks, intent-driven networking, vehicular networks, and human-centric service provisioning, supported by numerical evaluations. Furthermore, we identify current research challenges, review emerging open-source platforms, and highlight promising future research directions to guide robust, scalable, and trustworthy Agentic AI deployments for next-generation edge environments."}, {'id': 'arxiv_2510.08529', 'title': 'CoMAS: Co-Evolving Multi-Agent Systems via Interaction Rewards', 'URL': 'http://arxiv.org/abs/2510.08529', 'extra_urls': ['http://arxiv.org/abs/2510.08529'], 'type': 'article', 'author': [{'family': 'Xue', 'given': 'Xiangyuan'}, {'family': 'Zhou', 'given': 'Yifan'}, {'family': 'Zhang', 'given': 'Guibin'}, {'family': 'Zhang', 'given': 'Zaibin'}, {'family': 'Li', 'given': 'Yijiang'}, {'family': 'Zhang', 'given': 'Chen'}, {'family': 'Yin', 'given': 'Zhenfei'}, {'family': 'Torr', 'given': 'Philip'}, {'family': 'Ouyang', 'given': 'Wanli'}, {'family': 'Bai', 'given': 'Lei'}], 'publisher': 'arXiv', 'abstract': "Self-evolution is a central research topic in enabling large language model (LLM)-based agents to continually improve their capabilities after pretraining. Recent research has witnessed a transition from reinforcement learning (RL)-free to RL-based methods. Current RL-based methods either rely on dense external reward signals or extract intrinsic reward signals from LLMs themselves. However, these approaches diverge from the self-evolution mechanisms observed in human intelligence, where individuals learn and improve through mutual discussion and collaboration. In this work, we introduce Co-Evolving Multi-Agent Systems (CoMAS), a novel framework that enables agents to improve autonomously by learning from inter-agent interactions without external supervision. CoMAS generates intrinsic rewards from rich discussion dynamics, employs an LLM-as-a-judge mechanism to formulate these rewards, and optimizes each agent's policy through RL, thereby enabling decentralized and scalable co-evolution. Experimental results demonstrate that CoMAS consistently outperforms untrained agents and achieves state-of-the-art performance across most evaluation settings. Ablation studies confirm the necessity of interaction-based reward signals and reveal promising scalability as the number and diversity of agents increase. These findings establish CoMAS as a novel and effective paradigm for self-evolution in LLM-based agents."}, {'id': 'arxiv_2509.15160', 'title': 'An Evaluation-Centric Paradigm for Scientific Visualization Agents', 'URL': 'http://arxiv.org/abs/2509.15160', 'extra_urls': ['http://arxiv.org/abs/2509.15160'], 'type': 'article', 'author': [{'family': 'Ai', 'given': 'Kuangshi'}, {'family': 'Miao', 'given': 'Haichao'}, {'family': 'Li', 'given': 'Zhimin'}, {'family': 'Wang', 'given': 'Chaoli'}, {'family': 'Liu', 'given': 'Shusen'}], 'publisher': 'arXiv', 'abstract': 'Recent advances in multi-modal large language models (MLLMs) have enabled increasingly sophisticated autonomous visualization agents capable of translating user intentions into data visualizations. However, measuring progress and comparing different agents remains challenging, particularly in scientific visualization (SciVis), due to the absence of comprehensive, large-scale benchmarks for evaluating real-world capabilities. This position paper examines the various types of evaluation required for SciVis agents, outlines the associated challenges, provides a simple proof-of-concept evaluation example, and discusses how evaluation benchmarks can facilitate agent self-improvement. We advocate for a broader collaboration to develop a SciVis agentic evaluation benchmark that would not only assess existing capabilities but also drive innovation and stimulate future development in the field.'}, {'id': 'arxiv_2508.21148', 'title': 'A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers', 'URL': 'http://arxiv.org/abs/2508.21148', 'extra_urls': ['http://arxiv.org/abs/2508.21148'], 'type': 'article', 'author': [{'family': 'Hu', 'given': 'Ming'}, {'family': 'Ma', 'given': 'Chenglong'}, {'family': 'Li', 'given': 'Wei'}, {'family': 'Xu', 'given': 'Wanghan'}, {'family': 'Wu', 'given': 'Jiamin'}, {'family': 'Hu', 'given': 'Jucheng'}, {'family': 'Li', 'given': 'Tianbin'}, {'family': 'Zhuang', 'given': 'Guohang'}, {'family': 'Liu', 'given': 'Jiaqi'}, {'family': 'Lu', 'given': 'Yingzhou'}, {'family': 'Chen', 'given': 'Ying'}, {'family': 'Zhang', 'given': 'Chaoyang'}, {'family': 'Tan', 'given': 'Cheng'}, {'family': 'Ying', 'given': 'Jie'}, {'family': 'Wu', 'given': 'Guocheng'}, {'family': 'Gao', 'given': 'Shujian'}, {'family': 'Chen', 'given': 'Pengcheng'}, {'family': 'Lin', 'given': 'Jiashi'}, {'family': 'Wu', 'given': 'Haitao'}, {'family': 'Chen', 'given': 'Lulu'}, {'family': 'Wang', 'given': 'Fengxiang'}, {'family': 'Zhang', 'given': 'Yuanyuan'}, {'family': 'Zhao', 'given': 'Xiangyu'}, {'family': 'Tang', 'given': 'Feilong'}, {'family': 'Su', 'given': 'Encheng'}, {'family': 'Ning', 'given': 'Junzhi'}, {'family': 'Liu', 'given': 'Xinyao'}, {'family': 'Du', 'given': 'Ye'}, {'family': 'Ji', 'given': 'Changkai'}, {'family': 'Jiang', 'given': 'Pengfei'}, {'family': 'Tang', 'given': 'Cheng'}, {'family': 'Huang', 'given': 'Ziyan'}, {'family': 'Liu', 'given': 'Jiyao'}, {'family': 'Wei', 'given': 'Jiaqi'}, {'family': 'Yang', 'given': 'Yuejin'}, {'family': 'Zhang', 'given': 'Xiang'}, {'family': 'Wang', 'given': 'Guangshuai'}, {'family': 'Yang', 'given': 'Yue'}, {'family': 'Xu', 'given': 'Huihui'}, {'family': 'Chen', 'given': 'Ziyang'}, {'family': 'Wang', 'given': 'Yizhou'}, {'family': 'Tang', 'given': 'Chen'}, {'family': 'Wu', 'given': 'Jianyu'}, {'family': 'Ren', 'given': 'Yuchen'}, {'family': 'Yan', 'given': 'Siyuan'}, {'family': 'Wang', 'given': 'Zhonghua'}, {'family': 'Xu', 'given': 'Zhongxing'}, {'family': 'Su', 'given': 'Shiyan'}, {'family': 'Sun', 'given': 'Shangquan'}, {'family': 'Zhao', 'given': 'Runkai'}, {'family': 'Zhang', 'given': 'Zhisheng'}, {'family': 'Yang', 'given': 'Dingkang'}, {'family': 'Wei', 'given': 'Jinjie'}, {'family': 'Wang', 'given': 'Jiaqi'}, {'family': 'Xu', 'given': 'Jiahao'}, {'family': 'Yan', 'given': 'Jiangtao'}, {'family': 'Tang', 'given': 'Wenhao'}, {'family': 'Zhu', 'given': 'Hongze'}, {'family': 'Liu', 'given': 'Yu'}, {'family': 'Wang', 'given': 'Fudi'}, {'family': 'Shen', 'given': 'Yiqing'}, {'family': 'Ji', 'given': 'Yuanfeng'}, {'family': 'Su', 'given': 'Yanzhou'}, {'family': 'Xie', 'given': 'Tong'}, {'family': 'Shan', 'given': 'Hongming'}, {'family': 'Feng', 'given': 'Chun-Mei'}, {'family': 'Hou', 'given': 'Zhi'}, {'family': 'Song', 'given': 'Diping'}, {'family': 'Liu', 'given': 'Lihao'}, {'family': 'Huang', 'given': 'Yanyan'}, {'family': 'Yu', 'given': 'Lequan'}, {'family': 'Fu', 'given': 'Bin'}, {'family': 'Wang', 'given': 'Shujun'}, {'family': 'Li', 'given': 'Xiaomeng'}, {'family': 'Hu', 'given': 'Xiaowei'}, {'family': 'Gu', 'given': 'Yun'}, {'family': 'Fei', 'given': 'Ben'}, {'family': 'Wang', 'given': 'Benyou'}, {'family': 'Cao', 'given': 'Yuewen'}, {'family': 'Shen', 'given': 'Minjie'}, {'family': 'Xu', 'given': 'Jie'}, {'family': 'Duan', 'given': 'Haodong'}, {'family': 'Yan', 'given': 'Fang'}, {'family': 'Hao', 'given': 'Hongxia'}, {'family': 'Li', 'given': 'Jielan'}, {'family': 'Du', 'given': 'Jiajun'}, {'family': 'Wang', 'given': 'Yanbo'}, {'family': 'Razzak', 'given': 'Imran'}, {'family': 'Deng', 'given': 'Zhongying'}, {'family': 'Zhang', 'given': 'Chi'}, {'family': 'Wu', 'given': 'Lijun'}, {'family': 'He', 'given': 'Conghui'}, {'family': 'Lu', 'given': 'Zhaohui'}, {'family': 'Huang', 'given': 'Jinhai'}, {'family': 'Shao', 'given': 'Wenqi'}, {'family': 'Liu', 'given': 'Yihao'}, {'family': 'Luo', 'given': 'Siqi'}, {'family': 'Xin', 'given': 'Yi'}, {'family': 'Liu', 'given': 'Xiaohong'}, {'family': 'Ling', 'given': 'Fenghua'}, {'family': 'Li', 'given': 'Yuqiang'}, {'family': 'Wang', 'given': 'Aoran'}, {'family': 'Sun', 'given': 'Siqi'}, {'family': 'Zheng', 'given': 'Qihao'}, {'family': 'Dong', 'given': 'Nanqing'}, {'family': 'Fu', 'given': 'Tianfan'}, {'family': 'Zhou', 'given': 'Dongzhan'}, {'family': 'Lu', 'given': 'Yan'}, {'family': 'Zhang', 'given': 'Wenlong'}, {'family': 'Ye', 'given': 'Jin'}, {'family': 'Cai', 'given': 'Jianfei'}, {'family': 'Chen', 'given': 'Yirong'}, {'family': 'Ouyang', 'given': 'Wanli'}, {'family': 'Qiao', 'given': 'Yu'}, {'family': 'Ge', 'given': 'Zongyuan'}, {'family': 'Tang', 'given': 'Shixiang'}, {'family': 'He', 'given': 'Junjun'}, {'family': 'Song', 'given': 'Chunfeng'}, {'family': 'Bai', 'given': 'Lei'}, {'family': 'Zhou', 'given': 'Bowen'}], 'publisher': 'arXiv', 'abstract': 'Scientific Large Language Models (Sci-LLMs) are transforming how knowledge is represented, integrated, and applied in scientific research, yet their progress is shaped by the complex nature of scientific data. This survey presents a comprehensive, data-centric synthesis that reframes the development of Sci-LLMs as a co-evolution between models and their underlying data substrate. We formulate a unified taxonomy of scientific data and a hierarchical model of scientific knowledge, emphasizing the multimodal, cross-scale, and domain-specific challenges that differentiate scientific corpora from general natural language processing datasets. We systematically review recent Sci-LLMs, from general-purpose foundations to specialized models across diverse scientific disciplines, alongside an extensive analysis of over 270 pre-/post-training datasets, showing why Sci-LLMs pose distinct demands -- heterogeneous, multi-scale, uncertainty-laden corpora that require representations preserving domain invariance and enabling cross-modal reasoning. On evaluation, we examine over 190 benchmark datasets and trace a shift from static exams toward process- and discovery-oriented assessments with advanced evaluation protocols. These data-centric analyses highlight persistent issues in scientific data development and discuss emerging solutions involving semi-automated annotation pipelines and expert validation. Finally, we outline a paradigm shift toward closed-loop systems where autonomous agents based on Sci-LLMs actively experiment, validate, and contribute to a living, evolving knowledge base. Collectively, this work provides a roadmap for building trustworthy, continually evolving artificial intelligence (AI) systems that function as a true partner in accelerating scientific discovery.'}, {'id': 'arxiv_2508.02994', 'title': 'When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs', 'URL': 'http://arxiv.org/abs/2508.02994', 'extra_urls': ['http://arxiv.org/abs/2508.02994'], 'type': 'article', 'author': [{'family': 'Yu', 'given': 'Fangyi'}], 'publisher': 'arXiv', 'abstract': 'As large language models (LLMs) grow in capability and autonomy, evaluating their outputs-especially in open-ended and complex tasks-has become a critical bottleneck. A new paradigm is emerging: using AI agents as the evaluators themselves. This "agent-as-a-judge" approach leverages the reasoning and perspective-taking abilities of LLMs to assess the quality and safety of other models, promising calable and nuanced alternatives to human evaluation. In this review, we define the agent-as-a-judge concept, trace its evolution from single-model judges to dynamic multi-agent debate frameworks, and critically examine their strengths and shortcomings. We compare these approaches across reliability, cost, and human alignment, and survey real-world deployments in domains such as medicine, law, finance, and education. Finally, we highlight pressing challenges-including bias, robustness, and meta evaluation-and outline future research directions. By bringing together these strands, our review demonstrates how agent-based judging can complement (but not replace) human oversight, marking a step toward trustworthy, scalable evaluation for next-generation LLMs.'}, {'id': 'arxiv_2510.15186', 'title': 'MAGPIE: A benchmark for Multi-AGent contextual PrIvacy Evaluation', 'URL': 'http://arxiv.org/abs/2510.15186', 'extra_urls': ['http://arxiv.org/abs/2510.15186'], 'type': 'article', 'author': [{'family': 'Juneja', 'given': 'Gurusha'}, {'family': 'Pasupulati', 'given': 'Jayanth Naga Sai'}, {'family': 'Albalak', 'given': 'Alon'}, {'family': 'Hua', 'given': 'Wenyue'}, {'family': 'Wang', 'given': 'William Yang'}], 'publisher': 'arXiv', 'abstract': 'A core challenge for autonomous LLM agents in collaborative settings is balancing robust privacy understanding and preservation alongside task efficacy. Existing privacy benchmarks only focus on simplistic, single-turn interactions where private information can be trivially omitted without affecting task outcomes. In this paper, we introduce MAGPIE (Multi-AGent contextual PrIvacy Evaluation), a novel benchmark of 200 high-stakes tasks designed to evaluate privacy understanding and preservation in multi-agent collaborative, non-adversarial scenarios. MAGPIE integrates private information as essential for task resolution, forcing agents to balance effective collaboration with strategic information control. Our evaluation reveals that state-of-the-art agents, including GPT-5 and Gemini 2.5-Pro, exhibit significant privacy leakage, with Gemini 2.5-Pro leaking up to 50.7% and GPT-5 up to 35.1% of the sensitive information even when explicitly instructed not to. Moreover, these agents struggle to achieve consensus or task completion and often resort to undesirable behaviors such as manipulation and power-seeking (e.g., Gemini 2.5-Pro demonstrating manipulation in 38.2% of the cases). These findings underscore that current LLM agents lack robust privacy understanding and are not yet adequately aligned to simultaneously preserve privacy and maintain effective collaboration in complex environments.'}, {'id': 'arxiv_2412.14461', 'title': 'To Err Is Human; To Annotate, SILICON? Reducing Measurement Error in LLM Annotation', 'URL': 'http://arxiv.org/abs/2412.14461', 'extra_urls': ['http://arxiv.org/abs/2412.14461'], 'type': 'article', 'author': [{'family': 'Cheng', 'given': 'Xiang'}, {'family': 'Mayya', 'given': 'Raveesh'}, {'family': 'Sedoc', 'given': 'Jo\xe3o'}], 'publisher': 'arXiv', 'abstract': 'Unstructured text data annotation is foundational to management research and Large Language Models (LLMs) promise a cost-effective and scalable alternative to human annotation. The validity of insights drawn from LLM annotated data critically depends on minimizing the discrepancy between LLM assigned labels and the unobserved ground truth, as well as ensuring long-term reproducibility of results. We address the gap in the literature on LLM annotation by decomposing measurement error in LLM-based text annotation into four distinct sources: (1) guideline-induced error from inconsistent annotation criteria, (2) baseline-induced error from unreliable human reference standards, (3) prompt-induced error from suboptimal meta-instruction formatting, and (4) model-induced error from architectural differences across LLMs. We develop the SILICON methodology to systematically reduce measurement error from LLM annotation in all four sources above. Empirical validation across seven management research cases shows iteratively refined guidelines substantially increases the LLM-human agreement compared to one-shot guidelines; expert-generated baselines exhibit higher inter-annotator agreement as well as are less prone to producing misleading LLM-human agreement estimates compared to crowdsourced baselines; placing content in the system prompt reduces prompt-induced error; and model performance varies substantially across tasks. To further reduce error, we introduce a cost-effective multi-LLM labeling method, where only low-confidence items receive additional labels from alternative models. Finally, in addressing closed source model retirement cycles, we introduce an intuitive regression-based methodology to establish robust reproducibility protocols. Our evidence indicates that reducing each error source is necessary, and that SILICON supports reproducible, rigorous annotation in management research.'}, {'id': 'arxiv_2504.10768', 'title': 'The Art of Audience Engagement: LLM-Based Thin-Slicing of Scientific Talks', 'URL': 'http://arxiv.org/abs/2504.10768', 'extra_urls': ['http://arxiv.org/abs/2504.10768'], 'type': 'article', 'author': [{'family': 'Schm\xe4lzle', 'given': 'Ralf'}, {'family': 'Lim', 'given': 'Sue'}, {'family': 'Du', 'given': 'Yuetong'}, {'family': 'Bente', 'given': 'Gary'}], 'publisher': 'arXiv', 'abstract': 'This paper examines the thin-slicing approach - the ability to make accurate judgments based on minimal information - in the context of scientific presentations. Drawing on research from nonverbal communication and personality psychology, we show that brief excerpts (thin slices) reliably predict overall presentation quality. Using a novel corpus of over one hundred real-life science talks, we employ Large Language Models (LLMs) to evaluate transcripts of full presentations and their thin slices. By correlating LLM-based evaluations of short excerpts with full-talk assessments, we determine how much information is needed for accurate predictions. Our results demonstrate that LLM-based evaluations align closely with human ratings, proving their validity, reliability, and efficiency. Critically, even very short excerpts (less than 10 percent of a talk) strongly predict overall evaluations. This suggests that the first moments of a presentation convey relevant information that is used in quality evaluations and can shape lasting impressions. The findings are robust across different LLMs and prompting strategies. This work extends thin-slicing research to public speaking and connects theories of impression formation to LLMs and current research on AI communication. We discuss implications for communication and social cognition research on message reception. Lastly, we suggest an LLM-based thin-slicing framework as a scalable feedback tool to enhance human communication.'}, {'id': 'llms_do', 'title': "Can't LLMs do that? Supporting Third-Party Audits under the DSA: Exploring Large Language Models for Systemic Risk Evaluation of the Digital Services Act in an Interdisciplinary Setting", 'URL': 'https://dl.acm.org/doi/10.1145/3707640.3731929', 'type': 'article', 'author': [{'family': 'Sekwenz', 'given': 'Marie-Therese'}, {'family': 'Gsenger', 'given': 'Rita'}, {'family': 'Stocker', 'given': 'Volker'}, {'family': 'G\xf6rnemann', 'given': 'Esther'}, {'family': 'Talypova', 'given': 'Dinara'}, {'family': 'Parkin', 'given': 'Simon'}, {'family': 'Greminger', 'given': 'Lea'}, {'family': 'Smaragdakis', 'given': 'Georgios'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'This paper investigates the feasibility and potential role of using Large Language Models (LLMs) to support systemic risk audits under the European Union\u2019s Digital Services Act (DSA). It examines how automated tools can enhance the work of DSA auditors and other ecosystem actors by enabling scalable, explainable, and legally grounded content analysis. An interdisciplinary expert workshop with twelve participants from legal, technical, and social science backgrounds explored prompting strategies for LLM-assisted auditing. Thematic analysis of the sessions identified key challenges and design considerations, including prompt engineering, model interpretability, legal alignment, and user empowerment. Findings highlight the potential of LLMs to improve annotation workflows and expand audit scale, while underscoring the continued importance of human oversight, iterative testing, and cross-disciplinary collaboration. This study offers practical insights for integrating AI tools into auditing processes and contributes to emerging methodologies for operationalizing systemic risk evaluations under the DSA.'}, {'id': 'arxiv_2411.15594', 'title': 'A Survey on LLM-as-a-Judge', 'URL': 'http://arxiv.org/abs/2411.15594', 'extra_urls': ['http://arxiv.org/abs/2411.15594'], 'type': 'article', 'author': [{'family': 'Gu', 'given': 'Jiawei'}, {'family': 'Jiang', 'given': 'Xuhui'}, {'family': 'Shi', 'given': 'Zhichao'}, {'family': 'Tan', 'given': 'Hexiang'}, {'family': 'Zhai', 'given': 'Xuehao'}, {'family': 'Xu', 'given': 'Chengjin'}, {'family': 'Li', 'given': 'Wei'}, {'family': 'Shen', 'given': 'Yinghan'}, {'family': 'Ma', 'given': 'Shengjie'}, {'family': 'Liu', 'given': 'Honghao'}, {'family': 'Wang', 'given': 'Saizhuo'}, {'family': 'Zhang', 'given': 'Kun'}, {'family': 'Wang', 'given': 'Yuanzhuo'}, {'family': 'Gao', 'given': 'Wen'}, {'family': 'Ni', 'given': 'Lionel'}, {'family': 'Guo', 'given': 'Jian'}], 'publisher': 'arXiv', 'abstract': 'Accurate and consistent evaluation is crucial for decision-making across numerous fields, yet it remains a challenging task due to inherent subjectivity, variability, and scale. Large Language Models (LLMs) have achieved remarkable success across diverse domains, leading to the emergence of "LLM-as-a-Judge," where LLMs are employed as evaluators for complex tasks. With their ability to process diverse data types and provide scalable, cost-effective, and consistent assessments, LLMs present a compelling alternative to traditional expert-driven evaluations. However, ensuring the reliability of LLM-as-a-Judge systems remains a significant challenge that requires careful design and standardization. This paper provides a comprehensive survey of LLM-as-a-Judge, addressing the core question: How can reliable LLM-as-a-Judge systems be built? We explore strategies to enhance reliability, including improving consistency, mitigating biases, and adapting to diverse assessment scenarios. Additionally, we propose methodologies for evaluating the reliability of LLM-as-a-Judge systems, supported by a novel benchmark designed for this purpose. To advance the development and real-world deployment of LLM-as-a-Judge systems, we also discussed practical applications, challenges, and future directions. This survey serves as a foundational reference for researchers and practitioners in this rapidly evolving field.'}, {'id': 'a_system', 'title': 'Plurals: A System for Guiding LLMs via Simulated Social Ensembles', 'URL': 'https://dl.acm.org/doi/10.1145/3706598.3713675', 'type': 'article', 'author': [{'family': 'Ashkinaze', 'given': 'Joshua'}, {'family': 'Fry', 'given': 'Emily'}, {'family': 'Edara', 'given': 'Narendra'}, {'family': 'Gilbert', 'given': 'Eric'}, {'family': 'Budak', 'given': 'Ceren'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Recent debates raised concerns that language models may favor certain viewpoints. But what if the solution is not to aim for a \u201cview from nowhere\u201d but rather to leverage different viewpoints? We introduce Plurals, a system and Python library for pluralistic AI deliberation. Plurals consists of Agents (LLMs, optionally with personas) which deliberate within customizable Structures, with Moderators overseeing deliberation. Plurals is a generator of simulated social ensembles. Plurals integrates with government datasets to create nationally representative personas, includes deliberation templates inspired by deliberative democracy, and allows users to customize both information-sharing structures and deliberation behavior within Structures. Six case studies demonstrate fidelity to theoretical constructs and efficacy. Three randomized experiments show simulated focus groups produced output resonant with an online sample of the relevant audiences (chosen over zero-shot generation in 75% of trials). Plurals is both a paradigm and a concrete system for pluralistic AI.'}, {'id': 'can_video_llms', 'title': 'Can Video LLMs Refuse to Answer? Alignment for Answerability in Video Large Language Models', 'URL': 'https://openreview.net/forum?id=P9VdRQOyqu', 'extra_urls': ['https://openreview.net/forum?id=P9VdRQOyqu'], 'type': 'article', 'author': [{'family': 'Yoon', 'given': 'Eunseop'}, {'family': 'Yoon', 'given': 'Hee Suk'}, {'family': 'Hasegawa-Johnson', 'given': 'Mark A.'}, {'family': 'Yoo', 'given': 'Chang D.'}], 'abstract': 'In the broader context of deep learning, Multimodal Large Language Models have achieved significant breakthroughs by leveraging powerful Large Language Models as a backbone to align different modalities into the language space. A prime exemplification is the development of Video Large Language Models (Video-LLMs). While numerous advancements have been proposed to enhance the video understanding capabilities of these models, they are predominantly trained on questions generated directly from video content. However, in real-world scenarios, users often pose questions that extend beyond the informational scope of the video, highlighting the need for Video-LLMs to assess the relevance of the question. We demonstrate that even the best-performing Video-LLMs fail to reject unfit questions-not necessarily due to a lack of video understanding, but because they have not been trained to identify and refuse such questions. To address this limitation, we propose alignment for answerability, a framework that equips Video-LLMs with the ability to evaluate the relevance of a question based on the input video and appropriately decline to answer when the question exceeds the scope of the video, as well as an evaluation framework with a comprehensive set of metrics designed to measure model behavior before and after alignment. Furthermore, we present a pipeline for creating a dataset specifically tailored for alignment for answerability, leveraging existing video-description paired datasets.'}, {'id': 'arxiv_2502.12964', 'title': "Trust Me, I'm Wrong: LLMs Hallucinate with Certainty Despite Knowing the Answer", 'URL': 'http://arxiv.org/abs/2502.12964', 'extra_urls': ['http://arxiv.org/abs/2502.12964'], 'type': 'article', 'author': [{'family': 'Simhi', 'given': 'Adi'}, {'family': 'Itzhak', 'given': 'Itay'}, {'family': 'Barez', 'given': 'Fazl'}, {'family': 'Stanovsky', 'given': 'Gabriel'}, {'family': 'Belinkov', 'given': 'Yonatan'}], 'publisher': 'arXiv', 'abstract': 'Prior work on large language model (LLM) hallucinations has associated them with model uncertainty or inaccurate knowledge. In this work, we define and investigate a distinct type of hallucination, where a model can consistently answer a question correctly, but a seemingly trivial perturbation, which can happen in real-world settings, causes it to produce a hallucinated response with high certainty. This phenomenon, which we dub CHOKE (Certain Hallucinations Overriding Known Evidence), is particularly concerning in high-stakes domains such as medicine or law, where model certainty is often used as a proxy for reliability. We show that CHOKE examples are consistent across prompts, occur in different models and datasets, and are fundamentally distinct from other hallucinations. This difference leads existing mitigation methods to perform worse on CHOKE examples than on general hallucinations. Finally, we introduce a probing-based mitigation that outperforms existing methods on CHOKE hallucinations. These findings reveal an overlooked aspect of hallucinations, emphasizing the need to understand their origins and improve mitigation strategies to enhance LLM safety. The code is available at https://github.com/technion-cs-nlp/Trust_me_Im_wrong .'}, {'id': 'arxiv_2506.09038', 'title': 'AbstentionBench: Reasoning LLMs Fail on Unanswerable Questions', 'URL': 'http://arxiv.org/abs/2506.09038', 'extra_urls': ['http://arxiv.org/abs/2506.09038'], 'type': 'article', 'author': [{'family': 'Kirichenko', 'given': 'Polina'}, {'family': 'Ibrahim', 'given': 'Mark'}, {'family': 'Chaudhuri', 'given': 'Kamalika'}, {'family': 'Bell', 'given': 'Samuel J.'}], 'publisher': 'arXiv', 'abstract': "For Large Language Models (LLMs) to be reliably deployed in both everyday and high-stakes domains, knowing when not to answer is equally critical as answering correctly. Real-world user queries, which can be underspecified, ill-posed, or fundamentally unanswerable, require LLMs to reason about uncertainty and selectively abstain -- i.e., refuse to answer definitively. However, abstention remains understudied, without a systematic evaluation framework for modern LLMs. In this work, we introduce AbstentionBench, a large-scale benchmark for holistically evaluating abstention across 20 diverse datasets, including questions with unknown answers, underspecification, false premises, subjective interpretations, and outdated information. Evaluating 20 frontier LLMs reveals abstention is an unsolved problem, and one where scaling models is of little use. While recent reasoning LLMs have shown impressive results in complex problem solving, surprisingly, we find that reasoning fine-tuning degrades abstention (by $24\\%$ on average), even for math and science domains on which reasoning models are explicitly trained. We find that while a carefully crafted system prompt can boost abstention in practice, it does not resolve models' fundamental inability to reason about uncertainty. We release AbstentionBench to foster research into advancing LLM reliability."}, {'id': 'arxiv_2510.10390', 'title': 'RefusalBench: Generative Evaluation of Selective Refusal in Grounded Language Models', 'URL': 'http://arxiv.org/abs/2510.10390', 'extra_urls': ['http://arxiv.org/abs/2510.10390'], 'type': 'article', 'author': [{'family': 'Muhamed', 'given': 'Aashiq'}, {'family': 'Ribeiro', 'given': 'Leonardo F. R.'}, {'family': 'Dreyer', 'given': 'Markus'}, {'family': 'Smith', 'given': 'Virginia'}, {'family': 'Diab', 'given': 'Mona T.'}], 'publisher': 'arXiv', 'abstract': 'The ability of language models in RAG systems to selectively refuse to answer based on flawed context is critical for safety, yet remains a significant failure point. Our large-scale study reveals that even frontier models struggle in this setting, with refusal accuracy dropping below 50% on multi-document tasks, while exhibiting either dangerous overconfidence or overcaution. Static benchmarks fail to reliably evaluate this capability, as models exploit dataset-specific artifacts and memorize test instances. We introduce RefusalBench, a generative methodology that programmatically creates diagnostic test cases through controlled linguistic perturbation. Our framework employs 176 distinct perturbation strategies across six categories of informational uncertainty and three intensity levels. Evaluation of over 30 models uncovers systematic failure patterns: refusal comprises separable detection and categorization skills, and neither scale nor extended reasoning improves performance. We find that selective refusal is a trainable, alignment-sensitive capability, offering a clear path for improvement. We release two benchmarks -- RefusalBench-NQ (single document) and RefusalBench-GaRAGe (multi-document) -- and our complete generation framework to enable continued, dynamic evaluation of this critical capability.'}, {'id': 'arxiv_2510.14591', 'title': 'Just-In-Time Objectives: A General Approach for Specialized AI Interactions', 'URL': 'http://arxiv.org/abs/2510.14591', 'extra_urls': ['http://arxiv.org/abs/2510.14591'], 'type': 'article', 'author': [{'family': 'Lam', 'given': 'Michelle S.'}, {'family': 'Shaikh', 'given': 'Omar'}, {'family': 'Xu', 'given': 'Hallie'}, {'family': 'Guo', 'given': 'Alice'}, {'family': 'Yang', 'given': 'Diyi'}, {'family': 'Heer', 'given': 'Jeffrey'}, {'family': 'Landay', 'given': 'James A.'}, {'family': 'Bernstein', 'given': 'Michael S.'}], 'publisher': 'arXiv', 'abstract': 'Large language models promise a broad set of functions, but when not given a specific objective, they default to milquetoast results such as drafting emails littered with cliches. We demonstrate that inferring the user\'s in-the-moment objective, then rapidly optimizing for that singular objective, enables LLMs to produce tools, interfaces, and responses that are more responsive and desired. We contribute an architecture for automatically inducing just-in-time objectives by passively observing user behavior, then steering downstream AI systems through generation and evaluation against this objective. Inducing just-in-time objectives (e.g., "Clarify the abstract\'s research contribution") enables automatic generation of tools, e.g., those that critique a draft based on relevant HCI methodologies, anticipate related researchers\' reactions, or surface ambiguous terminology. In a series of experiments (N=14, N=205) on participants\' own tasks, JIT objectives enable LLM outputs that achieve 66-86% win rates over typical LLMs, and in-person use sessions (N=17) confirm that JIT objectives produce specialized tools unique to each participant.'}, {'id': 'uncovering_confident', 'title': 'Uncovering Confident Failures: The Complementary Roles of Aleatoric and Epistemic Uncertainty in LLMs', 'URL': 'https://openreview.net/forum?id=9Jq7wNrpUI#discussion', 'extra_urls': ['https://openreview.net/forum?id=9Jq7wNrpUI#discussion'], 'type': 'article', 'author': [{'family': 'Hamidieh', 'given': 'Kimia'}, {'family': 'Thost', 'given': 'Veronika'}, {'family': 'Gerych', 'given': 'Walter'}, {'family': 'Yurochkin', 'given': 'Mikhail'}, {'family': 'Ghassemi', 'given': 'Marzyeh'}], 'abstract': 'Large language models (LLMs) often produce confident yet incorrect responses, and uncertainty quantification in LLMs is one potential solution to more robust usage. Recent works routinely rely on self-consistency to estimate aleatoric uncertainty (AU), yet this proxy collapses precisely when models are overconfident, and produce the same incorrect answer across samples. We address this failure mode by introducing an epistemic term that measures semantic disagreement across a small ensemble of scale-matched LLMs. Specifically, we operationalize epistemic uncertainty (EU) as the gap between inter-model and intra-model response similarity, and define total uncertainty (TU) as the sum of AU and EU. The estimator is training-free and uses only black-box outputs: a few responses per model suffice. Across a range of LLMs, and long-form generation tasks, we compare TU to AU and measure uncertainty calibration by AUROC with respect to correctness and selective abstention via uncertainty thresholding. We find that TU consistently achieves higher AUROC in predicting correctness and improves selective abstention compared to AU alone. EU further exposes confident errors that AU misses, especially on tasks with near-unique correct answers, and improves the reliability of LLM uncertainty estimates.'}, {'id': 'arxiv_2508.01208', 'title': 'Calibrated Prediction Set in Fault Detection with Risk Guarantees via Significance Tests', 'URL': 'http://arxiv.org/abs/2508.01208', 'extra_urls': ['http://arxiv.org/abs/2508.01208'], 'type': 'article', 'author': [{'family': 'Mei', 'given': 'Mingchen'}, {'family': 'Li', 'given': 'Yi'}, {'family': 'Qian', 'given': 'YiYao'}, {'family': 'Jia', 'given': 'Zijun'}], 'publisher': 'arXiv', 'abstract': 'Fault detection is crucial for ensuring the safety and reliability of modern industrial systems. However, a significant scientific challenge is the lack of rigorous risk control and reliable uncertainty quantification in existing diagnostic models, particularly when facing complex scenarios such as distributional shifts. To address this issue, this paper proposes a novel fault detection method that integrates significance testing with the conformal prediction framework to provide formal risk guarantees. The method transforms fault detection into a hypothesis testing task by defining a nonconformity measure based on model residuals. It then leverages a calibration dataset to compute p-values for new samples, which are used to construct prediction sets mathematically guaranteed to contain the true label with a user-specified probability, $1-\\alpha$. Fault classification is subsequently performed by analyzing the intersection of the constructed prediction set with predefined normal and fault label sets. Experimental results on cross-domain fault diagnosis tasks validate the theoretical properties of our approach. The proposed method consistently achieves an empirical coverage rate at or above the nominal level ($1-\\alpha$), demonstrating robustness even when the underlying point-prediction models perform poorly. Furthermore, the results reveal a controllable trade-off between the user-defined risk level ($\\alpha$) and efficiency, where higher risk tolerance leads to smaller average prediction set sizes. This research contributes a theoretically grounded framework for fault detection that enables explicit risk control, enhancing the trustworthiness of diagnostic systems in safety-critical applications and advancing the field from simple point predictions to informative, uncertainty-aware outputs.'}, {'id': 'arxiv_2509.24202', 'title': 'Can Large Language Models Express Uncertainty Like Human?', 'URL': 'http://arxiv.org/abs/2509.24202', 'extra_urls': ['http://arxiv.org/abs/2509.24202'], 'type': 'article', 'author': [{'family': 'Tao', 'given': 'Linwei'}, {'family': 'Yeh', 'given': 'Yi-Fan'}, {'family': 'Kai', 'given': 'Bo'}, {'family': 'Dong', 'given': 'Minjing'}, {'family': 'Huang', 'given': 'Tao'}, {'family': 'Lamb', 'given': 'Tom A.'}, {'family': 'Yu', 'given': 'Jialin'}, {'family': 'Torr', 'given': 'Philip H. S.'}, {'family': 'Xu', 'given': 'Chang'}], 'publisher': 'arXiv', 'abstract': 'Large language models (LLMs) are increasingly used in high-stakes settings, where overconfident responses can mislead users. Reliable confidence estimation has been shown to enhance trust and task accuracy. Yet existing methods face practical barriers: logits are often hidden, multi-sampling is computationally expensive, and verbalized numerical uncertainty (e.g., giving a 0-100 score) deviates from natural communication. We revisit linguistic confidence (LC), where models express uncertainty through hedging language (e.g., probably, might), offering a lightweight and human-centered alternative. To advance this direction, we (1) release the first diverse, large-scale dataset of hedging expressions with human-annotated confidence scores, and (2) propose a lightweight mapper that converts hedges into confidence scores at near-zero cost. Building on these resources, we (3) conduct the first systematic study of LC across modern LLMs and QA benchmarks, revealing that while most LLMs underperform in expressing reliable LC, carefully designed prompting achieves competitive calibration and discriminability. Finally, we (4) introduce a fine-tuning framework that further improves LC reliability. Taken together, our work positions linguistic confidence as a scalable, efficient, and human-aligned approach to LLM uncertainty estimation, and calls for deeper exploration of this promising yet underexplored direction.'}, {'id': 'federated_learning', 'title': 'Confusion-Resistant Federated Learning via Diffusion-Based Data Harmonization on Non-IID Data', 'URL': 'https://openreview.net/forum?id=G89r8Mgi5r', 'extra_urls': ['https://openreview.net/forum?id=G89r8Mgi5r'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Xiaohong'}, {'family': 'Xiao', 'given': 'Canran'}, {'family': 'Liu', 'given': 'Yongmei'}], 'abstract': 'Federated learning has become a pivotal distributed learning paradigm, involving collaborative model updates across multiple nodes with private data. However, handling non-i.i.d. (not identically and independently distributed) data and ensuring model consistency across heterogeneous environments present significant challenges. These challenges often lead to model performance degradation and increased difficulty in achieving effective communication among participant models. In this work, we propose Confusion-Resistant Federated Learning via Consistent Diffusion (CRFed), a novel framework designed to address these issues. Our approach introduces a new diffusion-based data harmonization mechanism that includes data augmentation, noise injection, and iterative denoising to ensure consistent model updates across non-i.i.d. data distributions. This mechanism aims to reduce data distribution disparities among participating nodes, enhancing the coordination and consistency of model updates. Moreover, we design a confusion-resistant strategy leveraging an indicator function and adaptive learning rate adjustment to mitigate the adverse effects of data heterogeneity and model inconsistency. Specifically, we calculate importance sampling weights based on the optimal sampling probability, which guides the selection of clients and the sampling of their data, ensuring that model updates are robust and aligned across different nodes. Extensive experiments on benchmark datasets, including MNIST, FashionMNIST, CIFAR-10, CIFAR-100, and NIPD, demonstrate the effectiveness of CRFed in improving accuracy, convergence speed, and overall robustness in federated learning scenarios with severe data heterogeneity.'}, {'id': 'integrating_graceful_degradation', 'title': 'Integrating Graceful Degradation and Recovery through Requirement-driven Adaptation', 'URL': 'https://dl.acm.org/doi/10.1145/3643915.3644090', 'type': 'article', 'author': [{'family': 'Chu', 'given': 'Simon'}, {'family': 'Koe', 'given': 'Justin'}, {'family': 'Garlan', 'given': 'David'}, {'family': 'Kang', 'given': 'Eunsuk'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Cyber-physical systems (CPS) are subject to environmental uncertainties such as adverse operating conditions, malicious attacks, and hardware degradation. These uncertainties may lead to failures that put the system in a sub-optimal or unsafe state. Systems that are resilient to such uncertainties rely on two types of operations: (1) graceful degradation, for ensuring that the system maintains an acceptable level of safety during unexpected environmental conditions and (2) recovery, to facilitate the resumption of normal system functions. Typically, mechanisms for degradation and recovery are developed independently from each other, and later integrated into a system, requiring the designer to develop an additional, ad-hoc logic for activating and coordinating between the two operations.In this paper, we propose a self-adaptation approach for improving system resiliency through automated triggering and coordination of graceful degradation and recovery. The key idea behind our approach is to treat degradation and recovery as requirement-driven adaptation tasks: Degradation can be thought of as temporarily weakening original (i.e., ideal) system requirements to be achieved by the system, and recovery as strengthening the weakened requirements when the environment returns within an expected operating boundary. Furthermore, by treating weakening and strengthening as dual operations, we argue that a single requirement-based adaptation method is sufficient to enable coordination between degradation and recovery. Given system requirements specified in signal temporal logic (STL), we propose a run-time adaptation framework that performs degradation and recovery in response to environmental changes. We describe a prototype implementation of our framework and demonstrate the feasibility of the proposed approach using a case study in unmanned underwater vehicles.'}, {'id': 'arxiv_2502.14743', 'title': 'Multi-Agent Coordination across Diverse Applications: A Survey', 'URL': 'http://arxiv.org/abs/2502.14743', 'extra_urls': ['http://arxiv.org/abs/2502.14743'], 'type': 'article', 'author': [{'family': 'Sun', 'given': 'Lijun'}, {'family': 'Yang', 'given': 'Yijun'}, {'family': 'Duan', 'given': 'Qiqi'}, {'family': 'Shi', 'given': 'Yuhui'}, {'family': 'Lyu', 'given': 'Chao'}, {'family': 'Chang', 'given': 'Yu-Cheng'}, {'family': 'Lin', 'given': 'Chin-Teng'}, {'family': 'Shen', 'given': 'Yang'}], 'publisher': 'arXiv', 'abstract': 'Multi-agent coordination studies the underlying mechanism enabling the trending spread of diverse multi-agent systems (MAS) and has received increasing attention, driven by the expansion of emerging applications and rapid AI advances. This survey outlines the current state of coordination research across applications through a unified understanding that answers four fundamental coordination questions: (1) what is coordination; (2) why coordination; (3) who to coordinate with; and (4) how to coordinate. Our purpose is to explore existing ideas and expertise in coordination and their connections across diverse applications, while identifying and highlighting emerging and promising research directions. First, general coordination problems that are essential to varied applications are identified and analyzed. Second, a number of MAS applications are surveyed, ranging from widely studied domains, e.g., search and rescue, warehouse automation and logistics, and transportation systems, to emerging fields including humanoid and anthropomorphic robots, satellite systems, and large language models (LLMs). Finally, open challenges about the scalability, heterogeneity, and learning mechanisms of MAS are analyzed and discussed. In particular, we identify the hybridization of hierarchical and decentralized coordination, human-MAS coordination, and LLM-based MAS as promising future directions.'}, {'id': 'arxiv_2504.00587', 'title': 'AgentNet: Decentralized Evolutionary Coordination for LLM-based Multi-Agent Systems', 'URL': 'http://arxiv.org/abs/2504.00587', 'extra_urls': ['http://arxiv.org/abs/2504.00587'], 'type': 'article', 'author': [{'family': 'Yang', 'given': 'Yingxuan'}, {'family': 'Chai', 'given': 'Huacan'}, {'family': 'Shao', 'given': 'Shuai'}, {'family': 'Song', 'given': 'Yuanyi'}, {'family': 'Qi', 'given': 'Siyuan'}, {'family': 'Rui', 'given': 'Renting'}, {'family': 'Zhang', 'given': 'Weinan'}], 'publisher': 'arXiv', 'abstract': 'The rapid advancement of large language models (LLMs) has enabled the development of multi-agent systems where multiple LLM-based agents collaborate on complex tasks. However, existing systems often rely on centralized coordination, leading to scalability bottlenecks, reduced adaptability, and single points of failure. Privacy and proprietary knowledge concerns further hinder cross-organizational collaboration, resulting in siloed expertise. We propose AgentNet, a decentralized, Retrieval-Augmented Generation (RAG)-based framework that enables LLM-based agents to specialize, evolve, and collaborate autonomously in a dynamically structured Directed Acyclic Graph (DAG). Unlike prior approaches with static roles or centralized control, AgentNet allows agents to adjust connectivity and route tasks based on local expertise and context. AgentNet introduces three key innovations: (1) a fully decentralized coordination mechanism that eliminates the need for a central orchestrator, enhancing robustness and emergent intelligence; (2) dynamic agent graph topology that adapts in real time to task demands, ensuring scalability and resilience; and (3) a retrieval-based memory system for agents that supports continual skill refinement and specialization. By minimizing centralized control and data exchange, AgentNet enables fault-tolerant, privacy-preserving collaboration across organizations. Experiments show that AgentNet achieves higher task accuracy than both single-agent and centralized multi-agent baselines.'}, {'id': 'arxiv_2311.05304', 'title': 'Data Valuation and Detections in Federated Learning', 'URL': 'http://arxiv.org/abs/2311.05304', 'extra_urls': ['http://arxiv.org/abs/2311.05304'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Wenqian'}, {'family': 'Fu', 'given': 'Shuran'}, {'family': 'Zhang', 'given': 'Fengrui'}, {'family': 'Pang', 'given': 'Yan'}], 'publisher': 'arXiv', 'abstract': 'Federated Learning (FL) enables collaborative model training while preserving the privacy of raw data. A challenge in this framework is the fair and efficient valuation of data, which is crucial for incentivizing clients to contribute high-quality data in the FL task. In scenarios involving numerous data clients within FL, it is often the case that only a subset of clients and datasets are pertinent to a specific learning task, while others might have either a negative or negligible impact on the model training process. This paper introduces a novel privacy-preserving method for evaluating client contributions and selecting relevant datasets without a pre-specified training algorithm in an FL task. Our proposed approach FedBary, utilizes Wasserstein distance within the federated context, offering a new solution for data valuation in the FL framework. This method ensures transparent data valuation and efficient computation of the Wasserstein barycenter and reduces the dependence on validation datasets. Through extensive empirical experiments and theoretical analyses, we demonstrate the potential of this data valuation method as a promising avenue for FL research.'}, {'id': 'fair_and_efficient', 'title': 'Fair and Efficient Contribution Valuation for Vertical Federated Learning', 'URL': 'https://openreview.net/forum?id=sLQb8q0sUi', 'extra_urls': ['https://openreview.net/forum?id=sLQb8q0sUi'], 'type': 'article', 'author': [{'family': 'Fan', 'given': 'Zhenan'}, {'family': 'Fang', 'given': 'Huang'}, {'family': 'Wang', 'given': 'Xinglu'}, {'family': 'Zhou', 'given': 'Zirui'}, {'family': 'Pei', 'given': 'Jian'}, {'family': 'Friedlander', 'given': 'Michael'}, {'family': 'Zhang', 'given': 'Yong'}], 'abstract': 'Federated learning is an emerging technology for training machine learning models across decentralized data sources without sharing data. Vertical federated learning, also known as feature-based federated learning, applies to scenarios where data sources have the same sample IDs but different feature sets. To ensure fairness among data owners, it is critical to objectively assess the contributions from different data sources and compensate the corresponding data owners accordingly. The Shapley value is a provably fair contribution valuation metric originating from cooperative game theory. However, its straight-forward computation requires extensively retraining a model on each potential combination of data sources, leading to prohibitively high communication and computation overheads due to multiple rounds of federated learning. To tackle this challenge, we propose a contribution valuation metric called vertical federated Shapley value (VerFedSV) based on the classic Shapley value. We show that VerFedSV not only satisfies many desirable properties of fairness but is also efficient to compute. Moreover, VerFedSV can be adapted to both synchronous and asynchronous vertical federated learning algorithms. Both theoretical analysis and extensive experimental results demonstrate the fairness, efficiency, adaptability, and effectiveness of VerFedSV.'}, {'id': 'arxiv_2506.17419', 'title': 'UProp: Investigating the Uncertainty Propagation of LLMs in Multi-Step Agentic Decision-Making', 'URL': 'http://arxiv.org/abs/2506.17419', 'extra_urls': ['http://arxiv.org/abs/2506.17419'], 'type': 'article', 'author': [{'family': 'Duan', 'given': 'Jinhao'}, {'family': 'Diffenderfer', 'given': 'James'}, {'family': 'Madireddy', 'given': 'Sandeep'}, {'family': 'Chen', 'given': 'Tianlong'}, {'family': 'Kailkhura', 'given': 'Bhavya'}, {'family': 'Xu', 'given': 'Kaidi'}], 'publisher': 'arXiv', 'abstract': 'As Large Language Models (LLMs) are integrated into safety-critical applications involving sequential decision-making in the real world, it is essential to know when to trust LLM decisions. Existing LLM Uncertainty Quantification (UQ) methods are primarily designed for single-turn question-answering formats, resulting in multi-step decision-making scenarios, e.g., LLM agentic system, being underexplored. In this paper, we introduce a principled, information-theoretic framework that decomposes LLM sequential decision uncertainty into two parts: (i) internal uncertainty intrinsic to the current decision, which is focused on existing UQ methods, and (ii) extrinsic uncertainty, a Mutual-Information (MI) quantity describing how much uncertainty should be inherited from preceding decisions. We then propose UProp, an efficient and effective extrinsic uncertainty estimator that converts the direct estimation of MI to the estimation of Pointwise Mutual Information (PMI) over multiple Trajectory-Dependent Decision Processes (TDPs). UProp is evaluated over extensive multi-step decision-making benchmarks, e.g., AgentBench and HotpotQA, with state-of-the-art LLMs, e.g., GPT-4.1 and DeepSeek-V3. Experimental results demonstrate that UProp significantly outperforms existing single-turn UQ baselines equipped with thoughtful aggregation strategies. Moreover, we provide a comprehensive analysis of UProp, including sampling efficiency, potential applications, and intermediate uncertainty propagation, to demonstrate its effectiveness. Codes will be available at https://github.com/jinhaoduan/UProp.'}, {'id': 'arxiv_2509.02401', 'title': "Towards Agents That Know When They Don't Know: Uncertainty as a Control Signal for Structured Reasoning", 'URL': 'http://arxiv.org/abs/2509.02401', 'extra_urls': ['http://arxiv.org/abs/2509.02401'], 'type': 'article', 'author': [{'family': 'Stoisser', 'given': 'Josefa Lia'}, {'family': 'Martell', 'given': 'Marc Boubnovski'}, {'family': 'Phillips', 'given': 'Lawrence'}, {'family': 'Mazzoni', 'given': 'Gianluca'}, {'family': 'Harder', 'given': 'Lea M\xf8rch'}, {'family': 'Torr', 'given': 'Philip'}, {'family': 'Ferkinghoff-Borg', 'given': 'Jesper'}, {'family': 'Martens', 'given': 'Kaspar'}, {'family': 'Fauqueur', 'given': 'Julien'}], 'publisher': 'arXiv', 'abstract': 'Large language model (LLM) agents are increasingly deployed in structured biomedical data environments, yet they often produce fluent but overconfident outputs when reasoning over complex multi-table data. We introduce an uncertainty-aware agent for query-conditioned multi-table summarization that leverages two complementary signals: (i) retrieval uncertainty--entropy over multiple table-selection rollouts--and (ii) summary uncertainty--combining self-consistency and perplexity. Summary uncertainty is incorporated into reinforcement learning (RL) with Group Relative Policy Optimization (GRPO), while both retrieval and summary uncertainty guide inference-time filtering and support the construction of higher-quality synthetic datasets. On multi-omics benchmarks, our approach improves factuality and calibration, nearly tripling correct and useful claims per summary (3.0\\(\\rightarrow\\)8.4 internal; 3.6\\(\\rightarrow\\)9.9 cancer multi-omics) and substantially improving downstream survival prediction (C-index 0.32\\(\\rightarrow\\)0.63). These results demonstrate that uncertainty can serve as a control signal--enabling agents to abstain, communicate confidence, and become more reliable tools for complex structured-data environments.'}, {'id': 'arxiv_2510.11414', 'title': 'Uncertainty-Aware, Risk-Adaptive Access Control for Agentic Systems using an LLM-Judged TBAC Model', 'URL': 'http://arxiv.org/abs/2510.11414', 'extra_urls': ['http://arxiv.org/abs/2510.11414'], 'type': 'article', 'author': [{'family': 'Fleming', 'given': 'Charles'}, {'family': 'Kundu', 'given': 'Ashish'}, {'family': 'Kompella', 'given': 'Ramana'}], 'publisher': 'arXiv', 'abstract': "The proliferation of autonomous AI agents within enterprise environments introduces a critical security challenge: managing access control for emergent, novel tasks for which no predefined policies exist. This paper introduces an advanced security framework that extends the Task-Based Access Control (TBAC) model by using a Large Language Model (LLM) as an autonomous, risk-aware judge. This model makes access control decisions not only based on an agent's intent but also by explicitly considering the inherent \\textbf{risk associated with target resources} and the LLM's own \\textbf{model uncertainty} in its decision-making process. When an agent proposes a novel task, the LLM judge synthesizes a just-in-time policy while also computing a composite risk score for the task and an uncertainty estimate for its own reasoning. High-risk or high-uncertainty requests trigger more stringent controls, such as requiring human approval. This dual consideration of external risk and internal confidence allows the model to enforce a more robust and adaptive version of the principle of least privilege, paving the way for safer and more trustworthy autonomous systems."}, {'id': 'arxiv_2504.15722', 'title': 'From predictions to confidence intervals: an empirical study of conformal prediction methods for in-context learning', 'URL': 'http://arxiv.org/abs/2504.15722', 'extra_urls': ['http://arxiv.org/abs/2504.15722'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Zhe'}, {'family': 'Rossi', 'given': 'Simone'}, {'family': 'Yuan', 'given': 'Rui'}, {'family': 'Hannagan', 'given': 'Thomas'}], 'publisher': 'arXiv', 'abstract': 'Transformers have become a standard architecture in machine learning, demonstrating strong in-context learning (ICL) abilities that allow them to learn from the prompt at inference time. However, uncertainty quantification for ICL remains an open challenge, particularly in noisy regression tasks. This paper investigates whether ICL can be leveraged for distribution-free uncertainty estimation, proposing a method based on conformal prediction to construct prediction intervals with guaranteed coverage. While traditional conformal methods are computationally expensive due to repeated model fitting, we exploit ICL to efficiently generate confidence intervals in a single forward pass. Our empirical analysis compares this approach against ridge regression-based conformal methods, showing that conformal prediction with in-context learning (CP with ICL) achieves robust and scalable uncertainty estimates. Additionally, we evaluate its performance under distribution shifts and establish scaling laws to guide model training. These findings bridge ICL and conformal prediction, providing a theoretically grounded and new framework for uncertainty quantification in transformer-based models.'}, {'id': 'arxiv_2508.07556', 'title': 'Uncertainty-Driven Reliability: Selective Prediction and Trustworthy Deployment in Modern Machine Learning', 'URL': 'http://arxiv.org/abs/2508.07556', 'extra_urls': ['http://arxiv.org/abs/2508.07556'], 'type': 'article', 'author': [{'family': 'Rabanser', 'given': 'Stephan'}], 'publisher': 'arXiv', 'abstract': 'Machine learning (ML) systems are increasingly deployed in high-stakes domains where reliability is paramount. This thesis investigates how uncertainty estimation can enhance the safety and trustworthiness of ML, focusing on selective prediction -- where models abstain when confidence is low. We first show that a model\'s training trajectory contains rich uncertainty signals that can be exploited without altering its architecture or loss. By ensembling predictions from intermediate checkpoints, we propose a lightweight, post-hoc abstention method that works across tasks, avoids the cost of deep ensembles, and achieves state-of-the-art selective prediction performance. Crucially, this approach is fully compatible with differential privacy (DP), allowing us to study how privacy noise affects uncertainty quality. We find that while many methods degrade under DP, our trajectory-based approach remains robust, and we introduce a framework for isolating the privacy-uncertainty trade-off. Next, we then develop a finite-sample decomposition of the selective classification gap -- the deviation from the oracle accuracy-coverage curve -- identifying five interpretable error sources and clarifying which interventions can close the gap. This explains why calibration alone cannot fix ranking errors, motivating methods that improve uncertainty ordering. Finally, we show that uncertainty signals can be adversarially manipulated to hide errors or deny service while maintaining high accuracy, and we design defenses combining calibration audits with verifiable inference. Together, these contributions advance reliable ML by improving, evaluating, and safeguarding uncertainty estimation, enabling models that not only make accurate predictions -- but also know when to say "I do not know".'}, {'id': 'arxiv_2510.13297', 'title': 'Federated Conditional Conformal Prediction via Generative Models', 'URL': 'http://arxiv.org/abs/2510.13297', 'extra_urls': ['http://arxiv.org/abs/2510.13297'], 'type': 'article', 'author': [{'family': 'Xu', 'given': 'Rui'}, {'family': 'Chen', 'given': 'Xingyuan'}, {'family': 'Huang', 'given': 'Wenxing'}, {'family': 'Huang', 'given': 'Minxuan'}, {'family': 'Xie', 'given': 'Yun'}, {'family': 'Chen', 'given': 'Weiyan'}, {'family': 'Xie', 'given': 'Sihong'}], 'publisher': 'arXiv', 'abstract': 'Conformal Prediction (CP) provides distribution-free uncertainty quantification by constructing prediction sets that guarantee coverage of the true labels. This reliability makes CP valuable for high-stakes federated learning scenarios such as multi-center healthcare. However, standard CP assumes i.i.d. data, which is violated in federated settings where client distributions differ substantially. Existing federated CP methods address this by maintaining marginal coverage on each client, but such guarantees often fail to reflect input-conditional uncertainty. In this work, we propose Federated Conditional Conformal Prediction (Fed-CCP) via generative models, which aims for conditional coverage that adapts to local data heterogeneity. Fed-CCP leverages generative models, such as normalizing flows or diffusion models, to approximate conditional data distributions without requiring the sharing of raw data. This enables each client to locally calibrate conformal scores that reflect its unique uncertainty, while preserving global consistency through federated aggregation. Experiments on real datasets demonstrate that Fed-CCP achieves more adaptive prediction sets.'}, {'id': 'arxiv_2510.15233', 'title': 'Adaptive Individual Uncertainty under Out-Of-Distribution Shift with Expert-Routed Conformal Prediction', 'URL': 'http://arxiv.org/abs/2510.15233', 'extra_urls': ['http://arxiv.org/abs/2510.15233'], 'type': 'article', 'author': [{'family': 'Badkul', 'given': 'Amitesh'}, {'family': 'Xie', 'given': 'Lei'}], 'publisher': 'arXiv', 'abstract': 'Reliable, informative, and individual uncertainty quantification (UQ) remains missing in current ML community. This hinders the effective application of AI/ML to risk-sensitive domains. Most methods either fail to provide coverage on new data, inflate intervals so broadly that they are not actionable, or assign uncertainties that do not track actual error, especially under a distribution shift. In high-stakes drug discovery, protein-ligand affinity (PLI) prediction is especially challenging as assay noise is heterogeneous, chemical space is imbalanced and large, and practical evaluations routinely involve distribution shift. In this work, we introduce a novel uncertainty quantification method, Trustworthy Expert Split-conformal with Scaled Estimation for Efficient Reliable Adaptive intervals (TESSERA), that provides per-sample uncertainty with reliable coverage guarantee, informative and adaptive prediction interval widths that track the absolute error. We evaluate on protein-ligand binding affinity prediction under both independent and identically distributed (i.i.d.) and scaffold-based out-of-distribution (OOD) splits, comparing against strong UQ baselines. TESSERA attains near-nominal coverage and the best coverage-width trade-off as measured by the Coverage-Width Criterion (CWC), while maintaining competitive adaptivity (lowest Area Under the Sparsification Error (AUSE)). Size-Stratified Coverage (SSC) further confirms that intervals are right-sized, indicating width increases when data are scarce or noisy, and remain tight when predictions are reliable. By unifying Mixture of Expert (MoE) diversity with conformal calibration, TESSERA delivers trustworthy, tight, and adaptive uncertainties that are well-suited to selective prediction and downstream decision-making in the drug-discovery pipeline and other applications.'}, {'id': 'arxiv_2509.13717', 'title': 'A Conformal Prediction Framework for Uncertainty Quantification in Physics-Informed Neural Networks', 'URL': 'http://arxiv.org/abs/2509.13717', 'extra_urls': ['http://arxiv.org/abs/2509.13717'], 'type': 'article', 'author': [{'family': 'Yu', 'given': 'Yifan'}, {'family': 'Ho', 'given': 'Cheuk Hin'}, {'family': 'Wang', 'given': 'Yangshuai'}], 'publisher': 'arXiv', 'abstract': 'Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving PDEs, yet existing uncertainty quantification (UQ) approaches for PINNs generally lack rigorous statistical guarantees. In this work, we bridge this gap by introducing a distribution-free conformal prediction (CP) framework for UQ in PINNs. This framework calibrates prediction intervals by constructing nonconformity scores on a calibration set, thereby yielding distribution-free uncertainty estimates with rigorous finite-sample coverage guarantees for PINNs. To handle spatial heteroskedasticity, we further introduce local conformal quantile estimation, enabling spatially adaptive uncertainty bands while preserving theoretical guarantee. Through systematic evaluations on typical PDEs (damped harmonic oscillator, Poisson, Allen-Cahn, and Helmholtz equations) and comprehensive testing across multiple uncertainty metrics, our results demonstrate that the proposed framework achieves reliable calibration and locally adaptive uncertainty intervals, consistently outperforming heuristic UQ approaches. By bridging PINNs with distribution-free UQ, this work introduces a general framework that not only enhances calibration and reliability, but also opens new avenues for uncertainty-aware modeling of complex PDE systems.'}, {'id': 'arxiv_2410.01767', 'title': 'Utility-Directed Conformal Prediction: A Decision-Aware Framework for Actionable Uncertainty Quantification', 'URL': 'http://arxiv.org/abs/2410.01767', 'extra_urls': ['http://arxiv.org/abs/2410.01767'], 'type': 'article', 'author': [{'family': 'Cortes-Gomez', 'given': 'Santiago'}, {'family': 'Pati\xf1o', 'given': 'Carlos'}, {'family': 'Byun', 'given': 'Yewon'}, {'family': 'Wu', 'given': 'Steven'}, {'family': 'Horvitz', 'given': 'Eric'}, {'family': 'Wilder', 'given': 'Bryan'}], 'publisher': 'arXiv', 'abstract': 'Interest has been growing in decision-focused machine learning methods which train models to account for how their predictions are used in downstream optimization problems. Doing so can often improve performance on subsequent decision problems. However, current methods for uncertainty quantification do not incorporate any information about downstream decisions. We develop a methodology based on conformal prediction to identify prediction sets that account for a downstream cost function, making them more appropriate to inform high-stakes decision-making. Our approach harnesses the strengths of conformal methods -- modularity, model-agnosticism, and statistical coverage guarantees -- while incorporating downstream decisions and user-specified utility functions. We prove that our methods retain standard coverage guarantees. Empirical evaluation across a range of datasets and utility metrics demonstrates that our methods achieve significantly lower costs than standard conformal methods. We present a real-world use case in healthcare diagnosis, where our method effectively incorporates the hierarchical structure of dermatological diseases. The method successfully generates sets with coherent diagnostic meaning, potentially aiding triage for dermatology diagnosis and illustrating how our method can ground high-stakes decision-making employing domain knowledge.'}, {'id': 'arxiv_2510.15103', 'title': 'Continual Learning via Sparse Memory Finetuning', 'URL': 'http://arxiv.org/abs/2510.15103', 'extra_urls': ['http://arxiv.org/abs/2510.15103'], 'type': 'article', 'author': [{'family': 'Lin', 'given': 'Jessy'}, {'family': 'Zettlemoyer', 'given': 'Luke'}, {'family': 'Ghosh', 'given': 'Gargi'}, {'family': 'Yih', 'given': 'Wen-Tau'}, {'family': 'Markosyan', 'given': 'Aram'}, {'family': 'Berges', 'given': 'Vincent-Pierre'}, {'family': 'O\u011fuz', 'given': 'Barlas'}], 'publisher': 'arXiv', 'abstract': "Modern language models are powerful, but typically static after deployment. A major obstacle to building models that continually learn over time is catastrophic forgetting, where updating on new data erases previously acquired capabilities. Motivated by the intuition that mitigating forgetting is challenging because trainable parameters are shared across all tasks, we investigate whether sparse parameter updates can enable learning without catastrophic forgetting. We introduce sparse memory finetuning, leveraging memory layer models (Berges et al., 2024), which are sparsely updated by design. By updating only the memory slots that are highly activated by a new piece of knowledge relative to usage on pretraining data, we reduce interference between new knowledge and the model's existing capabilities. We evaluate learning and forgetting compared to full finetuning and parameter-efficient finetuning with LoRA on two question answering tasks. We find that sparse memory finetuning learns new knowledge while exhibiting substantially less forgetting: while NaturalQuestions F1 drops by 89% after full finetuning on new facts and 71% with LoRA, sparse memory finetuning yields only an 11% drop with the same level of new knowledge acquisition. Our results suggest sparsity in memory layers offers a promising path toward continual learning in large language models."}, {'id': 'arxiv_2506.04133', 'title': 'TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems', 'URL': 'http://arxiv.org/abs/2506.04133', 'extra_urls': ['http://arxiv.org/abs/2506.04133'], 'type': 'article', 'author': [{'family': 'Raza', 'given': 'Shaina'}, {'family': 'Sapkota', 'given': 'Ranjan'}, {'family': 'Karkee', 'given': 'Manoj'}, {'family': 'Emmanouilidis', 'given': 'Christos'}], 'publisher': 'arXiv', 'abstract': 'Agentic AI systems, built upon large language models (LLMs) and deployed in multi-agent configurations, are redefining intelligence, autonomy, collaboration, and decision-making across enterprise and societal domains. This review presents a structured analysis of Trust, Risk, and Security Management (TRiSM) in the context of LLM-based Agentic Multi-Agent Systems (AMAS). We begin by examining the conceptual foundations of Agentic AI and highlight its architectural distinctions from traditional AI agents. We then adapt and extend the AI TRiSM framework for Agentic AI, structured around key pillars: \\textit{ Explainability, ModelOps, Security, Privacy} and \\textit{their Lifecycle Governance}, each contextualized to the challenges of AMAS. A risk taxonomy is proposed to capture the unique threats and vulnerabilities of Agentic AI, ranging from coordination failures to prompt-based adversarial manipulation. To support practical assessment in Agentic AI works, we introduce two novel metrics: the Component Synergy Score (CSS), which quantifies the quality of inter-agent collaboration, and the Tool Utilization Efficacy (TUE), which evaluates the efficiency of tool use within agent workflows. We further discuss strategies for improving explainability in Agentic AI, as well as approaches to enhancing security and privacy through encryption, adversarial robustness, and regulatory compliance. The review concludes with a research roadmap for the responsible development and deployment of Agentic AI, highlighting key directions to align emerging systems with TRiSM principles-ensuring safety, transparency, and accountability in their operation.'}, {'id': 'arxiv_2508.08997', 'title': 'Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory', 'URL': 'http://arxiv.org/abs/2508.08997', 'extra_urls': ['http://arxiv.org/abs/2508.08997'], 'type': 'article', 'author': [{'family': 'Yuen', 'given': 'Sizhe'}, {'family': 'Medina', 'given': 'Francisco Gomez'}, {'family': 'Su', 'given': 'Ting'}, {'family': 'Du', 'given': 'Yali'}, {'family': 'Sobey', 'given': 'Adam J.'}], 'publisher': 'arXiv', 'abstract': 'Multi-agent systems built on Large Language Models (LLMs) show exceptional promise for complex collaborative problem-solving, yet they face fundamental challenges stemming from context window limitations that impair memory consistency, role adherence, and procedural integrity. This paper introduces Intrinsic Memory Agents, a novel framework that addresses these limitations through structured agent-specific memories that evolve intrinsically with agent outputs. Specifically, our method maintains role-aligned memory templates that preserve specialized perspectives while focusing on task-relevant information. We benchmark our approach on the PDDL dataset, comparing its performance to existing state-of-the-art multi-agentic memory approaches and showing an improvement of 38.6\\% with the highest token efficiency. An additional evaluation is performed on a complex data pipeline design task, we demonstrate that our approach produces higher quality designs when comparing 5 metrics: scalability, reliability, usability, cost-effectiveness and documentation with additional qualitative evidence of the improvements. Our findings suggest that addressing memory limitations through structured, intrinsic approaches can improve the capabilities of multi-agent LLM systems on structured planning tasks.'}, {'id': 'arxiv_2508.18765', 'title': 'Governance-as-a-Service: A Multi-Agent Framework for AI System Compliance and Policy Enforcement', 'URL': 'http://arxiv.org/abs/2508.18765', 'extra_urls': ['http://arxiv.org/abs/2508.18765'], 'type': 'article', 'author': [{'family': 'Gaurav', 'given': 'Suyash'}, {'family': 'Heikkonen', 'given': 'Jukka'}, {'family': 'Chaudhary', 'given': 'Jatin'}], 'publisher': 'arXiv', 'abstract': 'As AI systems evolve into distributed ecosystems with autonomous execution, asynchronous reasoning, and multi-agent coordination, the absence of scalable, decoupled governance poses a structural risk. Existing oversight mechanisms are reactive, brittle, and embedded within agent architectures, making them non-auditable and hard to generalize across heterogeneous deployments. We introduce Governance-as-a-Service (GaaS): a modular, policy-driven enforcement layer that regulates agent outputs at runtime without altering model internals or requiring agent cooperation. GaaS employs declarative rules and a Trust Factor mechanism that scores agents based on compliance and severity-weighted violations. It enables coercive, normative, and adaptive interventions, supporting graduated enforcement and dynamic trust modulation. To evaluate GaaS, we conduct three simulation regimes with open-source models (LLaMA3, Qwen3, DeepSeek-R1) across content generation and financial decision-making. In the baseline, agents act without governance; in the second, GaaS enforces policies; in the third, adversarial agents probe robustness. All actions are intercepted, evaluated, and logged for analysis. Results show that GaaS reliably blocks or redirects high-risk behaviors while preserving throughput. Trust scores track rule adherence, isolating and penalizing untrustworthy components in multi-agent systems. By positioning governance as a runtime service akin to compute or storage, GaaS establishes infrastructure-level alignment for interoperable agent ecosystems. It does not teach agents ethics; it enforces them.'}, {'id': 'arxiv_2404.10142', 'title': 'Shaping Realities: Enhancing 3D Generative AI with Fabrication Constraints', 'URL': 'http://arxiv.org/abs/2404.10142', 'extra_urls': ['http://arxiv.org/abs/2404.10142'], 'type': 'article', 'author': [{'family': 'Faruqi', 'given': 'Faraz'}, {'family': 'Tian', 'given': 'Yingtao'}, {'family': 'Phadnis', 'given': 'Vrushank'}, {'family': 'Jampani', 'given': 'Varun'}, {'family': 'Mueller', 'given': 'Stefanie'}], 'publisher': 'arXiv', 'abstract': 'Generative AI tools are becoming more prevalent in 3D modeling, enabling users to manipulate or create new models with text or images as inputs. This makes it easier for users to rapidly customize and iterate on their 3D designs and explore new creative ideas. These methods focus on the aesthetic quality of the 3D models, refining them to look similar to the prompts provided by the user. However, when creating 3D models intended for fabrication, designers need to trade-off the aesthetic qualities of a 3D model with their intended physical properties. To be functional post-fabrication, 3D models have to satisfy structural constraints informed by physical principles. Currently, such requirements are not enforced by generative AI tools. This leads to the development of aesthetically appealing, but potentially non-functional 3D geometry, that would be hard to fabricate and use in the real world. This workshop paper highlights the limitations of generative AI tools in translating digital creations into the physical world and proposes new augmentations to generative AI tools for creating physically viable 3D models. We advocate for the development of tools that manipulate or generate 3D models by considering not only the aesthetic appearance but also using physical properties as constraints. This exploration seeks to bridge the gap between digital creativity and real-world applicability, extending the creative potential of generative AI into the tangible domain.'}, {'id': 'accumulative_fidelity_maximization', 'title': 'Accumulative Fidelity Maximization of Inference Services in DT-Assisted Edge Computing', 'URL': 'https://ieeexplore.ieee.org/document/11062774', 'extra_urls': ['https://ieeexplore.ieee.org/document/11062774'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Jing'}, {'family': 'Liang', 'given': 'Weifa'}, {'family': 'Wang', 'given': 'Jianping'}, {'family': 'Jia', 'given': 'Xiaohua'}], 'abstract': 'Digital twin (DT) technology illuminates the smooth integration of cyber and physical worlds in alignment with the Industry 4.0 initiative. Through synchronizations with physical objects, DTs of objects can reflect the states of the objects with high fidelity. Machine learning-based service models through continual training by the DT update data can provide users with accurate inference services. Orthogonal to the DT technology, mobile edge computing (MEC) is a promising computing paradigm that shifts computing power to the edge network, which is particularly appropriate for delay-sensitive intelligent services. In this paper, we study the fidelity enhancement of service models in a DT-assisted edge computing environment empowered by 6G communication, through continuously training service models, using DT update data obtained from their mobile \\mathbfIoT devices (objects) in a real-time manner. To this end, we first formulate an accumulative fidelity maximization problem that jointly considers the placement of DTs and models, with the aim to maximize the accumulative fidelity gain of all models while minimizing the total cost of resource consumed due to DT updating and service model training. We then develop an efficient algorithm for a sub-optimization problem - the placement problem of DTs and models, under the assumption that the mobility profile of each mobile object is given. When both DTs and models have already been placed, we devise an algorithm for the accumulative fidelity maximization problem that schedules each object to choose an access point (AP) to upload its update data at each time slot for a given time horizon to maximize the accumulative fidelity of all service models while minimizing the total cost of various resources consumed. We finally evaluate the performance of the proposed algorithms through simulations. Simulation results indicate that the proposed algorithms are promising, and outperform their baselines nearly by 20%.'}, {'id': 'regtech_and', 'title': 'FinTech, RegTech and the Reconceptualization of Financial Regulation', 'URL': 'https://papers.ssrn.com/abstract=2847806', 'extra_urls': ['https://papers.ssrn.com/abstract=2847806'], 'type': 'article', 'author': [{'family': 'Arner', 'given': 'Douglas W.'}, {'family': 'Barberis', 'given': 'Janos Nathan'}, {'family': 'Buckley', 'given': 'Ross P.'}], 'publisher': 'Social Science Research Network', 'abstract': 'The regulatory changes and technological developments following the 2008 Global Financial Crisis are fundamentally changing the nature of financial markets, services and institutions. At the juncture of these two phenomena lies regulatory technology or \u2018RegTech\u2019 \u2013 the use of technology, particularly information technology, in the context of regulatory monitoring, reporting and compliance.'}, {'id': 'arxiv_2407.18418', 'title': 'Know Your Limits: A Survey of Abstention in Large Language Models', 'URL': 'https://arxiv.org/abs/2407.18418', 'extra_urls': ['https://arxiv.org/abs/2407.18418'], 'type': 'article', 'author': [{'family': 'Bingbing Wen'}, {'family': 'Jihan Yao'}, {'family': 'Shangbin Feng'}, {'family': 'Chenjun Xu'}, {'family': 'Yulia Tsvetkov'}, {'family': 'Bill Howe'}, {'family': 'Lucy Lu Wang'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2507.15439', 'title': 'Human vs. Algorithmic Auditors: The Impact of Entity Type and Ambiguity   on Human Dishonesty', 'URL': 'https://arxiv.org/abs/2507.15439', 'extra_urls': ['https://arxiv.org/abs/2507.15439'], 'type': 'article', 'author': [{'family': 'Marius Protte'}, {'family': 'Behnud Mir Djawadi'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.15918', 'title': 'Extracting Probabilistic Knowledge from Large Language Models for   Bayesian Network Parameterization', 'URL': 'https://arxiv.org/abs/2505.15918', 'extra_urls': ['https://arxiv.org/abs/2505.15918'], 'type': 'article', 'author': [{'family': 'Aliakbar Nafar'}, {'family': 'Kristen Brent Venable'}, {'family': 'Zijun Cui'}, {'family': 'Parisa Kordjamshidi'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2405.06258', 'title': 'Automatic Generation of Model and Data Cards: A Step Towards Responsible   AI', 'URL': 'https://arxiv.org/abs/2405.06258', 'extra_urls': ['https://arxiv.org/abs/2405.06258'], 'type': 'article', 'author': [{'family': 'Jiarui Liu'}, {'family': 'Wenkai Li'}, {'family': 'Zhijing Jin'}, {'family': 'Mona Diab'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2307.15475', 'title': 'FeedbackLogs: Recording and Incorporating Stakeholder Feedback into   Machine Learning Pipelines', 'URL': 'https://arxiv.org/abs/2307.15475', 'extra_urls': ['https://arxiv.org/abs/2307.15475'], 'type': 'article', 'author': [{'family': 'Matthew Barker'}, {'family': 'Emma Kallina'}, {'family': 'Dhananjay Ashok'}, {'family': 'Katherine M. Collins'}, {'family': 'Ashley Casovan'}, {'family': 'Adrian Weller'}, {'family': 'Ameet Talwalkar'}, {'family': 'Valerie Chen'}, {'family': 'Umang Bhatt'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2303.08774', 'title': 'GPT-4 Technical Report', 'URL': 'https://arxiv.org/abs/2303.08774', 'extra_urls': ['https://arxiv.org/abs/2303.08774'], 'type': 'article', 'author': [{'family': 'OpenAI'}, {'family': 'Josh Achiam'}, {'family': 'Steven Adler'}, {'family': 'Sandhini Agarwal'}, {'family': 'Lama Ahmad'}, {'family': 'Ilge Akkaya'}, {'family': 'Florencia Leoni Aleman'}, {'family': 'Diogo Almeida'}, {'family': 'Janko Altenschmidt'}, {'family': 'Sam Altman'}, {'family': 'Shyamal Anadkat'}, {'family': 'Red Avila'}, {'family': 'Igor Babuschkin'}, {'family': 'Suchir Balaji'}, {'family': 'Valerie Balcom'}, {'family': 'Paul Baltescu'}, {'family': 'Haiming Bao'}, {'family': 'Mohammad Bavarian'}, {'family': 'Jeff Belgum'}, {'family': 'Irwan Bello'}, {'family': 'Jake Berdine'}, {'family': 'Gabriel Bernadett-Shapiro'}, {'family': 'Christopher Berner'}, {'family': 'Lenny Bogdonoff'}, {'family': 'Oleg Boiko'}, {'family': 'Madelaine Boyd'}, {'family': 'Anna-Luisa Brakman'}, {'family': 'Greg Brockman'}, {'family': 'Tim Brooks'}, {'family': 'Miles Brundage'}, {'family': 'Kevin Button'}, {'family': 'Trevor Cai'}, {'family': 'Rosie Campbell'}, {'family': 'Andrew Cann'}, {'family': 'Brittany Carey'}, {'family': 'Chelsea Carlson'}, {'family': 'Rory Carmichael'}, {'family': 'Brooke Chan'}, {'family': 'Che Chang'}, {'family': 'Fotis Chantzis'}, {'family': 'Derek Chen'}, {'family': 'Sully Chen'}, {'family': 'Ruby Chen'}, {'family': 'Jason Chen'}, {'family': 'Mark Chen'}, {'family': 'Ben Chess'}, {'family': 'Chester Cho'}, {'family': 'Casey Chu'}, {'family': 'Hyung Won Chung'}, {'family': 'Dave Cummings'}, {'family': 'Jeremiah Currier'}, {'family': 'Yunxing Dai'}, {'family': 'Cory Decareaux'}, {'family': 'Thomas Degry'}, {'family': 'Noah Deutsch'}, {'family': 'Damien Deville'}, {'family': 'Arka Dhar'}, {'family': 'David Dohan'}, {'family': 'Steve Dowling'}, {'family': 'Sheila Dunning'}, {'family': 'Adrien Ecoffet'}, {'family': 'Atty Eleti'}, {'family': 'Tyna Eloundou'}, {'family': 'David Farhi'}, {'family': 'Liam Fedus'}, {'family': 'Niko Felix'}, {'family': 'Sim\xf3n Posada Fishman'}, {'family': 'Juston Forte'}, {'family': 'Isabella Fulford'}, {'family': 'Leo Gao'}, {'family': 'Elie Georges'}, {'family': 'Christian Gibson'}, {'family': 'Vik Goel'}, {'family': 'Tarun Gogineni'}, {'family': 'Gabriel Goh'}, {'family': 'Rapha Gontijo-Lopes'}, {'family': 'Jonathan Gordon'}, {'family': 'Morgan Grafstein'}, {'family': 'Scott Gray'}, {'family': 'Ryan Greene'}, {'family': 'Joshua Gross'}, {'family': 'Shixiang Shane Gu'}, {'family': 'Yufei Guo'}, {'family': 'Chris Hallacy'}, {'family': 'Jesse Han'}, {'family': 'Jeff Harris'}, {'family': 'Yuchen He'}, {'family': 'Mike Heaton'}, {'family': 'Johannes Heidecke'}, {'family': 'Chris Hesse'}, {'family': 'Alan Hickey'}, {'family': 'Wade Hickey'}, {'family': 'Peter Hoeschele'}, {'family': 'Brandon Houghton'}, {'family': 'Kenny Hsu'}, {'family': 'Shengli Hu'}, {'family': 'Xin Hu'}, {'family': 'Joost Huizinga'}, {'family': 'Shantanu Jain'}, {'family': 'Shawn Jain'}, {'family': 'Joanne Jang'}, {'family': 'Angela Jiang'}, {'family': 'Roger Jiang'}, {'family': 'Haozhun Jin'}, {'family': 'Denny Jin'}, {'family': 'Shino Jomoto'}, {'family': 'Billie Jonn'}, {'family': 'Heewoo Jun'}, {'family': 'Tomer Kaftan'}, {'family': '\u0141ukasz Kaiser'}, {'family': 'Ali Kamali'}, {'family': 'Ingmar Kanitscheider'}, {'family': 'Nitish Shirish Keskar'}, {'family': 'Tabarak Khan'}, {'family': 'Logan Kilpatrick'}, {'family': 'Jong Wook Kim'}, {'family': 'Christina Kim'}, {'family': 'Yongjik Kim'}, {'family': 'Jan Hendrik Kirchner'}, {'family': 'Jamie Kiros'}, {'family': 'Matt Knight'}, {'family': 'Daniel Kokotajlo'}, {'family': '\u0141ukasz Kondraciuk'}, {'family': 'Andrew Kondrich'}, {'family': 'Aris Konstantinidis'}, {'family': 'Kyle Kosic'}, {'family': 'Gretchen Krueger'}, {'family': 'Vishal Kuo'}, {'family': 'Michael Lampe'}, {'family': 'Ikai Lan'}, {'family': 'Teddy Lee'}, {'family': 'Jan Leike'}, {'family': 'Jade Leung'}, {'family': 'Daniel Levy'}, {'family': 'Chak Ming Li'}, {'family': 'Rachel Lim'}, {'family': 'Molly Lin'}, {'family': 'Stephanie Lin'}, {'family': 'Mateusz Litwin'}, {'family': 'Theresa Lopez'}, {'family': 'Ryan Lowe'}, {'family': 'Patricia Lue'}, {'family': 'Anna Makanju'}, {'family': 'Kim Malfacini'}, {'family': 'Sam Manning'}, {'family': 'Todor Markov'}, {'family': 'Yaniv Markovski'}, {'family': 'Bianca Martin'}, {'family': 'Katie Mayer'}, {'family': 'Andrew Mayne'}, {'family': 'Bob McGrew'}, {'family': 'Scott Mayer McKinney'}, {'family': 'Christine McLeavey'}, {'family': 'Paul McMillan'}, {'family': 'Jake McNeil'}, {'family': 'David Medina'}, {'family': 'Aalok Mehta'}, {'family': 'Jacob Menick'}, {'family': 'Luke Metz'}, {'family': 'Andrey Mishchenko'}, {'family': 'Pamela Mishkin'}, {'family': 'Vinnie Monaco'}, {'family': 'Evan Morikawa'}, {'family': 'Daniel Mossing'}, {'family': 'Tong Mu'}, {'family': 'Mira Murati'}, {'family': 'Oleg Murk'}, {'family': 'David M\xe9ly'}, {'family': 'Ashvin Nair'}, {'family': 'Reiichiro Nakano'}, {'family': 'Rajeev Nayak'}, {'family': 'Arvind Neelakantan'}, {'family': 'Richard Ngo'}, {'family': 'Hyeonwoo Noh'}, {'family': 'Long Ouyang'}, {'family': "Cullen O'Keefe"}, {'family': 'Jakub Pachocki'}, {'family': 'Alex Paino'}, {'family': 'Joe Palermo'}, {'family': 'Ashley Pantuliano'}, {'family': 'Giambattista Parascandolo'}, {'family': 'Joel Parish'}, {'family': 'Emy Parparita'}, {'family': 'Alex Passos'}, {'family': 'Mikhail Pavlov'}, {'family': 'Andrew Peng'}, {'family': 'Adam Perelman'}, {'family': 'Filipe de Avila Belbute Peres'}, {'family': 'Michael Petrov'}, {'family': 'Henrique Ponde de Oliveira Pinto'}, {'family': 'Michael'}, {'family': 'Pokorny'}, {'family': 'Michelle Pokrass'}, {'family': 'Vitchyr H. Pong'}, {'family': 'Tolly Powell'}, {'family': 'Alethea Power'}, {'family': 'Boris Power'}, {'family': 'Elizabeth Proehl'}, {'family': 'Raul Puri'}, {'family': 'Alec Radford'}, {'family': 'Jack Rae'}, {'family': 'Aditya Ramesh'}, {'family': 'Cameron Raymond'}, {'family': 'Francis Real'}, {'family': 'Kendra Rimbach'}, {'family': 'Carl Ross'}, {'family': 'Bob Rotsted'}, {'family': 'Henri Roussez'}, {'family': 'Nick Ryder'}, {'family': 'Mario Saltarelli'}, {'family': 'Ted Sanders'}, {'family': 'Shibani Santurkar'}, {'family': 'Girish Sastry'}, {'family': 'Heather Schmidt'}, {'family': 'David Schnurr'}, {'family': 'John Schulman'}, {'family': 'Daniel Selsam'}, {'family': 'Kyla Sheppard'}, {'family': 'Toki Sherbakov'}, {'family': 'Jessica Shieh'}, {'family': 'Sarah Shoker'}, {'family': 'Pranav Shyam'}, {'family': 'Szymon Sidor'}, {'family': 'Eric Sigler'}, {'family': 'Maddie Simens'}, {'family': 'Jordan Sitkin'}, {'family': 'Katarina Slama'}, {'family': 'Ian Sohl'}, {'family': 'Benjamin Sokolowsky'}, {'family': 'Yang Song'}, {'family': 'Natalie Staudacher'}, {'family': 'Felipe Petroski Such'}, {'family': 'Natalie Summers'}, {'family': 'Ilya Sutskever'}, {'family': 'Jie Tang'}, {'family': 'Nikolas Tezak'}, {'family': 'Madeleine B. Thompson'}, {'family': 'Phil Tillet'}, {'family': 'Amin Tootoonchian'}, {'family': 'Elizabeth Tseng'}, {'family': 'Preston Tuggle'}, {'family': 'Nick Turley'}, {'family': 'Jerry Tworek'}, {'family': 'Juan Felipe Cer\xf3n Uribe'}, {'family': 'Andrea Vallone'}, {'family': 'Arun Vijayvergiya'}, {'family': 'Chelsea Voss'}, {'family': 'Carroll Wainwright'}, {'family': 'Justin Jay Wang'}, {'family': 'Alvin Wang'}, {'family': 'Ben Wang'}, {'family': 'Jonathan Ward'}, {'family': 'Jason Wei'}, {'family': 'CJ Weinmann'}, {'family': 'Akila Welihinda'}, {'family': 'Peter Welinder'}, {'family': 'Jiayi Weng'}, {'family': 'Lilian Weng'}, {'family': 'Matt Wiethoff'}, {'family': 'Dave Willner'}, {'family': 'Clemens Winter'}, {'family': 'Samuel Wolrich'}, {'family': 'Hannah Wong'}, {'family': 'Lauren Workman'}, {'family': 'Sherwin Wu'}, {'family': 'Jeff Wu'}, {'family': 'Michael Wu'}, {'family': 'Kai Xiao'}, {'family': 'Tao Xu'}, {'family': 'Sarah Yoo'}, {'family': 'Kevin Yu'}, {'family': 'Qiming Yuan'}, {'family': 'Wojciech Zaremba'}, {'family': 'Rowan Zellers'}, {'family': 'Chong Zhang'}, {'family': 'Marvin Zhang'}, {'family': 'Shengjia Zhao'}, {'family': 'Tianhao Zheng'}, {'family': 'Juntang Zhuang'}, {'family': 'William Zhuk'}, {'family': 'Barret Zoph'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_1803.09010', 'title': 'Datasheets for Datasets', 'URL': 'https://arxiv.org/abs/1803.09010', 'extra_urls': ['https://arxiv.org/abs/1803.09010'], 'type': 'article', 'author': [{'family': 'Timnit Gebru'}, {'family': 'Jamie Morgenstern'}, {'family': 'Briana Vecchione'}, {'family': 'Jennifer Wortman Vaughan'}, {'family': 'Hanna Wallach'}, {'family': 'Hal Daum\xe9 III'}, {'family': 'Kate Crawford'}], 'issued': {'date-parts': [[2018]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.20295', 'title': 'SelfReflect: Can LLMs Communicate Their Internal Answer Distribution?', 'URL': 'https://arxiv.org/abs/2505.20295', 'extra_urls': ['https://arxiv.org/abs/2505.20295'], 'type': 'article', 'author': [{'family': 'Michael Kirchhof'}, {'family': 'Luca F\xfcger'}, {'family': 'Adam Goli\u0144ski'}, {'family': 'Eeshan Gunesh Dhekane'}, {'family': 'Arno Blaas'}, {'family': 'Seong Joon Oh'}, {'family': 'Sinead Williamson'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2412.20892', 'title': 'Rethinking Aleatoric and Epistemic Uncertainty', 'URL': 'https://arxiv.org/abs/2412.20892', 'extra_urls': ['https://arxiv.org/abs/2412.20892'], 'type': 'article', 'author': [{'family': 'Freddie Bickford Smith'}, {'family': 'Jannik Kossen'}, {'family': 'Eleanor Trollope'}, {'family': 'Mark van der Wilk'}, {'family': 'Adam Foster'}, {'family': 'Tom Rainforth'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2402.10189', 'title': 'Uncertainty Quantification for In-Context Learning of Large Language   Models', 'URL': 'https://arxiv.org/abs/2402.10189', 'extra_urls': ['https://arxiv.org/abs/2402.10189'], 'type': 'article', 'author': [{'family': 'Chen Ling'}, {'family': 'Xujiang Zhao'}, {'family': 'Xuchao Zhang'}, {'family': 'Wei Cheng'}, {'family': 'Yanchi Liu'}, {'family': 'Yiyou Sun'}, {'family': 'Mika Oishi'}, {'family': 'Takao Osaki'}, {'family': 'Katsushi Matsuda'}, {'family': 'Jie Ji'}, {'family': 'Guangji Bai'}, {'family': 'Liang Zhao'}, {'family': 'Haifeng Chen'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2311.08718', 'title': 'Decomposing Uncertainty for Large Language Models through Input   Clarification Ensembling', 'URL': 'https://arxiv.org/abs/2311.08718', 'extra_urls': ['https://arxiv.org/abs/2311.08718'], 'type': 'article', 'author': [{'family': 'Bairu Hou'}, {'family': 'Yujian Liu'}, {'family': 'Kaizhi Qian'}, {'family': 'Jacob Andreas'}, {'family': 'Shiyu Chang'}, {'family': 'Yang Zhang'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_1703.04977', 'title': 'What Uncertainties Do We Need in Bayesian Deep Learning for Computer   Vision?', 'URL': 'https://arxiv.org/abs/1703.04977', 'extra_urls': ['https://arxiv.org/abs/1703.04977'], 'type': 'article', 'author': [{'family': 'Kendall', 'given': 'Alex'}, {'family': 'Gal', 'given': 'Yarin'}], 'issued': {'date-parts': [[2017]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2412.02646', 'title': 'Interpretable Generalized Additive Models for Datasets with Missing   Values', 'URL': 'https://arxiv.org/abs/2412.02646', 'extra_urls': ['https://arxiv.org/abs/2412.02646'], 'type': 'article', 'author': [{'family': 'Hayden McTavish'}, {'family': 'Jon Donnelly'}, {'family': 'Margo Seltzer'}, {'family': 'Cynthia Rudin'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2004.13912', 'title': 'Neural Additive Models: Interpretable Machine Learning with Neural Nets', 'URL': 'https://arxiv.org/abs/2004.13912', 'extra_urls': ['https://arxiv.org/abs/2004.13912'], 'type': 'article', 'author': [{'family': 'Rishabh Agarwal'}, {'family': 'Levi Melnick'}, {'family': 'Nicholas Frosst'}, {'family': 'Xuezhou Zhang'}, {'family': 'Ben Lengerich'}, {'family': 'Rich Caruana'}, {'family': 'Geoffrey Hinton'}], 'issued': {'date-parts': [[2020]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2509.12527', 'title': 'Selective Risk Certification for LLM Outputs via Information-Lift   Statistics: PAC-Bayes, Robustness, and Skeleton Design', 'URL': 'https://arxiv.org/abs/2509.12527', 'extra_urls': ['https://arxiv.org/abs/2509.12527'], 'type': 'article', 'author': [{'family': 'Sanjeda Akter'}, {'family': 'Ibne Farabi Shihab'}, {'family': 'Anuj Sharma'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2402.15610', 'title': 'Selective "Selective Prediction": Reducing Unnecessary Abstention in   Vision-Language Reasoning', 'URL': 'https://arxiv.org/abs/2402.15610', 'extra_urls': ['https://arxiv.org/abs/2402.15610'], 'type': 'article', 'author': [{'family': 'Tejas Srinivasan'}, {'family': 'Jack Hessel'}, {'family': 'Tanmay Gupta'}, {'family': 'Bill Yuchen Lin'}, {'family': 'Yejin Choi'}, {'family': 'Jesse Thomason'}, {'family': 'Khyathi Raghavi Chandu'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2502.06884', 'title': 'Learning Conformal Abstention Policies for Adaptive Risk Management in   Large Language and Vision-Language Models', 'URL': 'https://arxiv.org/abs/2502.06884', 'extra_urls': ['https://arxiv.org/abs/2502.06884'], 'type': 'article', 'author': [{'family': 'Sina Tayebati'}, {'family': 'Divake Kumar'}, {'family': 'Nastaran Darabi'}, {'family': 'Dinithi Jayasuriya'}, {'family': 'Ranganath Krishnan'}, {'family': 'Amit Ranjan Trivedi'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_1705.08500', 'title': 'Selective Classification for Deep Neural Networks', 'URL': 'https://arxiv.org/abs/1705.08500', 'extra_urls': ['https://arxiv.org/abs/1705.08500'], 'type': 'article', 'author': [{'family': 'Yonatan Geifman'}, {'family': 'Ran El-Yaniv'}], 'issued': {'date-parts': [[2017]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2305.18404', 'title': 'Conformal Prediction with Large Language Models for Multi-Choice   Question Answering', 'URL': 'https://arxiv.org/abs/2305.18404', 'extra_urls': ['https://arxiv.org/abs/2305.18404'], 'type': 'article', 'author': [{'family': 'Bhawesh Kumar'}, {'family': 'Charlie Lu'}, {'family': 'Gauri Gupta'}, {'family': 'Anil Palepu'}, {'family': 'David Bellamy'}, {'family': 'Ramesh Raskar'}, {'family': 'Andrew Beam'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_1904.06019', 'title': 'Conformal Prediction Under Covariate Shift', 'URL': 'https://arxiv.org/abs/1904.06019', 'extra_urls': ['https://arxiv.org/abs/1904.06019'], 'type': 'article', 'author': [{'family': 'Ryan J. Tibshirani'}, {'family': 'Rina Foygel Barber'}, {'family': 'Emmanuel J. Candes'}, {'family': 'Aaditya Ramdas'}], 'issued': {'date-parts': [[2019]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_1905.03222', 'title': 'Conformalized Quantile Regression', 'URL': 'https://arxiv.org/abs/1905.03222', 'extra_urls': ['https://arxiv.org/abs/1905.03222'], 'type': 'article', 'author': [{'family': 'Yaniv Romano'}, {'family': 'Evan Patterson'}, {'family': 'Emmanuel J. Cand\xe8s'}], 'issued': {'date-parts': [[2019]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2009.14193', 'title': 'Uncertainty Sets for Image Classifiers using Conformal Prediction', 'URL': 'https://arxiv.org/abs/2009.14193', 'extra_urls': ['https://arxiv.org/abs/2009.14193'], 'type': 'article', 'author': [{'family': 'Anastasios Angelopoulos'}, {'family': 'Stephen Bates'}, {'family': 'Jitendra Malik'}, {'family': 'Michael I. Jordan'}], 'issued': {'date-parts': [[2020]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2412.05563', 'title': 'A Survey on Uncertainty Quantification of Large Language Models:   Taxonomy, Open Research Challenges, and Future Directions', 'URL': 'https://arxiv.org/abs/2412.05563', 'extra_urls': ['https://arxiv.org/abs/2412.05563'], 'type': 'article', 'author': [{'family': 'Ola Shorinwa'}, {'family': 'Zhiting Mei'}, {'family': 'Justin Lidard'}, {'family': 'Allen Z. Ren'}, {'family': 'Anirudha Majumdar'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2506.01333', 'title': 'ETDI: Mitigating Tool Squatting and Rug Pull Attacks in Model Context   Protocol (MCP) by using OAuth-Enhanced Tool Definitions and Policy-Based   Access Control', 'URL': 'https://arxiv.org/abs/2506.01333', 'extra_urls': ['https://arxiv.org/abs/2506.01333'], 'type': 'article', 'author': [{'family': 'Manish Bhatt'}, {'family': 'Vineeth Sai Narajala'}, {'family': 'Idan Habler'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.20020', 'title': 'Ontology- and LLM-based Data Harmonization for Federated Learning in   Healthcare', 'URL': 'https://arxiv.org/abs/2505.20020', 'extra_urls': ['https://arxiv.org/abs/2505.20020'], 'type': 'article', 'author': [{'family': 'Natallia Kokash'}, {'family': 'Lei Wang'}, {'family': 'Thomas H. Gillespie'}, {'family': 'Adam Belloum'}, {'family': 'Paola Grosso'}, {'family': 'Sara Quinney'}, {'family': 'Lang Li'}, {'family': 'Bernard de Bono'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2402.08088', 'title': 'Out-of-Distribution Detection and Data Drift Monitoring using   Statistical Process Control', 'URL': 'https://arxiv.org/abs/2402.08088', 'extra_urls': ['https://arxiv.org/abs/2402.08088'], 'type': 'article', 'author': [{'family': 'Ghada Zamzmi'}, {'family': 'Kesavan Venkatesh'}, {'family': 'Brandon Nelson'}, {'family': 'Smriti Prathapan'}, {'family': 'Paul H. Yi'}, {'family': 'Berkman Sahiner'}, {'family': 'Jana G. Delfino'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2410.24105', 'title': 'Matchmaker: Self-Improving Large Language Model Programs for Schema   Matching', 'URL': 'https://arxiv.org/abs/2410.24105', 'extra_urls': ['https://arxiv.org/abs/2410.24105'], 'type': 'article', 'author': [{'family': 'Nabeel Seedat'}, {'family': 'Mihaela van der Schaar'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2509.10691', 'title': 'Privacy-Preserving Decentralized Federated Learning via Explainable   Adaptive Differential Privacy', 'URL': 'https://arxiv.org/abs/2509.10691', 'extra_urls': ['https://arxiv.org/abs/2509.10691'], 'type': 'article', 'author': [{'family': 'Fardin Jalil Piran'}, {'family': 'Zhiling Chen'}, {'family': 'Yang Zhang'}, {'family': 'Qianyu Zhou'}, {'family': 'Jiong Tang'}, {'family': 'Farhad Imani'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2309.07864', 'title': 'The Rise and Potential of Large Language Model Based Agents: A Survey', 'URL': 'https://arxiv.org/abs/2309.07864', 'extra_urls': ['https://arxiv.org/abs/2309.07864'], 'type': 'article', 'author': [{'family': 'Zhiheng Xi'}, {'family': 'Wenxiang Chen'}, {'family': 'Xin Guo'}, {'family': 'Wei He'}, {'family': 'Yiwen Ding'}, {'family': 'Boyang Hong'}, {'family': 'Ming Zhang'}, {'family': 'Junzhe Wang'}, {'family': 'Senjie Jin'}, {'family': 'Enyu Zhou'}, {'family': 'Rui Zheng'}, {'family': 'Xiaoran Fan'}, {'family': 'Xiao Wang'}, {'family': 'Limao Xiong'}, {'family': 'Yuhao Zhou'}, {'family': 'Weiran Wang'}, {'family': 'Changhao Jiang'}, {'family': 'Yicheng Zou'}, {'family': 'Xiangyang Liu'}, {'family': 'Zhangyue Yin'}, {'family': 'Shihan Dou'}, {'family': 'Rongxiang Weng'}, {'family': 'Wensen Cheng'}, {'family': 'Qi Zhang'}, {'family': 'Wenjuan Qin'}, {'family': 'Yongyan Zheng'}, {'family': 'Xipeng Qiu'}, {'family': 'Xuanjing Huang'}, {'family': 'Tao Gui'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2107.07511', 'title': 'A Gentle Introduction to Conformal Prediction and Distribution-Free   Uncertainty Quantification', 'URL': 'https://arxiv.org/abs/2107.07511', 'extra_urls': ['https://arxiv.org/abs/2107.07511'], 'type': 'article', 'author': [{'family': 'Anastasios N. Angelopoulos'}, {'family': 'Stephen Bates'}], 'issued': {'date-parts': [[2021]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2505.22852', 'title': 'Operationalizing CaMeL: Strengthening LLM Defenses for Enterprise   Deployment', 'URL': 'https://arxiv.org/abs/2505.22852', 'extra_urls': ['https://arxiv.org/abs/2505.22852'], 'type': 'article', 'author': [{'family': 'Krti Tallam'}, {'family': 'Emma Miller'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2508.10991', 'title': 'MCP-Guard: A Defense Framework for Model Context Protocol Integrity in   Large Language Model Applications', 'URL': 'https://arxiv.org/abs/2508.10991', 'extra_urls': ['https://arxiv.org/abs/2508.10991'], 'type': 'article', 'author': [{'family': 'Wenpeng Xing'}, {'family': 'Zhonghao Qi'}, {'family': 'Yupeng Qin'}, {'family': 'Yilin Li'}, {'family': 'Caini Chang'}, {'family': 'Jiahui Yu'}, {'family': 'Changting Lin'}, {'family': 'Zhenzhen Xie'}, {'family': 'Meng Han'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'arXiv'}, {'id': 'arxiv_2401.13178', 'title': 'AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents', 'URL': 'https://arxiv.org/abs/2401.13178', 'extra_urls': ['https://arxiv.org/abs/2401.13178'], 'type': 'article', 'author': [{'family': 'Chang Ma'}, {'family': 'Junlei Zhang'}, {'family': 'Zhihao Zhu'}, {'family': 'Cheng Yang'}, {'family': 'Yujiu Yang'}, {'family': 'Yaohui Jin'}, {'family': 'Zhenzhong Lan'}, {'family': 'Lingpeng Kong'}, {'family': 'Junxian He'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'arXiv'}, {'id': 'using_of_digital', 'title': 'Using of Digital Twin Technology on the Stages of Implementation of ERP Systems', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10705183', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10705183'], 'type': 'article', 'author': [{'family': 'Hrischev', 'given': 'Radoslav'}, {'family': 'Shakev', 'given': 'Nikola'}], 'abstract': 'The globalization is challenging for the business and the companies must adapt quickly to changing market conditions, customer demands, rising resource costs and political uncertainties using new effective management systems, based on the digitalization of the economy in all its aspects. The concept Digital Twin appeared and in recent years, Digital Twin has evolved from an outcome to a driver of Industry 4.0. This paper discusses the conceptual framework and potential applications of advanced software tools for modeling and simulation as base of Digital Twin of business process and manufacturing systems. The relationship between the application of Digital Twin technology and modern Enterprise Resource Planning (ERP) systems in the phases of deployment is presented.'}, {'id': 'arxiv_2504.03692', 'title': 'A Theoretical Framework for Graph-based Digital Twins for Supply Chain Management and Optimization', 'URL': 'http://arxiv.org/abs/2504.03692', 'extra_urls': ['http://arxiv.org/abs/2504.03692'], 'type': 'article', 'author': [{'family': 'Wasi', 'given': 'Azmine Toushik'}, {'family': 'Anik', 'given': 'Mahfuz Ahmed'}, {'family': 'Rahman', 'given': 'Abdur'}, {'family': 'Hoque', 'given': 'Md Iqramul'}, {'family': 'Islam', 'given': 'MD Shafikul'}, {'family': 'Ahsan', 'given': 'Md Manjurul'}], 'publisher': 'arXiv', 'abstract': 'Supply chain management is growing increasingly complex due to globalization, evolving market demands, and sustainability pressures, yet traditional systems struggle with fragmented data and limited analytical capabilities. Graph-based modeling offers a powerful way to capture the intricate relationships within supply chains, while Digital Twins (DTs) enable real-time monitoring and dynamic simulations. However, current implementations often face challenges related to scalability, data integration, and the lack of sustainability-focused metrics. To address these gaps, we propose a Graph-Based Digital Twin Framework for Supply Chain Optimization, which combines graph modeling with DT architecture to create a dynamic, real-time representation of supply networks. Our framework integrates a Data Integration Layer to harmonize disparate sources, a Graph Construction Module to model complex dependencies, and a Simulation and Analysis Engine for scalable optimization. Importantly, we embed sustainability metrics - such as carbon footprints and resource utilization - into operational dashboards to drive eco-efficiency. By leveraging the synergy between graph-based modeling and DTs, our approach enhances scalability, improves decision-making, and enables organizations to proactively manage disruptions, cut costs, and transition toward greener, more resilient supply chains.'}, {'id': 'arxiv_2204.06972', 'title': 'The multi-modal universe of fast-fashion: the Visuelle 2.0 benchmark', 'URL': 'http://arxiv.org/abs/2204.06972', 'extra_urls': ['http://arxiv.org/abs/2204.06972'], 'type': 'article', 'author': [{'family': 'Skenderi', 'given': 'Geri'}, {'family': 'Joppi', 'given': 'Christian'}, {'family': 'Denitto', 'given': 'Matteo'}, {'family': 'Scarpa', 'given': 'Berniero'}, {'family': 'Cristani', 'given': 'Marco'}], 'publisher': 'arXiv', 'abstract': 'We present Visuelle 2.0, the first dataset useful for facing diverse prediction problems that a fast-fashion company has to manage routinely. Furthermore, we demonstrate how the use of computer vision is substantial in this scenario. Visuelle 2.0 contains data for 6 seasons / 5355 clothing products of Nuna Lie, a famous Italian company with hundreds of shops located in different areas within the country. In particular, we focus on a specific prediction problem, namely short-observation new product sale forecasting (SO-fore). SO-fore assumes that the season has started and a set of new products is on the shelves of the different stores. The goal is to forecast the sales for a particular horizon, given a short, available past (few weeks), since no earlier statistics are available. To be successful, SO-fore approaches should capture this short past and exploit other modalities or exogenous data. To these aims, Visuelle 2.0 is equipped with disaggregated data at the item-shop level and multi-modal information for each clothing item, allowing computer vision approaches to come into play. The main message that we deliver is that the use of image data with deep networks boosts performances obtained when using the time series in long-term forecasting scenarios, ameliorating the WAPE and MAE by up to 5.48% and 7% respectively compared to competitive baseline methods. The dataset is available at https://humaticslab.github.io/forecasting/visuelle'}, {'id': 'arxiv_2501.15411', 'title': 'The Potential of Large Language Models in Supply Chain Management: Advancing Decision-Making, Efficiency, and Innovation', 'URL': 'http://arxiv.org/abs/2501.15411', 'extra_urls': ['http://arxiv.org/abs/2501.15411'], 'type': 'article', 'author': [{'family': 'Aghaei', 'given': 'Raha'}, {'family': 'Kiaei', 'given': 'Ali A.'}, {'family': 'Boush', 'given': 'Mahnaz'}, {'family': 'Vahidi', 'given': 'Javad'}, {'family': 'Barzegar', 'given': 'Zeynab'}, {'family': 'Rofoosheh', 'given': 'Mahan'}], 'publisher': 'arXiv', 'abstract': 'The integration of large language models (LLMs) into supply chain management (SCM) is revolutionizing the industry by improving decision-making, predictive analytics, and operational efficiency. This white paper explores the transformative impact of LLMs on various SCM functions, including demand forecasting, inventory management, supplier relationship management, and logistics optimization. By leveraging advanced data analytics and real-time insights, LLMs enable organizations to optimize resources, reduce costs, and improve responsiveness to market changes. Key findings highlight the benefits of integrating LLMs with emerging technologies such as IoT, blockchain, and robotics, which together create smarter and more autonomous supply chains. Ethical considerations, including bias mitigation and data protection, are taken into account to ensure fair and transparent AI practices. In addition, the paper discusses the need to educate the workforce on how to manage new AI-driven processes and the long-term strategic benefits of adopting LLMs. Strategic recommendations for SCM professionals include investing in high-quality data management, promoting cross-functional collaboration, and aligning LLM initiatives with overall business goals. The findings highlight the potential of LLMs to drive innovation, sustainability, and competitive advantage in the ever-changing supply chain management landscape.'}, {'id': 'arxiv_2509.03811', 'title': 'Leveraging LLM-Based Agents for Intelligent Supply Chain Planning', 'URL': 'http://arxiv.org/abs/2509.03811', 'extra_urls': ['http://arxiv.org/abs/2509.03811'], 'type': 'article', 'author': [{'family': 'Qi', 'given': 'Yongzhi'}, {'family': 'Yin', 'given': 'Jiaheng'}, {'family': 'Zhang', 'given': 'Jianshen'}, {'family': 'Geng', 'given': 'Dongyang'}, {'family': 'Chen', 'given': 'Zhengyu'}, {'family': 'Hu', 'given': 'Hao'}, {'family': 'Qi', 'given': 'Wei'}, {'family': 'Shen', 'given': 'Zuo-Jun Max'}], 'publisher': 'arXiv', 'abstract': "In supply chain management, planning is a critical concept. The movement of physical products across different categories, from suppliers to warehouse management, to sales, and logistics transporting them to customers, entails the involvement of many entities. It covers various aspects such as demand forecasting, inventory management, sales operations, and replenishment. How to collect relevant data from an e-commerce platform's perspective, formulate long-term plans, and dynamically adjust them based on environmental changes, while ensuring interpretability, efficiency, and reliability, is a practical and challenging problem. In recent years, the development of AI technologies, especially the rapid progress of large language models, has provided new tools to address real-world issues. In this work, we construct a Supply Chain Planning Agent (SCPA) framework that can understand domain knowledge, comprehend the operator's needs, decompose tasks, leverage or create new tools, and return evidence-based planning reports. We deploy this framework in JD.com's real-world scenario, demonstrating the feasibility of LLM-agent applications in the supply chain. It effectively reduced labor and improved accuracy, stock availability, and other key metrics."}, {'id': 'the', 'title': "Position: What's the next frontier for Data-centric AI? Data Savvy Agents!", 'URL': 'https://openreview.net/forum?id=2GEipEDZB0', 'extra_urls': ['https://openreview.net/forum?id=2GEipEDZB0'], 'type': 'article', 'author': [{'family': 'Seedat', 'given': 'Nabeel'}, {'family': 'Liu', 'given': 'Jiashuo'}, {'family': 'Schaar', 'given': 'Mihaela van der'}], 'abstract': 'The recent surge in AI agents that autonomously communicate, collaborate with humans and use diverse tools has unlocked promising opportunities in various real-world settings. However, a vital aspect remains underexplored: how agents handle data. Agents cannot achieve scalable autonomy without the ability to dynamically acquire, process, and continually evolve their data ecosystems to navigate complex and changing environments. In this position paper, we argue that data-savvy capabilities should be a top priority in the design of agentic systems to ensure reliable real-world deployment. Specifically, we propose four key capabilities to realize this vision: (1) Proactive data acquisition: enabling agents to autonomously gather task-critical knowledge or solicit human input to address data gaps; (2) Sophisticated data processing: requiring context-aware and flexible handling of diverse data challenges and inputs; (3) Interactive test data synthesis: shifting from static benchmarks to dynamically generated interactive test data for agent evaluation; and (4) Continual adaptation: empowering agents to iteratively refine their data and background knowledge to adapt to shifting environments. While current agent research predominantly emphasizes reasoning, we hope this work inspires a broader reflection on the role of data-savvy agents as the next frontier in data-centric AI.'}, {'id': 'arxiv_2406.14758', 'title': 'Compliance Cards: Automated EU AI Act Compliance Analyses amidst a Complex AI Supply Chain', 'URL': 'http://arxiv.org/abs/2406.14758', 'extra_urls': ['http://arxiv.org/abs/2406.14758'], 'type': 'article', 'author': [{'family': 'Marino', 'given': 'Bill'}, {'family': 'Chaudhary', 'given': 'Yaqub'}, {'family': 'Pi', 'given': 'Yulu'}, {'family': 'Yew', 'given': 'Rui-Jie'}, {'family': 'Aleksandrov', 'given': 'Preslav'}, {'family': 'Rahman', 'given': 'Carwyn'}, {'family': 'Shen', 'given': 'William F.'}, {'family': 'Robinson', 'given': 'Isaac'}, {'family': 'Lane', 'given': 'Nicholas D.'}], 'publisher': 'arXiv', 'abstract': "As the AI supply chain grows more complex, AI systems and models are increasingly likely to incorporate multiple internally- or externally-sourced components such as datasets and (pre-trained) models. In such cases, determining whether or not the aggregate AI system or model complies with the EU AI Act (AIA) requires a multi-step process in which compliance-related information about both the AI system or model and all its component parts is: (1) gathered, potentially from multiple arms-length sources; (2) harmonized, if necessary; (3) inputted into an analysis that looks across all of it to render a compliance prediction. Because this process is so complex and time-consuming, it threatens to overburden the limited compliance resources of the AI providers (i.e., developers) who bear much of the responsibility for complying with the AIA. It also renders rapid or real-time compliance analyses infeasible in many AI development scenarios where they would be beneficial to providers. To address these shortcomings, we introduce a complete system for automating provider-side AIA compliance analyses amidst a complex AI supply chain. This system has two key elements. First is an interlocking set of computational, multi-stakeholder transparency artifacts that capture AIA-specific metadata about both: (1) the provider's overall AI system or model; and (2) the datasets and pre-trained models it incorporates as components. Second is an algorithm that operates across all those artifacts to render a real-time prediction about whether or not the aggregate AI system or model complies with the AIA. All told, this system promises to dramatically facilitate and democratize provider-side AIA compliance analyses (and, perhaps by extension, provider-side AIA compliance)."}, {'id': 'arxiv_2509.13813', 'title': 'Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs', 'URL': 'http://arxiv.org/abs/2509.13813', 'extra_urls': ['http://arxiv.org/abs/2509.13813'], 'type': 'article', 'author': [{'family': 'Phillips', 'given': 'Edward'}, {'family': 'Wu', 'given': 'Sean'}, {'family': 'Molaei', 'given': 'Soheila'}, {'family': 'Belgrave', 'given': 'Danielle'}, {'family': 'Thakur', 'given': 'Anshul'}, {'family': 'Clifton', 'given': 'David'}], 'publisher': 'arXiv', 'abstract': 'Large language models demonstrate impressive results across diverse tasks but are still known to hallucinate, generating linguistically plausible but incorrect answers to questions. Uncertainty quantification has been proposed as a strategy for hallucination detection, but no existing black-box approach provides estimates for both global and local uncertainty. The former attributes uncertainty to a batch of responses, while the latter attributes uncertainty to individual responses. Current local methods typically rely on white-box access to internal model states, whilst black-box methods only provide global uncertainty estimates. We introduce a geometric framework to address this, based on archetypal analysis of batches of responses sampled with only black-box model access. At the global level, we propose Geometric Volume, which measures the convex hull volume of archetypes derived from response embeddings. At the local level, we propose Geometric Suspicion, which ranks responses by reliability and enables hallucination reduction through preferential response selection. Unlike prior dispersion methods which yield only a single global score, our approach provides semantic boundary points which have utility for attributing reliability to individual responses. Experiments show that our framework performs comparably to or better than prior methods on short form question-answering datasets, and achieves superior results on medical datasets where hallucinations carry particularly critical risks. We also provide theoretical justification by proving a link between convex hull volume and entropy.'}, {'id': 'arxiv_2503.00172', 'title': 'A Survey of Uncertainty Estimation Methods on Large Language Models', 'URL': 'http://arxiv.org/abs/2503.00172', 'extra_urls': ['http://arxiv.org/abs/2503.00172'], 'type': 'article', 'author': [{'family': 'Xia', 'given': 'Zhiqiu'}, {'family': 'Xu', 'given': 'Jinxuan'}, {'family': 'Zhang', 'given': 'Yuqian'}, {'family': 'Liu', 'given': 'Hang'}], 'publisher': 'arXiv', 'abstract': 'Large language models (LLMs) have demonstrated remarkable capabilities across various tasks. However, these models could offer biased, hallucinated, or non-factual responses camouflaged by their fluency and realistic appearance. Uncertainty estimation is the key method to address this challenge. While research efforts in uncertainty estimation are ramping up, there is a lack of comprehensive and dedicated surveys on LLM uncertainty estimation. This survey presents four major avenues of LLM uncertainty estimation. Furthermore, we perform extensive experimental evaluations across multiple methods and datasets. At last, we provide critical and promising future directions for LLM uncertainty estimation.'}, {'id': 'a_dataset', 'title': 'GarmentCodeData: A Dataset of\xa03D Made-to-Measure Garments with Sewing Patterns', 'URL': 'urn:isbn:978-3-031-73027-6', 'type': 'article', 'author': [{'family': 'Korosteleva', 'given': 'Maria'}, {'family': 'Kesdogan', 'given': 'Timur Levent'}, {'family': 'Kemper', 'given': 'Fabian'}, {'family': 'Wenninger', 'given': 'Stephan'}, {'family': 'Koller', 'given': 'Jasmin'}, {'family': 'Zhang', 'given': 'Yuhan'}, {'family': 'Botsch', 'given': 'Mario'}, {'family': 'Sorkine-Hornung', 'given': 'Olga'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Springer Nature Switzerland', 'abstract': 'Recent research interest in learning-based processing of garments, from virtual fitting to generation and reconstruction, stumbles on a scarcity of high-quality public data in the domain. We contribute to resolving this need by presenting the first large-scale synthetic dataset of 3D made-to-measure garments with sewing patterns, as well as its generation pipeline. GarmentCodeData contains 115,000 data points that cover a variety of designs in many common garment categories: tops, shirts, dresses, jumpsuits, skirts, pants, etc., fitted to a variety of body shapes sampled from a custom statistical body model based on CAESAR\xa0[28], as well as a standard reference body shape, applying three different textile materials. To enable the creation of datasets of such complexity, we introduce a set of algorithms for automatically taking tailor\u2019s measures on sampled body shapes, sampling strategies for sewing pattern design, and propose an automatic, open-source 3D garment draping pipeline based on a fast XPBD simulator\xa0[22], while contributing several solutions for collision resolution and drape correctness to enable scalability.'}, {'id': 'generation', 'title': 'WordRobe: Text-Guided Generation of\xa0Textured 3D Garments', 'URL': 'urn:isbn:978-3-031-73232-4', 'type': 'article', 'author': [{'family': 'Srivastava', 'given': 'Astitva'}, {'family': 'Manu', 'given': 'Pranav'}, {'family': 'Raj', 'given': 'Amit'}, {'family': 'Jampani', 'given': 'Varun'}, {'family': 'Sharma', 'given': 'Avinash'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Springer Nature Switzerland', 'abstract': 'In this paper, we tackle a new and challenging problem of text-driven generation of 3D garments with high-quality textures. We propose, WordRobe, a novel framework for the generation of unposed &amp; textured 3D garment meshes from user-friendly text prompts. We achieve this by first learning a latent representation of 3D garments using a novel coarse-to-fine training strategy and a loss for latent disentanglement, promoting better latent interpolation. Subsequently, we align the garment latent space to the CLIP embedding space in a weakly supervised manner, enabling text-driven 3D garment generation and editing. For appearance modeling, we leverage the zero-shot generation capability of ControlNet to synthesize view-consistent texture maps in a single feed-forward inference step, thereby drastically decreasing the generation time as compared to existing methods. We demonstrate superior performance over current SOTAs for learning 3D garment latent space, garment interpolation, and text-driven texture synthesis, supported by quantitative evaluation and qualitative user study. The unposed 3D garment meshes generated using WordRobe can be directly fed to standard cloth simulation &amp; animation pipelines without any post-processing.'}, {'id': 'designing_creative', 'title': 'CRAFT: Designing Creative and Functional 3D Objects', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10944124', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10944124'], 'type': 'article', 'author': [{'family': 'Guo', 'given': 'Michelle'}, {'family': 'Tang', 'given': 'Mia'}, {'family': 'Cha', 'given': 'Hannah'}, {'family': 'Zhang', 'given': 'Ruohan'}, {'family': 'Liu', 'given': 'C. Karen'}, {'family': 'Wu', 'given': 'Jiajun'}], 'abstract': 'For designing a wide range of everyday objects, the design process should be aware of both the human body and the underlying semantics of the design specification. However, these two objectives present significant challenges to the current AI-based designing tools. In this work, we present a method to synthesize body-aware 3D objects from a base mesh given an input body geometry and either text or image as guidance. The generated objects can be simulated on virtual characters, or fabricated for real-world use. We propose to use a mesh deformation procedure that optimizes for both semantic alignment as well as contact and penetration losses. Using our method, users can generate both virtual or real-world objects from text, image, or sketch, without the need for manual artist intervention. We present both qualitative and quantitative results on various object categories, demonstrating the effectiveness of our approach.'}, {'id': 'arxiv_2508.17712', 'title': 'NGD: Neural Gradient Based Deformation for Monocular Garment Reconstruction', 'URL': 'http://arxiv.org/abs/2508.17712', 'extra_urls': ['http://arxiv.org/abs/2508.17712'], 'type': 'article', 'author': [{'family': 'Dasgupta', 'given': 'Soham'}, {'family': 'Naik', 'given': 'Shanthika'}, {'family': 'Savalia', 'given': 'Preet'}, {'family': 'Ingle', 'given': 'Sujay Kumar'}, {'family': 'Sharma', 'given': 'Avinash'}], 'publisher': 'arXiv', 'abstract': 'Dynamic garment reconstruction from monocular video is an important yet challenging task due to the complex dynamics and unconstrained nature of the garments. Recent advancements in neural rendering have enabled high-quality geometric reconstruction with image/video supervision. However, implicit representation methods that use volume rendering often provide smooth geometry and fail to model high-frequency details. While template reconstruction methods model explicit geometry, they use vertex displacement for deformation, which results in artifacts. Addressing these limitations, we propose NGD, a Neural Gradient-based Deformation method to reconstruct dynamically evolving textured garments from monocular videos. Additionally, we propose a novel adaptive remeshing strategy for modelling dynamically evolving surfaces like wrinkles and pleats of the skirt, leading to high-quality reconstruction. Finally, we learn dynamic texture maps to capture per-frame lighting and shadow effects. We provide extensive qualitative and quantitative evaluations to demonstrate significant improvements over existing SOTA methods and provide high-quality garment reconstructions.'}, {'id': 'arxiv_2507.21288', 'title': 'Learning Simulatable Models of Cloth with Spatially-varying Constitutive Properties', 'URL': 'http://arxiv.org/abs/2507.21288', 'extra_urls': ['http://arxiv.org/abs/2507.21288'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Guanxiong'}, {'family': 'Suri', 'given': 'Shashwat'}, {'family': 'Wu', 'given': 'Yuhao'}, {'family': 'Voulga', 'given': 'Etienne'}, {'family': 'Levin', 'given': 'David I. W.'}, {'family': 'Pai', 'given': 'Dinesh K.'}], 'publisher': 'arXiv', 'abstract': "Materials used in real clothing exhibit remarkable complexity and spatial variation due to common processes such as stitching, hemming, dyeing, printing, padding, and bonding. Simulating these materials, for instance using finite element methods, is often computationally demanding and slow. Worse, such methods can suffer from numerical artifacts called ``membrane locking'' that makes cloth appear artificially stiff. Here we propose a general framework, called Mass-Spring Net, for learning a simple yet efficient surrogate model that captures the effects of these complex materials using only motion observations. The cloth is discretized into a mass-spring network with unknown material parameters that are learned directly from the motion data, using a novel force-and-impulse loss function. Our approach demonstrates the ability to accurately model spatially varying material properties from a variety of data sources, and immunity to membrane locking which plagues FEM-based simulations. Compared to graph-based networks and neural ODE-based architectures, our method achieves significantly faster training times, higher reconstruction accuracy, and improved generalization to novel dynamic scenarios."}, {'id': 'arxiv_2509.08828', 'title': 'SAFT: Shape and Appearance of Fabrics from Template via Differentiable Physical Simulations from Monocular Video', 'URL': 'http://arxiv.org/abs/2509.08828', 'extra_urls': ['http://arxiv.org/abs/2509.08828'], 'type': 'article', 'author': [{'family': 'Stotko', 'given': 'David'}, {'family': 'Klein', 'given': 'Reinhard'}], 'publisher': 'arXiv', 'abstract': 'The reconstruction of three-dimensional dynamic scenes is a well-established yet challenging task within the domain of computer vision. In this paper, we propose a novel approach that combines the domains of 3D geometry reconstruction and appearance estimation for physically based rendering and present a system that is able to perform both tasks for fabrics, utilizing only a single monocular RGB video sequence as input. In order to obtain realistic and high-quality deformations and renderings, a physical simulation of the cloth geometry and differentiable rendering are employed. In this paper, we introduce two novel regularization terms for the 3D reconstruction task that improve the plausibility of the reconstruction by addressing the depth ambiguity problem in monocular video. In comparison with the most recent methods in the field, we have reduced the error in the 3D reconstruction by a factor of 2.64 while requiring a medium runtime of 30 min per scene. Furthermore, the optimized motion achieves sufficient quality to perform an appearance estimation of the deforming object, recovering sharp details from this single monocular RGB video.'}, {'id': 'arxiv_2503.08678', 'title': 'GarmentCrafter: Progressive Novel View Synthesis for Single-View 3D Garment Reconstruction and Editing', 'URL': 'http://arxiv.org/abs/2503.08678', 'extra_urls': ['http://arxiv.org/abs/2503.08678'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Yuanhao'}, {'family': 'Zhang', 'given': 'Cheng'}, {'family': 'Fraz\xe3o', 'given': 'Gon\xe7alo'}, {'family': 'Yang', 'given': 'Jinlong'}, {'family': 'Ichim', 'given': 'Alexandru-Eugen'}, {'family': 'Beeler', 'given': 'Thabo'}, {'family': 'Torre', 'given': 'Fernando De la'}], 'publisher': 'arXiv', 'abstract': 'We introduce GarmentCrafter, a new approach that enables non-professional users to create and modify 3D garments from a single-view image. While recent advances in image generation have facilitated 2D garment design, creating and editing 3D garments remains challenging for non-professional users. Existing methods for single-view 3D reconstruction often rely on pre-trained generative models to synthesize novel views conditioning on the reference image and camera pose, yet they lack cross-view consistency, failing to capture the internal relationships across different views. In this paper, we tackle this challenge through progressive depth prediction and image warping to approximate novel views. Subsequently, we train a multi-view diffusion model to complete occluded and unknown clothing regions, informed by the evolving camera pose. By jointly inferring RGB and depth, GarmentCrafter enforces inter-view coherence and reconstructs precise geometries and fine details. Extensive experiments demonstrate that our method achieves superior visual fidelity and inter-view coherence compared to state-of-the-art single-view 3D garment reconstruction methods.'}, {'id': 'arxiv_2508.09977', 'title': 'A Survey on 3D Gaussian Splatting Applications: Segmentation, Editing, and Generation', 'URL': 'http://arxiv.org/abs/2508.09977', 'extra_urls': ['http://arxiv.org/abs/2508.09977'], 'type': 'article', 'author': [{'family': 'He', 'given': 'Shuting'}, {'family': 'Ji', 'given': 'Peilin'}, {'family': 'Yang', 'given': 'Yitong'}, {'family': 'Wang', 'given': 'Changshuo'}, {'family': 'Ji', 'given': 'Jiayi'}, {'family': 'Wang', 'given': 'Yinglin'}, {'family': 'Ding', 'given': 'Henghui'}], 'publisher': 'arXiv', 'abstract': '3D Gaussian Splatting (3DGS) has recently emerged as a powerful alternative to Neural Radiance Fields (NeRF) for 3D scene representation, offering high-fidelity photorealistic rendering with real-time performance. Beyond novel view synthesis, the explicit and compact nature of 3DGS enables a wide range of downstream applications that require geometric and semantic understanding. This survey provides a comprehensive overview of recent progress in 3DGS applications. It first introduces 2D foundation models that support semantic understanding and control in 3DGS applications, followed by a review of NeRF-based methods that inform their 3DGS counterparts. We then categorize 3DGS applications into segmentation, editing, generation, and other functional tasks. For each, we summarize representative methods, supervision strategies, and learning paradigms, highlighting shared design principles and emerging trends. Commonly used datasets and evaluation protocols are also summarized, along with comparative analyses of recent methods across public benchmarks. To support ongoing research and development, a continually updated repository of papers, code, and resources is maintained at https://github.com/heshuting555/Awesome-3DGS-Applications.'}, {'id': 'arxiv_2506.12348', 'title': 'Real-Time Per-Garment Virtual Try-On with Temporal Consistency for Loose-Fitting Garments', 'URL': 'http://arxiv.org/abs/2506.12348', 'extra_urls': ['http://arxiv.org/abs/2506.12348'], 'type': 'article', 'author': [{'family': 'Wu', 'given': 'Zaiqiang'}, {'family': 'Shen', 'given': 'I.-Chao'}, {'family': 'Igarashi', 'given': 'Takeo'}], 'abstract': 'Per-garment virtual try-on methods collect garment-specific datasets and train networks tailored to each garment to achieve superior results. However, these approaches often struggle with loose-fitting garments due to two key limitations: (1) They rely on human body semantic maps to align garments with the body, but these maps become unreliable when body contours are obscured by loose-fitting garments, resulting in degraded outcomes; (2) They train garment synthesis networks on a per-frame basis without utilizing temporal information, leading to noticeable jittering artifacts. To address the first limitation, we propose a two-stage approach for robust semantic map estimation. First, we extract a garment-invariant representation from the raw input image. This representation is then passed through an auxiliary network to estimate the semantic map. This enhances the robustness of semantic map estimation under loose-fitting garments during garment-specific dataset generation. To address the second limitation, we introduce a recurrent garment synthesis framework that incorporates temporal dependencies to improve frame-to-frame coherence while maintaining real-time performance. We conducted qualitative and quantitative evaluations to demonstrate that our method outperforms existing approaches in both image quality and temporal coherence. Ablation studies further validate the effectiveness of the garment-invariant representation and the recurrent synthesis framework.'}, {'id': 'gaussian_reconstructing', 'title': 'Gaussian Garments: Reconstructing Simulation-Ready Clothing with Photorealistic Appearance from Multi-View Video', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11125573', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11125573'], 'type': 'article', 'author': [{'family': 'Rong', 'given': 'Boxiang'}, {'family': 'Grigorev', 'given': 'Artur'}, {'family': 'Wang', 'given': 'Wenbo'}, {'family': 'Black', 'given': 'Michael J.'}, {'family': 'Thomaszewski', 'given': 'Bernhard'}, {'family': 'Tsalicoglou', 'given': 'Christina'}, {'family': 'Hilliges', 'given': 'Otmar'}], 'abstract': 'We introduce Gaussian Garments, a novel approach for reconstructing realistic simulation-ready garment assets from multi-view videos. Our method represents garments with a combination of a 3D mesh and a Gaussian texture that encodes both the color and high-frequency surface details. This representation enables accurate registration of garment geometries to multi-view videos and helps disentangle albedo textures from lighting effects. Furthermore, we demonstrate how a pretrained graph neural network (GNN) can be fine-tuned to replicate the real behavior of each garment. The reconstructed Gaussian Garments can be automatically combined into multi-garment outfits and animated with the fine-tuned GNN.'}, {'id': 'arxiv_2501.10455', 'title': 'PhyDeformer: High-Quality Non-Rigid Garment Registration with Physics-Awareness', 'URL': 'http://arxiv.org/abs/2501.10455', 'extra_urls': ['http://arxiv.org/abs/2501.10455'], 'type': 'article', 'author': [{'family': 'Yu', 'given': 'Boyang'}, {'family': 'Cordier', 'given': 'Frederic'}, {'family': 'Seo', 'given': 'Hyewon'}], 'publisher': 'arXiv', 'abstract': 'We present PhyDeformer, a new deformation method for high-quality garment mesh registration. It operates in two phases: In the first phase, a garment grading is performed to achieve a coarse 3D alignment between the mesh template and the target mesh, accounting for proportional scaling and fit (e.g. length, size). Then, the graded mesh is refined to align with the fine-grained details of the 3D target through an optimization coupled with the Jacobian-based deformation framework. Both quantitative and qualitative evaluations on synthetic and real garments highlight the effectiveness of our method.'}, {'id': 'arxiv_2311.12194', 'title': 'DiffAvatar: Simulation-Ready Garment Optimization with Differentiable Simulation', 'URL': 'http://arxiv.org/abs/2311.12194', 'extra_urls': ['http://arxiv.org/abs/2311.12194'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Yifei'}, {'family': 'Chen', 'given': 'Hsiao-yu'}, {'family': 'Larionov', 'given': 'Egor'}, {'family': 'Sarafianos', 'given': 'Nikolaos'}, {'family': 'Matusik', 'given': 'Wojciech'}, {'family': 'Stuyck', 'given': 'Tuur'}], 'publisher': 'arXiv', 'abstract': "The realism of digital avatars is crucial in enabling telepresence applications with self-expression and customization. While physical simulations can produce realistic motions for clothed humans, they require high-quality garment assets with associated physical parameters for cloth simulations. However, manually creating these assets and calibrating their parameters is labor-intensive and requires specialized expertise. Current methods focus on reconstructing geometry, but don't generate complete assets for physics-based applications. To address this gap, we propose \\papername,~a novel approach that performs body and garment co-optimization using differentiable simulation. By integrating physical simulation into the optimization loop and accounting for the complex nonlinear behavior of cloth and its intricate interaction with the body, our framework recovers body and garment geometry and extracts important material parameters in a physically plausible way. Our experiments demonstrate that our approach generates realistic clothing and body shape suitable for downstream applications. We provide additional insights and results on our webpage: https://people.csail.mit.edu/liyifei/publication/diffavatar/"}, {'id': 'arxiv_2503.12052', 'title': 'Tailor: An Integrated Text-Driven CG-Ready Human and Garment Generation System', 'URL': 'http://arxiv.org/abs/2503.12052', 'extra_urls': ['http://arxiv.org/abs/2503.12052'], 'type': 'article', 'author': [{'family': 'Sun', 'given': 'Zhiyao'}, {'family': 'Wen', 'given': 'Yu-Hui'}, {'family': 'Lin', 'given': 'Matthieu'}, {'family': 'Fang', 'given': 'Ho-Jui'}, {'family': 'Ye', 'given': 'Sheng'}, {'family': 'Lv', 'given': 'Tian'}, {'family': 'Liu', 'given': 'Yong-Jin'}], 'publisher': 'arXiv', 'abstract': 'Creating detailed 3D human avatars with garments typically requires specialized expertise and labor-intensive processes. Although recent advances in generative AI have enabled text-to-3D human/clothing generation, current methods fall short in offering accessible, integrated pipelines for producing ready-to-use clothed avatars. To solve this, we introduce Tailor, an integrated text-to-avatar system that generates high-fidelity, customizable 3D humans with simulation-ready garments. Our system includes a three-stage pipeline. We first employ a large language model to interpret textual descriptions into parameterized body shapes and semantically matched garment templates. Next, we develop topology-preserving deformation with novel geometric losses to adapt garments precisely to body geometries. Furthermore, an enhanced texture diffusion module with a symmetric local attention mechanism ensures both view consistency and photorealistic details. Quantitative and qualitative evaluations demonstrate that Tailor outperforms existing SoTA methods in terms of fidelity, usability, and diversity. Code will be available for academic use.'}, {'id': 'arxiv_2504.03468', 'title': 'D-Garment: Physics-Conditioned Latent Diffusion for Dynamic Garment Deformations', 'URL': 'http://arxiv.org/abs/2504.03468', 'extra_urls': ['http://arxiv.org/abs/2504.03468'], 'type': 'article', 'author': [{'family': 'Dumoulin', 'given': 'Antoine'}, {'family': 'Boukhayma', 'given': 'Adnane'}, {'family': 'Boissieux', 'given': 'Laurence'}, {'family': 'Damodaran', 'given': 'Bharath Bhushan'}, {'family': 'Hellier', 'given': 'Pierre'}, {'family': 'Wuhrer', 'given': 'Stefanie'}], 'publisher': 'arXiv', 'abstract': "Adjusting and deforming 3D garments to body shapes, body motion, and cloth material is an important problem in virtual and augmented reality. Applications are numerous, ranging from virtual change rooms to the entertainment and gaming industry. This problem is challenging as garment dynamics influence geometric details such as wrinkling patterns, which depend on physical input including the wearer's body shape and motion, as well as cloth material features. Existing work studies learning-based modeling techniques to generate garment deformations from example data, and physics-inspired simulators to generate realistic garment dynamics. We propose here a learning-based approach trained on data generated with a physics-based simulator. Compared to prior work, our 3D generative model learns garment deformations for loose cloth geometry, especially for large deformations and dynamic wrinkles driven by body motion and cloth material. Furthermore, the model can be efficiently fitted to observations captured using vision sensors. We propose to leverage the capability of diffusion models to learn fine-scale detail: we model the 3D garment in a 2D parameter space, and learn a latent diffusion model using this representation independent from the mesh resolution. This allows to condition global and local geometric information with body and material information. We quantitatively and qualitatively evaluate our method on both simulated data and data captured with a multi-view acquisition platform. Compared to strong baselines, our method is more accurate in terms of Chamfer distance."}, {'id': 'guided', 'title': 'GarmentGS: Point-Cloud Guided Gaussian Splatting for High-Fidelity Non-Watertight 3D Garment Reconstruction', 'URL': 'https://dl.acm.org/doi/10.1145/3731715.3733478', 'type': 'article', 'author': [{'family': 'Tang', 'given': 'Zhihao'}, {'family': 'Yang', 'given': 'Shenghao'}, {'family': 'Zhang', 'given': 'Hongtao'}, {'family': 'Zhao', 'given': 'Mingbo'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Traditional 3D garment creation requires extensive manual operations, resulting in time and labor costs. Recently, 3D Gaussian Splatting has achieved breakthrough progress in 3D scene reconstruction and rendering, attracting widespread attention and opening new pathways for 3D garment reconstruction. However, due to the unstructured and irregular nature of Gaussian primitives, it is difficult to reconstruct high-fidelity, non-watertight 3D garments. In this paper, we present GarmentGS, a dense point cloud-guided method that can reconstruct high-fidelity garment surfaces with high geometric accuracy and generate non-watertight, single-layer meshes. Our method introduces a fast dense point cloud reconstruction module that can complete garment point cloud reconstruction in 10 minutes, compared to traditional methods that require several hours. Furthermore, we use dense point clouds to guide the movement, flattening, and rotation of Gaussian primitives, enabling better distribution on the garment surface to achieve superior rendering effects and geometric accuracy. Through numerical and visual comparisons, our method achieves fast training and real-time rendering while maintaining competitive quality.'}, {'id': 'arxiv_2504.21476', 'title': 'GarmentDiffusion: 3D Garment Sewing Pattern Generation with Multimodal Diffusion Transformers', 'URL': 'http://arxiv.org/abs/2504.21476', 'extra_urls': ['http://arxiv.org/abs/2504.21476'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Xinyu'}, {'family': 'Yao', 'given': 'Qi'}, {'family': 'Wang', 'given': 'Yuanda'}], 'abstract': 'Garment sewing patterns are fundamental design elements that bridge the gap between design concepts and practical manufacturing. The generative modeling of sewing patterns is crucial for creating diversified garments. However, existing approaches are limited either by reliance on a single input modality or by suboptimal generation efficiency. In this work, we present GarmentDiffusion, a new generative model capable of producing centimeter-precise, vectorized 3D sewing patterns from multimodal inputs (text, image, and incomplete sewing pattern). Our method efficiently encodes 3D sewing pattern parameters into compact edge token representations, achieving a sequence length that is 10 times shorter than that of the autoregressive SewingGPT in DressCode. By employing a diffusion transformer, we simultaneously denoise all edge tokens along the temporal axis, while maintaining a constant number of denoising steps regardless of dataset-specific edge and panel statistics. With all combination of designs of our model, the sewing pattern generation speed is accelerated by 100 times compared to SewingGPT. We achieve new state-of-the-art results on DressCodeData, as well as on the largest sewing pattern dataset, namely GarmentCodeData. The project website is available at https://shenfu-research.github.io/Garment-Diffusion/.'}, {'id': 'arxiv_2501.13692', 'title': 'Training-Free Consistency Pipeline for Fashion Repose', 'URL': 'http://arxiv.org/abs/2501.13692', 'extra_urls': ['http://arxiv.org/abs/2501.13692'], 'type': 'article', 'author': [{'family': 'Aghilar', 'given': 'Potito'}, {'family': 'Anelli', 'given': 'Vito Walter'}, {'family': 'Trizio', 'given': 'Michelantonio'}, {'family': 'Noia', 'given': 'Tommaso Di'}], 'publisher': 'arXiv', 'abstract': 'Recent advancements in diffusion models have significantly broadened the possibilities for editing images of real-world objects. However, performing non-rigid transformations, such as changing the pose of objects or image-based conditioning, remains challenging. Maintaining object identity during these edits is difficult, and current methods often fall short of the precision needed for industrial applications, where consistency is critical. Additionally, fine-tuning diffusion models requires custom training data, which is not always accessible in real-world scenarios. This work introduces FashionRepose, a training-free pipeline for non-rigid pose editing specifically designed for the fashion industry. The approach integrates off-the-shelf models to adjust poses of long-sleeve garments, maintaining identity and branding attributes. FashionRepose uses a zero-shot approach to perform these edits in near real-time, eliminating the need for specialized training. consistent image editing. The solution holds potential for applications in the fashion industry and other fields demanding identity preservation in image editing.'}, {'id': 'arxiv_2510.04822', 'title': 'AvatarVTON: 4D Virtual Try-On for Animatable Avatars', 'URL': 'http://arxiv.org/abs/2510.04822', 'extra_urls': ['http://arxiv.org/abs/2510.04822'], 'type': 'article', 'author': [{'family': 'Jiang', 'given': 'Zicheng'}, {'family': 'Gao', 'given': 'Jixin'}, {'family': 'He', 'given': 'Shengfeng'}, {'family': 'Li', 'given': 'Xinzhe'}, {'family': 'Zheng', 'given': 'Yulong'}, {'family': 'Yang', 'given': 'Zhaotong'}, {'family': 'Dong', 'given': 'Junyu'}, {'family': 'Du', 'given': 'Yong'}], 'publisher': 'arXiv', 'abstract': 'We propose AvatarVTON, the first 4D virtual try-on framework that generates realistic try-on results from a single in-shop garment image, enabling free pose control, novel-view rendering, and diverse garment choices. Unlike existing methods, AvatarVTON supports dynamic garment interactions under single-view supervision, without relying on multi-view garment captures or physics priors. The framework consists of two key modules: (1) a Reciprocal Flow Rectifier, a prior-free optical-flow correction strategy that stabilizes avatar fitting and ensures temporal coherence; and (2) a Non-Linear Deformer, which decomposes Gaussian maps into view-pose-invariant and view-pose-specific components, enabling adaptive, non-linear garment deformations. To establish a benchmark for 4D virtual try-on, we extend existing baselines with unified modules for fair qualitative and quantitative comparisons. Extensive experiments show that AvatarVTON achieves high fidelity, diversity, and dynamic garment realism, making it well-suited for AR/VR, gaming, and digital-human applications.'}, {'id': 'arxiv_2509.16960', 'title': 'SemanticGarment: Semantic-Controlled Generation and Editing of 3D Gaussian Garments', 'URL': 'http://arxiv.org/abs/2509.16960', 'extra_urls': ['http://arxiv.org/abs/2509.16960'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Ruiyan'}, {'family': 'Cheng', 'given': 'Zhengxue'}, {'family': 'Lin', 'given': 'Zonghao'}, {'family': 'Ling', 'given': 'Jun'}, {'family': 'Liu', 'given': 'Yuzhou'}, {'family': 'An', 'given': 'Yanru'}, {'family': 'Xie', 'given': 'Rong'}, {'family': 'Song', 'given': 'Li'}], 'abstract': '3D digital garment generation and editing play a pivotal role in fashion design, virtual try-on, and gaming. Traditional methods struggle to meet the growing demand due to technical complexity and high resource costs. Learning-based approaches offer faster, more diverse garment synthesis based on specific requirements and reduce human efforts and time costs. However, they still face challenges such as inconsistent multi-view geometry or textures and heavy reliance on detailed garment topology and manual rigging. We propose SemanticGarment, a 3D Gaussian-based method that realizes high-fidelity 3D garment generation from text or image prompts and supports semantic-based interactive editing for flexible user customization. To ensure multi-view consistency and garment fitting, we propose to leverage structural human priors for the generative model by introducing a 3D semantic clothing model, which initializes the geometry structure and lays the groundwork for view-consistent garment generation and editing. Without the need to regenerate or rely on existing mesh templates, our approach allows for rapid and diverse modifications to existing Gaussians, either globally or within a local region. To address the artifacts caused by self-occlusion for garment reconstruction based on single image, we develop a self-occlusion optimization strategy to mitigate holes and artifacts that arise when directly animating self-occluded garments. Extensive experiments are conducted to demonstrate our superior performance in 3D garment generation and editing.'}, {'id': 'arxiv_2408.09126', 'title': 'Barbie: Text to Barbie-Style 3D Avatars', 'URL': 'http://arxiv.org/abs/2408.09126', 'extra_urls': ['http://arxiv.org/abs/2408.09126'], 'type': 'article', 'author': [{'family': 'Sun', 'given': 'Xiaokun'}, {'family': 'Zhang', 'given': 'Zhenyu'}, {'family': 'Tai', 'given': 'Ying'}, {'family': 'Tang', 'given': 'Hao'}, {'family': 'Yi', 'given': 'Zili'}, {'family': 'Yang', 'given': 'Jian'}], 'publisher': 'arXiv', 'abstract': "To integrate digital humans into everyday life, there is a strong demand for generating high-quality, fine-grained disentangled 3D avatars that support expressive animation and simulation capabilities, ideally from low-cost textual inputs. Although text-driven 3D avatar generation has made significant progress by leveraging 2D generative priors, existing methods still struggle to fulfill all these requirements simultaneously. To address this challenge, we propose Barbie, a novel text-driven framework for generating animatable 3D avatars with separable shoes, accessories, and simulation-ready garments, truly capturing the iconic ``Barbie doll'' aesthetic. The core of our framework lies in an expressive 3D representation combined with appropriate modeling constraints. Unlike previous methods, we innovatively employ G-Shell to uniformly model both watertight components (e.g., bodies, shoes, and accessories) and non-watertight garments compatible with simulation. Furthermore, we introduce a well-designed initialization and a hole regularization loss to ensure clean open surface modeling. These disentangled 3D representations are then optimized by specialized expert diffusion models tailored to each domain, ensuring high-fidelity outputs. To mitigate geometric artifacts and texture conflicts when combining different expert models, we further propose several effective geometric losses and strategies. Extensive experiments demonstrate that Barbie outperforms existing methods in both dressed human and outfit generation. Our framework further enables diverse applications, including apparel combination, editing, expressive animation, and physical simulation. Our project page is: https://xiaokunsun.github.io/Barbie.github.io"}, {'id': 'arxiv_2411.19528', 'title': 'RAGDiffusion: Faithful Cloth Generation via External Knowledge Assimilation', 'URL': 'http://arxiv.org/abs/2411.19528', 'extra_urls': ['http://arxiv.org/abs/2411.19528'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Yuhan'}, {'family': 'Tan', 'given': 'Xianfeng'}, {'family': 'Shang', 'given': 'Wenxiang'}, {'family': 'Wu', 'given': 'Yubo'}, {'family': 'Wang', 'given': 'Jian'}, {'family': 'Chen', 'given': 'Xuanhong'}, {'family': 'Zhang', 'given': 'Yi'}, {'family': 'Lin', 'given': 'Ran'}, {'family': 'Ni', 'given': 'Bingbing'}], 'publisher': 'arXiv', 'abstract': 'Standard clothing asset generation involves restoring forward-facing flat-lay garment images displayed on a clear background by extracting clothing information from diverse real-world contexts, which presents significant challenges due to highly standardized structure sampling distributions and clothing semantic absence in complex scenarios. Existing models have limited spatial perception, often exhibiting structural hallucinations and texture distortion in this high-specification generative task. To address this issue, we propose a novel Retrieval-Augmented Generation (RAG) framework, termed RAGDiffusion, to enhance structure determinacy and mitigate hallucinations by assimilating knowledge from language models and external databases. RAGDiffusion consists of two processes: (1) Retrieval-based structure aggregation, which employs contrastive learning and a Structure Locally Linear Embedding (SLLE) to derive global structure and spatial landmarks, providing both soft and hard guidance to counteract structural ambiguities; and (2) Omni-level faithful garment generation, which introduces a coarse-to-fine texture alignment that ensures fidelity in pattern and detail components within the diffusing. Extensive experiments on challenging real-world datasets demonstrate that RAGDiffusion synthesizes structurally and texture-faithful clothing assets with significant performance improvements, representing a pioneering effort in high-specification faithful generation with RAG to confront intrinsic hallucinations and enhance fidelity.'}, {'id': 'realistic', 'title': 'GaussianIP: Identity-Preserving Realistic 3D Human Generation via Human-Centric Diffusion Prior', 'URL': 'https://openaccess.thecvf.com/content/CVPR2025/html/Tang_GaussianIP_Identity-Preserving_Realistic_3D_Human_Generation_via_Human-Centric_Diffusion_Prior_CVPR_2025_paper.html', 'extra_urls': ['https://openaccess.thecvf.com/content/CVPR2025/html/Tang_GaussianIP_Identity-Preserving_Realistic_3D_Human_Generation_via_Human-Centric_Diffusion_Prior_CVPR_2025_paper.html'], 'type': 'article', 'author': [{'family': 'Tang', 'given': 'Zichen'}, {'family': 'Yao', 'given': 'Yuan'}, {'family': 'Cui', 'given': 'Miaomiao'}, {'family': 'Bo', 'given': 'Liefeng'}, {'family': 'Yang', 'given': 'Hongyu'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'arxiv_2501.04631', 'title': 'Disentangled Clothed Avatar Generation with Layered Representation', 'URL': 'http://arxiv.org/abs/2501.04631', 'extra_urls': ['http://arxiv.org/abs/2501.04631'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Weitian'}, {'family': 'Yan', 'given': 'Yichao'}, {'family': 'Wu', 'given': 'Sijing'}, {'family': 'Liao', 'given': 'Manwen'}, {'family': 'Yang', 'given': 'Xiaokang'}], 'publisher': 'arXiv', 'abstract': 'Clothed avatar generation has wide applications in virtual and augmented reality, filmmaking, and more. Previous methods have achieved success in generating diverse digital avatars, however, generating avatars with disentangled components (\\eg, body, hair, and clothes) has long been a challenge. In this paper, we propose LayerAvatar, the first feed-forward diffusion-based method for generating component-disentangled clothed avatars. To achieve this, we first propose a layered UV feature plane representation, where components are distributed in different layers of the Gaussian-based UV feature plane with corresponding semantic labels. This representation supports high-resolution and real-time rendering, as well as expressive animation including controllable gestures and facial expressions. Based on the well-designed representation, we train a single-stage diffusion model and introduce constrain terms to address the severe occlusion problem of the innermost human body layer. Extensive experiments demonstrate the impressive performances of our method in generating disentangled clothed avatars, and we further explore its applications in component transfer. The project page is available at: https://olivia23333.github.io/LayerAvatar/'}, {'id': '3d_garment', 'title': 'Garment3DGen: 3D Garment Stylization and Texture Generation', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11125610', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11125610'], 'type': 'article', 'author': [{'family': 'Sarafianos', 'given': 'Nikolaos'}, {'family': 'Stuyck', 'given': 'Tuur'}, {'family': 'Xiang', 'given': 'Xiaoyu'}, {'family': 'Li', 'given': 'Yilei'}, {'family': 'Popovic', 'given': 'Jovan'}, {'family': 'Ranjan', 'given': 'Rakesh'}], 'abstract': 'We introduce Garment3DGen a new method to synthesize 3D garment assets from a base mesh given a single input image as guidance. Our proposed approach allows users to generate 3D textured clothes based on both real and synthetic images, such as those generated by text prompts. The generated assets can be directly draped and simulated on human bodies. We leverage the recent progress of image-to-3D diffusion methods to generate 3D garment geometries. However, since these geometries cannot be utilized directly for downstream tasks, we propose to use them as pseudo ground-truth and set up a mesh deformation optimization procedure that deforms a base template mesh to match the generated 3D target. Carefully designed losses allow the base mesh to freely deform towards the desired target, yet preserve mesh quality and topology such that they can be simulated. Finally, we generate high-fidelity texture maps that are globally and locally consistent and faithfully capture the input guidance, allowing us to render the generated 3D assets. With Garment3DGen users can generate the simulation-ready 3D garment of their choice without the need of artist intervention. We present a plethora of quantitative and qualitative'}, {'id': 'arxiv_2412.14453', 'title': 'Multimodal Latent Diffusion Model for Complex Sewing Pattern Generation', 'URL': 'http://arxiv.org/abs/2412.14453', 'extra_urls': ['http://arxiv.org/abs/2412.14453'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Shengqi'}, {'family': 'Cheng', 'given': 'Yuhao'}, {'family': 'Chen', 'given': 'Zhuo'}, {'family': 'Ren', 'given': 'Xingyu'}, {'family': 'Zhu', 'given': 'Wenhan'}, {'family': 'Li', 'given': 'Lincheng'}, {'family': 'Bi', 'given': 'Mengxiao'}, {'family': 'Yang', 'given': 'Xiaokang'}, {'family': 'Yan', 'given': 'Yichao'}], 'publisher': 'arXiv', 'abstract': 'Generating sewing patterns in garment design is receiving increasing attention due to its CG-friendly and flexible-editing nature. Previous sewing pattern generation methods have been able to produce exquisite clothing, but struggle to design complex garments with detailed control. To address these issues, we propose SewingLDM, a multi-modal generative model that generates sewing patterns controlled by text prompts, body shapes, and garment sketches. Initially, we extend the original vector of sewing patterns into a more comprehensive representation to cover more intricate details and then compress them into a compact latent space. To learn the sewing pattern distribution in the latent space, we design a two-step training strategy to inject the multi-modal conditions, \\ie, body shapes, text prompts, and garment sketches, into a diffusion model, ensuring the generated garments are body-suited and detail-controlled. Comprehensive qualitative and quantitative experiments show the effectiveness of our proposed method, significantly surpassing previous approaches in terms of complex garment design and various body adaptability. Our project page: https://shengqiliu1.github.io/SewingLDM.'}, {'id': 'a_multimodal', 'title': 'AIpparel: A Multimodal Foundation Model for Digital Garments', 'URL': 'https://openaccess.thecvf.com/content/CVPR2025/html/Nakayama_AIpparel_A_Multimodal_Foundation_Model_for_Digital_Garments_CVPR_2025_paper.html', 'extra_urls': ['https://openaccess.thecvf.com/content/CVPR2025/html/Nakayama_AIpparel_A_Multimodal_Foundation_Model_for_Digital_Garments_CVPR_2025_paper.html'], 'type': 'article', 'author': [{'family': 'Nakayama', 'given': 'Kiyohiro'}, {'family': 'Ackermann', 'given': 'Jan'}, {'family': 'Kesdogan', 'given': 'Timur Levent'}, {'family': 'Zheng', 'given': 'Yang'}, {'family': 'Korosteleva', 'given': 'Maria'}, {'family': 'Sorkine-Hornung', 'given': 'Olga'}, {'family': 'Guibas', 'given': 'Leonidas J.'}, {'family': 'Yang', 'given': 'Guandao'}, {'family': 'Wetzstein', 'given': 'Gordon'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'arxiv_2509.09324', 'title': 'Fine-Grained Customized Fashion Design with Image-into-Prompt benchmark and dataset from LMM', 'URL': 'http://arxiv.org/abs/2509.09324', 'extra_urls': ['http://arxiv.org/abs/2509.09324'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Hui'}, {'family': 'You', 'given': 'Yi'}, {'family': 'Chen', 'given': 'Qiqi'}, {'family': 'Zhang', 'given': 'Bingfeng'}, {'family': 'Huang', 'given': 'George Q.'}], 'publisher': 'arXiv', 'abstract': "Generative AI evolves the execution of complex workflows in industry, where the large multimodal model empowers fashion design in the garment industry. Current generation AI models magically transform brainstorming into fancy designs easily, but the fine-grained customization still suffers from text uncertainty without professional background knowledge from end-users. Thus, we propose the Better Understanding Generation (BUG) workflow with LMM to automatically create and fine-grain customize the cloth designs from chat with image-into-prompt. Our framework unleashes users' creative potential beyond words and also lowers the barriers of clothing design/editing without further human involvement. To prove the effectiveness of our model, we propose a new FashionEdit dataset that simulates the real-world clothing design workflow, evaluated from generation similarity, user satisfaction, and quality. The code and dataset: https://github.com/detectiveli/FashionEdit."}, {'id': 'texture', 'title': 'FabricDiffusion: High-Fidelity Texture Transfer for 3D Garments Generation from In-The-Wild Images', 'URL': 'https://dl.acm.org/doi/10.1145/3680528.3687637', 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Cheng'}, {'family': 'Wang', 'given': 'Yuanhao'}, {'family': 'Vicente', 'given': 'Francisco'}, {'family': 'Wu', 'given': 'Chenglei'}, {'family': 'Yang', 'given': 'Jinlong'}, {'family': 'Beeler', 'given': 'Thabo'}, {'family': 'De la Torre', 'given': 'Fernando'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'We introduce FabricDiffusion, a method for transferring fabric textures from a single clothing image to 3D garments of arbitrary shapes. Existing approaches typically synthesize textures on the garment surface through 2D-to-3D texture mapping or depth-aware inpainting via generative models. Unfortunately, these methods often struggle to capture and preserve texture details, particularly due to challenging occlusions, distortions, or poses in the input image. Inspired by the observation that in the fashion industry, most garments are constructed by stitching sewing patterns with flat, repeatable textures, we cast the task of clothing texture transfer as extracting distortion-free, tileable texture materials that are subsequently mapped onto the UV space of the garment. Building upon this insight, we train a denoising diffusion model with a large-scale synthetic dataset to rectify distortions in the input texture image. This process yields a flat texture map that enables a tight coupling with existing Physically-Based Rendering (PBR) material generation pipelines, allowing for realistic relighting of the garment under various lighting conditions. We show that FabricDiffusion can transfer various features from a single clothing image including texture patterns, material properties, and detailed prints and logos. Extensive experiments demonstrate that our model significantly outperforms state-to-the-art methods on both synthetic data and real-world, in-the-wild clothing images while generalizing to unseen textures and garment shapes.'}, {'id': '3dgs_guided', 'title': 'GarmentDreamer: 3DGS Guided Garment Synthesis with Diverse Geometry and Texture Details', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11125627', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11125627'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Boqian'}, {'family': 'Li', 'given': 'Xuan'}, {'family': 'Jiang', 'given': 'Ying'}, {'family': 'Xie', 'given': 'Tianyi'}, {'family': 'Gao', 'given': 'Feng'}, {'family': 'Wang', 'given': 'Huamin'}, {'family': 'Yang', 'given': 'Yin'}, {'family': 'Jiang', 'given': 'Chenfanfu'}], 'abstract': 'Traditional 3D garment creation is labor-intensive, involving sketching, modeling, UV mapping, and texturing, which are time-consuming and costly. Recent advances in diffusion-based generative models have enabled new possibilities for 3D garment generation from text prompts, images, and videos. However, existing methods either suffer from inconsistencies among multi-view images or require additional processes to separate cloth from the underlying human model. In this paper, we propose GarmentDreamer, a novel method that leverages 3D Gaussian Splatting (GS) as guidance to generate wearable, simulation-ready 3D garment meshes from text prompts. In contrast to using multi-view images directly predicted by generative models as guidance, our 3DGS guidance ensures consistent optimization in both garment deformation and texture synthesis. Our method introduces a novel garment augmentation module, guided by normal and RGBA information, and employs implicit Neural Texture Fields (NeTF) combined with Variational Score Distillation (VSD) to generate diverse geometric and texture details. We validate the effectiveness of our approach through comprehensive qualitative and quantitative experiments, showcasing the superior performance of GarmentDreamer over state-of-the-art alternatives11Demos and codes are available at https://xuan-li.github.io/GarmentDreamerDemo/.'}, {'id': 'arxiv_2504.20409', 'title': 'GarmentX: Autoregressive Parametric Representations for High-Fidelity 3D Garment Generation', 'URL': 'http://arxiv.org/abs/2504.20409', 'extra_urls': ['http://arxiv.org/abs/2504.20409'], 'type': 'article', 'author': [{'family': 'Guo', 'given': 'Jingfeng'}, {'family': 'Chen', 'given': 'Jinnan'}, {'family': 'Chen', 'given': 'Weikai'}, {'family': 'Sun', 'given': 'Zhenyu'}, {'family': 'Li', 'given': 'Lanjiong'}, {'family': 'Zhao', 'given': 'Baozhu'}, {'family': 'Zhu', 'given': 'Lingting'}, {'family': 'Wang', 'given': 'Xin'}, {'family': 'Liu', 'given': 'Qi'}], 'publisher': 'arXiv', 'abstract': 'This work presents GarmentX, a novel framework for generating diverse, high-fidelity, and wearable 3D garments from a single input image. Traditional garment reconstruction methods directly predict 2D pattern edges and their connectivity, an overly unconstrained approach that often leads to severe self-intersections and physically implausible garment structures. In contrast, GarmentX introduces a structured and editable parametric representation compatible with GarmentCode, ensuring that the decoded sewing patterns always form valid, simulation-ready 3D garments while allowing for intuitive modifications of garment shape and style. To achieve this, we employ a masked autoregressive model that sequentially predicts garment parameters, leveraging autoregressive modeling for structured generation while mitigating inconsistencies in direct pattern prediction. Additionally, we introduce GarmentX dataset, a large-scale dataset of 378,682 garment parameter-image pairs, constructed through an automatic data generation pipeline that synthesizes diverse and high-quality garment images conditioned on parametric garment representations. Through integrating our method with GarmentX dataset, we achieve state-of-the-art performance in geometric fidelity and input image alignment, significantly outperforming prior approaches. We will release GarmentX dataset upon publication.'}, {'id': 'arxiv_2412.17811', 'title': 'ChatGarment: Garment Estimation, Generation and Editing via Large Language Models', 'URL': 'http://arxiv.org/abs/2412.17811', 'extra_urls': ['http://arxiv.org/abs/2412.17811'], 'type': 'article', 'author': [{'family': 'Bian', 'given': 'Siyuan'}, {'family': 'Xu', 'given': 'Chenghao'}, {'family': 'Xiu', 'given': 'Yuliang'}, {'family': 'Grigorev', 'given': 'Artur'}, {'family': 'Liu', 'given': 'Zhen'}, {'family': 'Lu', 'given': 'Cewu'}, {'family': 'Black', 'given': 'Michael J.'}, {'family': 'Feng', 'given': 'Yao'}], 'publisher': 'arXiv', 'abstract': "We introduce ChatGarment, a novel approach that leverages large vision-language models (VLMs) to automate the estimation, generation, and editing of 3D garments from images or text descriptions. Unlike previous methods that struggle in real-world scenarios or lack interactive editing capabilities, ChatGarment can estimate sewing patterns from in-the-wild images or sketches, generate them from text descriptions, and edit garments based on user instructions, all within an interactive dialogue. These sewing patterns can then be draped on a 3D body and animated. This is achieved by finetuning a VLM to directly generate a JSON file that includes both textual descriptions of garment types and styles, as well as continuous numerical attributes. This JSON file is then used to create sewing patterns through a programming parametric model. To support this, we refine the existing programming model, GarmentCode, by expanding its garment type coverage and simplifying its structure for efficient VLM fine-tuning. Additionally, we construct a large-scale dataset of image-to-sewing-pattern and text-to-sewing-pattern pairs through an automated data pipeline. Extensive evaluations demonstrate ChatGarment's ability to accurately reconstruct, generate, and edit garments from multimodal inputs, highlighting its potential to simplify workflows in fashion and gaming applications. Code and data are available at https://chatgarment.github.io/ ."}, {'id': 'arxiv_2305.06131', 'title': 'Generative AI meets 3D: A Survey on Text-to-3D in AIGC Era', 'URL': 'http://arxiv.org/abs/2305.06131', 'extra_urls': ['http://arxiv.org/abs/2305.06131'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Chenghao'}, {'family': 'Zhang', 'given': 'Chaoning'}, {'family': 'Cho', 'given': 'Joseph'}, {'family': 'Waghwase', 'given': 'Atish'}, {'family': 'Lee', 'given': 'Lik-Hang'}, {'family': 'Rameau', 'given': 'Francois'}, {'family': 'Yang', 'given': 'Yang'}, {'family': 'Bae', 'given': 'Sung-Ho'}, {'family': 'Hong', 'given': 'Choong Seon'}], 'publisher': 'arXiv', 'abstract': 'Generative AI has made significant progress in recent years, with text-guided content generation being the most practical as it facilitates interaction between human instructions and AI-generated content (AIGC). Thanks to advancements in text-to-image and 3D modeling technologies, like neural radiance field (NeRF), text-to-3D has emerged as a nascent yet highly active research field. Our work conducts a comprehensive survey on this topic and follows up on subsequent research progress in the overall field, aiming to help readers interested in this direction quickly catch up with its rapid development. First, we introduce 3D data representations, including both Structured and non-Structured data. Building on this pre-requisite, we introduce various core technologies to achieve satisfactory text-to-3D results. Additionally, we present mainstream baselines and research directions in recent text-to-3D technology, including fidelity, efficiency, consistency, controllability, diversity, and applicability. Furthermore, we summarize the usage of text-to-3D technology in various applications, including avatar generation, texture generation, scene generation and 3D editing. Finally, we discuss the agenda for the future development of text-to-3D.'}, {'id': 'towards_intelligent', 'title': 'StyleMe: Towards Intelligent Fashion Generation with Designer Style', 'URL': 'https://dl.acm.org/doi/10.1145/3544548.3581377', 'type': 'article', 'author': [{'family': 'Wu', 'given': 'Di'}, {'family': 'Yu', 'given': 'Zhiwang'}, {'family': 'Ma', 'given': 'Nan'}, {'family': 'Jiang', 'given': 'Jianan'}, {'family': 'Wang', 'given': 'Yuetian'}, {'family': 'Zhou', 'given': 'Guixiang'}, {'family': 'Deng', 'given': 'Hanhui'}, {'family': 'Li', 'given': 'Yi'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Hand-drawn sketches and sketch colourization are the most laborious but necessary steps for fashion designers to design exquisite clothes, especially when the fashion design requires distinctive and personal characteristics from designer style. This paper presents an artificial intelligent aided fashion design system, namely StyleMe, to support the automatic generation of clothing sketches with designer style. Given the clothing pictures specified by the designer, StyleMe can use deep learning based generative model to generate clothing sketches that are consistent with the designer style. The system also supports intelligent colourization on clothing sketch by style transfer, according to specified styles from the real fashion images. Through a series of performance evaluations and user studies, we found that our system can generate effective clothing sketches as good as fashion designers\u2019 human work, and significantly improve the efficiency of fashion design with its sketch colourization method.'}, {'id': 'a_scriptable', 'title': 'PM4Furniture: A Scriptable Parametric Modeling Interface for Conceptual Furniture Design Using PM4VR', 'URL': 'https://dl.acm.org/doi/10.1145/3703619.3706030', 'type': 'article', 'author': [{'family': 'Li', 'given': 'Wanwan'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'In the field of furniture design, Virtual Reality (VR) has shown potential in enabling immersive prototyping and visualization. However, current VR design tools are often limited by a lack of parametrization, making it challenging for designers to iterate complex furniture forms quickly. This paper presents PM4Furniture, a scriptable parametric modeling interface tailored for VR-based conceptual furniture design. The proposed system leverages a scripting interface of PM4VR framework with a low learning curve that allows designers to adjust the parameters of 3D furniture models in real time. By integrating a VR environment, PM4Furniture enhances user\u2019s interaction and intuitive adjustments of design parameters with immediate visual feedback. We evaluate this novel interface through a preliminary user study with designers interacting with furniture design in an immersive VR environment, revealing PM4Furniture\u2019s design efficiency and creativity in VR furniture prototyping.'}, {'id': 'a_scriptable', 'title': 'PM4Bag: A Scriptable Parametric Modeling Interface for Conceptual Bag Design Using PM4VR', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10677763', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10677763'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Wanwan'}], 'abstract': 'This paper introduces PM4Bag, a novel scriptable parametric modeling interface tailored for conceptual bag design. Leveraging the power of PM4VR, a cutting-edge Parametric Modeling (PM) interface for the Virtual Reality (VR) platform, PM4Bag offers designers a seamless and intuitive toolset to create and customize bag designs in a virtual environment. This paper presents the design and implementation of PM4Bag, highlighting its key features, such as script-based design automation, real-time visualization, and interactive parameter adjustment. A preliminary user study demonstrates the effectiveness and efficiency of PM4Bag in designing a range of diverse bag concepts in virtual reality. The results indicate that PM4Bag facilitates and enhances the creativity and productivity of bag designers, offering a promising avenue for future research in the field of parametric modeling for the conceptual bag design industry.'}, {'id': 'a_scriptable', 'title': 'PM4Fashion: A Scriptable Parametric Modeling Interface for Conceptual Fashion Design Using PM4VR', 'URL': 'https://dl.acm.org/doi/10.1145/3670105.3670159', 'type': 'article', 'author': [{'family': 'Li', 'given': 'Wanwan'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'In the dynamic realm of fashion design, integrating emerging technologies of computational intelligence is essential to enhance creative activities and bring forth novel design concepts. This paper introduces PM4Fashion, a cutting-edge scriptable parametric modeling interface for conceptual fashion design. Leveraging the capabilities of PM4VR (Parametric Modeling for Virtual Reality), PM4Fashion provides designers with a novel interactive toolset to ideate and iterate conceptual fashion design in a virtual environment through diverse design possibilities of advanced parametric modeling technology via virtual reality-enabled platforms.'}, {'id': 'empowering_users', 'title': 'Empowering Non-Expert Users in Fashion Remanufacturing: Enhancing Human-Multi-Robot Interaction through Real-Time Visualization', 'URL': 'https://dl.acm.org/doi/10.1145/3706599.3716232', 'type': 'article', 'author': [{'family': 'Gollob', 'given': 'Emanuel'}, {'family': 'Bastan', 'given': 'Amir'}, {'family': 'Braumann', 'given': 'Johannes'}, {'family': 'Luible-Baer', 'given': 'Christiane'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Automating textile repair and remanufacturing can significantly improve the ecological and societal impact of textiles. However, the complex behavior of textiles poses challenges for integrating robotics into fashion. This research addresses these challenges by developing a platform that empowers non-experts to define complex multi-robot tasks through visualization-enhanced hand guiding. By leveraging collaborative automation, our approach facilitates intuitive human-multi-robot interaction without extensive technical knowledge. Our approach employs flexible, parametric systems and a dual-robot setup to achieve high precision and operational flexibility in remanufacturing processes. Utilizing Grasshopper for path planning and VVVV for real-time interaction, we create a user-friendly interface allowing non-experts to interact intuitively with robots. This work demonstrates how real-time visualization can make advanced robotic capabilities accessible to non-expert users in the fashion industry. By enabling non-experts to leverage these technologies, we aim to transform remanufacturing processes and foster innovation in human-robot collaboration in the fashion and textiles sector.'}, {'id': 'supporting_modular', 'title': 'QUILT: Supporting Modular Design of Machine-Knitting Programs', 'URL': 'https://dl.acm.org/doi/10.1145/3746059.3747608', 'type': 'article', 'author': [{'family': 'Hester', 'given': 'Jack'}, {'family': 'Law', 'given': 'Sebastian'}, {'family': 'Hofmann', 'given': 'Megan'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Knitting machines can manufacture complex layered, textured, and multi-material fabrics and garments. With new programming languages and interfaces there is greater access to the machine\u2019s capabilities. Developers can now create machine instructions that produce a fabric sample or garment. Such files can be easily shared with others, but modifying and combining these samples requires extensive expertise in knitting-specific programming languages, substantial effort, and time. Knit programming offers little support for modular design. We take a step towards modular knitting-machine programming and present QUILT: Quality Unification Infrastructure for Loop-based Textiles. QUILT enables knit programmers to create swatches from knitting programs and lay these swatches out spatially on a 2-dimensional grid. We use three novel knit-program merging algorithms to merge the connected swatches into a quilt program. The knitted structures of each swatch remain unchanged, and our algorithms ensure that the swatches are joined by a seamless boundary that maintains the constraints of knitting-machine programming and knitted-structure construction.'}, {'id': 'making_and', 'title': 'texTile: Making and Re-making Crochet Granny Square Garments Through Computational Design and 3D-printed Connectors', 'URL': 'https://dl.acm.org/doi/10.1145/3715336.3735819', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3715336.3735819'], 'type': 'article', 'author': [{'family': 'Del Valle', 'given': 'Ashley'}, {'family': 'Jacobs', 'given': 'Jennifer'}, {'family': 'Yu', 'given': 'Emilie'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'The rapid turnover of clothing contributes significantly to textile waste. Modular garment-making offers a potential solution by extending garment lifetimes through repair, resizing, and re-purposing, but producing modular garments introduces challenges not supported by existing design approaches or fabrication techniques. We explore the integration of computational design and digital fabrication to propose an alternative path for fashion, where making and re-making become integral to our relationship with garments. We present texTile, a modular fashion workflow that enables designers to assemble reusable crochet tiles into garments. To support our workflow, we developed digitally fabricated connectors for easy assembly and disassembly, a custom pattern solver and user interface to guide garment design, and a visualization tool to help plan manual assembly and reassembly. We conducted a user study with four experienced crocheters. Our results show that texTile can support the construction of tailored garments that integrate re-use as a core principle.'}, {'id': 'curl_quantization_for', 'title': 'Curl Quantization for Automatic Placement of Knit Singularities', 'URL': 'https://dl.acm.org/doi/10.1145/3721238.3730715', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3721238.3730715'], 'type': 'article', 'author': [{'family': 'Mitra', 'given': 'Rahul'}, {'family': 'Couplet', 'given': 'Matt\xe9o'}, {'family': 'Wang', 'given': 'Tongtong'}, {'family': 'Hoffman', 'given': 'Megan'}, {'family': 'Wu', 'given': 'Kui'}, {'family': 'Chien', 'given': 'Edward'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'We develop a method for automatic placement of knit singularities based on curl quantization, extending the knit-planning frameworks of Mitra et&amp;nbsp;al. [2024; 2023]. Stripe patterns are generated that closely follow the isolines of an underlying knitting time function, and has course and wale singularities in regions of high curl for the normalized time function gradient and its 90\xb0 rotated field, respectively. Singularities are placed in an iterative fashion, and we show that this strategy allows us to easily maintain the structural constraints necessary for machine-knitting, e.g., the helix-free constraint, and to satisfy user constraints such as stripe alignment and singularity placement. Our more performant approach obviates the need for a mixed-integer solve [Mitra et&amp;nbsp;al. 2023], manual fixing of singularity positions, or the running of a singularity matching procedure in post-processing [Mitra et&amp;nbsp;al. 2024]. Our global optimization also produces smooth knit graphs that provide quick simulation-free previews of rendered knits without the surface artifacts of competing methods. Furthermore, we extend our method to the popular cut-and-sew garment design paradigm. We validate our method by machine-knitting and rendering yarn-based visualizations of prototypical models in the 3D and cut-and-sew settings.'}, {'id': 'fabricating_accessible', 'title': 'KnitA11y: Fabricating Accessible Designs with Machine Knitting', 'URL': 'https://dl.acm.org/doi/10.1145/3706599.3719709', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3706599.3719709'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Tongyan'}, {'family': 'Zhao', 'given': 'Hanwen'}, {'family': 'Shahpurwala', 'given': 'Yusuf'}, {'family': 'Hofmann', 'given': 'Megan'}, {'family': 'Mankoff', 'given': 'Jennifer'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Association for Computing Machinery', 'abstract': 'Digital knitting machines provide a fast and efficient way to create garments, but commercial knitting tools are limited to predefined templates. While many knitting design tools help users create patterns from scratch, modifying existing patterns remains challenging. This paper introduces KnitA11y, a digital machine knitting pipeline that enables users to import hand-knitting patterns, add accessibility features, and fabricate them using machine knitting. We support modifications such as holes, pockets, and straps/handles, based on common accessible functional modifications identified in a survey of Ravelry.com. KnitA11y offers an interactive design interface that allows users to visualize patterns and customize the position and shape of modifications. We demonstrate KnitA11y\u2019s capabilities through diverse examples, including a sensory-friendly scarf with a pocket, a hat with a hole for assistive devices, a sock with a pull handle, and a mitten with a pocket for heating pads to alleviate Raynaud\u2019s symptoms.'}, {'id': 'arxiv_2306.15166', 'title': 'Constraining Generative Models for Engineering Design with Negative Data', 'URL': 'http://arxiv.org/abs/2306.15166', 'extra_urls': ['http://arxiv.org/abs/2306.15166'], 'type': 'article', 'author': [{'family': 'Regenwetter', 'given': 'Lyle'}, {'family': 'Giannone', 'given': 'Giorgio'}, {'family': 'Srivastava', 'given': 'Akash'}, {'family': 'Gutfreund', 'given': 'Dan'}, {'family': 'Ahmed', 'given': 'Faez'}], 'publisher': 'arXiv', 'abstract': "Generative models have recently achieved remarkable success and widespread adoption in society, yet they often struggle to generate realistic and accurate outputs. This challenge extends beyond language and vision into fields like engineering design, where safety-critical engineering standards and non-negotiable physical laws tightly constrain what outputs are considered acceptable. In this work, we introduce a novel training method to guide a generative model toward constraint-satisfying outputs using `negative data' -- examples of what to avoid. Our negative-data generative model (NDGM) formulation easily outperforms classic models, generating 1/6 as many constraint-violating samples using 1/8 as much data in certain problems. It also consistently outperforms other baselines, achieving a balance between constraint satisfaction and distributional similarity that is unsurpassed by any other model in 12 of the 14 problems tested. This widespread superiority is rigorously demonstrated across numerous synthetic tests and real engineering problems, such as ship hull synthesis with hydrodynamic constraints and vehicle design with impact safety constraints. Our benchmarks showcase both the best-in-class performance of our new NDGM formulation and the overall dominance of NDGMs versus classic generative models. We publicly release the code and benchmarks at https://github.com/Lyleregenwetter/NDGMs."}, {'id': 'arxiv_2405.12420', 'title': 'GarmentDreamer: 3DGS Guided Garment Synthesis with Diverse Geometry and Texture Details', 'URL': 'http://arxiv.org/abs/2405.12420', 'extra_urls': ['http://arxiv.org/abs/2405.12420'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Boqian'}, {'family': 'Li', 'given': 'Xuan'}, {'family': 'Jiang', 'given': 'Ying'}, {'family': 'Xie', 'given': 'Tianyi'}, {'family': 'Gao', 'given': 'Feng'}, {'family': 'Wang', 'given': 'Huamin'}, {'family': 'Yang', 'given': 'Yin'}, {'family': 'Jiang', 'given': 'Chenfanfu'}], 'publisher': 'arXiv', 'abstract': 'Traditional 3D garment creation is labor-intensive, involving sketching, modeling, UV mapping, and texturing, which are time-consuming and costly. Recent advances in diffusion-based generative models have enabled new possibilities for 3D garment generation from text prompts, images, and videos. However, existing methods either suffer from inconsistencies among multi-view images or require additional processes to separate cloth from the underlying human model. In this paper, we propose GarmentDreamer, a novel method that leverages 3D Gaussian Splatting (GS) as guidance to generate wearable, simulation-ready 3D garment meshes from text prompts. In contrast to using multi-view images directly predicted by generative models as guidance, our 3DGS guidance ensures consistent optimization in both garment deformation and texture synthesis. Our method introduces a novel garment augmentation module, guided by normal and RGBA information, and employs implicit Neural Texture Fields (NeTF) combined with Score Distillation Sampling (SDS) to generate diverse geometric and texture details. We validate the effectiveness of our approach through comprehensive qualitative and quantitative experiments, showcasing the superior performance of GarmentDreamer over state-of-the-art alternatives. Our project page is available at: https://xuan-li.github.io/GarmentDreamerDemo/.'}, {'id': 'arxiv_2302.02913', 'title': 'Beyond Statistical Similarity: Rethinking Metrics for Deep Generative Models in Engineering Design', 'URL': 'http://arxiv.org/abs/2302.02913', 'extra_urls': ['http://arxiv.org/abs/2302.02913'], 'type': 'article', 'author': [{'family': 'Regenwetter', 'given': 'Lyle'}, {'family': 'Srivastava', 'given': 'Akash'}, {'family': 'Gutfreund', 'given': 'Dan'}, {'family': 'Ahmed', 'given': 'Faez'}], 'publisher': 'arXiv', 'abstract': "Deep generative models such as Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), Diffusion Models, and Transformers, have shown great promise in a variety of applications, including image and speech synthesis, natural language processing, and drug discovery. However, when applied to engineering design problems, evaluating the performance of these models can be challenging, as traditional statistical metrics based on likelihood may not fully capture the requirements of engineering applications. This paper doubles as a review and practical guide to evaluation metrics for deep generative models (DGMs) in engineering design. We first summarize the well-accepted `classic' evaluation metrics for deep generative models grounded in machine learning theory. Using case studies, we then highlight why these metrics seldom translate well to design problems but see frequent use due to the lack of established alternatives. Next, we curate a set of design-specific metrics which have been proposed across different research communities and can be used for evaluating deep generative models. These metrics focus on unique requirements in design and engineering, such as constraint satisfaction, functional performance, novelty, and conditioning. Throughout our discussion, we apply the metrics to models trained on simple-to-visualize 2-dimensional example problems. Finally, we evaluate four deep generative models on a bicycle frame design problem and structural topology generation problem. In particular, we showcase the use of proposed metrics to quantify performance target achievement, design novelty, and geometric constraints. We publicly release the code for the datasets, models, and metrics used throughout the paper at https://decode.mit.edu/projects/metrics/."}, {'id': 'arxiv_2112.01988', 'title': 'ROCA: Robust CAD Model Retrieval and Alignment from a Single Image', 'URL': 'http://arxiv.org/abs/2112.01988', 'extra_urls': ['http://arxiv.org/abs/2112.01988'], 'type': 'article', 'author': [{'family': 'G\xfcmeli', 'given': 'Can'}, {'family': 'Dai', 'given': 'Angela'}, {'family': 'Nie\xdfner', 'given': 'Matthias'}], 'abstract': 'We present ROCA, a novel end-to-end approach that retrieves and aligns 3D CAD models from a shape database to a single input image. This enables 3D perception of an observed scene from a 2D RGB observation, characterized as a lightweight, compact, clean CAD representation. Core to our approach is our differentiable alignment optimization based on dense 2D-3D object correspondences and Procrustes alignment. ROCA can thus provide a robust CAD alignment while simultaneously informing CAD retrieval by leveraging the 2D-3D correspondences to learn geometrically similar CAD models. Experiments on challenging, real-world imagery from ScanNet show that ROCA significantly improves on state of the art, from 9.5% to 17.6% in retrieval-aware CAD alignment accuracy.'}, {'id': 'arxiv_2412.08603', 'title': 'Design2GarmentCode: Turning Design Concepts to Tangible Garments Through Program Synthesis', 'URL': 'http://arxiv.org/abs/2412.08603', 'extra_urls': ['http://arxiv.org/abs/2412.08603'], 'type': 'article', 'author': [{'family': 'Zhou', 'given': 'Feng'}, {'family': 'Liu', 'given': 'Ruiyang'}, {'family': 'Liu', 'given': 'Chen'}, {'family': 'He', 'given': 'Gaofeng'}, {'family': 'Li', 'given': 'Yong-Lu'}, {'family': 'Jin', 'given': 'Xiaogang'}, {'family': 'Wang', 'given': 'Huamin'}], 'publisher': 'arXiv', 'abstract': 'Sewing patterns, the essential blueprints for fabric cutting and tailoring, act as a crucial bridge between design concepts and producible garments. However, existing uni-modal sewing pattern generation models struggle to effectively encode complex design concepts with a multi-modal nature and correlate them with vectorized sewing patterns that possess precise geometric structures and intricate sewing relations. In this work, we propose a novel sewing pattern generation approach \\textbf{Design2GarmentCode} based on Large Multimodal Models (LMMs), to generate parametric pattern-making programs from multi-modal design concepts. LMM offers an intuitive interface for interpreting diverse design inputs, while pattern-making programs could serve as well-structured and semantically meaningful representations of sewing patterns, and act as a robust bridge connecting the cross-domain pattern-making knowledge embedded in LMMs with vectorized sewing patterns. Experimental results demonstrate that our method can flexibly handle various complex design expressions such as images, textual descriptions, designer sketches, or their combinations, and convert them into size-precise sewing patterns with correct stitches. Compared to previous methods, our approach significantly enhances training efficiency, generation quality, and authoring flexibility.'}, {'id': 'arxiv_2304.03442', 'title': 'Generative Agents: Interactive Simulacra of Human Behavior', 'URL': 'https://arxiv.org/abs/2304.03442', 'extra_urls': ['https://arxiv.org/abs/2304.03442'], 'type': 'article', 'author': [{'family': 'Park', 'given': 'Joon Sung'}, {'family': "O'Brien", 'given': 'Joseph C.'}, {'family': 'Cai', 'given': 'Carrie J.'}, {'family': 'Morris', 'given': 'Meredith Ringel'}, {'family': 'Liang', 'given': 'Percy'}, {'family': 'Bernstein', 'given': 'Michael S.'}], 'publisher': 'arXiv', 'abstract': "Believable proxies of human behavior can empower interactive applications\nranging from immersive environments to rehearsal spaces for interpersonal\ncommunication to prototyping tools. In this paper, we introduce generative\nagents--computational software agents that simulate believable human behavior.\nGenerative agents wake up, cook breakfast, and head to work; artists paint,\nwhile authors write; they form opinions, notice each other, and initiate\nconversations; they remember and reflect on days past as they plan the next\nday. To enable generative agents, we describe an architecture that extends a\nlarge language model to store a complete record of the agent's experiences\nusing natural language, synthesize those memories over time into higher-level\nreflections, and retrieve them dynamically to plan behavior. We instantiate\ngenerative agents to populate an interactive sandbox environment inspired by\nThe Sims, where end users can interact with a small town of twenty five agents\nusing natural language. In an evaluation, these generative agents produce\nbelievable individual and emergent social behaviors: for example, starting with\nonly a single user-specified notion that one agent wants to throw a Valentine's\nDay party, the agents autonomously spread invitations to the party over the\nnext two days, make new acquaintances, ask each other out on dates to the\nparty, and coordinate to show up for the party together at the right time. We\ndemonstrate through ablation that the components of our agent\narchitecture--observation, planning, and reflection--each contribute critically\nto the believability of agent behavior. By fusing large language models with\ncomputational, interactive agents, this work introduces architectural and\ninteraction patterns for enabling believable simulations of human behavior."}, {'id': 'arxiv_2410.10762', 'title': 'AFlow: Automating Agentic Workflow Generation', 'URL': 'http://arxiv.org/abs/2410.10762', 'extra_urls': ['http://arxiv.org/abs/2410.10762'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Jiayi'}, {'family': 'Xiang', 'given': 'Jinyu'}, {'family': 'Yu', 'given': 'Zhaoyang'}, {'family': 'Teng', 'given': 'Fengwei'}, {'family': 'Chen', 'given': 'Xionghui'}, {'family': 'Chen', 'given': 'Jiaqi'}, {'family': 'Zhuge', 'given': 'Mingchen'}, {'family': 'Cheng', 'given': 'Xin'}, {'family': 'Hong', 'given': 'Sirui'}, {'family': 'Wang', 'given': 'Jinlin'}, {'family': 'Zheng', 'given': 'Bingnan'}, {'family': 'Liu', 'given': 'Bang'}, {'family': 'Luo', 'given': 'Yuyu'}, {'family': 'Wu', 'given': 'Chenglin'}], 'publisher': 'arXiv', 'abstract': "Large language models (LLMs) have demonstrated remarkable potential in solving complex tasks across diverse domains, typically by employing agentic workflows that follow detailed instructions and operational sequences. However, constructing these workflows requires significant human effort, limiting scalability and generalizability. Recent research has sought to automate the generation and optimization of these workflows, but existing methods still rely on initial manual setup and fall short of achieving fully automated and effective workflow generation. To address this challenge, we reformulate workflow optimization as a search problem over code-represented workflows, where LLM-invoking nodes are connected by edges. We introduce AFlow, an automated framework that efficiently explores this space using Monte Carlo Tree Search, iteratively refining workflows through code modification, tree-structured experience, and execution feedback. Empirical evaluations across six benchmark datasets demonstrate AFlow's efficacy, yielding a 5.7% average improvement over state-of-the-art baselines. Furthermore, AFlow enables smaller models to outperform GPT-4o on specific tasks at 4.55% of its inference cost in dollars. The code is available at https://github.com/FoundationAgents/AFlow."}, {'id': 'arxiv_2507.06250', 'title': 'We Urgently Need Privilege Management in MCP: A Measurement of API Usage in MCP Ecosystems', 'URL': 'http://arxiv.org/abs/2507.06250', 'extra_urls': ['http://arxiv.org/abs/2507.06250'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Zhihao'}, {'family': 'Li', 'given': 'Kun'}, {'family': 'Ma', 'given': 'Boyang'}, {'family': 'Xu', 'given': 'Minghui'}, {'family': 'Zhang', 'given': 'Yue'}, {'family': 'Cheng', 'given': 'Xiuzhen'}], 'publisher': 'arXiv', 'abstract': 'The Model Context Protocol (MCP) has emerged as a widely adopted mechanism for connecting large language models to external tools and resources. While MCP promises seamless extensibility and rich integrations, it also introduces a substantially expanded attack surface: any plugin can inherit broad system privileges with minimal isolation or oversight. In this work, we conduct the first large-scale empirical analysis of MCP security risks. We develop an automated static analysis framework and systematically examine 2,562 real-world MCP applications spanning 23 functional categories. Our measurements reveal that network and system resource APIs dominate usage patterns, affecting 1,438 and 1,237 servers respectively, while file and memory resources are less frequent but still significant. We find that Developer Tools and API Development plugins are the most API-intensive, and that less popular plugins often contain disproportionately high-risk operations. Through concrete case studies, we demonstrate how insufficient privilege separation enables privilege escalation, misinformation propagation, and data tampering. Based on these findings, we propose a detailed taxonomy of MCP resource access, quantify security-relevant API usage, and identify open challenges for building safer MCP ecosystems, including dynamic permission models and automated trust assessment.'}, {'id': 'arxiv_2509.24272', 'title': 'When MCP Servers Attack: Taxonomy, Feasibility, and Mitigation', 'URL': 'http://arxiv.org/abs/2509.24272', 'extra_urls': ['http://arxiv.org/abs/2509.24272'], 'type': 'article', 'author': [{'family': 'Zhao', 'given': 'Weibo'}, {'family': 'Liu', 'given': 'Jiahao'}, {'family': 'Ruan', 'given': 'Bonan'}, {'family': 'Li', 'given': 'Shaofei'}, {'family': 'Liang', 'given': 'Zhenkai'}], 'publisher': 'arXiv', 'abstract': 'Model Context Protocol (MCP) servers enable AI applications to connect to external systems in a plug-and-play manner, but their rapid proliferation also introduces severe security risks. Unlike mature software ecosystems with rigorous vetting, MCP servers still lack standardized review mechanisms, giving adversaries opportunities to distribute malicious implementations. Despite this pressing risk, the security implications of MCP servers remain underexplored. To address this gap, we present the first systematic study that treats MCP servers as active threat actors and decomposes them into core components to examine how adversarial developers can implant malicious intent. Specifically, we investigate three research questions: (i) what types of attacks malicious MCP servers can launch, (ii) how vulnerable MCP hosts and Large Language Models (LLMs) are to these attacks, and (iii) how feasible it is to carry out MCP server attacks in practice. Our study proposes a component-based taxonomy comprising twelve attack categories. For each category, we develop Proof-of-Concept (PoC) servers and demonstrate their effectiveness across diverse real-world host-LLM settings. We further show that attackers can generate large numbers of malicious servers at virtually no cost. We then test state-of-the-art scanners on the generated servers and found that existing detection approaches are insufficient. These findings highlight that malicious MCP servers are easy to implement, difficult to detect with current tools, and capable of causing concrete damage to AI agent systems. Addressing this threat requires coordinated efforts among protocol designers, host developers, LLM providers, and end users to build a more secure and resilient MCP ecosystem.'}, {'id': 'arxiv_2503.13657', 'title': 'Why Do Multi-Agent LLM Systems Fail?', 'URL': 'http://arxiv.org/abs/2503.13657', 'extra_urls': ['http://arxiv.org/abs/2503.13657'], 'type': 'article', 'author': [{'family': 'Cemri', 'given': 'Mert'}, {'family': 'Pan', 'given': 'Melissa Z.'}, {'family': 'Yang', 'given': 'Shuyi'}, {'family': 'Agrawal', 'given': 'Lakshya A.'}, {'family': 'Chopra', 'given': 'Bhavya'}, {'family': 'Tiwari', 'given': 'Rishabh'}, {'family': 'Keutzer', 'given': 'Kurt'}, {'family': 'Parameswaran', 'given': 'Aditya'}, {'family': 'Klein', 'given': 'Dan'}, {'family': 'Ramchandran', 'given': 'Kannan'}, {'family': 'Zaharia', 'given': 'Matei'}, {'family': 'Gonzalez', 'given': 'Joseph E.'}, {'family': 'Stoica', 'given': 'Ion'}], 'publisher': 'arXiv', 'abstract': "Despite growing enthusiasm for Multi-Agent LLM Systems (MAS), their performance gains on popular benchmarks often remain minimal compared with single-agent frameworks. This gap highlights the need to systematically analyze the challenges hindering MAS effectiveness. We present MAST (Multi-Agent System Failure Taxonomy), the first empirically grounded taxonomy designed to understand MAS failures. We analyze seven popular MAS frameworks across over 200 tasks, involving six expert human annotators. Through this process, we identify 14 unique failure modes, organized into 3 overarching categories, (i) specification issues, (ii) inter-agent misalignment, and (iii) task verification. MAST emerges iteratively from rigorous inter-annotator agreement studies, achieving a Cohen's Kappa score of 0.88. To support scalable evaluation, we develop a validated LLM-as-a-Judge pipeline integrated with MAST. We leverage two case studies to demonstrate MAST's practical utility in analyzing failures and guiding MAS development. Our findings reveal that identified failures require more complex solutions, highlighting a clear roadmap for future research. We open source our comprehensive dataset and LLM annotator to facilitate further development of MAS."}, {'id': 'doi_10_1109_BIGCOMP_2016_7425981', 'title': 'A runtime verification framework for dynamically adaptive multi-agent systems', 'URL': 'https://doi.org/10.1109/BIGCOMP.2016.7425981', 'extra_urls': ['https://doi.org/10.1109/BIGCOMP.2016.7425981'], 'type': 'article', 'author': [{'family': 'Lim', 'given': 'Yoo Jin'}, {'family': 'Hong', 'given': 'Gwangui'}, {'family': 'Shin', 'given': 'Donghwan'}, {'family': 'Jee', 'given': 'Eunkyoung'}, {'family': 'Bae', 'given': 'Doo-Hwan'}], 'abstract': 'Dynamically adaptive multi-agent systems (DAMS) consist of multiple agents that adapt to changing system and environmental conditions in order to achieve collaborative goals. As DAMS are found in applications across various domains, ensuring the correct and safe adaptations of DAMS has become more important. Formal verification techniques such as model checking present a promising approach to guaranteeing the correctness of a software system with respect to certain system requirements. Previous works on formal verification for dynamically adaptive system or multi-agent system, however, have not addressed the runtime and collaborative nature inherent to DAMS operations. This work proposes a runtime verification framework for DAMS (DAMS-RV) based on an adaptive feedback loop, which is activated for each adaptation that system makes after a change in the system or environment. The proposed framework is described using a collaborative nurse agent system as a running example. A case study with an application scenario provides insights into how DAMS-RV can serve as a feasible and effective framework for DAMS verification.', 'DOI': '10.1109/BIGCOMP.2016.7425981'}, {'id': 'billion', 'title': "H&amp;M's $4.3 billion problem: A bundle of unsold clothes", 'URL': 'https://www.bloomberg.com/news/articles/2018-03-27/h-m-s-4-3-billion-problem-is-a-bunch-of-clothes-nobody-wants', 'extra_urls': ['https://www.bloomberg.com/news/articles/2018-03-27/h-m-s-4-3-billion-problem-is-a-bunch-of-clothes-nobody-wants'], 'type': 'article', 'author': [{'family': 'Bloomberg News'}], 'issued': {'date-parts': [[2018]]}}, {'id': 'the_resale', 'title': 'The resale effect: Impact of authentication on luxury resale values', 'URL': '#item_20342', 'type': 'article', 'author': [{'family': 'Vestiaire Collective'}], 'issued': {'date-parts': [[2022]]}}, {'id': 'arxiv_2510.00229', 'title': 'DualTune: Decoupled Fine-Tuning for On-Device Agentic Systems', 'URL': 'http://arxiv.org/abs/2510.00229', 'extra_urls': ['http://arxiv.org/abs/2510.00229'], 'type': 'article', 'author': [{'family': 'Kadekodi', 'given': 'Rohan'}, {'family': 'Jin', 'given': 'Zhan'}, {'family': 'Kamahori', 'given': 'Keisuke'}, {'family': 'Gu', 'given': 'Yile'}, {'family': 'Khatiri', 'given': 'Sean'}, {'family': 'Bayindirli', 'given': 'Noah H.'}, {'family': 'Gorbunov', 'given': 'Sergey'}, {'family': 'Kasikci', 'given': 'Baris'}], 'publisher': 'arXiv', 'abstract': 'The deployment of Large Language Models (LLMs) as agentic orchestrators has revolutionized task automation, but the need for privacy-preserving, cost-effective solutions demands on-device inference capabilities. However, local LLMs consistently underperform compared to frontier models in tool calling scenarios, struggling with both tool selection from large tool sets and accurate argument generation for complex parameter structures. We introduce a methodology that disaggregates a tool-calling task into two distinct subtasks: tool selection and argument generation. We propose "decoupled fine-tuning", a novel post-training approach that employs LoRA fine-tuning to create dedicated LoRA adapters for tool selection and tool-specific argument generation using separate loss masking for each of the subtasks. Furthermore, we present DualTune, an inference framework that leverages the LoRA adapters created using decoupled fine-tuning to perform efficient agent orchestration with the help of local models on end-user devices. DualTune decomposes the tool-call generation step into tool selection and argument generation, and dynamically loads the corresponding LoRA adapters to generate tool calls. Additionally, DualTune implements hierarchical orchestration to restrict the number of tools required for tool selection. Our experiments on the MCP-Bench benchmark demonstrate that the Qwen-2.5-7B model trained using decoupled fine-tuning improves the tool calling accuracy of the base model by 46%, and outperforms other local reasoning, non-reasoning and fine-tuned models of similar size in all cases, and models that are 2x larger, in most cases.'}, {'id': 'arxiv_2510.15994', 'title': 'MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents', 'URL': 'http://arxiv.org/abs/2510.15994', 'extra_urls': ['http://arxiv.org/abs/2510.15994'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Dongsen'}, {'family': 'Li', 'given': 'Zekun'}, {'family': 'Luo', 'given': 'Xu'}, {'family': 'Liu', 'given': 'Xuannan'}, {'family': 'Li', 'given': 'Peipei'}, {'family': 'Xu', 'given': 'Wenjun'}], 'publisher': 'arXiv', 'abstract': 'The Model Context Protocol (MCP) standardizes how large language model (LLM) agents discover, describe, and call external tools. While MCP unlocks broad interoperability, it also enlarges the attack surface by making tools first-class, composable objects with natural-language metadata, and standardized I/O. We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling. MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed attacks; (2) an evaluation harness that executes attacks by running real tools (both benign and malicious) via MCP rather than simulation; and (3) a robustness metric that quantifies the trade-off between security and performance: Net Resilient Performance (NRP). We evaluate nine popular LLM agents across 10 domains and 400+ tools, producing 2,000 attack instances. Results reveal the effectiveness of attacks against each stage of MCP. Models with stronger performance are more vulnerable to attacks due to their outstanding tool calling and instruction following capabilities. MSB provides a practical baseline for researchers and practitioners to study, compare, and harden MCP agents.'}, {'id': 'arxiv_2505.12490', 'title': 'Improving Google A2A Protocol: Protecting Sensitive Data and Mitigating Unintended Harms in Multi-Agent Systems', 'URL': 'http://arxiv.org/abs/2505.12490', 'extra_urls': ['http://arxiv.org/abs/2505.12490'], 'type': 'article', 'author': [{'family': 'Louck', 'given': 'Yedidel'}, {'family': 'Stulman', 'given': 'Ariel'}, {'family': 'Dvir', 'given': 'Amit'}], 'publisher': 'arXiv', 'abstract': 'Googles A2A protocol provides a secure communication framework for AI agents but demonstrates critical limitations when handling highly sensitive information such as payment credentials and identity documents. These gaps increase the risk of unintended harms, including unauthorized disclosure, privilege escalation, and misuse of private data in generative multi-agent environments. In this paper, we identify key weaknesses of A2A: insufficient token lifetime control, lack of strong customer authentication, overbroad access scopes, and missing consent flows. We propose protocol-level enhancements grounded in a structured threat model for semi-trusted multi-agent systems. Our refinements introduce explicit consent orchestration, ephemeral scoped tokens, and direct user-to-service data channels to minimize exposure across time, context, and topology. Empirical evaluation using adversarial prompt injection tests shows that the enhanced protocol substantially reduces sensitive data leakage while maintaining low communication latency. Comparative analysis highlights the advantages of our approach over both the original A2A specification and related academic proposals. These contributions establish a practical path for evolving A2A into a privacy-preserving framework that mitigates unintended harms in multi-agent generative AI systems.'}, {'id': 'doi_10_1038_s41746-024-01085-w', 'title': 'Distribution shift detection for the postmarket surveillance of medical AI algorithms: a retrospective simulation study', 'URL': 'https://doi.org/10.1038/s41746-024-01085-w', 'extra_urls': ['https://doi.org/10.1038/s41746-024-01085-w'], 'type': 'article', 'author': [{'family': 'Koch', 'given': 'Lisa M.'}, {'family': 'Baumgartner', 'given': 'Christian F.'}, {'family': 'Berens', 'given': 'Philipp'}], 'abstract': 'Distribution shifts remain a problem for the safe application of regulated medical AI systems, and may impact their real-world performance if undetected. Postmarket shifts can occur for example if algorithms developed on data from various acquisition settings and a heterogeneous population are predominantly applied in hospitals with lower quality data acquisition or other centre-specific acquisition factors, or where some ethnicities are over-represented. Therefore, distribution shift detection could be important for monitoring AI-based medical products during postmarket surveillance. We implemented and evaluated three deep-learning based shift detection techniques (classifier-based, deep kernel, and multiple univariate kolmogorov-smirnov tests) on simulated shifts in a dataset of 130\u2019486 retinal images. We trained a deep learning classifier for diabetic retinopathy grading. We then simulated population shifts by changing the prevalence of patients\u2019 sex, ethnicity, and co-morbidities, and example acquisition shifts by changes in image quality. We observed classification subgroup performance disparities w.r.t. image quality, patient sex, ethnicity and co-morbidity presence. The sensitivity at detecting referable diabetic retinopathy ranged from 0.50 to 0.79 for different ethnicities. This motivates the need for detecting shifts after deployment. Classifier-based tests performed best overall, with perfect detection rates for quality and co-morbidity subgroup shifts at a sample size of 1000. It was the only method to detect shifts in patient sex, but required large sample sizes ($$&gt; 30^{\\prime} 000$$). All methods identified easier-to-detect out-of-distribution shifts with small (\u2264300) sample sizes. We conclude that effective tools exist for detecting clinically relevant distribution shifts. In particular classifier-based tests can be easily implemented components in the post-market surveillance strategy of medical device manufacturers.', 'DOI': '10.1038/s41746-024-01085-w'}, {'id': 'doi_10_1038_s42256-024-00857-z', 'title': 'Systematic analysis of 32,111 AI model cards characterizes documentation practice in AI', 'URL': 'https://doi.org/10.1038/s42256-024-00857-z', 'extra_urls': ['https://doi.org/10.1038/s42256-024-00857-z'], 'type': 'article', 'author': [{'family': 'Liang', 'given': 'Weixin'}, {'family': 'Rajani', 'given': 'Nazneen'}, {'family': 'Yang', 'given': 'Xinyu'}, {'family': 'Ozoani', 'given': 'Ezinwanne'}, {'family': 'Wu', 'given': 'Eric'}, {'family': 'Chen', 'given': 'Yiqun'}, {'family': 'Smith', 'given': 'Daniel Scott'}, {'family': 'Zou', 'given': 'James'}], 'abstract': 'The rapid proliferation of AI models has underscored the importance of thorough documentation, which enables users to understand, trust and effectively use these models in various applications. Although developers are encouraged to produce model cards, it\u2019s not clear how much or what information these cards contain. In this study we conduct a comprehensive analysis of 32,111 AI model documentations on Hugging Face, a leading platform for distributing and deploying AI models. Our investigation sheds light on the prevailing model card documentation practices. Most AI models with a substantial number of downloads provide model cards, although with uneven informativeness. We find that sections addressing environmental impact, limitations and evaluation exhibit the lowest filled-out rates, whereas the training section is the one most consistently filled-out. We analyse the content of each section to characterize practitioners\u2019 priorities. Interestingly, there are considerable discussions of data, sometimes with equal or even greater emphasis than the model itself. Our study provides a systematic assessment of community norms and practices surroinding model documentation through large-scale data science and linguistic analysis.', 'DOI': '10.1038/s42256-024-00857-z'}, {'id': 'doi_10_1007_s10676-024-09757-7', 'title': 'Use case cards: a use case reporting framework inspired by the European AI Act', 'URL': 'https://doi.org/10.1007/s10676-024-09757-7', 'extra_urls': ['https://doi.org/10.1007/s10676-024-09757-7'], 'type': 'article', 'author': [{'family': 'Hupont', 'given': 'Isabelle'}, {'family': 'Fern\xe1ndez-Llorca', 'given': 'David'}, {'family': 'Baldassarri', 'given': 'Sandra'}, {'family': 'G\xf3mez', 'given': 'Emilia'}], 'abstract': 'Despite recent efforts by the Artificial Intelligence (AI) community to move towards standardised procedures for documenting models, methods, systems or datasets, there is currently no methodology focused on use cases aligned with the risk-based approach of the European AI Act (AI Act). In this paper, we propose a new framework for the documentation of use cases that we call use case cards, based on the use case modelling included in the Unified Markup Language (UML) standard. Unlike other documentation methodologies, we focus on the intended purpose and operational use of an AI system. It consists of two main parts: firstly, a UML-based template, tailored to allow implicitly assessing the risk level of the AI system and defining relevant requirements, and secondly, a supporting UML diagram designed to provide information about the system-user interactions and relationships. The proposed framework is the result of a co-design process involving a relevant team of EU policy experts and scientists. We have validated our proposal with 11 experts with different backgrounds and a reasonable knowledge of the AI Act as a prerequisite. We provide the 5 use case cards used in the co-design and validation process. Use case cards allows framing and contextualising use cases in an effective way, and we hope this methodology can be a useful tool for policy makers and providers for documenting use cases, assessing the risk level, adapting the different requirements and building a catalogue of existing usages of AI.', 'DOI': '10.1007/s10676-024-09757-7'}, {'id': 'doi_10_1108_IMDS-08-2022-0468', 'title': 'Using deep learning to interpolate the missing data in time-series for\xa0credit risks along supply chain', 'URL': 'https://doi.org/10.1108/IMDS-08-2022-0468', 'extra_urls': ['https://doi.org/10.1108/IMDS-08-2022-0468'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Wenfeng'}, {'family': 'Lim', 'given': 'Ming K.'}, {'family': 'Yang', 'given': 'Mei'}, {'family': 'Li', 'given': 'Xingzhi'}, {'family': 'Ni', 'given': 'Du'}], 'abstract': 'As the supply chain is a highly integrated infrastructure in modern business, the risks in supply chain are also becoming highly contagious among the target company. This motivates researchers to continuously add new features to the datasets for the credit risk prediction (CRP). However, adding new features can easily lead to missing of the data.Based on the gaps summarized from the literature in CRP, this study first introduces the approaches to the building of datasets and the framing of the algorithmic models. Then, this study tests the interpolation effects of the algorithmic model in three artificial datasets with different missing rates and compares its predictability before and after the interpolation in a real dataset with the missing data in irregular time-series.The algorithmic model of the time-decayed long short-term memory (TD-LSTM) proposed in this study can monitor the missing data in irregular time-series by capturing more and better time-series information, and interpolating the missing data efficiently. Moreover, the algorithmic model of Deep Neural Network can be used in the CRP for the datasets with the missing data in irregular time-series after the interpolation by the TD-LSTM.This study fully validates the TD-LSTM interpolation effects and demonstrates that the predictability of the dataset after interpolation is improved. Accurate and timely CRP can undoubtedly assist a target company in avoiding losses. Identifying credit risks and taking preventive measures ahead of time, especially in the case of public emergencies, can help the company minimize losses.', 'DOI': '10.1108/IMDS-08-2022-0468'}, {'id': 'missing_data_assumptions', 'title': 'Missing Data Assumptions', 'URL': 'https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-040720-031104', 'extra_urls': ['https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-040720-031104'], 'type': 'article', 'author': [{'family': 'Little', 'given': 'Roderick J.'}], 'abstract': 'I review assumptions about the missing-data mechanisms that underlie methods for the statistical analysis of data with missing values. I describe Rubin&amp;apos;s original definition of missing at random (MAR), its motivation and criticisms, and his sufficient conditions for ignoring the missingness mechanism for likelihood-based, Bayesian, and frequentist inference. Related definitions, including missing completely at random, always MAR, always missing completely at random, and partially MAR, are also covered. I present a formal argument for weakening Rubin&amp;apos;s sufficient conditions for frequentist maximum likelihood inference with precision based on the observed information. Some simple examples of MAR are described, together with an example where the missingness mechanism can be ignored even though MAR does not hold. Alternative approaches to statistical inference based on the likelihood function are reviewed, along with non-likelihood frequentist approaches, including weighted generalized estimating equations. Connections with the causal inference literature are also discussed. Finally, alternatives to Rubin&amp;apos;s MAR definition are discussed, including informative missingness, informative censoring, and coarsening at random. The intent is to provide a relatively nontechnical discussion, although some of the underlying issues are challenging and touch on fundamental questions of statistical inference.'}, {'id': 'future_images_of', 'title': 'Future images of data in circular economy for textiles', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0040162522003833', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0040162522003833'], 'type': 'article', 'author': [{'family': 'Luoma', 'given': 'P\xe4ivi'}, {'family': 'Penttinen', 'given': 'Esko'}, {'family': 'Tapio', 'given': 'Petri'}, {'family': 'Toppinen', 'given': 'Anne'}], 'abstract': "Rapid expansion of digitalization and in the volume of data available constitutes a major driver toward circular economy. In the textile industry, with its vast quantities of waste and huge environmental impact, transformation toward such circularity is necessary but challenging. To explore how the use of data could support building sustainability-aligned pathways to circular economy of textiles, a study employing a two-round disaggregative Delphi approach (engaging 33 experts in the first round, in May 2021, and 26 in the second, in June 2021) articulated alternative images of the future. The three images, dubbed Transparency, Conflicting Interests, and Sustainable Textiles, imply that the role for data is intertwined with sustainability aspirations. The results highlight that exploiting data in pursuit of circular economy is a collaborative effort involving business value networks that include consumers and regulators. Availability and sharing of accountability-affording, meaningful data on textiles' life cycle and value network function as a key enabler. By working with the images developed, actors can better assess their circular-economy commitments, planned actions, and the consequences of these. Furthermore, the images provide a tool for mutual discussion of the development desired and of related responsibilities and uncertainties."}, {'id': 'a_comprehensive_review', 'title': 'A comprehensive review of circular economy research in the textile and clothing industry', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0959652624006991', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0959652624006991'], 'type': 'article', 'author': [{'family': 'Saha', 'given': 'Krishnendu'}, {'family': 'Dey', 'given': 'Prasanta Kumar'}, {'family': 'Kumar', 'given': 'Vikas'}], 'abstract': 'The textile and clothing industry is a significant global sector due to its economic and social contributions. However, it is one of the most polluting industries. There has been a significant uptake of research on circular economy implementation to reduce its environmental impacts. Nevertheless, there is a critical gap in reviewing how the research field is evolving and what the core focus and underlying assumptions of the existing research are. This paper utilises bibliometrics, content analysis, and problematisation to comprehensively examine the state of research. Analysing 132 primary documents dating from January 2014 to April 2023, this study reveals that sustainability-oriented innovation and transition challenges are the core focus of existing research. Technology-oriented circularity and its positive impact on sustainability is the in-house assumption that almost all studies are founded on. Besides unpacking the risk of such assumptions, this study provides tangible suggestions for future research on circular economy disruption, its rebound effect, and sustainability-oriented innovation. Although the time lag and language biases may have impacted the representation of current research trends, findings from this study can facilitate academic research and industry practice in implementing circular economy practices for a more sustainable future.'}, {'id': 'supply_chain_traceability', 'title': 'Supply chain traceability and transparency: How do fashion companies perform and evaluate?', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1002/fcsr.70024', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1002/fcsr.70024'], 'type': 'article', 'author': [{'family': 'Bari', 'given': 'Md Sadaqul'}, {'family': 'Jin', 'given': 'Byoungho Ellie'}, {'family': 'Min', 'given': 'Yoo-Won'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'This study explores how companies practice and assess their traceability and transparency efforts, offering an initial comparison of their approaches. Qualitative research methodology and inductive theorizing approaches were utilized. One-on-one in-depth interviews with 11 apparel industry professionals and thematic analysis via NVivo 12 revealed that companies use advanced tools like Oritain technology and certifications for traceability but simpler methods for transparency. While internal traceability evaluation systems exist, none are in place for transparency. The findings highlight the need for affordable solutions for smaller companies with financial constraints and standardized indicators for a holistic assessment of traceability initiatives.'}, {'id': 'doi_10_1007_978-981-95-0469-5_14', 'title': 'Regulatory Standards and Certifications for Sustainable Textiles', 'URL': 'https://doi.org/10.1007/978-981-95-0469-5_14', 'type': 'article', 'author': [{'family': 'Walter', 'given': 'Chipambwa'}, {'family': 'Pethile', 'given': 'Dzingai'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Springer Nature', 'abstract': 'Globally, the textile industry is encountering increased scrutiny as it has a significant environmental impact, as it contributes to water pollution, excessive waste production, widespread use of hazardous chemicals, and elevated energy consumption during manufacturing. In recent years, sustainability has become crucial in the textile industry, motivated by eco-conscious customers, environmental concerns, and evolving legal demands. To support this shift, a variety of standards and certifications have been introduced by regulatory bodies and organizations worldwide. This chapter takes a closer look at key global sustainability standards and the specific certifications designed to help the textile sector operate more responsibly. This chapter also looks at how textile certifications are being put into practice, using a range of case studies to highlight key takeaways and real-world insights. It explores how different levels of regulation, regional, national, and international, interact to shape sustainability standards and ensure industry-wide compliance. The chapter also focuses on the role of technology in the certification process, including a review of current tools and emerging trends. The chapter concludes by addressing some of the major challenges, such as aligning various standards, compliance verification, and cost implications for manufacturers. At the same time, it also highlights how these standards and regulations create opportunities for innovation and boost competitiveness in the market.', 'DOI': '10.1007/978-981-95-0469-5_14'}, {'id': 'doi_10_1007_s13280-023-01865-w', 'title': 'Paradoxical tensions in exploiting data to implement circular economy in the textile industry', 'URL': 'https://doi.org/10.1007/s13280-023-01865-w', 'extra_urls': ['https://doi.org/10.1007/s13280-023-01865-w'], 'type': 'article', 'author': [{'family': 'Luoma', 'given': 'P\xe4ivi'}, {'family': 'Penttinen', 'given': 'Esko'}, {'family': 'Tapio', 'given': 'Petri'}, {'family': 'Toppinen', 'given': 'Anne'}], 'abstract': 'Increasing utilization of data, enabled by digitalization, constitutes a major driver toward circular economy but is not without potential paradoxical tensions. A two-round disaggregative Delphi study and analysis of the qualitative material generated in it explored these tensions. They were found to cohere around three themes: consumer concurrence, business transparency, and technology relevance. The first theme is connected with consumers\u2019 behavior and their perceptions as to data\u2019s value, the transparency one involves alignment of business interests and practices with data-driven developments, and the third pertains to the actual environmental impact of digital technologies used to initiate data-driven circular economy. Business decision-making should address both the positive and the negative effects, in both the short and long term. Insight as to these tensions supports discovering how businesses can successfully utilize data in their efforts promoting circular economy within the complex reality of dynamically changing business environments.', 'DOI': '10.1007/s13280-023-01865-w'}, {'id': 'consumer_behavioral_intention', 'title': 'Consumer behavioral intention for sustainable garments: do materials used and the level of garment\u2019s visibility and skin contact matter?', 'URL': 'https://www.sciencedirect.com/science/article/pii/S2444569X2500109X', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S2444569X2500109X'], 'type': 'article', 'author': [{'family': 'Schiaroli', 'given': 'Valerio'}, {'family': 'Dangelico', 'given': 'Rosa Maria'}, {'family': 'Fraccascia', 'given': 'Luca'}], 'abstract': 'Sustainable fashion consumption can be promoted only by understanding the motivation behind consumers\u2019 decision to purchase sustainable clothing. This study explores the determinants of consumers\u2019 purchasing intentions for two clothing items with different functions, characterized by different levels of visibility and skin contact (underwear and jacket) made with two sustainable materials (biobased and recycled). A conceptual framework was tested using the SEM technique on data collected through a questionnaire administered to 768 Italian consumers. Sustainable fashion knowledge, availability of sustainable garments, influence of celebrities and influencers, and environmental concerns significantly affected purchase intentions for the four product categories investigated. Moreover, gender and age significantly influenced purchase intention. The findings highlighted that purchase intentions and their determinants vary based on the levels of visibility and skin contact associated with the products and the type of sustainable materials used. Several contributions to the theory and managerial implications are provided.'}, {'id': 'doi_10_1080_08911762_2025_2472776', 'title': 'The Role of Environmental Concerns and Self-Expression in Ethical Fashion Consumption: A Mediated Model of Consumer Values', 'URL': 'https://doi.org/10.1080/08911762.2025.2472776', 'extra_urls': ['https://doi.org/10.1080/08911762.2025.2472776'], 'type': 'article', 'author': [{'family': 'Upadhyay', 'given': 'Nitin'}, {'family': 'Kamble', 'given': 'Aakash'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'The global fashion industry faces growing scrutiny for its significant environmental and social impacts, prompting an urgent need to understand consumer motivations for ethical fashion consumption. This study addresses the gap in knowledge regarding how environmental concerns and self-expressive benefits influence consumer intentions to purchase ethical fashion products. Drawing on Symbolic Self-Completion Theory and the Theory of Consumption Values, the research explores the mediating role of functional, social, and emotional values in these relationships. Data were collected from a survey of 422 consumers in India, a rapidly growing yet underexplored ethical fashion market. The findings reveal that environmental concerns and self-expressive benefits positively influence functional, social, and emotional consumption values. These values, in turn, significantly mediate the relationship between the antecedents and purchase intentions. These findings offer valuable insights to promote sustainable consumption practices while contributing to the theoretical understanding of ethical consumerism.', 'DOI': '10.1080/08911762.2025.2472776'}, {'id': 'strategic_marketing_of', 'title': 'Strategic marketing of sustainable fashion: Exploring approaches and contradictions in the positioning of fashion rental', 'URL': 'https://www.sciencedirect.com/science/article/pii/S2666791624000216', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S2666791624000216'], 'type': 'article', 'author': [{'family': 'Pet\xe4nen', 'given': 'P\xe4ivi'}, {'family': 'Tuovila', 'given': 'Hannamaija'}, {'family': 'Heikkil\xe4', 'given': 'Pirjo'}], 'abstract': 'Despite the potential of sustainable fashion alternatives such as fashion rental, the market share of these business models is low, and they are considered niche offerings in the fashion market dominated by unsustainable options. However, limited research exists on the strategic marketing efforts required to position and scale these models. The aim of this study was to explore the strategic marketing of sustainable fashion by identifying approaches and contradictions in the positioning of fashion rental as a sustainable alternative. A qualitative multiple-case study was conducted involving five fashion rental companies in Finland. The findings were interpreted using Customer Value Propositions (CVPs) as a conceptual framework for exploring the economic, functional, emotional, and symbolic dimensions of proposed customer value as indicators for positioning. The study identified two approaches for positioning fashion rental: 1) in relation to ownership and 2) in relation to consumerism. These approaches revealed contradictions between detaching from and encouraging product ownership and balancing between maintaining and reducing consumerism. The results suggest that fashion rental companies navigate between niche and mainstream audiences by applying plasticity in their strategic marketing and that these activities occur within a highly complex environment. This article provides insights into the intermediate position of sustainable fashion alternatives, and expands the understanding of the gap between the acknowledged need to move to sustainable fashion and the minor share of these options on the market.'}, {'id': 'long_live_the', 'title': 'Long Live the Future: Exploring Sustainable Consumption Frames in the Swedish Second-Hand Fashion Market', 'URL': 'http://lup.lub.lu.se/student-papers/record/9211650', 'extra_urls': ['http://lup.lub.lu.se/student-papers/record/9211650'], 'type': 'article', 'author': [{'family': 'Krakhmaleva', 'given': 'Olga'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'This thesis focuses on the concept \u201csustainable consumption\u201d and how it is conceptually constructed by Swedish secondhand actors, specifically non-profit actors who actively engage in the resale of clothing. Our current excessive overconsumption of fashion and pressing need to shift to a more sustainable mode of consumption requires us to critically assess the definition of our sustainability ideals and examine the actors who are tasked with implementing them. To carry out this study, Collective Action Frames and Master Frames theories are applied to sustainability reports by Swedish non-profit actors: Erikshj\xe4lpen, Myrorna, and Artikel2, covering the time period 2018 to 2024. The methodology is based on the framing method and qualitative content analysis. The findings identify eight collective action frames which inform the findings of three master frames: \u201cCircular Economy\u201d, \u201cSaving the Environment\u201d, and \u201cEthical Consumption\u201d. The study concludes that the actors conceptualize sustainable consumption as the collection of circular strategies with messages of reducing emissions, producing positive environmental impact, empowerment, accessibility, and motive guided both by an altruistic and self-fulfilling purpose.'}, {'id': 'research_opportunities_in', 'title': 'Research Opportunities in Supply Chain Transparency', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1111/poms.13115', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1111/poms.13115'], 'type': 'article', 'author': [{'family': 'Sodhi', 'given': 'ManMohan S.'}, {'family': 'Tang', 'given': 'Christopher S.'}], 'issued': {'date-parts': [[2019]]}, 'abstract': 'More firms than ever before are disclosing the provenance of their products, results of product testing, and suppliers\u2019 compliance with labor-practice norms in their annual reports, sustainability reports, and press releases, besides making such information available on third-party websites. However, collecting and disclosing such information is not only costly but also does not provide clear benefits. While the terminology is not yet standard in the literature, this study distinguishes supply chain transparency from visibility. Here, visibility refers to managers\u2019 efforts to learn more about operations upstream in their supply chains. In contrast, by transparency, we mean a company disclosing information to consumers, investors, and other stakeholders about compliance with consumer-expected norms in its supply chain operations and products. To motivate further research on supply chain transparency, we first report recent examples of companies providing supply chain transparency. Then we present potential benefits of supply chain visibility and supply chain transparency, respectively, for the company. Finally, we propose topics for research on supply chain transparency arranged by stakeholder.'}, {'id': 'international_spillover_effects', 'title': "International spillover effects in the EU's textile supply chains: A global SDG assessment", 'URL': 'https://www.sciencedirect.com/science/article/pii/S0301479721010999', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0301479721010999'], 'type': 'article', 'author': [{'family': 'Malik', 'given': 'Arunima'}, {'family': 'Lafortune', 'given': 'Guillaume'}, {'family': 'Carter', 'given': 'Sarah'}, {'family': 'Li', 'given': 'Mengyu'}, {'family': 'Lenzen', 'given': 'Manfred'}, {'family': 'Kroll', 'given': 'Christian'}], 'abstract': "Successful implementation of the Sustainable Development Goals (SDGs) requires world countries to account for actions that inadvertently generate negative impacts on other countries. These actions/effects are called \u2018spillovers\u2019, and can hinder a country's SDG progress. In this work, we analyse negative social spillover effects, focussing specifically on the occupational health and safety aspects of workers in textile supply chains. We select two indicators: fatal accidents and non-fatal accidents that take place in global supply chains for satisfying consumption of textile products (such as clothing, leather products) by European Union (EU) countries. Specifically, we scan global supply chains originating in countries outside of EU for meeting the demands of its citizens. To this end, we employ a well-established technique of multi-regional input-output analysis, featuring information on 15,000 sectors for 189 countries, to scan international supply chain routes that are linked to consumption of textile products by EU countries. Our findings suggest that Italy, Germany, France, Spain, Poland, Belgium and Portugal are collectively responsible for about 80% of both fatal- and non-fatal accidents that are attributed to the EU's consumption-based footprint. These findings not only call for a need for coherent SDG policies that consider spillover effects, but also the need for these effects to be included in EU's strategic instruments and policy-related tools."}, {'id': 'doi_10_1038_s41561-018-0113-9', 'title': 'Environmental and social footprints of international trade', 'URL': 'https://doi.org/10.1038/s41561-018-0113-9', 'extra_urls': ['https://doi.org/10.1038/s41561-018-0113-9'], 'type': 'article', 'author': [{'family': 'Wiedmann', 'given': 'Thomas'}, {'family': 'Lenzen', 'given': 'Manfred'}], 'abstract': 'Globalization has led to an increasing geospatial separation of production and consumption, and, as a consequence, to an unprecedented displacement of environmental and social impacts through international trade. A large proportion of total global impacts can be associated with trade, and the trend is rising. Advances in global multi-region input-output models have allowed researchers to draw detailed, international supply-chain connections between harmful production in social and environmental hotspots and affluent consumption in global centres of wealth. The general direction of impact displacement is from developed to developing countries\u2014an increase of health impacts in China from air pollution linked to export production for the United States being one prominent example. The relocation of production across countries counteracts national mitigation policies and may negate ostensible achievements in decoupling impacts from economic growth. A comprehensive implementation of the United Nations Sustainable Development Goals therefore requires the inclusion of footprint indicators to avoid loopholes in national sustainability assessments.', 'DOI': '10.1038/s41561-018-0113-9'}, {'id': 'doi_10_1016_j_jclepro_2016_05_144', 'title': 'Review on life cycle inventory: methods, examples and applications', 'URL': 'https://doi.org/10.1016/j.jclepro.2016.05.144', 'extra_urls': ['https://doi.org/10.1016/j.jclepro.2016.05.144'], 'type': 'article', 'author': [{'family': 'Islam', 'given': 'Samantha'}, {'family': 'Ponnambalam', 'given': 'S. G.'}, {'family': 'Lam', 'given': 'Hon Loong'}], 'abstract': 'Life cycle inventory (LCI) is the crucial phase of Life cycle assessment (LCA) which deals with the quantification and accumulation of a system inputs and outputs data. The three main currently available LCI methods are: Process based modeling, Input output (IO) LCI and Hybrid method. Different studies in literature adopt different methods of LCI. In contrast, different methods may provide different environmental impact results for the same product. Therefore, which LCI method should be chosen is highly important during conducting LCA studies. In order to choose a particular LCI method, one should know the calculation technique, relative advantages and limitations for the intended purpose. However, the knowledge about these methods and their application is split over various studies in literature. In this paper, a review on LCI evolution and their various methodological developments are presented along with numerical examples, advantages, disadvantages and application. This study is useful for choosing and applying an appropriate LCI method. It enables further exploration of advanced topic such as LCA software and extended LCA application like: Life cycle costing, Sustainability assessment, Green supply chain, Green product design and so on.', 'DOI': '10.1016/j.jclepro.2016.05.144'}, {'id': 'improving_matching_models', 'title': 'Improving Matching Models With Contextual Attention for Multi-Turn Response Selection in Retrieval-Based Chatbots', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10886991', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10886991'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Jingyu'}, {'family': 'Ma', 'given': 'Bing'}, {'family': 'Nan', 'given': 'Yafeng'}, {'family': 'He', 'given': 'Yixiao'}, {'family': 'Sun', 'given': 'Haifeng'}, {'family': 'Liu', 'given': 'Cong'}, {'family': 'Tao', 'given': 'Shimin'}, {'family': 'Qi', 'given': 'Qi'}, {'family': 'Liao', 'given': 'Jianxin'}], 'abstract': 'Multi-turn response selection is an important task in artificial intelligence. Early methods match each utterance with a response to obtain the matching information between utterance and response, then aggregate the matching vectors in chronological order. They are lightweight but ignore the dependencies between utterances, which is very important for mining useful matching information in utterance-response pair. Recently, some PLM-based methods can consider both relations between utterance and response and relations within utterances. However, they cost huge computational resource and suffer from loss of information due to the maximum length limit. In this research, we propose a lightweight, effective and low-loss method, CSMN. We initially expand the traditional attention to context-aware attention, making the model to dynamically learn complete matching information from response, utterance and context during the utterance-response matching. A hierarchical context-aware aggregation network is then applied for the further improvement of the proposed model. Experimental results on three large-scale dialogue datasets collected from social networks demonstrate the effectiveness of our proposed model. CSMN outperforms all traditional methods and is comparable to existing PLM-based methods with a extremely low cost of computational resource, which improves the response quality and user experience in multi-turn dialogue systems, and has important practical applications in resource-constrained environments.'}, {'id': 'doi_10_1080_10447318_2025_2495118', 'title': 'Designing Authentic Customer-Chatbot Interactions: A Necessary Condition Analysis of Emotional Intelligence and Anthropomorphic Features in Human-Computer Interaction', 'URL': 'https://doi.org/10.1080/10447318.2025.2495118', 'extra_urls': ['https://doi.org/10.1080/10447318.2025.2495118'], 'type': 'article', 'author': [{'family': 'Khan', 'given': 'Md Irfanuzzaman'}, {'family': 'Tarofder', 'given': 'Arun Kumar'}, {'family': 'Gopinathan', 'given': 'Sharmini'}, {'family': 'Haque', 'given': 'Ahasanul'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'This study offers a novel framework of perceived authenticity (PA) in chatbot-mediated service interactions by drawing on insights from Mind Perception Theory, Theory of Mind, the Authenticity Model of Computer-Mediated Communication, and Uncanny Valley Theory. The model integrates emotional and anthropomorphic cues by including perceived humanness, empathy, warmth, and humor. Survey data from 396 participants were analyzed using Partial Least Squares Structural Equation Modeling. The results indicate that empathy exerts the strongest influence on perceived authenticity, followed by perceived humanness and warmth, while humor plays a complementary role. PA significantly enhances trust, rapport, and satisfaction but has limited effect on frustration. Necessary Condition Analysis identifies minimum thresholds of key predictors needed to achieve high PA. Moderation analysis reveals that empathy and humanness are more effective for male-presenting chatbots, while humor enhances authenticity for female-presenting ones. The findings offer significant theoretical and practical implications in the domain of human -chatbot interaction.', 'DOI': '10.1080/10447318.2025.2495118'}, {'id': 'empathic_a', 'title': 'Empathic chatbots: A double-edged sword in customer experiences', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0148296324005782', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0148296324005782'], 'type': 'article', 'author': [{'family': 'Juquelier', 'given': 'Antoine'}, {'family': 'Poncin', 'given': 'Ingrid'}, {'family': 'Haz\xe9e', 'given': 'Simon'}], 'abstract': 'Recent breakthroughs in affective computing have enabled the shift from mechanical to empathic chatbots, now capable of detecting, decoding, and mimicking customers\u2019 thoughts and feelings to respond appropriately. While artificial empathy is believed to potentially bridge the human-artificial intelligence gap in customer experience, recent studies offer mixed support for its effectiveness in improving customer outcomes, leaving managers perplexed about the added value of empathic chatbots. Building on social presence theory, this paper investigates whether, how, and when empathic chatbot-led services enhance customer experience. Results from three experiments show that empathic chatbots trigger perceptions of social presence and information quality, which positively influence customer satisfaction. The findings further reveal that empathic chatbots can harm customer experience under certain conditions, particularly when customers feel time pressure. This paper provides insights into how and when to implement empathy in chatbots to enhance customer experience and boost customer satisfaction.'}, {'id': 'doi_10_1108_APJML-10-2024-1464', 'title': 'When empathy is enhanced by human\u2013AI interaction: an\xa0investigation of anthropomorphism and responsiveness on customer experience with AI chatbots', 'URL': 'https://doi.org/10.1108/APJML-10-2024-1464', 'extra_urls': ['https://doi.org/10.1108/APJML-10-2024-1464'], 'type': 'article', 'author': [{'family': 'Truong', 'given': 'Thi Thu Ha'}, {'family': 'Chen', 'given': 'Ja Shen'}], 'abstract': 'Artificial intelligence chatbots are increasingly employed as substitutes for human service agents in customer service. This study investigates how two key chatbot features, anthropomorphism and responsiveness, enhance the customer experience by fostering social presence and empathy, which in turn influence continuance intention. The moderating roles of privacy concerns and the need for human interaction (NFHI) are also examined.Data were collected from 461 respondents through an online survey on the Amazon Mechanical Turk platform, and partial least squares structural equation modeling was used to analyze the relationships.Both anthropomorphism and responsiveness significantly enhance social presence and empathy in chatbot interactions. Social presence mediates the relationship between chatbot features and empathy, which positively impacts continuance intention. Privacy concerns negatively moderate the relationship between empathy and continuance intention, whereas NFHI positively moderates it.Businesses should design chatbots with human-like behaviors and responsive features to create more engaging and empathetic interactions. Addressing privacy concerns and catering to users with high NFHI can further boost continued chatbot use.This study extends the stimuli-organism-response framework and social presence theory to chatbot interactions and provides insights into how psychological barriers influence user experience and continuance intention.', 'DOI': '10.1108/APJML-10-2024-1464'}, {'id': 'the_illusion_of', 'title': 'The Illusion of Empathy: How AI Chatbots Shape Conversation Perception', 'URL': 'https://ojs.aaai.org/index.php/AAAI/article/view/33569', 'extra_urls': ['https://ojs.aaai.org/index.php/AAAI/article/view/33569'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Tingting'}, {'family': 'Giorgi', 'given': 'Salvatore'}, {'family': 'Aich', 'given': 'Ankit'}, {'family': 'Lahnala', 'given': 'Allison'}, {'family': 'Curtis', 'given': 'Brenda'}, {'family': 'Ungar', 'given': 'Lyle'}, {'family': 'Sedoc', 'given': 'Jo\xe3o'}], 'abstract': "As AI chatbots increasingly incorporate empathy, understanding user-centered perceptions of chatbot empathy and its impact on conversation quality remains essential yet under-explored. This study examines how chatbot identity and perceived empathy influence users' overall conversation experience. Analyzing 155 conversations from two datasets, we found that while GPT-based chatbots were rated significantly higher in conversational quality, they were consistently perceived as less empathetic than human conversational partners. Empathy ratings from GPT-4o annotations aligned with user ratings, reinforcing the perception of lower empathy in chatbots compared to humans. Our findings underscore the critical role of perceived empathy in shaping conversation quality, revealing that achieving high-quality human-AI interactions requires more than simply embedding empathetic language; it necessitates addressing the nuanced ways users interpret and experience empathy in conversations with chatbots."}, {'id': 'the_power_of', 'title': 'The power of emojis: Enhancing the willingness to adopt chatbot recommendations', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0969698925001675', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0969698925001675'], 'type': 'article', 'author': [{'family': 'Yan', 'given': 'Huili'}, {'family': 'Tian', 'given': 'Tian'}, {'family': 'Xiong', 'given': 'Hao'}], 'abstract': 'Chatbots have become an integral component of online services in the tourism industry. Emojis, which act as crucial nonverbal cues, have gained widespread attention because of their unique role in enhancing the emotional expression of chatbots. However, the impact of emoji use by chatbots on consumers\u2019 willingness to adopt recommendations has yet to receive sufficient scholarly attention. On the basis of the emotion as social information (EASI) model, this study conducts three online experiments to explore the mechanisms by which emoji use by chatbots influences the willingness to adopt recommendations within the context of tourism services. The findings from the three studies indicate that (1) compared with chatbots that do not use emojis, those that incorporate emojis significantly enhance consumers\u2019 willingness to adopt recommendations; (2) empathy and trust serve as mediators in this relationship; and (3) relationship norm orientation and identity disclosure moderate both the main effect and the mediating effects. This study contributes to the literature on emoji use in chatbots and provides practical insights for tourism companies in the design and deployment of chatbots.'}, {'id': 'amazon_0137670109', 'title': 'Patterns for API Design: Simplifying Integration with Loosely Coupled Message Exchanges', 'URL': 'https://www.amazon.com/Patterns-API-Design-Simplifying-Addison-Wesley/dp/0137670109', 'type': 'book', 'author': [{'family': 'Zimmermann', 'given': 'Olaf'}, {'family': 'Stocker', 'given': 'Mirko'}, {'family': 'Lubke', 'given': 'Daniel'}, {'family': 'Zdun', 'given': 'Uwe'}, {'family': 'Pautasso', 'given': 'Cesare'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'Addison-Wesley Professional', 'abstract': 'Proven Patterns for Designing Evolvable High-Quality APIs--For Any Domain, Technology, or PlatformAPIs enable breakthrough innovation and digital transformation in organizations and ecosystems of all kinds. To create user-friendly, reliable and well-performing APIs, architects, designers, and developers need expert design guidance. This practical guide cuts through the complexity of API conversations and their message contents, introducing comprehensive guidelines and heuristics for designing APIs sustainably and specifying them clearly, for whatever technologies or platforms you use.In Patterns for API Design: Simplifying Integration with Loosely Coupled Message Exchanges, five expert architects and developers cover the entire API lifecycle, from launching projects and establishing goals through defining requirements, elaborating designs, planning evolution, and creating useful documentation. They crystallize the collective knowledge of many practitioners into 44 API design patterns, consistently explained with context, pros and cons, conceptual solutions, and concrete examples. To make their pattern language accessible, they present a domain model, a running case study, decision narratives with pattern selection options and criteria, and walkthroughs of real-world projects applying the patterns in two different industries.Identify and overcome API design challenges with patternsSize your endpoint types and operations adequatelyDesign request and response messages and their representationsRefine your message design for qualityPlan to evolve your APIsDocument and communicate your API contractsCombine patterns to solve real-world problems and make the right tradeoffs"This book provides a healthy mix of theory and practice, containing numerous nuggets of deep advice but never losing the big picture . . . grounded in real-world experience and documented with academic rigor applied and practitioner community feedback incorporated. I am confident that [it] will serve the community well, today and tomorrow."--Prof. Dr. Dr. h. c. Frank Leymann, Managing Director, Institute of Architecture of Application Systems, University of Stuttgart'}, {'id': 'information_systems_in', 'title': 'Information systems in supply chain integration and management', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0377221703005186', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0377221703005186'], 'type': 'article', 'author': [{'family': 'Gunasekaran', 'given': 'A'}, {'family': 'Ngai', 'given': 'E. W. T'}], 'abstract': 'Supply chain management (SCM) is the 21st century global operations strategy for achieving organizational competitiveness. Companies are attempting to find ways to improve their flexibility and responsiveness and in turn competitiveness by changing their operations strategy, methods and technologies that include the implementation of SCM paradigm and information technology (IT). However, a thorough and critical review of literature is yet to be carried out with the objective of bringing out pertinent factors and useful insights into the role and implications of IT in SCM. In this paper, the literature available on IT in SCM have been classified using suitable criteria and then critically reviewed to develop a framework for studying the applications of IT in SCM. Based on this review and analysis, recommendations have been made regarding the application of IT in SCM and some future research directions are indicated.'}, {'id': 'preparing_in_the', 'title': 'Preparing in the Light of Uncertainty: How Textile Companies respond to New Regulations on the Digital Product Passport', 'URL': 'https://studenttheses.uu.nl/handle/20.500.12932/48177', 'extra_urls': ['https://studenttheses.uu.nl/handle/20.500.12932/48177'], 'type': 'thesis', 'author': [{'family': 'Quick', 'given': 'Lea'}], 'issued': {'date-parts': [[2024]]}, 'abstract': "European regulations are pushing for the implementation of a Digital Product Passport (DPP) to enhance transparency, circularity, and sustainability in different sectors, including the textile industry. This mandated information disclosure is a response to the textile industry's complex supply chains and should help mitigate its growing negative environmental and social impact. The DPP provides comprehensive data on products\u2019 origins, composition, and impact. This study aims to investigate how companies in the European textile sector perceive and respond to the upcoming DPP regulations characterised by regulatory uncertainty. The qualitative study of 16 semi-structured interviews with industry stakeholders revealed four different archetypes of companies, namely Enthusiastic Pioneers, Proactive Planners, Cautious Strategists, and Confident Procrastinators. Those types demonstrate different strategic responses and adoption strategies to the DPP. The findings illustrate that while some companies perceive the DPP as an opportunity to innovate and strengthen sustainability efforts, others remain hesitant, referring to challenges concerning data management and resource requirements. Some companies have started actively engaging with the DPP, either positioning themselves as pioneers in its implementation or taking precautionary steps to ensure they are fully prepared to comply with the upcoming regulations. In contrast, other companies apply a wait-and-see approach, confident in their ability to react when necessary. While the studied sample generally shows a positive and proactive attitude towards the DPP, the research indicates that many companies outside the sample investigated are rather sceptical and passive in their behaviour. Regulatory uncertainty builds a major challenge, affecting companies\u2019 strategies and planning. Policymakers are advised to provide clear guidelines while offering supporting resources and information. Companies are encouraged to engage proactively in industry collaborations and early compliance efforts. Future research should focus on broader cross-industry comparisons and longitudinal studies to analyse the adoption process and potential shifts in the four archetypes resulting from the final regulatory enforcement. This thesis contributes to the literature on regulatory uncertainty and innovation adoption, offering recommendations for companies and policymakers to navigate the transition to the DPP effectively."}, {'id': 'doi_10_1186_s13677-024-00618-8', 'title': 'Privacy-preserving federated learning based on partial low-quality data', 'URL': 'https://doi.org/10.1186/s13677-024-00618-8', 'extra_urls': ['https://doi.org/10.1186/s13677-024-00618-8'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Huiyong'}, {'family': 'Wang', 'given': 'Qi'}, {'family': 'Ding', 'given': 'Yong'}, {'family': 'Tang', 'given': 'Shijie'}, {'family': 'Wang', 'given': 'Yujue'}], 'abstract': 'Traditional machine learning requires collecting data from participants for training, which may lead to malicious acquisition of privacy in participants\u2019 data. Federated learning provides a method to protect participants\u2019 data privacy by transferring the training process from a centralized server to terminal devices. However, the server may still obtain participants\u2019 privacy through inference attacks and other methods. In addition, the data provided by participants varies in quality, and the excessive involvement of low-quality data in the training process can render the model unusable, which is an important issue in current mainstream federated learning. To address the aforementioned issues, this paper proposes a Privacy Preserving Federated Learning Scheme with Partial Low-Quality Data (PPFL-LQDP). It can achieve good training results while allowing participants to utilize partial low-quality data, thereby enhancing the privacy and security of the federated learning scheme. Specifically, we use a distributed Paillier cryptographic mechanism to protect the privacy and security of participants\u2019 data during the Federated training process. Additionally, we construct composite evaluation values for the data held by participants to reduce the involvement of low-quality data, thereby minimizing the negative impact of such data on the model. Through experiments on the MNIST dataset, we demonstrate that this scheme can complete the model training of federated learning with the participation of partial low-quality data, while effectively protecting the security and privacy of participants\u2019 data. Comparisons with related schemes also show that our scheme has good overall performance.', 'DOI': '10.1186/s13677-024-00618-8'}, {'id': 'doi_10_1080_00207543_2024_2432469', 'title': 'An adaptive federated learning system for information sharing in supply chains', 'URL': 'https://doi.org/10.1080/00207543.2024.2432469', 'extra_urls': ['https://doi.org/10.1080/00207543.2024.2432469'], 'type': 'article', 'author': [{'family': 'Zheng', 'given': 'Ge'}, {'family': 'Ivanov', 'given': 'Dmitry'}, {'family': 'Brintrup', 'given': 'Alexandra'}], 'abstract': "Information sharing in supply chains can be challenged by privacy concerns. Equating data and information, the existing literature primarily focuses on the incentivisation behind information sharing between firms. The field of AI may bring a new way of looking at this problem by asking the following question: what if we do not share raw data but share learned information from it instead? This raises the next question, with whom and when should supply chain members share information, which we address in this paper. We develop a novel adaptive federated learning approach for the generation and usage of collective knowledge without direct data exchange and test the approach with a use case for collectively predicting supply risk. We propose a privacy-preserving network formation and clustering algorithm, which enables supply chain members to decide when to enter a collective information-sharing network, and how they should form information-sharing teams. Using data from an e-commerce platform, we illustrate how our approach outperforms the suppliers' own prediction models. We further show that clustering suppliers in teams achieves the best performance and converges faster compared to two benchmarks. The heterogeneity of information contribution by firms and those who benefit from collective information also raises important research questions on the role of cooperation in supply chains.", 'DOI': '10.1080/00207543.2024.2432469'}, {'id': 'doi_10_1007_978-3-030-63076-8_11', 'title': 'A Principled Approach to Data Valuation for Federated Learning', 'URL': 'https://doi.org/10.1007/978-3-030-63076-8_11', 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Tianhao'}, {'family': 'Rausch', 'given': 'Johannes'}, {'family': 'Zhang', 'given': 'Ce'}, {'family': 'Jia', 'given': 'Ruoxi'}, {'family': 'Song', 'given': 'Dawn'}], 'issued': {'date-parts': [[2020]]}, 'publisher': 'Springer International Publishing', 'abstract': 'Federated learning (FL) is a popular technique to train machine learning (ML) models on decentralized data sources. In order to sustain long-term participation of data owners, it is important to fairly appraise each data source and compensate data owners for their contribution to the training process. The Shapley value (SV) defines a unique payoff scheme that satisfies many desiderata for a data value notion. It has been increasingly used for valuing training data in centralized learning. However, computing the SV requires exhaustively evaluating the model performance on every subset of data sources, which incurs prohibitive communication cost in the federated setting. Besides, the canonical SV ignores the order of data sources during training, which conflicts with the sequential nature of FL. This chapter proposes a variant of the SV amenable to FL, which we call the federated Shapley value. The federated SV preserves the desirable properties of the canonical SV while it can be calculated without incurring extra communication cost and is also able to capture the effect of participation order on data value. We conduct a thorough empirical study of the federated SV on a range of tasks, including noisy label detection, adversarial participant detection, and data summarization on different benchmark datasets, and demonstrate that it can reflect the real utility of data sources for FL and has the potential to enhance system robustness, security, and efficiency. We also report and analyze \u201cfailure cases\u201d and hope to stimulate future research.', 'DOI': '10.1007/978-3-030-63076-8_11'}, {'id': 'doi_10_1007_s12599-024-00893-4', 'title': 'Data Sovereignty in Inter-organizational Information Systems', 'URL': 'https://doi.org/10.1007/s12599-024-00893-4', 'extra_urls': ['https://doi.org/10.1007/s12599-024-00893-4'], 'type': 'article', 'author': [{'family': 'Opriel', 'given': 'Sebastian'}, {'family': 'M\xf6ller', 'given': 'Frederik'}, {'family': 'Strobel', 'given': 'Gero'}, {'family': 'Otto', 'given': 'Boris'}], 'abstract': "Car manufacturers and suppliers in the Automotive industry increasingly face the issue of optimization of highly complex supply chains that need to accommodate each customer's precise demands, requiring a vast array of parts and information to be available at the right place and at the right time. This involves data sharing between organizations, which is hindered by various issues, such as fear of data misappropriation by the data receiver or the involuntary disclosure of business secrets. The paper proposes design principles for a novel type of Inter-Organizational Information System, which addresses these challenges through the technical implementation of data sovereignty. The study reports on an Action Design Research study in the Automotive industry between a car manufacturer and a 1st-tier supplier. It contributes (a) design requirements, (b) design features, (c) an instantiation, and (d) design principles for this type of data sovereign inter-organizational information system.", 'DOI': '10.1007/s12599-024-00893-4'}, {'id': 'smart_conceptual', 'title': 'Smart Products: Conceptual Review, Synthesis, and Research Directions', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1111/jpim.12544', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1111/jpim.12544'], 'type': 'article', 'author': [{'family': 'Raff', 'given': 'Stefan'}, {'family': 'Wentzel', 'given': 'Daniel'}, {'family': 'Obwegeser', 'given': 'Nikolaus'}], 'issued': {'date-parts': [[2020]]}, 'abstract': 'Smart products have received increasing attention from researchers and practitioners alike. One limitation of the existing literature, however, is that the term is often used as a blanket term and that there is no consensus on what a smart product actually is. Because different studies rely on differing conceptualizations, the current body of knowledge is scattered and lacks a uniform language and conceptual boundaries. Specifically, existing research has subsumed inherently different products under one collective term, has relied on a multitude of ad hoc criteria to define smart products or has conflated smart products with the services they render and/or the wider ecosystem, in which they operate. These developments limit the systematic advancement of the field and impede the integration of the smart product concept into related concepts such as the Internet of Things. To address these issues, this article provides an extensive analysis of the status quo of the field, with the goal of developing a common language and comprehensive conceptualization of smart products. First, existing studies on smart products were systematically reviewed across contributing disciplines and supplemented with a bibliometric analysis that allowed for a deeper understanding of the smart product concept within and across disciplines. This analysis revealed an initial set of 16 capability-based criteria that are currently applied to conceptualize smart products. Second, based on a systematic coding procedure, these criteria were synthesized and organized within a comprehensive framework delineating four distinct product archetypes for the digital age: (1) Digital, (2) Connected, (3) Responsive, and (4) Intelligent. Third, three major conceptual themes that arise from this framework are identified and possibilities for future research are pointed out. In sum, this work contributes to the literature by improving the understanding of smart products as an epistemic object and by laying the ground for more cumulative research endeavors.'}, {'id': 'doi_10_1007_s11747-018-0608-3', 'title': 'Relationship journeys in the internet of things: a new framework for understanding interactions between consumers and smart objects', 'URL': 'https://doi.org/10.1007/s11747-018-0608-3', 'extra_urls': ['https://doi.org/10.1007/s11747-018-0608-3'], 'type': 'article', 'author': [{'family': 'Novak', 'given': 'Thomas P.'}, {'family': 'Hoffman', 'given': 'Donna L.'}], 'abstract': 'Consumers\u2019 interactions with smart objects have a relational nature, and extensive research has supported the \u201crelationship metaphor\u201d as a fruitful way to understand consumer responses to consumption objects. But, smart objects pose unique challenges for considering the emergence of consumer\u2013object relationships, because their degrees of agency, autonomy, and authority lend them their own unique capacities for interaction. We present a new framework for consumer\u2013object relationships based on the circumplex model of interpersonal complementarity and situated in assemblage theory and object-oriented ontology. Consumer\u2013object relationship styles are defined in terms of two foundational dimensions of behavior, agency, and communion, based on the expressive roles played by consumer and object. The overlay of assemblage theory provides a conceptually rich understanding of the space of master\u2013servant, partner, and unstable relationship styles, along with their concomitant positive (enabling) versus negative (constraining) consumer experiences. The model\u2019s underlying geometry supports extensive empirical work and provides a powerful managerial framework for measuring and tracking consumer\u2013object relationships and the journeys they take over time.', 'DOI': '10.1007/s11747-018-0608-3'}, {'id': 'towards_a_framework', 'title': 'Towards a framework of smart-circular systems: An integrative literature review', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0959652619304743', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0959652619304743'], 'type': 'article', 'author': [{'family': 'Alcayaga', 'given': 'Andres'}, {'family': 'Wiener', 'given': 'Melanie'}, {'family': 'Hansen', 'given': 'Erik G.'}], 'abstract': 'Profiting from the benefits of smart products connected through the Internet of Things (IoT) could disrupt business models and has the potential to foster a circular economy by embracing a performance economy. Extant literature has offered insights into circular strategies, smart products and product-service systems (PSS) in isolated ways or by considering partial overlaps, but lacks a holistic account of their interplay. By means of an integrated review, this paper synthesises literatures from various domains to describe interrelationships among these three concepts and propose a conceptual framework of smart-circular systems. This paper thereby advances research by providing a description of three binary interrelationships: smart circularity, smart PSS and circular PSS. Moreover, the review elaborates a new understanding of smart-circular (product-service) systems by articulating the base strategy smart use and extending the following circular strategies (or technical loops): maintenance, reuse, remanufacturing and recycling. Finally, the review outlines a critique of the state of the literature on this phenomenon and offers suggestions to guide future empirical and theoretical research in the domains of circular strategies, services and business models.'}, {'id': 'doi_10_1007_s12351-023-00810-9', 'title': 'The value of secondary markets when consumers are socially conscious', 'URL': 'https://doi.org/10.1007/s12351-023-00810-9', 'extra_urls': ['https://doi.org/10.1007/s12351-023-00810-9'], 'type': 'article', 'author': [{'family': 'Zhao', 'given': 'You'}, {'family': 'Hou', 'given': 'Rui'}, {'family': 'Ding', 'given': 'Zhonghui'}], 'abstract': 'This study examines the effect of a secondary market with socially conscious consumers on a brand firm\u2019s profitability. The existing literature on the introduction of a secondary market usually assumes a channel setting. In practice, however, brand firms begin introducing physical products to secondary markets with a consumer-to-consumer setting, which is not considered in existing theories. Therefore, we develop a two-period pricing model to investigate the effect of secondary markets with socially conscious consumers and conduct a sensitivity analysis to examine the impact of the main parameters on the equilibrium outcomes. Conventional wisdom suggests that the introduction of the consumer-to-consumer secondary market is always detrimental to suppliers of durable physical goods. However, we demonstrate that a brand firm may benefit from introducing the physical product secondary market if the consumers are socially conscious under certain conditions, which stands in contrast to the existing literature. Moreover, consumers always prefer the introduction of a secondary market; that is, a \u201cwin\u2013win\u201d outcome may be achieved. In summary, our findings provide useful implications regarding when managers should introduce a secondary market in case consumers are socially conscious.', 'DOI': '10.1007/s12351-023-00810-9'}, {'id': 'doi_10_1007_s43615-024-00351-z', 'title': 'Deconstructing Customer Value Propositions for the Circular Product-as-a-Service Business Model: A Case Study from the Textile Industry', 'URL': 'https://doi.org/10.1007/s43615-024-00351-z', 'extra_urls': ['https://doi.org/10.1007/s43615-024-00351-z'], 'type': 'article', 'author': [{'family': 'Pet\xe4nen', 'given': 'P\xe4ivi'}, {'family': 'Sundqvist', 'given': 'Henna'}, {'family': 'Antikainen', 'given': 'Maria'}], 'abstract': 'Offering products as a service is a way to implement circular economy principles in business models and promote sustainability. However, in many markets, the model is still in its infancy in terms of market maturity and lacks customer acceptance. More understanding is needed of how product-as-a-service companies can enhance and reconfigure their competitive position by proposing meaningful customer value. For this purpose, this study focuses on customer value propositions (CVPs) as a strategic management concept in the circular economy. The aim of the study is to outline a deconstruction framework for systematically identifying the strategically manageable components of CVPs in circular product-as-a-service business models. The framework establishes a link between the elements of circular product-as-a-service business models and competitive CVPs. The framework is developed and validated with seven product-as-a-service business cases in the textile and clothing industry context. The results of the study provide insights into how product-as-a-service companies in the textile field aim to differentiate, how they structure customer value by identifying customer benefits and sacrifices, and what kind of resources and capabilities are needed for competing in the circular economy context.', 'DOI': '10.1007/s43615-024-00351-z'}, {'id': 'doi_10_1108_QMR-05-2023-0069', 'title': 'When the secondhand economy is not as good as it seems: understanding conflicts and their (ir)resolutions between users on secondhand resale platforms', 'URL': 'https://doi.org/10.1108/QMR-05-2023-0069', 'extra_urls': ['https://doi.org/10.1108/QMR-05-2023-0069'], 'type': 'article', 'author': [{'family': 'Cerio', 'given': 'Eva'}, {'family': 'Debenedetti', 'given': 'Alain'}, {'family': 'Sophie', 'given': 'Rieunier'}], 'abstract': 'Peer-to-peer (P2P) secondhand resale platforms (SRP) are competitive places where different value systems beyond market values interact. This study aims to investigate the conflicts that may arise in interactions between users on SRP and the extent to which these conflicts are (ir)resolved, by drawing on economies of worth theory.The study takes a qualitative and interpretative approach to examine 22 active users on P2P resales platforms such as Vinted, including in-depth interviews. Following the Straussian view of grounded theory, the study uses constant comparison (open, axial and selective coding) to analyze data on SRP users\u2019 experiences.Drawing on the economies of worth theory, the study shows that SRP users rely on four different value systems or \u201cworlds\u201d when using the platforms (market, domestic, green and civic worlds) that come into conflict, at either an interactional (three conflicts identified) or an individual (two conflicts identified) level. The findings reveal that these conflicts are temporarily resolved at the interactional level and in a sustainable way at the individual level.This study sheds further light on the relationship between consumers on SRP by offering a more nuanced perspective on these exchanges than market-oriented exchanges. It also analyzes the data through the economies of worth theory, which is an appropriate lens to better understand social interactions and conventions. Finally, the study offers recommendations on how managers can improve buyers\u2019 and sellers\u2019 experiences on these platforms and, thus, foster their satisfaction.', 'DOI': '10.1108/QMR-05-2023-0069'}, {'id': 'doi_10_1007_s11356-022-19255-2', 'title': 'Towards the circular economy in the fashion industry: the second-hand market as a best practice of sustainable responsibility for businesses and consumers', 'URL': 'https://doi.org/10.1007/s11356-022-19255-2', 'extra_urls': ['https://doi.org/10.1007/s11356-022-19255-2'], 'type': 'article', 'author': [{'family': 'D\u2019Adamo', 'given': 'Idiano'}, {'family': 'Lupi', 'given': 'Gianluca'}, {'family': 'Morone', 'given': 'Piergiuseppe'}, {'family': 'Settembre-Blundo', 'given': 'Davide'}], 'abstract': 'The transition to a circular economy is a key concern for the fashion industry. The emerging second-hand market is a practice that could enable the circular economy in the fashion industry. As this is an emerging trend, the literature has not yet sufficiently explored how it is possible to simultaneously meet consumer and industry expectations in the management of second-hand garments within the value chain. This article aimed to fill that gap with the analytic hierarchy process, which demonstrated that garment collection and recycling are not necessarily best practices for the circular economy. For this to happen, close collaboration between manufacturers and retailers in the value chain is needed to move the industry towards responsibly sustainable production and consumption models. The results emphasise that harvesting management and internal competition on low-cost collection are critical business drivers, while responsible consumption and benefits are opportunities for consumers.', 'DOI': '10.1007/s11356-022-19255-2'}, {'id': 'doi_10_1080_00207543_2025_2456991', 'title': 'The optimality of second-hand business decisions in the presence of consumer valuation uncertainty', 'URL': 'https://doi.org/10.1080/00207543.2025.2456991', 'extra_urls': ['https://doi.org/10.1080/00207543.2025.2456991'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Mengdan'}, {'family': 'Wang', 'given': 'Nengmin'}, {'family': 'Han', 'given': 'Zheng'}, {'family': 'Jiang', 'given': 'Bin'}], 'abstract': 'Valuation uncertainty of new products may expose consumers to undesirable trial-and-error costs and thus deter them from making a purchase. To mitigate such costs, manufacturers can incentivize consumers to recycle their products or offer second-hand products at lower prices. However, second-hand products may cannibalise new products, raising questions about the feasibility of adopting such a business model. Inspired by this observation, we build a game theoretic model where a manufacturer can develop two types of second-hand businesses (recycling-only or refurbishing-and-resale). We find that when consumers\u2019 trial-and-error costs on new products are low (high), the recycling-only (refurbishing-and-resale) model can be optimal for the manufacturer. In the former case, the recycling-only model converts a portion of non-buyers into buyers and thus improves profitability. In the latter case, the refurbishing-and-resale model induces consumers with high valuations to initially purchase second-hand products and later switch to new products. Interestingly, we also identify scenarios where the manufacturer benefits from not developing any second-hand business. Our findings are validated with real-world examples. Our results provide an explanation for the diversified choices regarding whether and how to implement second-hand business in practice.', 'DOI': '10.1080/00207543.2025.2456991'}, {'id': 'doi_10_1007_s11747-012-0308-3', 'title': 'Critical service logic: making sense of value creation and co-creation', 'URL': 'https://doi.org/10.1007/s11747-012-0308-3', 'extra_urls': ['https://doi.org/10.1007/s11747-012-0308-3'], 'type': 'article', 'author': [{'family': 'Gr\xf6nroos', 'given': 'Christian'}, {'family': 'Voima', 'given': 'P\xe4ivi'}], 'abstract': 'Because extant literature on the service logic of marketing is dominated by a metaphorical view of value co-creation, the roles of both service providers and customers remain analytically unspecified, without a theoretically sound foundation for value creation or co-creation. This article analyzes value creation and co-creation in service by analytically defining the roles of the customer and the firm, as well as the scope, locus, and nature of value and value creation. Value creation refers to customers\u2019 creation of value-in-use; co-creation is a function of interaction. Both the firm\u2019s and the customer\u2019s actions can be categorized by spheres (provider, joint, customer), and their interactions are either direct or indirect, leading to different forms of value creation and co-creation. This conceptualization of value creation spheres extends knowledge about how value-in-use emerges and how value creation can be managed; it also emphasizes the pivotal role of direct interactions for value co-creation opportunities.', 'DOI': '10.1007/s11747-012-0308-3'}, {'id': 'exploring_the_relationship', 'title': 'Exploring the Relationship Between Aesthetic Design as an Element of New Service Development and Performance', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-5885.2011.00827.x', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-5885.2011.00827.x'], 'type': 'article', 'author': [{'family': 'Candi', 'given': 'Marina'}, {'family': 'Saemundsson', 'given': 'R\xf6gnvaldur J.'}], 'issued': {'date-parts': [[2011]]}, 'abstract': "The purpose of this research is to investigate the conditions under which the use of aesthetic design as an element of new service development is likely to improve performance\u2014more specifically, to empirically examine how aesthetic design can contribute to competitive advantage, resistance to imitation, and profitability, and how these contributions are moderated by the process of commoditization. Based on analysis of three rounds of longitudinal data collected one year apart in a population of new technology-based firms, the findings are that aesthetic design as an element of new service development can contribute positively to competitive advantage, resistance to imitation, and profitability, but that the effectiveness of using aesthetic design to achieve these outcomes differs depending on the level of commoditization. Positive relationships are found between the use of aesthetic design and competitive advantage and profitability, respectively, when the level of commoditization is high. Furthermore, the positive relationship between aesthetic design and resistance to service imitation is stronger when the relative importance of aesthetic design in a firms' sector is low, that is, conditions under which aesthetic design is not already expected. This research suggests that practitioners should consider using aesthetic design to counteract commoditization when the markets in which they compete are characterized by ready access to services that meet customers' needs and expectations for features, performance, and reliability, and expectations for aesthetic design have not already become established. Furthermore, they should be aware that the use of aesthetic design may turn into a baseline customer requirement, implying that while attention to aesthetic design is necessary to compete it may cease to constitute a potential source of competitive advantage."}, {'id': 'doi_10_1016_j_jclepro_2018_02_001', 'title': 'Modelling environmental value: An examination of sustainable business models within the fashion industry', 'URL': 'https://doi.org/10.1016/j.jclepro.2018.02.001', 'extra_urls': ['https://doi.org/10.1016/j.jclepro.2018.02.001'], 'type': 'article', 'author': [{'family': 'Pal', 'given': 'Rudrajeet'}, {'family': 'Gander', 'given': 'Jonathan'}], 'abstract': 'The business models of enterprises in the global fashion industry produce highly negative outcomes for the environment. High water usage, pollution from chemical treatments used in dyeing and preparation and the disposal of large amounts of unsold stock through incineration or landfill deposits combine to make clothing one of the highest impact industries on the planet. This paper uses the sustainable logics of narrowing, slowing and closing the loop of resources used during the production, design, manufacture and distribution of fashion garments to analyse emerging business models that seek to reduce the environmental impact of the fashion system. Taking the business model conceptualization of an enterprise as a system designed to create value for the customer and capture value for the firm, we add a consideration of environmental value and derive propositions that test the possibility that emerging sustainable business models in fashion will replace the dominant, unsustainable model. The paper argues that lack of scalability, incompatibility with fashion customers value propositions plus obstacles to supply chain changes militate against the prospect of the currently designed sustainable business models becoming the standard model of the fashion industry.', 'DOI': '10.1016/j.jclepro.2018.02.001'}, {'id': 'doi_10_1016_j_jclepro_2018_02_014', 'title': 'The reDesign canvas: Fashion design as a tool for sustainability', 'URL': 'https://doi.org/10.1016/j.jclepro.2018.02.014', 'extra_urls': ['https://doi.org/10.1016/j.jclepro.2018.02.014'], 'type': 'article', 'author': [{'family': 'Kozlowski', 'given': 'Anika'}, {'family': 'Searcy', 'given': 'Cory'}, {'family': 'Bardecki', 'given': 'Michal'}], 'abstract': 'Many of the existing tools for design in a sustainable fashion context are too complex, overly conceptual, require experts to apply, have a high cost, were created for large corporations, or fall short in holistically supporting sustainable fashion design entrepreneurial practices. Micro-sized enterprises represent a significant portion of the fashion industry and can meaningfully contribute to the transition to a more sustainable apparel and textile industry. This paper addresses this gap through the development of an original design tool, the reDesign canvas, to support design entrepreneurs in developing sustainable fashion enterprises. Informed by design thinking and systems thinking, the canvas was developed based on an in-depth review of the academic literature and the collection of qualitative data. Qualitative data were gathered through both participatory action research (PAR) and interviews with 38 sustainable fashion design entrepreneurs and experts in sustainable fashion. Both the PAR and the interviews were used to test and refine the reDesign canvas in order to ensure it meets the needs of sustainable design entrepreneurs operating micro-sized companies. The final version of the canvas is based on 12 building blocks that a design entrepreneur would encounter in building a sustainable fashion brand. The reDesign canvas can help advance both the theory and practice of sustainable fashion design.', 'DOI': '10.1016/j.jclepro.2018.02.014'}, {'id': 'doi_10_1007_s10668-023-03943-1', 'title': 'Influencing mechanism of consumers\u2019 willingness to pay for circular products: a meta-analytic structural equation modeling', 'URL': 'https://doi.org/10.1007/s10668-023-03943-1', 'extra_urls': ['https://doi.org/10.1007/s10668-023-03943-1'], 'type': 'article', 'author': [{'family': 'Fu', 'given': 'Hanliang'}, {'family': 'He', 'given': 'Weijie'}, {'family': 'Guo', 'given': 'Xiaotong'}, {'family': 'Hou', 'given': 'Caixia'}], 'abstract': "Consumer purchases of circular products help alleviate resource shortages and protect the environment. Therefore, it is necessary to explore the influencing mechanism of consumers' willingness to pay (WTP) for circular products. Based on the framework of the theory of planned behavior, combined with perceived risk, environmental concern, social value, and product knowledge, this study employed the meta-analytic structural equation modeling based on the results of existing relevant empirical studies (32 samples, N\u2009=\u200914,032) to construct an integrated theoretical model of consumers' WTP for circular products. The findings demonstrated support for the integrated framework, and consumer attitude played a significant mediating role in the model framework. Moreover, the results also suggested that national cultures, types of circular products, and types of respondents were potential reasons for the differences in the results of some relevant studies. The integrated theoretical model focused on the difference evaluation and multivariate path analysis of the influencing factors of consumers' WTP for circular products and prospered the explanatory power and predictability of consumers' WTP for circular products.", 'DOI': '10.1007/s10668-023-03943-1'}, {'id': 'our_vision_of', 'title': 'Our vision of a circular economy for fashion', 'URL': 'https://www.ellenmacarthurfoundation.org/our-vision-of-a-circular-economy-for-fashion', 'extra_urls': ['https://www.ellenmacarthurfoundation.org/our-vision-of-a-circular-economy-for-fashion'], 'type': 'webpage', 'author': [{'family': 'Ellen MacArthur Foundation'}], 'abstract': 'In a circular economy for fashion, products are used more, made to be made again, and made from safe and recycled or renewable inputs.'}, {'id': 'doi_10_1007_s10479-025-06534-7', 'title': 'Human-artificial intelligence collaboration in supply chain outcomes: the mediating role of responsible artificial intelligence', 'URL': 'https://doi.org/10.1007/s10479-025-06534-7', 'extra_urls': ['https://doi.org/10.1007/s10479-025-06534-7'], 'type': 'article', 'author': [{'family': 'Vann Yaroson', 'given': 'Emilia'}, {'family': 'Abadie', 'given': 'Am\xe9lie'}, {'family': 'Roux', 'given': 'M\xe9lanie'}], 'abstract': "Human-artificial intelligence collaboration (CAIT) presents considerable opportunities for optimising supply chain outcomes. Nonetheless, it poses numerous ethical, technological, and organisational obstacles that could impede its efficacy. This study contends that responsible AI (RAI) systems can function as a conduit between CAIT and supply chain outcomes to tackle these challenges. Accordingly, we leveraged the resource-based view (RBV) and socio-technical system (STS) theoretical lenses to analyse the mediating role of RAI in the relationship between CAIT and two supply chain outcomes (supply chain wellbeing (SCWB) and sustainable business performance (SBP)). The suggested model was evaluated using PLS-SEM on survey data from 301 supply chain managers in the UK. Our analysed data revealed a statistically insignificant relationship between CAIT and supply chain outcomes (SCWB and SBP). However, the mediating role of RAI was confirmed. The findings suggest that CAIT is merely a component of a supply chain's capacity to produce intrinsic resources, rather than a universal solution. To harness the dividends of human-AI collaboration involves designing boundaries, aligning CAIT to supply chain goals and integrating ethical and transparent strategies. Our findings contribute to the discourse on AI use in supply chain literature by showing that CAIT can influence supply chain outcomes by bridging ethical, operational and technological gaps while fostering trust and efficiency.", 'DOI': '10.1007/s10479-025-06534-7'}, {'id': 'development_of_a', 'title': 'Development of a Decentralized Digital Product Passport for Enhanced Lifecycle Management of Electrical and Electronic Equipment', 'URL': 'https://www.sciencedirect.com/science/article/pii/S2212827125002860', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S2212827125002860'], 'type': 'article', 'author': [{'family': 'Paolucci', 'given': 'Alessandro'}, {'family': 'Gianvincenzi', 'given': 'Mattia'}, {'family': 'Marconi', 'given': 'Marco'}, {'family': 'Favi', 'given': 'Claudio'}, {'family': 'Pennino', 'given': 'Diego'}], 'abstract': 'The Eco-design for Sustainable Products Regulation has introduced the Digital Product Passport (DPP) as a key tool for tracking and promoting the sustainable development of products. Despite the growing interest in DPPs, standardized models are yet to be established, with only experimental alternatives available from various organizations. Moreover, no existing model fully exploits the data, as conducting a life cycle assessment (LCA) still necessitates acquiring additional data from various life cycle stages. This study aims to bridge this gap by developing a fully decentralized DPP prototype specifically for the Electrical and Electronic Equipment (EEE) sector. The research begins by defining a tree-structured hierarchical model for data collection and management, aligning with regulatory standards. The prototype\u2019s implementation employs an eXtended Markup Language (XML) file for data digitalization and blockchain technology to ensure secure data sharing and storage. Tested on a household appliance, the DPP prototype demonstrates how digital passports can enhance product lifecycle management, driving sustainability in the EEE sector and supporting the implementation of circular economy scenarios.'}, {'id': 'how_the_digital', 'title': 'How the digital product passport can embed sustainability in the supply chain: case study for the battery industry', 'URL': 'https://hdl.handle.net/10589/239975', 'extra_urls': ['https://hdl.handle.net/10589/239975'], 'type': 'article', 'author': [{'family': 'Pistoia', 'given': 'Alessandro'}], 'abstract': 'LAUREA MAGISTRALE'}, {'id': 'doi_10_1080_00405000_2025_2496840', 'title': 'Research status and development trends of digital twin technology in apparel production: a review', 'URL': 'https://doi.org/10.1080/00405000.2025.2496840', 'extra_urls': ['https://doi.org/10.1080/00405000.2025.2496840'], 'type': 'article', 'author': [{'family': 'Bi', 'given': 'Yanwei'}, {'family': 'Pan', 'given': 'Li'}, {'family': 'Cao', 'given': 'Liyao'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Research on the application of digital twin technology in apparel manufacturing is still in its early stages, with limited studies focusing specifically on its use in the apparel production process. This underscores the need for further promotion of the in-depth integration of digital twin technology into apparel manufacturing. This paper examines the need for its adoption in the apparel industry, highlighting key technologies such as multi-dimensional modeling, data analysis, and platform development. It also identifies potential improvements tailored to the specific needs of apparel production. Focusing on production line management, optimization, and maintenance, the paper assesses the current application of digital twins in the field. Additionally, it outlines technical challenges and explores emerging trends, including the integration of \u201cdesign-production-operations\u201d, data-driven worker behavior and production process interactions, global optimization for decision-making, resource-integrated cost control, and sustainable production maintenance through real-time monitoring. The study aims to analyze the unique characteristics of apparel production and promote the broader application of digital twin technology to enhance collaboration, optimize decision-making, and provide theoretical and practical guidance for its integration into apparel manufacturing.', 'DOI': '10.1080/00405000.2025.2496840'}, {'id': 'doi_10_1002_sd_2474', 'title': 'Sustainable value in the fashion industry: A case study of value construction/destruction using digital twins', 'URL': 'https://doi.org/10.1002/sd.2474', 'extra_urls': ['https://doi.org/10.1002/sd.2474'], 'type': 'article', 'author': [{'family': 'Wagner', 'given': 'Ralf'}, {'family': 'Kabalska', 'given': 'Agnieszka'}], 'issued': {'date-parts': [[2023]]}, 'abstract': 'New technologies\u2014especially the emergence of digital fashion and a growing interest in creating digital twins (DTs)\u2014are expected to alter existing value chains in the fashion industry as DT technology triggers a redesign of value creation processes. This qualitative case study demonstrates how and to what extent the development of DTs in the fashion industry addresses the sustainability needs of various stakeholders in both real-world and virtual-reality settings. The article examines the possibilities, benefits, and challenges of creating sustainable value in two distinct ways: traditionally, through physical processes, and through digital transformation by employing virtual processes via DTs. The main implication for further research is to examine the distribution of value facilitated by DT among heterogeneous stakeholders.', 'DOI': '10.1002/sd.2474'}, {'id': 'doi_10_1007_978-3-031-70262-4_5', 'title': 'Carbon Footprint of Fashion: Assessing and Addressing Carbon Emissions in Textile Production', 'URL': 'https://doi.org/10.1007/978-3-031-70262-4_5', 'type': 'article', 'author': [{'family': 'Mayer', 'given': 'Philomena'}, {'family': 'Tama Birkocak', 'given': 'Derya'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'Springer Nature Switzerland', 'abstract': 'The textile and apparel industry on global carbon emissions contributes approximately 10% to worldwide emissions. This sector, a major environmental polluter, involves energy-intensive processes from fiber production to textile care and disposal, including recycling and landfill. This chapter is focused on assessing textile products\u2019 CO2 emissions throughout their lifecycle, addressing the role of carbon footprinting in understanding the relative importance of different greenhouse gases.', 'DOI': '10.1007/978-3-031-70262-4_5'}, {'id': 'redefining_how', 'title': 'Redefining Choices. How Does Artificial Intelligence Support Decision-Making in Urban and Architectural Development?', 'URL': 'https://webthesis.biblio.polito.it/34480/', 'extra_urls': ['https://webthesis.biblio.polito.it/34480/'], 'type': 'thesis', 'author': [{'family': 'Calderon Herrera', 'given': 'Diana Sofia'}], 'publisher': 'Politecnico di Torino', 'abstract': 'In response to the increasing complexity of urban and architectural projects and the need for informed, viable, and objective problem-solving processes, this research examines the decision-making processes in urban and architectural realms. In particular, it explores how artificial intelligence (AI) can enhance specific stages of decision-support approaches. Through a combination of theoretical analysis with practical application, this thesis explores the use of Multi-Values Appraisal Methodology (MuVAM) to support decision-making in architecture with or without the support of artificial intelligence (AI). MuVAM is a new tool that combines problem structuring methods (PSMs) and multi-criteria decision analyses (MCDAs), offering a framework to address complex problems and evaluate multiple criteria. The research examines two aspects of the application of MuVAM: its stand-alone use, focusing on its ability to structure and analyze problems, and its integration with AI, exploring how this digital technology enhances its functionality. By addressing these complementary perspectives, the thesis highlights the features of MuVAM and the potential of AI in decision support systems. In particular, the thesis draws upon the observation and reporting of participants interacting in the workshops\u2019 environment. The workshops were experimented with through three case studies, at different scales: (i) the transformation of the district \u201cPointe Nord\u201d in Geneva; (ii) the adaptive reuse of the former Paracchi carpet factory in Turin; and (iii) the requalification of the San Salvario neighborhood in Turin. Each case study illustrates how structured decision-making, guided by the integrated methodology, can be applied in architecture to address site-specific challenges and optimize urban decision outcomes. Also, since the first one was performed without the use of AI combined with MuVAM, the applications were compared in this sense. Accordingly, by connecting theoretical research with practical experiments observation, the thesis highlights the challenges and opportunities of such integrations, incorporating decision-making processes and artificial intelligence into architecture.'}, {'id': 'doi_10_1007_s11301-025-00526-4', 'title': 'Exploring the role of trust in AI-driven decision-making: a systematic literature review', 'URL': 'https://doi.org/10.1007/s11301-025-00526-4', 'extra_urls': ['https://doi.org/10.1007/s11301-025-00526-4'], 'type': 'article', 'author': [{'family': 'Montealegre-L\xf3pez', 'given': 'Nathalie'}], 'abstract': 'The increasing integration of artificial intelligence (AI) into managerial decision-making is transforming how organizations operate. It enables both decision augmentation in which AI supports human managers by providing recommendations, and decision automation in which AI independently makes decisions. Trust in AI systems is a critical factor in successful human-AI collaboration, as it affects the acceptance, adoption, and effectiveness of AI-driven decisions. However, the literature on the interplay among trust, AI, and decision-making remains fragmented due to the multidisciplinary nature of this issue. This systematic literature review addresses this issue by synthesizing extant research on the role of trust in AI-driven decision-making within a managerial context. Using a categorization framework, the review classifies 70 relevant articles across two key dimensions: the type of AI-driven decision-making \u2014 augmented or automated \u2014 and the aspect of trust, including its foundations, dynamics, and outcomes. This structured approach highlights key findings in the literature and identifies areas requiring further investigation. The article not only provides a comprehensive overview of the current state of research but also proposes avenues for future research that could deepen our understanding of trust\u2019s role in AI-driven decision-making and its implications for managerial practices.', 'DOI': '10.1007/s11301-025-00526-4'}, {'id': 'doi_10_1108_JKM-03-2025-0375', 'title': 'The nexus between learning engagement, knowledge acquisition and valence of use: role of generative AI adoption in business context', 'URL': 'https://doi.org/10.1108/JKM-03-2025-0375', 'extra_urls': ['https://doi.org/10.1108/JKM-03-2025-0375'], 'type': 'article', 'author': [{'family': 'Jiang', 'given': 'Xuping'}, {'family': 'Yuan', 'given': 'Ling'}, {'family': 'O. Alshaghdali', 'given': 'Nourah'}, {'family': 'Galgotia', 'given': 'Aradhana'}, {'family': 'Monaco', 'given': 'Antonio'}, {'family': 'Dell\u2019Aversano', 'given': 'Speranza'}], 'abstract': 'This study aims to examine how generative artificial intelligence (Gen AI)-based knowledge acquisition and learning engagement relate to business executives\u2019 valence for using Gen AI.Based on expectancy-value theory and Vroom\u2019s theory of motivation, this study developed a theoretical model to analyze how performance expectancy and instrumentality of Gen AI relate to business executives\u2019 knowledge acquisition and learning engagement, which further influences their Gen AI valence. Motivation acts as a moderating variable to evaluate how business executives\u2019 motivation and competence in utilizing Gen AI enhance their knowledge and learning abilities, complementing their valence for Gen AI.The results indicate a positive relationship between performance expectancy and the instrumentality of Gen AI regarding business executives\u2019 knowledge acquisition and learning engagement, which positively correlates with their outcome valence of Gen AI.The results indicate a positive relationship between performance expectancy and the instrumentality of Gen AI regarding business executives\u2019 knowledge acquisition and learning engagement, which positively correlates with their outcome valence of Gen AI.', 'DOI': '10.1108/JKM-03-2025-0375'}, {'id': 'conditioned', 'title': 'Img2CAD: Conditioned 3-D CAD Model Generation From Single Image With Structured Visual Geometry', 'URL': 'https://ieeexplore.ieee.org/document/11089972', 'extra_urls': ['https://ieeexplore.ieee.org/document/11089972'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Tianrun'}, {'family': 'Yu', 'given': 'Chunan'}, {'family': 'Hu', 'given': 'Yuanqi'}, {'family': 'Li', 'given': 'Jing'}, {'family': 'Xu', 'given': 'Tao'}, {'family': 'Cao', 'given': 'Runlong'}, {'family': 'Zhu', 'given': 'Lanyun'}, {'family': 'Zang', 'given': 'Ying'}, {'family': 'Zhang', 'given': 'Yong'}, {'family': 'Li', 'given': 'Zejian'}, {'family': 'Sun', 'given': 'Lingyun'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'In this article, we propose Img2CAD, the first approach to our knowledge that uses 2-D image inputs to generate computer-aided design (CAD) models with editable parameters. Unlike existing artificial intelligence (AI) methods for 3-D model generation using text or image inputs often rely on mesh-based representations, which are incompatible with CAD tools and lack editability and fine control, Img2CAD enables seamless integration between AI-based 3-D reconstruction and CAD software. We have identified an innovative intermediate representation called structured visual geometry, characterized by vectorized wireframes extracted from objects. This representation significantly enhances the performance of generating conditioned CAD models. In addition, we introduce two new datasets to further support research in this area: a big cad model dataset (ABC)-mono, the largest known dataset comprising over 200 000 3-D CAD models with rendered images, and KOCAD, the first dataset featuring real-world captured objects alongside their ground truth CAD models, supporting further research in conditioned CAD model generation.'}, {'id': 'leveraging_large_language', 'title': 'Leveraging large language models in next generation intelligent manufacturing: Retrospect and prospect', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0278612525001943', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0278612525001943'], 'type': 'article', 'author': [{'family': 'Ma', 'given': 'Yunfei'}, {'family': 'Zheng', 'given': 'Shuai'}, {'family': 'Yang', 'given': 'Zheng'}, {'family': 'Zheng', 'given': 'Pai'}, {'family': 'Leng', 'given': 'Jiewu'}, {'family': 'Hong', 'given': 'Jun'}], 'abstract': 'Industry 5.0, as the guiding ideology of the new generation intelligent manufacturing, points the way for global industrial transformation. It emphasizes the collaborative cooperation between humans, machines and intelligent systems, and places humans at the core of the industrial production process, aiming to create a more flexible, personalized and sustainable production paradigm. Large language model, as an advanced natural language processing technology, has received attention from researchers related to Industry 5.0 due to its ease of use and powerful language processing capability. LLM is considered to be one of the key enabling technologies to drive the development of Industry 5.0 and has great application potential. After a rigorous review of existing approaches, we find there is few existing survey papers that focuses on how LLM will drive the development of Industry 5.0 applications. Therefore, this paper provides a comprehensive review of the application of LLM in the field of Industry 5.0. Firstly, we conduct a literature review to explore the current state of research related to Industry 5.0. Subsequently, we analyze LLM-based technologies, synergizing LLMs with Industry 5.0 enablers and the applications of LLM in various domains of intelligent manufacturing. Finally, we explore the challenges of LLM in real-world scenarios and future research directions in the context of Industry 5.0. It is hoped that this study will contribute to the further development of LLM-based solutions in the context of Industry 5.0 and unite various efforts to achieve the vision of Industry 5.0.'}, {'id': 'advanced_smart_contract', 'title': 'Advanced Smart Contract Vulnerability Detection via LLM-Powered Multi-Agent Systems', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11121619', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11121619'], 'type': 'article', 'author': [{'family': 'Wei', 'given': 'Zhiyuan'}, {'family': 'Sun', 'given': 'Jing'}, {'family': 'Sun', 'given': 'Yuqiang'}, {'family': 'Liu', 'given': 'Ye'}, {'family': 'Wu', 'given': 'Daoyuan'}, {'family': 'Zhang', 'given': 'Zijian'}, {'family': 'Zhang', 'given': 'Xianhao'}, {'family': 'Li', 'given': 'Meng'}, {'family': 'Liu', 'given': 'Yang'}, {'family': 'Li', 'given': 'Chunmiao'}, {'family': 'Wan', 'given': 'Mingchao'}, {'family': 'Dong', 'given': 'Jin'}, {'family': 'Zhu', 'given': 'Liehuang'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Blockchain\u2019s inherent immutability, while transformative, creates critical security risks in smart contracts, where undetected vulnerabilities can result in irreversible financial losses. Current auditing tools and approaches often address specific vulnerability types, yet there is a need for a comprehensive solution that can detect a wide range of vulnerabilities with high accuracy. We propose LLM-SmartAudit, a novel framework that leverages Large Language Models (LLMs) to automate smart contract vulnerability detection and analysis. Using a multi-agent conversational architecture with a bufferof-thought mechanism, LLM-SmartAudit maintains a dynamic record of insights generated throughout the audit process. This enables a collaborative system of specialized agents to iteratively refine their assessments, enhancing the accuracy and depth of vulnerability detection. To evaluate its effectiveness, LLMSmartAudit was tested on three datasets: a benchmark for common vulnerabilities, a real-world project corpus, and a CVE dataset. It outperformed existing tools with 98% accuracy on common vulnerabilities and demonstrates higher accuracy in real-world scenarios. Additionally, it successfully identifies 12 out of 13 CVEs, surpassing other LLM-based methods. These results demonstrate the effectiveness of multi-agent collaboration in automated smart contract auditing, offering a scalable, adaptive, and highly efficient solution for blockchain security analysis.'}, {'id': 'detecting_bad', 'title': 'SCALM: Detecting Bad Practices in Smart Contracts Through LLMs', 'URL': 'https://ojs.aaai.org/index.php/AAAI/article/view/32026', 'extra_urls': ['https://ojs.aaai.org/index.php/AAAI/article/view/32026'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Zongwei'}, {'family': 'Li', 'given': 'Xiaoqi'}, {'family': 'Li', 'given': 'Wenkai'}, {'family': 'Wang', 'given': 'Xin'}], 'abstract': 'As the Ethereum platform continues to mature and gain widespread usage, it is crucial to maintain high standards of smart contract writing practices. While bad practices in smart contracts may not directly lead to security issues, they do elevate the risk of encountering problems. Therefore, to understand and avoid these bad practices, this paper introduces the first systematic study of bad practices in smart contracts, delving into over 35 specific issues. Specifically, we propose a large language models (LLMs)-based framework, SCALM. It combines Step-Back Prompting and Retrieval-Augmented Generation (RAG) to effectively identify and address various bad practices. Our extensive experiments using multiple LLMs and datasets have shown that SCALM outperforms existing tools in detecting bad practices in smart contracts.'}, {'id': 'beyond', 'title': 'Beyond single-model AI: How architectural design drives reliable multi-agent orchestration', 'URL': 'https://venturebeat.com/ai/beyond-single-model-ai-how-architectural-design-drives-reliable-multi-agent-orchestration', 'extra_urls': ['https://venturebeat.com/ai/beyond-single-model-ai-how-architectural-design-drives-reliable-multi-agent-orchestration'], 'type': 'article', 'author': [{'family': 'Gupta', 'given': 'Nikhil'}], 'abstract': 'Successful AI agents require enterprises to orchestrate interactions, manage shared knowledge and plan for failure.'}, {'id': 'federated_smart', 'title': 'Federated learning-empowered smart manufacturing and product lifecycle management: A review', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1474034625000722', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1474034625000722'], 'type': 'article', 'author': [{'family': 'Leng', 'given': 'Jiewu'}, {'family': 'Li', 'given': 'Rongjie'}, {'family': 'Xie', 'given': 'Junxing'}, {'family': 'Zhou', 'given': 'Xueliang'}, {'family': 'Li', 'given': 'Xiang'}, {'family': 'Liu', 'given': 'Qiang'}, {'family': 'Chen', 'given': 'Xin'}, {'family': 'Shen', 'given': 'Weiming'}, {'family': 'Wang', 'given': 'Lihui'}], 'abstract': 'The proliferation of data silos poses a significant impediment to the advancement of machine learning applications. The traditional approach of centralized data learning is becoming increasingly impractical in certain domains, primarily due to escalating concerns over data privacy and security. Particularly in the manufacturing sector, the integration of Federated Learning (FL) presents a promising avenue for safeguarding collaborative data mining efforts across a network of distributed manufacturers. This paper offers an in-depth review of research about FL in the realms of smart manufacturing and product lifecycle management. We elucidate the imperative need for FL applications from a socio-technical systems perspective, underscoring the interplay between societal and technological factors. Subsequently, we delve into the categorization of FL methodologies and their pivotal enablers, contextualized within the framework of manufacturing engineering. This paper further presents a comprehensive overview of FL applications, complemented by an analysis of the key performance metrics that are germane to the manufacturing industry. In conclusion, we engage in a discourse on the technical challenges, societal barriers, and prospective research trajectories for FL. Our discussion is anchored towards the emerging paradigm of Industry 5.0, which envisions a future where resilient, human-centric, and sustainable manufacturing systems are seamlessly integrated with cutting-edge digital technologies.'}, {'id': 'doi_10_1080_00207543_2025_2543964', 'title': 'Enhancing supply chain visibility with generative AI: an exploratory case study on relationship prediction in knowledge graphs', 'URL': 'https://doi.org/10.1080/00207543.2025.2543964', 'extra_urls': ['https://doi.org/10.1080/00207543.2025.2543964'], 'type': 'article', 'author': [{'family': 'Zheng', 'given': 'Ge'}, {'family': 'Brintrup', 'given': 'Alexandra'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'A key stumbling block in effective supply chain risk management for companies and policymakers is a lack of visibility on interdependent supply network relationships. Relationship prediction, also called link prediction is an emergent area of supply chain surveillance research that aims to increase the visibility of supply chains using data-driven techniques. Existing methods have been successful for predicting relationships but struggle to extract the context in which these relationships are embedded \u2013 such as the products being supplied or locations they are supplied from. Lack of context prevents practitioners from distinguishing transactional relations from established supply chain relations, hindering accurate estimations of risk. In this work, we develop a new Generative Artificial Intelligence (GenAI) enhanced machine learning framework that leverages pre-trained language models as embedding models combined with machine learning models to predict supply chain relationships within knowledge graphs. By integrating Generative AI techniques, our approach captures the nuanced semantic relationships between entities, thereby improving supply chain visibility and facilitating more precise risk management. Using data from a real case study, we show that GenAI-enhanced link prediction surpasses all benchmarks, and demonstrate how GenAI models can be explored and effectively used in supply chain risk management.', 'DOI': '10.1080/00207543.2025.2543964'}, {'id': 'secure_federated_learning', 'title': 'Secure Federated Learning for Cloud-Fog Automation: Vulnerabilities, Challenges, Solutions, and Future Directions', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10870877', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10870877'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Zhuangzhuang'}, {'family': 'Wu', 'given': 'Libing'}, {'family': 'Jin', 'given': 'Jiong'}, {'family': 'Wang', 'given': 'Enshu'}, {'family': 'Liu', 'given': 'Bingyi'}, {'family': 'Han', 'given': 'Qing-Long'}], 'abstract': 'With the intelligence and automation of industrial Internet of Things, a new collaborative Cloud-Fog Automation paradigm has emerged. The emergence of federated learning (FL) has further enhanced the capabilities of Cloud-Fog Automation, making it possible to develop more secure and versatile collaborative industrial models. However, FL faces various security risks. More importantly, the security risks faced by FL when applied in Cloud-Fog Automation, along with corresponding security measures, have not yet been explored. To address this issue, we make an initial attempt to analyze the security of FL within the context of Cloud-Fog Automation, with the aim of facilitating the design of a more secure FL framework for this paradigm. Specifically, we first analyze the security risks that may be encountered at different phases, then analyze the challenges that need to be faced to resolve these risks. Subsequently, we conduct a systematic review of the state-of-the-art security solutions, and finally summarize the future research directions.'}, {'id': 'integration_of_distributed', 'title': 'Integration of Distributed Technologies for Intelligent Food Quality and Safety Management: Blockchain, IoT, and Federated Learning', 'URL': 'https://www.tandfonline.com/doi/full/10.1080/87559129.2025.2517292', 'extra_urls': ['https://www.tandfonline.com/doi/full/10.1080/87559129.2025.2517292'], 'type': 'article', 'author': [{'family': 'Ding', 'given': 'Haohan'}, {'family': 'Cheng', 'given': 'Wenxu'}, {'family': 'Song', 'given': 'Xiaodong'}, {'family': 'Dong', 'given': 'Guanjun'}, {'family': 'Cui', 'given': 'Xiaohui'}, {'family': 'Yu', 'given': 'Wei'}, {'family': 'Wilson', 'given': 'David I.'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'from_trust_to', 'title': 'From trust to truth: Advancements in mitigating the Blockchain Oracle problem', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1084804523000917', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1084804523000917'], 'type': 'article', 'author': [{'family': 'Hassan', 'given': 'Ammar'}, {'family': 'Makhdoom', 'given': 'Imran'}, {'family': 'Iqbal', 'given': 'Waseem'}, {'family': 'Ahmad', 'given': 'Awais'}, {'family': 'Raza', 'given': 'Asad'}], 'abstract': 'Smart contracts gave a new dimension to Blockchain applications. Subsequently, Blockchains evolved from decentralized cryptocurrency ledgers to platforms for developing decentralized applications. A decentralized application needs a variety of data from the real world that cannot be directly provided by smart contracts. Oracles provide a mechanism to input data to the smart contracts for decentralized applications in a trusted manner. Oracles are the entities that collect data from data sources, verify it and then transmit it to the Blockchain. The introduction of Oracles has brought back the issues of centralization, single point of failure and reliance on a trusted third party in the Blockchain ecosystem. Oracles have adopted different means to reduce centralization and achieve some trustless operating mechanisms involving decentralized algorithms based on voting or reputation. In this paper, we analyse the concept of the Blockchain Oracle problem, its effects on various Blockchain applications, various Oracle types and trust mechanisms. We also analyse some of the significant Oracles (like chainlink, provable), and their underlying mechanisms and compare them. In the end, we carry out a gap analysis and discuss some open research issues that must be addressed to achieve robust and secure decentralization.'}, {'id': 'arxiv_2506.00274v1', 'title': 'Chances and Challenges of the Model Context Protocol in Digital Forensics and Incident Response', 'URL': 'https://arxiv.org/abs/2506.00274v1', 'extra_urls': ['https://arxiv.org/abs/2506.00274v1'], 'type': 'webpage', 'author': [{'family': 'Hilgert', 'given': 'Jan-Niclas'}, {'family': 'Jakobs', 'given': 'Carlo'}, {'family': 'K\xfclper', 'given': 'Michael'}, {'family': 'Lambertz', 'given': 'Martin'}, {'family': 'Mahr', 'given': 'Axel'}, {'family': 'Padilla', 'given': 'Elmar'}], 'abstract': 'Large language models hold considerable promise for supporting forensic investigations, but their widespread adoption is hindered by a lack of transparency, explainability, and reproducibility. This paper explores how the emerging Model Context Protocol can address these challenges and support the meaningful use of LLMs in digital forensics. Through a theoretical analysis, we examine how MCP can be integrated across various forensic scenarios - ranging from artifact analysis to the generation of interpretable reports. We also outline both technical and conceptual considerations for deploying an MCP server in forensic environments. Our analysis reveals a wide range of use cases in which MCP not only strengthens existing forensic workflows but also facilitates the application of LLMs to areas of forensics where their use was previously limited. Furthermore, we introduce the concept of the inference constraint level - a way of characterizing how specific MCP design choices can deliberately constrain model behavior, thereby enhancing both auditability and traceability. Our insights demonstrate that MCP has significant potential as a foundational component for developing LLM-assisted forensic workflows that are not only more transparent, reproducible, and legally defensible, but also represent a step toward increased automation in digital forensic analysis. However, we also highlight potential challenges that the adoption of MCP may pose for digital forensics in the future.'}, {'id': 'doi_10_1108_IJCST-01-2023-0002', 'title': 'A review of parametric clothing pattern CAD software methodology', 'URL': 'https://doi.org/10.1108/IJCST-01-2023-0002', 'extra_urls': ['https://doi.org/10.1108/IJCST-01-2023-0002'], 'type': 'article', 'author': [{'family': 'Lee', 'given': 'Ah Lam'}, {'family': 'Han', 'given': 'Hyunsook'}], 'abstract': 'The main issue in the mass customization of apparel products is how to efficiently produce products of various sizes. A parametric pattern-making system is one of the notable ways to rectify this issue, but there is a lack of information on the parametric design itself and its application to the apparel industry. This study compares and analyzes three types of parametric clothing pattern CAD (P-CAD) software currently in use to identify the characteristics of each, and suggest a basic guideline for efficient and adaptable P-CAD software in the apparel industry.This study compared three different types of P-CAD software with different characteristics: SuperALPHA: PLUS(as known as YUKA), GRAFIS and Seamly2D. The authors analyzed the types and management methodologies of each software, according to the three essential components that refer to previous studies about parametric design systems: entities, constraints and parameters.The results demonstrated the advantages and disadvantages of methodology in terms of three essential components of each software. Based on the results, the authors proposed five strategies for P-CAD development that can be applied to the mass customization of clothing.This study is meaningful in that it consolidates and organizes information about P-CAD software that has previously been scattered. The framework used in this study has an academic value suggesting guidelines to analyze P-CAD systems.', 'DOI': '10.1108/IJCST-01-2023-0002'}, {'id': 'virtual_evaluation_of', 'title': "Virtual Evaluation of CLO 3D Auto-Grading Tool in Attaining the Fit of Women's Clothing with Complex Patterns", 'URL': 'https://journals.ekb.eg/article_432643.html', 'extra_urls': ['https://journals.ekb.eg/article_432643.html'], 'type': 'article', 'author': [{'family': 'Abdelazez Aborady', 'given': 'Asmaa G.'}, {'family': 'Al-Qatry', 'given': 'Doaa AQ'}], 'abstract': "Grading is a crucial task for pattern makers, involving increasing or decreasing the original pattern according to body measurements to produce different sizes for clothing production. Computer grading systems have advanced significantly; CLO 3D is one such system that provides distinctive grading features, including auto-grading and edit grading, which improve industrial efficiency and productivity. The auto-grading technique creates new patterns in different sizes based on existing patterns, reducing errors and eliminating the necessity for manual grading. This study employs the auto-grading features of CLO 3D in grading complex patterns. Besides, it ensures that the various graded sizes fit and conform to the body. Furthermore, evaluate the fit of the graded patterns for each style on the 3D parametric virtual mannequin using the fit maps supplied by the CLO 3D program. The basic bodice block pattern was drafted and graded with the CLO 3D auto-grading tool, then the fit of the graded pattern was evaluated with fit maps on a 3D parametric virtual mannequin. Therefore, two complex women's styles were selected and drafted using the CLO 3D program with size XS. The auto-grading technique was applied to the style's patterns with the sizes (S-M-L). The graded pattern fit was then evaluated with fit maps on a 3D parametric virtual mannequin. The results indicate that the auto-grading tool within the CLO 3D program has proven highly effective in grading complex styles, considering virtual Evaluation using the fit maps method. This tool facilitates the automatic grading of such complex styles, achieving accurate and well-fitted outcomes."}, {'id': 'doi_10_1177_00405175251318243', 'title': 'Personalized digital human modeling in the customized clothing industry under Industry 5.0', 'URL': 'https://doi.org/10.1177/00405175251318243', 'extra_urls': ['https://doi.org/10.1177/00405175251318243'], 'type': 'article', 'author': [{'family': 'Yu', 'given': 'Jinjing'}, {'family': 'Shi', 'given': 'Hui'}, {'family': 'Duan', 'given': 'Wenjie'}], 'abstract': 'To accelerate transformation in the clothing industry under Industry 5.0, in this study, a digital human model of regional young men was investigated, using a linear regression model approach. A total of 263 young men, supported by a 3D body scanning system, were selected for the experimental sample. Body indicators guiding a reverse model of the upper body were chosen, with body features identified through descriptive analysis and principal component analysis. Subsequently, a personalized linear regression model could be statistically analyzed, and personalized inverse models could be visualized by designing the algorithm flow of the digital human modeling system in Grasshopper. The model can be changed in real time to fit the concept of the human digital twin. Meanwhile, hierarchical clustering and fast clustering methods were used in combination to establish representative body shapes for young men in the region, and clustering centers were used as validation samples to demonstrate that the prediction accuracy of this digital human model system was more than 80% for most body indicators, validating the feasibility and reliability of the digital human model, based on linear regression. This study offers technical support for regional digital human modeling, establishes a model foundation for research on human surface details, and supplies a data reference for tailored clothing patterns.', 'DOI': '10.1177/00405175251318243'}, {'id': 'doi_10_1080_1362704X_2021_1981657', 'title': 'Digital 3D Fashion Designers: Cases of Atacac and The Fabricant', 'URL': 'https://doi.org/10.1080/1362704X.2021.1981657', 'extra_urls': ['https://doi.org/10.1080/1362704X.2021.1981657'], 'type': 'article', 'author': [{'family': 'S\xe4rm\xe4kari', 'given': 'Natalia'}], 'abstract': 'The phenomenon of \u201cdigital fashion\u201d has been lately addressed in media as the next significant step in the fashion industry. The increasing use of the 3D-software in fashion design processes is part of a wider \u201cfashion 4.0\u201d digitalization process. This article frames the phenomenon of digital fashion and presents an in-depth case study research on two pioneering companies in this area, Atacac and The Fabricant. How and why are they building their fashion design practice on digital 3D-design? How are these companies redefining the fashion design culture and the fashion designer? Drawing from sociology of professions, this article proposes that digital fashion is an emerging subfield within the field of fashion design, differentiating itself from the professional conventions and building new strategies of jurisdiction and legitimation. Driven by sociotechnical affordances and elevation of professional pride through ethical, conceptual, artistic and skill differentiation, digital fashion designer becomes also a digital artisan. In the increasingly virtual, or \u201cphygital\u201d space and a networked synergetic community of digital fashion, the professional, authorial, bodily and material boundaries of designers become fluid, transforming the traditional figure of fashion designer.', 'DOI': '10.1080/1362704X.2021.1981657'}, {'id': 'doi_10_1108_IJCST-12-2021-0179', 'title': 'Developing a prediction model for improving bifurcated garment fit for mass customization', 'URL': 'https://dx.doi.org/10.1108/IJCST-12-2021-0179', 'extra_urls': ['https://dx.doi.org/10.1108/IJCST-12-2021-0179'], 'type': 'article', 'author': [{'family': 'Galada', 'given': 'Aditi'}, {'family': 'Baytar', 'given': 'Fatma'}], 'abstract': 'Purpose. The purpose of the present study was to improve the fit of women\u2019s bifurcated garments by developing an equation that can predict the crotch length accurately by using a few basic body measurements. This equation could provide a simple mass-customization approach to the design of bifurcated garments.Design/methodology/approach. Demographic characteristics and easy-to-record body measurements available in the size USA database were used to predict the crotch length. Different methodologies including best subset regression, lasso regression and principal components regression were experimented with to identify the most important predictor variables and establish a relationship between the significant predictors and crotch length.Findings. The lasso regression model provided the highest accuracy, required only five body dimensions and dealt with multicollinearity. The preliminary pattern preparation and garment fit tests indicated that by utilizing the proposed equation, patterns of customized garments could be successfully altered to match the crotch length of the customer, thereby, improving the precision and efficiency of the pattern making process.Originality/value. Crotch length is a crucial measurement as it determines bifurcated garment comfort as well as aesthetic fit. The crotch length is usually estimated arbitrarily based on non-scientific methods while drafting patterns, and this increases the likelihood of dissatisfaction with the fit of the lower-body garments. The present study suggested an algorithm that could predict crotch length with 90.53% accuracy using the body dimensions height, hips, waist height, knee height and arm length.', 'DOI': '10.1108/IJCST-12-2021-0179'}, {'id': 'doi_10_1177_00405175241289578', 'title': 'An intelligent generative method of fashion design combining attribute knowledge and Stable Diffusion Model', 'URL': 'https://doi.org/10.1177/00405175241289578', 'extra_urls': ['https://doi.org/10.1177/00405175241289578'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Yumiao'}, {'family': 'Ma', 'given': 'Jingyi'}], 'abstract': 'Artificial intelligence generation technology has brought new opportunities to the field of fashion design. Attribute knowledge has a significant impact on the overall effect of fashion design. Contemporary generative methods of fashion design frequently yield results lacking semantic information or missing specific attributes. To address the problem, this study aims for an intelligent generative method of fashion design through constructing prompt templates and a specific attribute low-rank adaption (LoRA) to combine fashion attribute knowledge into the generative process of the Stable Diffusion Model. First, a fashion attribute knowledge graph is constructed to establish prompt templates, and natural language descriptions are transformed into professional and complete prompt through GPT-4. Second, the fashion dataset is annotated with templates to filter specific attributes for LoRA training, followed by controlling fashion attributes in generation. Furthermore, analyses of the generation of women\u2019s jacket designs show that the proposed method consistently improves the accuracy and stability of attributes in fashion design generation.', 'DOI': '10.1177/00405175241289578'}, {'id': 'garment_pattern', 'title': 'Garment pattern definition, development and application with associative feature approach', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0166361510000199', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0166361510000199'], 'type': 'article', 'author': [{'family': 'Au', 'given': 'C. K.'}, {'family': 'Ma', 'given': 'Y. -S.'}], 'abstract': 'Garment virtual design has been evolved significantly with the rapid development of 3D CAD tools, especially with the convenient availability of NURBS surface modeling capability. Parametric development of clothes is demanded in line with the trend of mass customization according to the true measures of customers or regulated sizes of certain markets. Virtual design features with well-defined associations with the parametric mannequins are enablers. To achieve an intelligent mass customization approach, the development of surface patches from 3D clothing designs to 2D flattened patterns become essential. This article addresses the definition, development and application of garment features with an associative feature approach.'}, {'id': 'doi_10_1177_00405175241290436', 'title': 'Dynamic modeling of deformation in traditional smocking in apparel', 'URL': 'https://doi.org/10.1177/00405175241290436', 'extra_urls': ['https://doi.org/10.1177/00405175241290436'], 'type': 'article', 'author': [{'family': 'Zhao', 'given': 'Yu'}, {'family': 'Cheng', 'given': 'Yan'}, {'family': 'Zhou', 'given': 'Feng'}, {'family': 'Zhou', 'given': 'Li'}, {'family': 'Xiang', 'given': 'Yi'}], 'abstract': 'Traditional smocking, as a cultural heritage, has been widely employed in the design of modern apparel for its unique aesthetics. However, it often faces deformation when worn by a moving person, resulting in diminished aesthetics. The aim in this study is to detect the deformation threshold of a garment created with traditional smocking in a dynamic environment to assist in an aesthetic design. To reach this objective, first a 3D model was created of the cross-section of a garment with traditional smocking at the waistline, worn by a human avatar in a standing position. Then, by inputting the pressure triggered by level walking, ascending stairs, or twisting at the waist, finite-element models of the cross-sectional outlines were constructed to determine the displacements occurring on a garment with traditional smocking. The deformation threshold was determined afterwards, and validated. There are two contributions from this work: (1) the proposal of a deformation threshold for traditional smocking to assist in modern design, which generalizes an implication of promoting the aesthetics of heritage apparel in modern society; (2) the presentation of, it is believed, the first ever evaluation of the aesthetics of traditional smocking, which provides a new method to identify the interaction of pressure and displacement for traditional smocking in a dynamic environment.', 'DOI': '10.1177/00405175241290436'}, {'id': 'enriching_garments', 'title': 'Foldsketch: enriching garments with physically reproducible folds', 'URL': 'https://dl.acm.org/doi/10.1145/3197517.3201310', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3197517.3201310'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Minchen'}, {'family': 'Sheffer', 'given': 'Alla'}, {'family': 'Grinspun', 'given': 'Eitan'}, {'family': 'Vining', 'given': 'Nicholas'}], 'issued': {'date-parts': [[2018]]}, 'abstract': "While folds and pleats add interest to garments and cloth objects, incorporating them into an existing design manually or using existing software requires expertise and time. We present FoldSketch, a new system that supports simple and intuitive fold and pleat design. FoldSketch users specify the fold or pleat configuration they seek using a simple schematic sketching interface; the system then algorithmically generates both the fold-enhanced 3D garment geometry that conforms to user specifications, and the corresponding 2D patterns that reproduce this geometry within a simulation engine. While previous work aspired to compute the desired patterns for a given target 3D garment geometry, our main algorithmic challenge is that we do not have target geometry to start with. Real-life garment folds have complex profile shapes, and their exact geometry and location on a garment are intricately linked to a range of physical factors such as fabric properties and the garment's interaction with the wearer's body; it is therefore virtually impossible to predict the 3D shape of a fold-enhanced garment using purely geometric means. At the same time, using physical simulation to model folds requires appropriate 2D patterns and initial drape, neither of which can be easily provided by the user. We obtain both the 3D fold-enhanced garment and its corresponding patterns and initial drape via an alternating 2D-3D algorithm. We first expand the input patterns by allocating excess material for the expected fold formation; we then use these patterns to produce an estimated fold-enhanced drape geometry that balances designer expectations against physical reproducibility. We use the patterns and the estimated drape as input to a simulation generating an initial reproducible output. We improve the output's alignment with designer expectations by progressively refining the patterns and the estimated drape, converging to a final fully physically reproducible fold-enhanced garment. Our experiments confirm that FoldSketch reliably converges to a desired garment geometry and corresponding patterns and drape, and works well with different physical simulators. We demonstrate the versatility of our approach by showcasing a collection of garments augmented with diverse fold and pleat layouts specified via the FoldSketch interface, and further validate our approach via comparisons to alternative solutions and feedback from potential users."}, {'id': 'garment_modeling_with', 'title': 'Garment modeling with a depth camera', 'URL': 'https://dl.acm.org/doi/10.1145/2816795.2818059', 'extra_urls': ['https://dl.acm.org/doi/10.1145/2816795.2818059'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Xiaowu'}, {'family': 'Zhou', 'given': 'Bin'}, {'family': 'Lu', 'given': 'Feixiang'}, {'family': 'Wang', 'given': 'Lin'}, {'family': 'Bi', 'given': 'Lang'}, {'family': 'Tan', 'given': 'Ping'}], 'issued': {'date-parts': [[2015]]}, 'abstract': 'Previous garment modeling techniques mainly focus on designing novel garments to dress up virtual characters. We study the modeling of real garments and develop a system that is intuitive to use even for novice users. Our system includes garment component detectors and design attribute classifiers learned from a manually labeled garment image database. In the modeling time, we scan the garment with a Kinect and build a rough shape by KinectFusion from the raw RGBD sequence. The detectors and classifiers will identify garment components (e.g. collar, sleeve, pockets, belt, and buttons) and their design attributes (e.g. falbala collar or lapel collar, hubble-bubble sleeve or straight sleeve) from the RGB images. Our system also contains a 3D deformable template database for garment components. Once the components and their designs are determined, we choose appropriate templates, stitch them together, and fit them to the initial garment mesh generated by KinectFusion. Experiments on various different garment styles consistently generate high quality results.'}, {'id': 'doi_10_1007_978-981-97-7528-6_7', 'title': 'The Advancement of Computer-Aided Design and Computer-Aided Manufacturing in the Fashion Apparel Industry: Toward a Sustainable Development', 'URL': 'https://doi.org/10.1007/978-981-97-7528-6_7', 'type': 'article', 'author': [{'family': 'Bui', 'given': 'Loan Thi Cam'}, {'family': 'Nguyen', 'given': 'Hang Thi Thu'}, {'family': 'Do', 'given': 'Luu Thanh'}, {'family': 'Huynh', 'given': 'Thuc Van'}, {'family': 'Ta', 'given': 'Thang Duc'}, {'family': 'Duong', 'given': 'An Thi Binh'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Springer Nature', 'abstract': 'The fashion apparel business has a transient nature regarding product lifecycles, which requires the adoption of adaptable production cycles to accommodate the constantly evolving customer preferences. The labour-intensive production and escalating sustainability concerns catalyse industrial advancements. The industrial landscape is undergoing significant transformations due to the implementation of industrial 4.0 technologies, specifically computer-aided design (CAD) and computer-aided manufacturing (CAM). CAD software facilitates the fabrication of intricate digital garment models, augmenting fashion designers\u2019 capabilities. The capacity to swiftly produce prototypes enables the investigation and execution of inventive concepts. Consequently, the design process becomes more efficient, leading to faster product launches. Moreover, CAD effectively incorporates CAM technologies, automating cutting and sewing operations. This serves to reduce errors and enhance manufacturing efficiency. The convergence of CAD and CAM technologies is fostering a more sustainable approach to apparel production. Firstly, CAD-CAM optimises material utilisation by enabling precise digital garment creation. This reduces fabric waste generated during the cutting process. Secondly, by automating production processes and minimising human error, CAD-CAM decreases overall production waste. Hence, the collective impact of these factors reduces the ecological impact in the context of garment production. Nevertheless, deploying CAD-CAM systems presents several challenges. One notable obstacle is the substantial initial capital commitment necessary for the acquisition of software, hardware, and complete people training initiatives. Additionally, the effective operation of these systems requires specialised knowledge, potentially aggravating pre-existing skill deficiencies within the business. Finally, ensuring seamless integration between CAD-CAM software suites is crucial to avoid data disruptions and workflow inefficiencies. Remarkably, CAD-CAM technologies are transforming fashion apparel manufacturing by increasing efficiency, elevating product quality, and fostering a more sustainable production method. As the industry embraces these groundbreaking advancements, finding a vital equilibrium between automation and the invaluable worth of human innovation is paramount.', 'DOI': '10.1007/978-981-97-7528-6_7'}, {'id': 'simulation', 'title': 'High-resolution fiber-level simulation of knitted patterns', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0010448525000740', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0010448525000740'], 'type': 'article', 'author': [{'family': 'Yang', 'given': 'Xin'}, {'family': 'Lu', 'given': 'Cheng'}, {'family': 'Shao', 'given': 'Huiqi'}, {'family': 'Shao', 'given': 'Guangwei'}, {'family': 'Jiang', 'given': 'Jinhua'}, {'family': 'Bi', 'given': 'Siyi'}, {'family': 'Chen', 'given': 'Nanliang'}], 'abstract': 'Knitted fabrics, characterized by intricate patterns, vibrant colors, and soft tactile properties, have long served as a source of inspiration in textile design. Leveraging digital technology to translate these design concepts into realistic models, this paper proposes a fiber-level 3D simulation framework for complex knitted structures, inspired by the digital element methodology. In this approach, yarns are discretized into fiber assemblies represented by sequences of control points. Improved beam elements connect adjacent points to model bending behavior, while rod elements simulate inter-fiber interactions. To improve structural controllability, dynamic boundary conditions and variable driving forces are introduced, enabling accurate capture of both global and local deformations. An efficient Array operation is developed to support scalable generation of fabric patterns under a modified periodic boundary condition. Experimental evaluations demonstrate that the proposed method achieves visually and structurally accurate simulations within a limited number of iterations. Comparative analysis with real fabric samples validates the effectiveness and fidelity of the simulation framework, making it suitable for applications in virtual textile design and performance prediction.'}, {'id': '3d_pattern', 'title': 'Goal-oriented 3D pattern adjustment with machine learning', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1524070325000190', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1524070325000190'], 'type': 'article', 'author': [{'family': 'Shastry', 'given': 'Megha'}, {'family': 'Fan', 'given': 'Ye'}, {'family': 'Martins', 'given': 'Clarissa'}, {'family': 'Pai', 'given': 'Dinesh K.'}], 'abstract': 'Fit and sizing of clothing are fundamental problems in the field of garment design, manufacture, and retail. Here we propose new computational methods for adjusting the fit of clothing on realistic models of the human body by interactively modifying desired fit attributes. Clothing fit represents the relationship between the body and the garment, and can be quantified using physical fit attributes such as ease and pressure on the body. However, the relationship between pattern geometry and such fit attributes is notoriously complex and nonlinear, requiring deep pattern making expertise to adjust patterns to achieve fit goals. Such attributes can be computed by physically based simulations, using soft avatars. Here we propose a method to learn the relationship between the fit attributes and the space of 2D pattern edits. We demonstrate our method via interactive tools that directly edit fit attributes in 3D and instantaneously predict the corresponding pattern adjustments. The approach has been tested with a range of garment types, and validated by comparing with physical prototypes. Our method introduces an alternative way to directly express fit adjustment goals, making pattern adjustment more broadly accessible. As an additional benefit, the proposed approach allows pattern adjustments to be systematized, enabling better communication and audit of decisions.'}, {'id': 'dress_anyone', 'title': 'Dress Anyone : Automatic Physically-Based Garment Pattern Refitting', 'URL': 'https://dl.acm.org/doi/10.1145/3747858', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3747858'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Hsiao-Yu'}, {'family': 'Larionov', 'given': 'Egor'}, {'family': 'Kavan', 'given': 'Ladislav'}, {'family': 'Lin', 'given': 'Gene'}, {'family': 'Roble', 'given': 'Doug'}, {'family': 'Sorkine-Hornung', 'given': 'Olga'}, {'family': 'Stuyck', 'given': 'Tuur'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Well-fitted clothing is essential for both real and virtual garments to enable self-expression and accurate representation for a large variety of body types. Common practice in the industry is to provide a pre-made selection of distinct garment sizes such as small, medium and large. While these may cater to certain groups of individuals that fall within this distribution, they often exclude large sections of the population. In contrast, individually tailored clothing offers a solution to obtain custom-fit garments that are tailored to each individual. However, manual tailoring is time-consuming and requires specialized knowledge, prohibiting the approach from being applied to produce fitted clothing at scale. To address this challenge, we propose a novel method leveraging differentiable simulation for refitting and draping 3D garments and their corresponding 2D pattern panels onto a new body shape. This enables a workflow where garments only need to be designed once, in a single size, and they can be automatically refitted to support numerous body size and shape variations. Our method enables downstream applications, where our optimized 3D drape can be directly ingested into game engines or other applications. Our 2D sewing patterns allow for accurate physics-based simulations and enables manufacturing clothing for the real world.'}, {'id': 'reconstructing_sewing', 'title': 'NeuralTailor: reconstructing sewing pattern structures from 3D point clouds of garments', 'URL': 'https://dl.acm.org/doi/10.1145/3528223.3530179', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3528223.3530179'], 'type': 'article', 'author': [{'family': 'Korosteleva', 'given': 'Maria'}, {'family': 'Lee', 'given': 'Sung-Hee'}], 'issued': {'date-parts': [[2022]]}, 'abstract': 'The fields of SocialVR, performance capture, and virtual try-on are often faced with a need to faithfully reproduce real garments in the virtual world. One critical task is the disentanglement of the intrinsic garment shape from deformations due to fabric properties, physical forces, and contact with the body. We propose to use a garment sewing pattern, a realistic and compact garment descriptor, to facilitate the intrinsic garment shape estimation. Another major challenge is a high diversity of shapes and designs in the domain. The most common approach for Deep Learning on 3D garments is to build specialized models for individual garments or garment types. We argue that building a unified model for various garment designs has the benefit of generalization to novel garment types, hence covering a larger design domain than individual models would. We introduce NeuralTailor, a novel architecture based on point-level attention for set regression with variable cardinality, and apply it to the task of reconstructing 2D garment sewing patterns from the 3D point cloud garment models. Our experiments show that NeuralTailor successfully reconstructs sewing patterns and generalizes to garment types with pattern topologies unseen during training.'}, {'id': 'a_neural_rendering', 'title': 'A Neural Rendering system for fashion design process', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0952197625007730', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0952197625007730'], 'type': 'article', 'author': [{'family': 'Balloni', 'given': 'Emanuele'}, {'family': 'Stacchio', 'given': 'Lorenzo'}, {'family': 'Mancini', 'given': 'Adriano'}, {'family': 'Frontoni', 'given': 'Emanuele'}, {'family': 'Zingaretti', 'given': 'Primo'}, {'family': 'Paolanti', 'given': 'Marina'}], 'abstract': 'The translation of images into detailed three-dimensional (3D) models represents a critical challenge in digital content creation, particularly for the Creative Industries (CI). Traditional 3D modeling methods are resource-intensive, while recent advances in Neural Rendering (NR) have introduced efficient and automated solutions. In the fashion industry, where visual fidelity and rapid prototyping are crucial, NR techniques such as Neural Radiance Fields (NeRFs) and 3D Gaussian Splatting (3DGS) are becoming relevant resources to digitize complex geometries and textures with a low-cost approach, enabling different applications like virtual fitting rooms, immersive e-commerce, and digital prototyping. However, the evaluation of their effectiveness in this field is still in its early phases. To address the industry\u2019s needs, we propose Fashion immersive Neural Rendering Interface (FENRI), a novel framework that integrates NR techniques for reconstructing 3D models from 2D images of fashion items. FENRI includes a WebXR-based visualization platform that allows immersive comparison and evaluation of NR-generated 3D models, supporting both experts and non-experts in selecting optimal designs. We applied FENRI to footwear design, collecting a novel dataset to compare NeRF and 3DGS methods through quantitative and qualitative analyses. In our study, the 3DGS method demonstrated superior performance over NeRF, as highlighted by the higher Peak Signal-to-Noise Ratio (PSNR) values (37.65 vs. 29.03, respectively) and Structural Similarity Index Measure (SSIM) scores (0.99 vs 0.96), while exhibiting a lower Learned Perceptual Image Patch Similarity (LPIPS) values (0.01 vs 0.04). Moreover, we showed that, by applying classical mesh post-processing techniques, we can increase the topological and visual quality of the 3D models synthesized by NR methods. These findings highlight the potential of NR techniques in the fashion industry\u2019s digital pipeline. By enabling rapid, immersive, and visually compelling design iterations, FENRI offers a scalable solution to the fashion industry\u2019s demand for high-quality 3D reconstructions, promoting innovation and sustainability.'}, {'id': 'leveraging_fashion', 'title': 'Leveraging Fashion E-commerce Data and Computer Graphics Toward Automated Pattern Making for Pants: A Preliminary Study', 'URL': 'https://www.iastatedigitalpress.com/itaa/article/id/17912/', 'extra_urls': ['https://www.iastatedigitalpress.com/itaa/article/id/17912/'], 'type': 'article', 'author': [{'family': 'Kong', 'given': 'Doyeon'}, {'family': 'Baytar', 'given': 'Fatma'}], 'abstract': 'Ergonomic pattern-making, based on anthropometric measurements, is essential to ensuring fit and comfort but faces challenges including cost and privacy issues. This study explores an economical way of creating patterns for pants by leveraging computer graphics and fashion e-commerce data, such as model and garment sizes, which are readily available online. In this study, 100% cotton denim jeans were selected as sample pants. Computer graphics algorithms were applied to an image of a pair of jeans to automatically detect edges from the image and generate pants patterns by calculating key measurements, such as the waist, hip, crotch, and leg openings. For evaluation, the same pair of jeans was purchased and the patterns were manually traced and digitized into Optitex PDS v.21. The resulting patterns were compared with the algorithm-generated pattern and evaluated using Clo3D v.7. The hip measurements showed the biggest difference between the two patterns, where the algorithm-generated pattern had crooked side seams. In addition, the horizontal lines (e.g., the hip and leg openings) appeared more distorted because those parts were photographed closer to the lens and displayed larger than the vertical lines. While some aspects of geometric distortion in imagery could be improved, this study presented a new method for generating patterns for jeans by synthesizing publicly available e-commerce data and computer graphics. Future studies on deep learning-based models, such as segmentation, could allow for the extraction of more precise edge points for use as critical measurement points.'}, {'id': 'doi_10_1186_s40691-025-00417-y', 'title': 'Developing an instrument with simulations to measure 3D to 2D fit correction skills in fashion design', 'URL': 'https://doi.org/10.1186/s40691-025-00417-y', 'extra_urls': ['https://doi.org/10.1186/s40691-025-00417-y'], 'type': 'article', 'author': [{'family': 'Galada', 'given': 'Aditi'}, {'family': 'Baytar', 'given': 'Fatma'}], 'abstract': "In fashion design education, students are taught how to prepare 2D patterns to create 3D garments through flat pattern making and draping courses. However, there is a lack of focus on garment fitting, and students are expected to have a natural intuition regarding fit corrections. As a result, most students graduate without gaining the crucial skill of reading misfit signs in 3D and acting on correcting 2D patterns accordingly. For this reason, in the current study, we developed a novel skill test instrument based on the Extended Skill Cycle Model using 3D simulations to quantify students' fit correction skills. We evaluated the instrument\u2019s reliability and validity for its suitability in teaching and research applications. Fit correction questions with virtual garment simulations were designed, and participants were provided with three potential pattern modification options, out of which one option corrected garment fit. The reliability of the questionnaire was determined using Cronbach\u2019s alpha, and validity was analyzed by comparing pre- and post-training scores, comparing scores of participants with different levels of experience, and calculating the item difficulty and discrimination index. There was a positive correlation between the pre- and posttraining test scores, confirming that the instrument could measure the increase in skill level. In addition, the pre-training scores of participants at the very minimum patternmaking experience level were lower than those of participants with higher experience levels. Therefore, our instrument could be used in patternmaking courses in fashion design education to measure student skill development.", 'DOI': '10.1186/s40691-025-00417-y'}, {'id': 'fabricable_discretized_ruled', 'title': 'Fabricable Discretized Ruled Surfaces', 'URL': 'https://dl.acm.org/doi/10.1145/3734519', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3734519'], 'type': 'article', 'author': [{'family': 'Baharami', 'given': 'Hassan'}, {'family': 'Piovarci', 'given': 'Michal'}, {'family': 'Tarini', 'given': 'Marco'}, {'family': 'Bickel', 'given': 'Bernd'}, {'family': 'Pietroni', 'given': 'Nico'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'We present a method to automatically approximate a given surface with a small set of patches, each being a developable ruled surface featuring long-ruling lines. These construction primitives are attractive for their inherent ease of fabrication by cutting and folding inextensible materials and for their favo rable structural properties. Our algorithm strikes a good tradeoff between the simplicity of produced designs (in terms of the number and shapes of the patches) and approximation quality. To this end, it is guided by a smooth curvature-aligned cross-field.Compared to traditional methods, we rely on final discretization steps to ensure the developability of the ruled surfaces and produce a fabricable layout, bypassing the need to enforce that the strips are strictly developable in continuous settings (which requires difficulty in enforcing geometric conditions). We demonstrate the effectiveness of the proposed algorithm by producing several viable designs and using them to physically fabricate various physical objects.'}, {'id': 'complex_surface_fabrication', 'title': 'Complex Surface Fabrication Via Developable Surface Approximation: A Survey', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10870379', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10870379'], 'type': 'article', 'author': [{'family': 'Yuan', 'given': 'Chao'}, {'family': 'Cao', 'given': 'Nan'}, {'family': 'Shi', 'given': 'Yang'}], 'abstract': 'Complex surfaces are commonly observed in various applications and have significant value in enhancing comfort, aesthetics, and functionality. However, their fabrication often involves complex and costly processes. To simplify the fabrication difficulty, significant research has focused on using 3D developable surfaces to approximate target 3D surfaces. This process involves converting target 3D surfaces into developable surfaces and then flattening them into 2D patterns. Since the geometric and topological diversity of target surfaces, this task is both comprehensive and intricate, encompassing multiple aspects from design to fabrication. In this paper, we review relevant technologies and methods in fabrication processes, classify them, and summarize a pipeline from design to fabrication. This provides a comprehensive introduction to the field for researchers and practitioners. Through the analysis of relevant literature, we also discuss some of the research challenges and future research opportunities.'}, {'id': 'doi_10_1177_0887302X241311027', 'title': 'Drivers and Enablers of Digital Readiness in the Fashion Industry: A Systematic Literature Review', 'URL': 'https://doi.org/10.1177/0887302X241311027', 'extra_urls': ['https://doi.org/10.1177/0887302X241311027'], 'type': 'article', 'author': [{'family': 'Sun', 'given': 'Xun (Catherine)'}, {'family': 'Ha-Brookshire', 'given': 'Jung E.'}], 'abstract': "The fashion industry is undertaking transformative changes driven by various digital technologies. However, these changes present challenges, ranging from employee resistance to slow organizational response to digital change, leading to a high rate of failure in digital transformations. Guided by the change readiness theory and Porter's Diamond Model, this study aims to conceptualize fashion digital readiness and systematically understand digital readiness in fashion business organizations, endeavoring to uncover the crucial drivers and enablers from a practical business perspective. Through a systematic review method, 64 peer-reviewed articles from Google Scholar reveals 5 clusters on the current state of literature, identifies 6 main drivers and 21 main enablers, and proposes the Fashion Digital Readiness\u2014Drivers and Enablers (FDR-D, E) framework. The study expands on the advancements in change readiness theory into fashion digital readiness, provides insights into the propositions, theoretical and practical implications, and highlights further research avenues.", 'DOI': '10.1177/0887302X241311027'}, {'id': 'doi_10_1080_17543266_2024_2413568', 'title': '3D digital technology in upcycling apparel design: the creation of a modular redesign system and designer perspectives', 'URL': 'https://doi.org/10.1080/17543266.2024.2413568', 'extra_urls': ['https://doi.org/10.1080/17543266.2024.2413568'], 'type': 'article', 'author': [{'family': 'Choi', 'given': 'Kyung-Hee'}], 'abstract': 'Despite advancements in sustainable apparel design, upcycling practices still face challenges limiting creativity and efficiency. This study develops a Modular Redesign System (MRS) using 3D digital technology to improve the upcycling process. The MRS was created with CLO3D and Aftereffects, producing ten redesign samples and demonstration videos. In-depth interviews with South Korean upcycling apparel designers were conducted to assess the system\u2019s perceived effectiveness and explore key issues in upcycling design. The MRS involves four stages: Selection, Virtualisation, Virtual Ideation, and Construction and Fitting. Findings highlight the MRS\u2019s ability to enhance ideation, reduce material waste, and save time and costs, offering practical solutions to current challenges in apparel redesign. The MRS also shows potential for mass customisation, serving as an effective communication tool for personalised upcycling services. This study bridges a gap in the literature by integrating 3D virtual simulation with modular design to advance sustainable and efficient upcycling practices.', 'DOI': '10.1080/17543266.2024.2413568'}, {'id': 'doi_10_1108_EJIM-03-2023-0223', 'title': 'Business model innovation of 3D-printing garment enterprises in digital transformation: business model innovation canvas approach', 'URL': 'https://doi.org/10.1108/EJIM-03-2023-0223', 'extra_urls': ['https://doi.org/10.1108/EJIM-03-2023-0223'], 'type': 'article', 'author': [{'family': 'Jin', 'given': 'Yuran'}, {'family': 'Zhu', 'given': 'Xiaolin'}, {'family': 'Zhang', 'given': 'Xiaoxu'}, {'family': 'Wang', 'given': 'Hui'}, {'family': 'Liu', 'given': 'Xiaoqin'}], 'abstract': '3D printing has been warmly welcomed by clothing enterprises for its customization capacity in recent years. However, such clothing enterprises have to face the digital transformation challenges brought by 3D printing. Since the business model is a competitive weapon for modern enterprises, there is a research gap between business model innovation and digital transformation challenges for 3D-printing garment enterprises. The aim of the paper is to innovate a new business model for 3D-printing garment enterprises in digital transformation.A business model innovation canvas (BMIC), a new method for business model innovation, is used to innovate a new 3D-printing clothing enterprises business model in the context of digital transformation. The business model canvas (BMC) method is adopted to illustrate the new business model. The business model ecosystem is used to design the operating architecture and mechanism of the new business model.First, 3D-printing clothing enterprises are facing digital transformation, and they urgently need to innovate new business models. Second, mass customization and distributed manufacturing are important ways of solving the business model problems faced by 3D-printing clothing enterprises in the process of digital transformation. Third, BMIC has proven to be an effective tool for business model innovation.The new mass deep customization-distributed manufacturing (MDC-DM) business model is universal. As such, it can provide an important theoretical reference for other scholars to study similar problems. The digital transformation background is taken into account in the process of business model innovation. Therefore, this is the first hybrid research that has been focused on 3D printing, garment enterprises, digital transformation and business model innovation. On the other hand, business model innovation is a type of exploratory research, which means that the MDC-DM business model\u2019s application effect cannot be immediately observed and requires further verification in the future.The new business model MDC-DM is not only applicable to 3D-printing garment enterprises but also to some other enterprises that are either using or will use 3D printing to enhance their core competitiveness.A new business model, MDC-DM, is created through BMIC, which allows 3D-printing garment enterprises to meet the challenges of digital transformation. In addition, the original canvas of the MDC-DM business model is designed using BMC. Moreover, the ecosystem of the MDC-DM business model is constructed, and its operation mechanisms are comprehensively designed.', 'DOI': '10.1108/EJIM-03-2023-0223'}, {'id': 'is_the_digitalisation', 'title': 'Is the digitalisation the future of the luxury industry?', 'URL': 'https://www.cell.com/heliyon/abstract/S2405-8440(24)16060-4', 'extra_urls': ['https://www.cell.com/heliyon/abstract/S2405-8440(24)16060-4'], 'type': 'article', 'author': [{'family': 'Sanz-Lopez', 'given': 'Francisco'}, {'family': 'Gallego-Losada', 'given': 'Roc\xedo'}, {'family': 'Montero-Navarro', 'given': 'Antonio'}, {'family': 'Garc\xeda-Abajo', 'given': 'Elisa'}]}, {'id': 'doi_10_1108_JFMM-09-2024-0380', 'title': 'Mapping the digital transformation in the fashion industry: the past, present and future', 'URL': 'https://doi.org/10.1108/JFMM-09-2024-0380', 'extra_urls': ['https://doi.org/10.1108/JFMM-09-2024-0380'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Sujun'}, {'family': 'Liu', 'given': 'Chuanlan'}], 'abstract': 'Fashion Industry Digital Transformation (FIDT) is critical for fostering a more informed, adaptive, technologically advanced and sustainable industry. There is a gap in up-to-date reviews regarding the fast-evolving application of digital technology in the fashion industry. This study provides an extensive and up-to-date examination of the current literature and proposes future research directions in FIDT.A systematic review was conducted using bibliometric and thematic analyses of 224 peer-reviewed journal articles published between 2011 and 2024. Seminal works predating 2011 were also reviewed to answer research questions and establish a foundational context for FIDT research.The review identified growing global interest in digital innovations, particularly in sustainability. Analysis revealed three intellectual clusters and six thematic keyword clusters, underscoring focal areas such as sustainability, AI-enhanced luxury experiences and consumer engagement in digital retail. Key challenges, including technological barriers and data security concerns, were also mapped alongside future research priorities.This study presents a comprehensive analysis of FIDT to date, offering a structured research agenda to guide future investigations. Insights provided can support stakeholders in leveraging digital transformation to foster innovation, enhance consumer experiences and promote sustainability in the fashion industry.', 'DOI': '10.1108/JFMM-09-2024-0380'}, {'id': 'collaboration_in', 'title': 'Human-AI Collaboration in the Fashion Design Process', 'URL': 'https://ojs.aaai.org/index.php/AAAI-SS/article/view/35573', 'extra_urls': ['https://ojs.aaai.org/index.php/AAAI-SS/article/view/35573'], 'type': 'article', 'author': [{'family': 'Tocchetti', 'given': 'Andrea'}, {'family': 'Monterosso', 'given': 'Giulia'}, {'family': 'Romualdi', 'given': 'Francesca Palazzetti'}, {'family': 'Bertola', 'given': 'Paola'}, {'family': 'Brambilla', 'given': 'Marco'}, {'family': 'Vandi', 'given': 'Angelica'}, {'family': 'Vacca', 'given': 'Federica'}], 'abstract': "The recent development of Generative AI (GenAI) revolutionized the fashion industry, automating tasks like market analysis and trend forecasting, as well as innovating cloth design. However, its potential application in supporting designers in the fashion design process for creativity purposes has yet to be explored. Our research studied the complexity and pitfalls of such a process through interviews with domain experts. Starting from that assessment, this article compares generic and context-specific GenAI tools from several perspectives to explore their features and capabilities in enhancing the cooperation between fashion designers and AI tools and agents in the creative process. The most promising systems are tested on typical creative tasks, including generating images from textual descriptions (specified according to technical criteria), generating variations of existing designs and pictures, and generating photographic images from sketches. The experiments involved two data sets and five domain-specific tasks. The effectiveness and limitations of the tools are evaluated quantitatively to assess how they can properly support the designers' work."}, {'id': 'generative_ai_in', 'title': 'Generative AI in Fashion: Overview', 'URL': 'https://dl.acm.org/doi/10.1145/3718098', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3718098'], 'type': 'article', 'author': [{'family': 'Shi', 'given': 'Wenda'}, {'family': 'Wong', 'given': 'Waikeung'}, {'family': 'Zou', 'given': 'Xingxing'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Generative Artificial Intelligence (GenAI) has recently gained immense popularity by offering various applications for generating high-quality and aesthetically pleasing content of image, 3D, and video data format. The innovative GenAI solutions have shifted paradigms across various design-related industries, particularly fashion. In this article, we explore the incorporation of GenAI into fashion-related tasks and applications. Our examination encompasses a thorough review of more than 470 research papers and an in-depth analysis of over 300 applications, focusing on their contributions to the field. These contributions are identified as 13 tasks within four categories: multi-modal fashion understanding, and fashion synthesis of image, 3D, and dynamic (video and animatable 3D) formats We delve into these methods, recognizing their potential to propel future endeavors toward achieving state-of-the-art performance. Furthermore, we present a comprehensive overview of 53 publicly available datasets suitable for training and benchmarking fashion-centric models, accompanied by the relevant evaluation metrics. Finally, we review real-world applications, unveiling existing challenges and future directions. With comprehensive investigation and in-depth analysis, this article is targeted to serve as a useful resource for understanding the current landscape of GenAI in fashion, paving the way for future innovations in this dynamic field. Papers discussed in this article, along with public code and datasets links are available at: .'}, {'id': 'sustainable_digital_fashion', 'title': 'Sustainable digital fashion in a metaverse ecosystem', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0969698924003953', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0969698924003953'], 'type': 'article', 'author': [{'family': 'Xin', 'given': 'Baogui'}, {'family': 'Song', 'given': 'Yaping'}, {'family': 'Tan', 'given': 'Hui'}, {'family': 'Peng', 'given': 'Wei'}], 'abstract': "The fashion industry ranks among the top polluters globally, yet the emergence of virtual worlds offers a chance for brands to switch to digital clothing as a greener option. This research explores whether the metaverse can enhance sustainability in fashion or worsen environmental issues, especially those linked to non-fungible tokens (NFTs). We introduce a game theory model to analyze the strategic dynamics between brand manufacturers and digital fashion platforms, factoring in platforms' abilities to reduce emissions. The model uncovers how these uncertainties influence pricing, investment, and performance outcomes. Our analysis is supported by a case study on DressX, a prominent digital fashion platform, showing that digital fashion brings technological innovation and environmental advantages. Platforms with greater emission reduction capacities and their collaborators witness increased revenues. However, information asymmetry complicates strategic decision-making, and the environmental implications of digital technologies underpinning the metaverse remain a critical concern. Platforms with advanced capabilities gain a competitive edge by managing costs effectively, whereas manufacturers profit at the platforms' expense. However, there is a strategic equilibrium that benefits both sides. Our study indicates that maximizing the environmental benefits of digital fashion demands responsible actions from all stakeholders, including careful technology selection, clear communication of capabilities, cost management, and strategic cooperation. Our game theory approach, combined with a real-world case study, provides a unique perspective on the strategic and environmental dynamics of digital fashion in the metaverse, contributing to the growing body of literature on sustainable fashion and digital ecosystems."}, {'id': 'doi_10_1108_APJML-11-2022-0945', 'title': 'The perceived value of digital fashion product and purchase intention: the mediating role of the flow experience in\xa0metaverse platforms', 'URL': 'https://doi.org/10.1108/APJML-11-2022-0945', 'extra_urls': ['https://doi.org/10.1108/APJML-11-2022-0945'], 'type': 'article', 'author': [{'family': 'Park', 'given': 'Yeonseo'}, {'family': 'Ko', 'given': 'Eunju'}, {'family': 'Do', 'given': 'Boram'}], 'abstract': "This paper aims to explore digital fashion products in the metaverse platform contexts and empirically examine the effect of the metaverse platform characteristics on the purchase intention of digital fashion products through users' flow experience and perceived value of the products.A survey method was used in this study. Answers from 314 metaverse users were analyzed, and the hypotheses were tested using the structural equations modeling and bootstrapping analysis.The analyses showed that telepresence, social interaction and economic flow had significant effects on users' flow experience among the metaverse platform characteristics, while the continuity and content creation of the metaverse platform did not have significant effects. The flow experience also appeared to have significant effects on multiple consumption values, including pleasure value, self-expression value and economic value. Last, the perceived pleasure value and economic value of digital fashion products had a positive effect on purchase intention.The main contribution of this research is that it is one of the first empirical attempts to investigate individual consumers' perceptions and experiences of digital fashion products in the context of metaverse platforms.", 'DOI': '10.1108/APJML-11-2022-0945'}, {'id': 'doi_10_1080_20932685_2023_2251033', 'title': 'The adoption of digital fashion as an end product: A systematic literature review of research foci and future research agenda', 'URL': 'https://doi.org/10.1080/20932685.2023.2251033', 'extra_urls': ['https://doi.org/10.1080/20932685.2023.2251033'], 'type': 'article', 'author': [{'family': 'Chan', 'given': 'Hazel Hoi Yau'}, {'family': 'Henninger', 'given': 'Claudia'}, {'family': 'Boardman', 'given': 'Rosy'}, {'family': 'Blazquez Cano', 'given': 'Marta'}], 'abstract': 'With the advancement of 3D design software, \u201cdigital fashion\u201d has evolved from a retail and design tool for physical fashion to a virtual-only end-product sold to consumers in wholly digital form. As many brands are now developing digital fashion end products as a new revenue stream, given its potential to reduce some levels of overconsumption of physical clothing, it warrants academic attention. However, the literature has predominantly defined digital fashion as a tool rather than an end-product, resulting in an incomplete definition of digital fashion. This hinders scholars\u2019 ability to fully comprehend and explore this emerging product category. This article aims to synthesize the current marketing/management literature on digital fashion and investigate the theories, context, characteristics, and methodology of digital fashion as an end-product. This study contributes to the literature by providing a comprehensive industry-accepted definition of digital fashion within a conceptual framework, categorizing six different types of digital fashion end-products, and establishing a future research agenda that will lead to new research streams.', 'DOI': '10.1080/20932685.2023.2251033'}, {'id': 'defining_digital', 'title': 'Defining digital fashion: Reshaping the field via a systematic review', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0747563222002291', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0747563222002291'], 'type': 'article', 'author': [{'family': 'Baek', 'given': 'Eunsoo'}, {'family': 'Haines', 'given': 'Shelley'}, {'family': 'Fares', 'given': 'Omar H.'}, {'family': 'Huang', 'given': 'Zhihong'}, {'family': 'Hong', 'given': 'Yuwei'}, {'family': 'Lee', 'given': 'Seung Hwan Mark'}], 'abstract': "The field of digital fashion is rapidly evolving, yet what constitutes digital fashion, and how it should be defined has not been firmly established. This study aims to conceptualize and define digital fashion and its components (themes). Applying an inductive approach, we initially identified 10 keywords linked to digital fashion via a Twitter analysis. Then, a systematic literature review was conducted (n\xa0=\xa0116 articles). Six themes related to digital fashion were identified: design, consumer, virtual, body, printing, and supply. Themes include topics relating to the advancement of digital technologies in the fashion design process, innovation to enhance consumer experiences, and improvements to the value chain. Inspired by the six themes, we define digital fashion as \u201cthe virtual creation, production, and representation of one's identity via computer-generated design.\u201d An overview of each theme and its contribution to the field of digital fashion is discussed. Future research developments to extend this domain are considered."}, {'id': 'unlocking_the_potential', 'title': 'Unlocking the Potential of Artificial Intelligence in Fashion Design and E-Commerce Applications: The Case of Midjourney', 'URL': 'https://www.mdpi.com/0718-1876/19/1/35', 'extra_urls': ['https://www.mdpi.com/0718-1876/19/1/35'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Yanbo'}, {'family': 'Liu', 'given': 'Chuanlan'}], 'abstract': 'The fashion industry has shown increasing interest in applying artificial intelligence (AI), yet there is a significant gap in exploring the potential of emerging diffusion-modeling-based AI image-generation systems for fashion design and commerce. Therefore, this study aims to assess the effectiveness of Midjourney, one such AI system, in both fashion design and related commerce applications. We employed the action research approach with the Functional, Expressive, and Aesthetic (FEA) Consumer Needs Model as the theoretical framework. Our research comprised three stages: refining an initial idea into well-defined textual design concepts, facilitating concept development, and validating the preceding observations and reflections by creating a new line of hemp-based products that were evaluated by targeted consumers through an online survey. Findings reveal that this AI tool can assist fashion designers in creating both visually expressive attire and ready-to-wear products, meeting defined design criteria and consumer needs. Midjourney shows promise in streamlining the fashion design process by enhancing ideation and optimizing design details. Potential e-commercial applications of such AI systems were proposed, benefiting physical and digital fashion businesses. It is noted that, to date, the major limitations of using Midjourney encompass its restriction to only facilitating early fashion design stages and necessitating substantial involvement from designers.'}, {'id': 'doi_10_1080_15487733_2022_2125640', 'title': 'Exploring the nature of digital transformation in the fashion industry: opportunities for supply chains, business models, and sustainability-oriented innovations', 'URL': 'https://doi.org/10.1080/15487733.2022.2125640', 'extra_urls': ['https://doi.org/10.1080/15487733.2022.2125640'], 'type': 'article', 'author': [{'family': 'Casciani', 'given': 'Daria'}, {'family': 'Chkanikova', 'given': 'Olga'}, {'family': 'Pal', 'given': 'Rudrajeet'}], 'abstract': 'This article provides a comprehensive overview of the digital transformation of the fashion industry and describes the opportunities and influences on supply chains, business models, and sustainability-oriented innovations that it offers. Desk research was performed to review emerging cases of companies that engage actively in using 3-dimensional virtual and digital (3DVD) technologies, such as 3D modeling, virtual and augmented reality (VR and AR), 2- and 3-dimensional (2D/3D) scanning, and digital twinning (DT). The analysis shows how the adoption of digital technologies provides opportunities to dematerialize the traditional fashion supply-chain model of garment production and distribution and maps the innovative shifts occurring in the fashion industry\u2019s processes, products, and services. The adoption of 3DVD technologies by fashion companies unleashes new opportunities with respect to innovation in products/services and optimization of operational processes to streamline activities, shorten the lead time for designing, prototyping, manufacturing, marketing and retailing, and reorganizing the working phases. These capabilities also drive multicentred business-model innovations and thus affect value creation and delivery and capture changes. In addition, the analysis shows that digital transformation affects the four dimensions of sustainability that are interconnected intrinsically across supply-chain processes. Cultural sustainability is paramount, as fashion is a complex cultural system that is able to create products/services that influence the environment, economy, and society. In particular, 3DVD technologies promote cultural transformation of design processes to achieve a remix of skills and open knowledge, a behavioral shift from the consumer perspective in terms of diversity and self-expression, and a change in the organizational culture of companies that drive the digital transformation.', 'DOI': '10.1080/15487733.2022.2125640'}, {'id': 'doi_10_1108_JFMM-10-2017-0114', 'title': '3D technology in fashion: from concept to consumer', 'URL': 'https://doi.org/10.1108/JFMM-10-2017-0114', 'extra_urls': ['https://doi.org/10.1108/JFMM-10-2017-0114'], 'type': 'article', 'author': [{'family': 'Arribas', 'given': 'Veronica'}, {'family': 'Alfaro', 'given': 'Jos\xe9 A.'}], 'abstract': 'The purpose of this paper is to show how 3D digital technology can bring value to the fashion industry by analysing the specific benefits it offers along the value chain. Additionally, the authors show some of the challenges ahead identified for both software and fashion firms.The authors present by means of a case study the experience of an haute couture designer who used 3D digital technology \u2013 in collaboration with a recognised 3D software company \u2013 for developing his first luxury footwear collection.The enhancement of creativity and a better communication with suppliers are just some of the benefits identified in the case study from the use of 3D digital technology. In addition, challenges such as the development of a digital culture or the need for technology simplification are drawn from the case.Apart from the benefits and challenges drawn from the case study, which can be useful to practitioners in this industry, the authors also identify the collaboration through which the experience took place as an interesting practice to implement as a previous step of a digital transformation strategy.Despite the growing interest the fashion industry is showing in the use of new digital technologies, academic research on this topic is still scarce. Therefore, the case study presented in this paper adds value to the literature showing how 3D technology can help fashion from concept to consumer.', 'DOI': '10.1108/JFMM-10-2017-0114'}, {'id': 'parametric_cad', 'title': 'Parametric CAD modeling: An analysis of strategies for design reusability', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0010448516000051', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0010448516000051'], 'type': 'article', 'author': [{'family': 'Camba', 'given': 'Jorge D.'}, {'family': 'Contero', 'given': 'Manuel'}, {'family': 'Company', 'given': 'Pedro'}], 'abstract': 'CAD model quality in parametric design scenarios largely determines the level of flexibility and adaptability of a 3D model (how easy it is to alter the geometry) as well as its reusability (the ability to use existing geometry in other contexts and applications). In the context of mechanical CAD systems, the nature of the feature-based parametric modeling paradigm, which is based on parent\u2013child interdependencies between features, allows a wide selection of approaches for creating a specific model. Despite the virtually unlimited range of possible strategies for modeling a part, only a small number of them can guarantee an appropriate internal structure which results in a truly reusable CAD model. In this paper, we present an analysis of formal CAD modeling strategies and best practices for history-based parametric design: Delphi\u2019s horizontal modeling, explicit reference modeling, and resilient modeling. Aspects considered in our study include the rationale to avoid the creation of unnecessary feature interdependencies, the sequence and selection criteria for those features, and the effects of parent/child relations on model alteration. We provide a comparative evaluation of these strategies in the form of a series of experiments using three industrial CAD models with different levels of complexity. We analyze the internal structure of the models and compare their robustness and flexibility when the geometry is modified. The results reveal significant advantages of formal modeling methodologies, particularly resilient techniques, over non-structured approaches as well as the unexpected problems of the horizontal strategy in numerous modeling situations.'}, {'id': 'doi_10_1108_FS-10-2021-0202', 'title': 'Augmented and virtual reality in apparel industry: a bibliometric review and future research agenda', 'URL': 'https://doi.org/10.1108/FS-10-2021-0202', 'extra_urls': ['https://doi.org/10.1108/FS-10-2021-0202'], 'type': 'article', 'author': [{'family': 'Goel', 'given': 'Pooja'}, {'family': 'Mahadevan', 'given': 'Kala'}, {'family': 'Punjani', 'given': 'Krunal K.'}], 'abstract': 'The purpose of the present study is to synthesize the extant literature on augmented reality and virtual reality in the apparel industry using bibliometric and network visualization techniques. This paper also highlights the existing gaps in the literature and sets out the future research trajectory.This study investigated research articles in the domain of augmented and virtual reality in the apparel industry to assess global trends in research production in this area, and top contributors to research by way of authors, journals, countries and institutions. The study carried out an analysis of 239 research articles from the Scopus database during the period 1995 to 2021. The study used open-source bibliometric tools such as Biblioshiny and VOSviewer to analyze the research literature over the search period and also identify emerging research avenues.The bibliometric analysis reveals that there is significant interest in this research domain. A total of 673 authors contributed to the 239 research articles analyzed and the number of multi-author documents exceeded those by single authors. Research in this domain is led by China with the maximum number of articles in the data set followed by the USA and France. However, the USA has received the highest number of citations. Donghua University from China is the largest contributor to research in this domain with 13 articles in the data set. The keyword co-occurrence analysis indicates that \u201cvirtual reality\u201d has the most number of co-occurrences and linkages with other keywords. Other important keywords include \u201caugmented reality,\u201d \u201cvirtual try-on\u201d and \u201ccloth simulation.\u201d The network visualization exercise also revealed significant collaboration between different countries in this research domain.The gaps highlighted in this study will act as a reference point for researchers to conduct future studies in the field of augmented and virtual reality in apparel industry. Practitioners will also gain a comprehensive understanding of this research domain.This study, to the best of the authors\u2019 knowledge, is the first attempt to integrate the disjoint literature of augmented and virtual reality in apparel industry through a mapping of the intellectual structure of this research domain. The study also contributes by way of providing a snapshot of future research avenues in the knowledge domain of augmented and virtual reality in the apparel industry.', 'DOI': '10.1108/FS-10-2021-0202'}, {'id': 'doi_10_1108_RJTA-02-2025-0017', 'title': 'Empowering students through generative AI and cultural diversity in interdisciplinary fashion design education', 'URL': 'https://doi.org/10.1108/RJTA-02-2025-0017', 'extra_urls': ['https://doi.org/10.1108/RJTA-02-2025-0017'], 'type': 'article', 'author': [{'family': 'Lee', 'given': 'Jennifer'}], 'abstract': 'This study aims to examine how integrating cultural diversity and generative AI into coursework can enhance students\u2019 creativity, critical thinking and innovation, enabling them to design culturally aware products for the global market.Grounded in Stanford\u2019s design thinking framework, the proposed course designs were developed to incorporate a range of cutting-edge artificial intelligence (AI) tools. A portion of the curriculum was pilot-tested in actual college courses with 52 students to assess its effectiveness in achieving the intended learning outcomes.Integrating generative AI and cultural diversity in a fashion design course enhanced students\u2019 creativity, critical thinking, cultural awareness and teamwork. AI tools simplified research and design tasks for those with fewer technical skills, allowing them to focus on innovation, whereas cultural diversity fostered collaboration and the exchange of ideas for global markets. This approach could also apply to Science, Technology, Engineering, and Mathematics (STEM) fields like engineering, where AI supports coding and design to improve learning and develop globally relevant solutions. This study had some limits. It used a small group of students from one school, so the results may not fit all. Some AI tools produced errors or were difficult to use, highlighting the need for clarity about AI\u2019s limitations and careful attention to cultural appropriateness in generated results. Future studies should have more students, better AI tools and focus on fair use.This research integrates generative AI with cultural diversity in a fashion design course to develop product design and development skills for the global market \u2013 a combination rarely examined in existing studies. It demonstrates how AI can empower students from diverse backgrounds to collaborate creatively while honoring cultural authenticity.', 'DOI': '10.1108/RJTA-02-2025-0017'}, {'id': 'doi_10_1177_00405175251352800', 'title': 'Body data-driven garment pattern construction in digital fashion innovations: a review', 'URL': 'https://doi.org/10.1177/00405175251352800', 'extra_urls': ['https://doi.org/10.1177/00405175251352800'], 'type': 'article', 'author': [{'family': 'Lyu', 'given': 'Yingrui'}, {'family': 'Wang', 'given': 'Zhaohui'}, {'family': 'Ye', 'given': 'Qinwen'}, {'family': 'Sun', 'given': 'Yuexin'}, {'family': 'Chao', 'given': 'Jing'}], 'abstract': 'Body data are indispensable for garment pattern construction, not only influencing garment quality but also shaping the competitiveness of apparel enterprises and driving the digital transformation of the fashion industry. Traditional pattern construction practices primarily rely on a limited number of one-dimensional (1D) measurements, with less consideration given to higher-dimensional body data, such as three-dimensional (3D) shapes and four-dimensional (4D) motion information. This underutilization of advanced anthropometric data reflects the technological limitations of past eras. With the rapid advancement of digital technologies, cutting-edge anthropometry and digital tools have significantly enhanced the integration of body data into pattern construction. To comprehensively understand the utilization of body data in digital pattern construction, as well as to clarify the current technological landscape and future directions, this review provides a thorough analysis of the evolution of body data utilization and facilitators in pattern construction, pattern construction methods based on multidimensional body data (1D\u20134D), as well as the distinctions and applications of these approaches. Furthermore, this review offers a comprehensive examination of the prospects and challenges in pattern construction, considering key aspects such as dynamic pattern construction, AI-driven generation, CAD system integration, and emerging business opportunities. It underscores the scientific and innovative potential of high-dimensional 4D body data and AI-powered tools in advancing modern garment pattern construction. By highlighting these developments, this review aims to provide researchers with valuable insights, enabling them to anticipate and explore uncharted possibilities in the field.', 'DOI': '10.1177/00405175251352800'}, {'id': 'mapping_the_research', 'title': 'Mapping the Research Landscape of Sustainable Fashion: A Bibliometric Analysis', 'URL': 'https://www.mdpi.com/3042-5042/2/4/21', 'extra_urls': ['https://www.mdpi.com/3042-5042/2/4/21'], 'type': 'article', 'author': [{'family': 'Ng', 'given': 'Sai-Leung'}, {'family': 'Chen', 'given': 'Shou-Hung'}], 'abstract': 'The fashion industry, despite its global economic importance, is a major contributor to environmental degradation and social inequality. In response, sustainable fashion has emerged as a growing movement advocating ethical, ecological, and socially responsible practices. This study presents a comprehensive bibliometric analysis of 1134 peer-reviewed journal articles on sustainable fashion indexed in Scopus from 1986 to 2025. Results show an exponential rise in research output after 2015, with interdisciplinary contributions from social sciences, business, environmental science, and engineering. By applying performance analysis and science mapping techniques, the study identifies five major research themes: \u201cConsumer Behavior,\u201d \u201cDesign Ethics,\u201d \u201cCircular Economy,\u201d \u201cInnovation,\u201d and \u201cDigital Media.\u201d The geographic distribution reveals strong outputs from both developed and emerging economies. This study provides an integrative overview of the intellectual landscape of sustainable fashion and serves as a roadmap for researchers, policymakers, and practitioners who are interested in the development of sustainable fashion.'}, {'id': 'analysis_of_woven', 'title': 'Analysis of Woven Fabric Mechanical Properties in the Context of Sustainable Clothing Development Process', 'URL': 'https://www.mdpi.com/2073-4360/17/15/2013', 'extra_urls': ['https://www.mdpi.com/2073-4360/17/15/2013'], 'type': 'article', 'author': [{'family': 'Mahni\u0107 Nagli\u0107', 'given': 'Maja'}, {'family': 'Petrak', 'given': 'Slavenka'}, {'family': 'Tomljenovi\u0107', 'given': 'Antoneta'}], 'abstract': 'This paper presents research in the field of computer-aided 3D clothing design, focusing on an investigation of three methods for determining the mechanical properties of woven fabrics and their impact on 3D clothing simulations in the context of sustainable apparel development. Five mechanical parameters were analyzed: tensile elongation in the warp and weft directions, shear stiffness, bending stiffness, specific weight, and fabric thickness. These parameters were integrated into the CLO3D CAD software v.2025.0.408, using data obtained via the KES-FB system, the Fabric Kit protocol, and the AI-based tool, SEDDI Textura 2024. Simulations of women\u2019s blouse and trousers were evaluated using dynamic tests and validated by real prototypes measured with the ARAMIS optical 3D system. Results show average differences between digital and real prototype deformation data up to 6% with an 8% standard deviation, confirming the high accuracy of 3D simulations based on the determined mechanical parameters of the real fabric sample. Notably, the AI-based method demonstrated excellent simulation results compared with real garments, highlighting its potential for accessible, sustainable, and scalable fabric digitization. Presented research is entirely in line with the current trends of digitization and sustainability in the textile industry. It contributes to the advancement of efficient digital prototyping workflows and emphasizes the importance of reliable mechanical characterization for predictive garment modeling.'}, {'id': 'doi_10_1108_TECHS-03-2025-0068', 'title': 'Augmented reality and sustainable luxury: transforming fashion retail in the UAE', 'URL': 'https://doi.org/10.1108/TECHS-03-2025-0068', 'extra_urls': ['https://doi.org/10.1108/TECHS-03-2025-0068'], 'type': 'article', 'author': [{'family': 'Zoubi', 'given': 'Munif'}, {'family': 'Estaitia', 'given': 'Huda'}, {'family': 'Morshed', 'given': 'Amer'}, {'family': 'Khrais', 'given': 'Laith T.'}, {'family': 'Haikal', 'given': 'Ehab'}, {'family': 'AlSheikh', 'given': 'Maha'}], 'abstract': 'This study aims to explore the potential of augmented reality (AR) in luxury retail in the United Arab Emirates (UAE) in terms of enhancing consumer engagement, purchase confidence and sustainability awareness. It also focuses on the demographic factors that affect the adoption of AR and to what extent it may promote sustainable consumption of fashion.A quantitative method using partial least squares structural equation modeling and multi-group analysis is employed to examine AR adoption and its impact on consumer behavior. Age demographics, gender, educational attainment and income are tested as moderators of AR-based sustainable fashion decisions.AR significantly enhances consumer confidence, reduces product return rates and builds trust in sustainable fashion. Younger, tech-savvy consumers have higher engagement, while artificial intelligence (AI)-powered AR solutions, such as virtual try-ons and sustainability transparency tools, foster ethical fashion awareness. AR adoption rate disparities persist among demographics, requiring tailored engagement strategies.Policymakers, retailers and technology developers have strategic learnings from the research. It emphasizes the requirement for hybrid retail models, AI-driven personalization and regulatory intervention to combat greenwashing and establish sustainability standards.Unlike more general studies on AR in digital retail, this one provides region-specific insight on its function in sustainable luxury fashion. Emphasizing rich areas like the UAE, it describes luxury retail as unique, premium and technologically forward. Following how AR interacts with consumer behavior and sustainability in line with Sustainable Development Goals 12 and 13 helps to add to knowledge.', 'DOI': '10.1108/TECHS-03-2025-0068'}, {'id': 'digital_technologies_in', 'title': 'Digital Technologies in the Sustainable Design and Development of Textiles and Clothing\u2014A Literature Review', 'URL': 'https://www.mdpi.com/2071-1050/17/4/1371', 'extra_urls': ['https://www.mdpi.com/2071-1050/17/4/1371'], 'type': 'article', 'author': [{'family': 'Glogar', 'given': 'Martina'}, {'family': 'Petrak', 'given': 'Slavenka'}, {'family': 'Mahni\u0107 Nagli\u0107', 'given': 'Maja'}], 'abstract': 'This paper examines the digital transformation of the textile and fashion industry, focusing on the alignment with sustainability principles through the integration of Industry 4.0 technologies. The introduction highlights the urgency of transitioning from conventional production methods to innovative, digitally enabled systems that promote a circular economy and resource efficiency. The main research questions address the contribution of Industry 4.0 elements to sustainable solutions, the directions of digitalization within the apparel sector, and the significant impact of digital technologies on the achievement of sustainability goals. The theoretical framework examines sustainability in the textile industry and emphasizes the need for a green transformation facilitated by digital technologies to reduce environmental impacts. Industry 4.0 concepts, as discussed in The Concept of Industry 4.0 in the Textile and Apparel Sector, are revolutionizing production through technologies such as IoT, AI, and blockchain, enabling traceability, customization, and energy-efficient operations. The paper also explores the evolution of the fashion and apparel industry into a high-tech sector, highlighting advances such as CAD-CAM systems, digital printing, and 3D technologies that improve precision, reduce waste, and support sustainable practices. In its conclusion, the paper emphasizes the crucial role of interdisciplinary collaboration, regulatory frameworks, and investment in skills development to overcome the challenges of implementing digital and sustainable practices. It posits that a strategic embrace of digital ecosystems and Industry 4.0 technologies is essential for creating a resilient and sustainable textile industry that is aligned with environmental and societal goals.'}, {'id': 'a_survey_on', 'title': 'A survey on CAD methods in 3D garment design', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0166361510000242', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0166361510000242'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Yong-Jin'}, {'family': 'Zhang', 'given': 'Dong-Liang'}, {'family': 'Yuen', 'given': 'Matthew Ming-Fai'}], 'abstract': 'With the advance in virtual reality applications, garment industry has strived for new developments. This paper reviews state-of-the-art CAD methods in 3D garment design. A large range of techniques are selected and organized into several key modules which form the core of a 3D garment design technology platform. In each module, basic techniques are presented first. Then advanced developments are systematically discussed and commented. The selected key modules \u2013 digital human modeling, 3D garment design and modification, numerical integration of draping, 2D pattern generation, geometric details modeling, parallel computation and GPU acceleration \u2013 are discussed in turn. Major challenges and solutions that have been addressed over the years are discussed. Finally, some of the ensuing challenges in 3D garment CAD technologies are outlined.'}, {'id': 'use_of_computational', 'title': 'Use of Computational Design Technology to Automate Sew Pattern Design for Dress Garment', 'URL': '#item_19790', 'type': 'article', 'author': [{'family': 'Minaoglou', 'given': 'Prodromos'}, {'family': 'Oancea', 'given': 'Gheorghe'}, {'family': 'Gupta', 'given': 'Manoj'}, {'family': 'Kyratsis', 'given': 'Panagiotis'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'CRC Press', 'abstract': 'Computational product design is a method that uses initial parameter values with an aim to automatically complete the design process. A 2D drawing or 3D computer model can be redefined with every change in the initial values and used for fabrication. Via Computational product design the designer does not manually complete the necessary geometry but uses programming languages and incorporates algorithms within a computer aided design application. The present chapter highlights the use of computational product design in designing and fabricating a garment. The algorithm produced, fully automates the design of the sew pattern and presents the final product. The only input needed is the dimensional definition of the user\u2019s body in the application and the rest of the process is carried out automatically. Dimensioning is carried out either by manual insertion or by using a 3D scanned digital model. Several downstream applications support the whole process i.e. 3D digital visualization facility of the product, definition of the code needed for manufacturing.'}, {'id': 'deep_shape', 'title': 'Three-dimensional deep shape optimization with a limited dataset', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0952197625015064', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0952197625015064'], 'type': 'article', 'author': [{'family': 'Kwon', 'given': 'Yongmin'}, {'family': 'Kang', 'given': 'Namwoo'}], 'abstract': 'Generative models have attracted considerable attention for their ability to produce novel shapes. However, their application in mechanical design remains constrained due to the limited size and variability of available datasets. This study proposes a deep learning-based optimization framework specifically tailored for shape optimization with limited datasets, leveraging positional encoding and a Lipschitz regularization term to robustly learn geometric characteristics and maintain a meaningful latent space. Through extensive experiments, the proposed approach demonstrates robustness, generalizability and effectiveness in addressing typical limitations of conventional optimization frameworks. The validity of the methodology is confirmed through multi-objective shape optimization experiments conducted on diverse three-dimensional datasets, including wheels and cars, highlighting the model\u2019s versatility in producing practical and high-quality design outcomes even under data-constrained conditions.'}, {'id': 'doi_10_1007_s42452-025-06833-5', 'title': 'Generative AI and CAD automation for diverse and novel mechanical component designs under data constraints', 'URL': 'https://doi.org/10.1007/s42452-025-06833-5', 'extra_urls': ['https://doi.org/10.1007/s42452-025-06833-5'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Kun-Ying'}, {'family': 'Huang', 'given': 'Cheng-Kai'}, {'family': 'Chen', 'given': 'Qing-Wei'}, {'family': 'Zhang', 'given': 'Hsuan-Cheng'}, {'family': 'Tang', 'given': 'Tsann-Tay'}], 'abstract': 'The efficient design of complex engineering components in data-constrained environments presents significant challenges to traditional methodologies. Existing deep learning-based generative design approaches often depend on large datasets, which limits their applicability in data-scarce contexts. Additionally, conventional image generation techniques often produce impractical designs, requiring extensive manual validation by engineers. This paper presents a novel method that integrates stable diffusion-based Generative AI with computer-aided design automation to minimize data requirements while maintaining high design accuracy. Through the implementation of low-rank adaptation fine-tuning, the proposed method reduces the required training data from over 16,600 to approximately 200 samples. This significant reduction in data ensures efficiency in data-scarce environments while ensuring compliance with stringent mechanical and aesthetic design requirements. Experimental results demonstrate a consistent 90% accuracy in generating feasible designs that meet these constraints. This paper also explores the relevant background and technological developments that support these experimental results, offering context for the challenges and solutions addressed. Furthermore, the automated validation system further enhances efficiency by filtering out all infeasible designs, thereby eliminating the need for manual expert validation. Experimental results demonstrate a 30% reduction in the overall design process, from initial concept to prototyping preparation, compared to traditional workflows, confirming the method\u2019s effectiveness in real-world applications. This research provides a scalable solution to the challenges of generative design in data-limited settings and contributes to advancing intelligent design systems across various engineering sectors.', 'DOI': '10.1007/s42452-025-06833-5'}, {'id': 'towards_agentic_smart', 'title': 'Towards agentic smart design: An industrial large model-driven human-in-the-loop agentic workflow for geometric modelling', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1568494625012335', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1568494625012335'], 'type': 'article', 'author': [{'family': 'Zheng', 'given': 'Keyou'}, {'family': 'Zhong', 'given': 'Yuanwei'}, {'family': 'Su', 'given': 'Xuyang'}, {'family': 'Leng', 'given': 'Jiewu'}, {'family': 'Liu', 'given': 'Qiang'}, {'family': 'Chen', 'given': 'Xin'}], 'abstract': 'Agentic workflows, powered by Industrial Large Models (ILMs), represent a significant development emphasizing collaboration between humans and intelligent systems. This paper presents a structured perspective on the role of agentic workflows for smart design and manufacturing, grounded in integrating ILMs. We define an agentic workflow as a labeled Activity-on-Vertex (AOV) graph, where each node represents a functionally closed subtask and is executed by an ILM-based agent, a human operator, or an automated system. This formalism supports analyzable, modular, and hybrid execution, offering a foundation for modeling complex, mixed-initiative processes in manufacturing environments. To support real-world deployment, we introduce a set of reusable agentic workflow patterns that describe how ILM agents perceive, plan, and act in coordination with other components. Besides, a proof-of-concept case study illustrates the practical application of the human-in-the-loop framework through the agentic generation of CAD models. The study covers task decomposition, workflow implementation, and benchmarking, providing evidence for the feasibility of agentic workflows. Building upon these findings, this work contributes to advancing the development and application of agentic workflows in smart manufacturing contexts.'}, {'id': 'diffusion_smart', 'title': 'Diffusion model-driven smart design and manufacturing: Prospects and challenges', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0278612525001864', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0278612525001864'], 'type': 'article', 'author': [{'family': 'Leng', 'given': 'Jiewu'}, {'family': 'Su', 'given': 'Xuyang'}, {'family': 'Liu', 'given': 'Zean'}, {'family': 'Zhou', 'given': 'Lianhong'}, {'family': 'Chen', 'given': 'Chong'}, {'family': 'Guo', 'given': 'Xin'}, {'family': 'Wang', 'given': 'Yiwei'}, {'family': 'Wang', 'given': 'Ru'}, {'family': 'Zhang', 'given': 'Chao'}, {'family': 'Liu', 'given': 'Qiang'}, {'family': 'Chen', 'given': 'Xin'}, {'family': 'Shen', 'given': 'Weiming'}, {'family': 'Wang', 'given': 'Lihui'}], 'abstract': 'Artificial Intelligence-Generated Content (AIGC), particularly diffusion models as a key component of Generative Artificial Intelligence (GenAI), are transforming smart design and manufacturing in the interplay of Industry 4.0 and Industry 5.0. This paper analyzes the applications of diffusion models in smart design and manufacturing, focusing on three key pillars: diffusion-driven generative design, smart control, and fault diagnosis. Diffusion models enhance manufacturing system flexibility, resilience, and sustainability through their applications as generative design engines, intelligent controllers for adaptive manufacturing processes, and predictive tools for fault diagnosis. This study provides a comprehensive review of the current state of diffusion model-driven smart design and manufacturing. It analyzes key challenges such as model efficiency, data dependency, and system integration, while providing a constructive perspective on potential solutions. This paper also integrates Industry 5.0 considerations by connecting the applications and technical solutions to the core values of human-centricity, sustainability, and resilience. It concludes by emphasizing the necessity of continuous refinement of diffusion models and interdisciplinary research to integrate them into smart design and manufacturing systems further, fostering a more human-centric, resilient, and sustainable industry.'}, {'id': 'controllable_diffusion', 'title': 'Diffusion-CAD: Controllable Diffusion Model for Generating Computer-Aided Design Models', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10857640', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10857640'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Aijia'}, {'family': 'Jia', 'given': 'Weiqiang'}, {'family': 'Zou', 'given': 'Qiang'}, {'family': 'Feng', 'given': 'Yixiong'}, {'family': 'Wei', 'given': 'Xiaoxiang'}, {'family': 'Zhang', 'given': 'Ye'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Generative methods for creating computer-aided design (CAD) models have gained significant attention over the past two years. However, existing methods lack fine-grained control over the generated CAD models, making it difficult to manage details such as model dimensions and the relative structure of components. To address these limitations, this study introduces Diffusion-CAD, a diffusion-based generative approach that outputs CAD construction sequences. Diffusion-CAD iteratively denoises Gaussian noise into continuous CAD vectors, which are then transformed into discrete CAD sequences. We designed classifier-free and classifier-guided methods to control the distribution of Gaussian noise, CAD sequences, and noisy CAD vectors separately, thereby achieving a variety of fine-grained control tasks. Extensive experiments demonstrated the superior performance and novel capabilities of the proposed method for conditional generation tasks.'}, {'id': 'doi_10_1007_s11704-024-40417-7', 'title': 'CAD-NeRF: learning NeRFs from uncalibrated few-view images by CAD model retrieval', 'URL': 'https://doi.org/10.1007/s11704-024-40417-7', 'extra_urls': ['https://doi.org/10.1007/s11704-024-40417-7'], 'type': 'article', 'author': [{'family': 'Wen', 'given': 'Xin'}, {'family': 'Zhu', 'given': 'Xuening'}, {'family': 'Yi', 'given': 'Renjiao'}, {'family': 'Wang', 'given': 'Zhifeng'}, {'family': 'Zhu', 'given': 'Chenyang'}, {'family': 'Xu', 'given': 'Kai'}], 'abstract': 'Reconstructing from multi-view images is a longstanding problem in 3D vision, where neural radiance fields (NeRFs) have shown great potential and get realistic rendered images of novel views. Currently, most NeRF methods either require accurate camera poses or a large number of input images, or even both. Reconstructing NeRF from few-view images without poses is challenging and highly ill-posed. To address this problem, we propose CAD-NeRF, a method reconstructed from less than 10 images without any known poses. Specifically, we build a mini library of several CAD models from ShapeNet and render them from many random views. Given sparse-view input images, we run a model and pose retrieval from the library, to get a model with similar shapes, serving as the density supervision and pose initializations. Here we propose a multi-view pose retrieval method to avoid pose conflicts among views, which is a new and unseen problem in uncalibrated NeRF methods. Then, the geometry of the object is trained by the CAD guidance. The deformation of the density field and camera poses are optimized jointly. Then texture and density are trained and fine-tuned as well. All training phases are in self-supervised manners. Comprehensive evaluations of synthetic and real images show that CAD-NeRF successfully learns accurate densities with a large deformation from retrieved CAD models, showing the generalization abilities.', 'DOI': '10.1007/s11704-024-40417-7'}, {'id': 'reinforcement_parametric', 'title': 'Reinforcement learning-based parametric CAD models reconstruction from 2D orthographic drawings', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0010448525000867', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0010448525000867'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Chao'}, {'family': 'Polette', 'given': 'Arnaud'}, {'family': 'Pinqui\xe9', 'given': 'Romain'}, {'family': 'Iida', 'given': 'Mirai'}, {'family': 'Charnace', 'given': 'Henri De'}, {'family': 'Pernot', 'given': 'Jean-Philippe'}], 'abstract': 'This paper introduces a reinforcement learning-based approach for reconstructing 3D parametric CAD models from 2D orthographic drawings. First, the 2D drawings are parsed to extract their constituent vertices and edges. These entities are subsequently converted into a newly defined loop-path representation, generating a list of loop-path pairs along with their associated parameters and candidates for the reconstruction process. The core of the approach is a DQN-based agent trained to select the sequences of loop-path pairs, which are then used to reconstruct the parametric CAD models in any CAD modeler. A parallel environment leveraging a neural network is proposed to accelerate the training process and eliminate the need for calls to an external CAD modeler to compute the rewards, which would otherwise break the training loop. The proposed approach reconstructs 3D parametric CAD models in less than a second, and it outperforms existing methods against traditional metrics on two datasets. The reconstructed CAD models are fully editable and can be easily modified for downstream applications. While the loop-path representation supports extrusion, revolution and sweep operations, experimental results on the two selected datasets highlight the superiority of the RL-based approach in handling sketch-extrude modeling operations.'}, {'id': 'overview_of_personalized', 'title': 'Overview of Personalized 3d Human Body Modeling Technology for Garment CAD', 'URL': 'https://jceim.org/index.php/ojs/article/view/95', 'extra_urls': ['https://jceim.org/index.php/ojs/article/view/95'], 'type': 'article', 'author': [{'family': 'Cai', 'given': 'Xiaoyao'}], 'abstract': '3D human models serve as the foundation for 3D garment design, while personalized human modeling has emerged as a significant research focus in computer graphics and computer vision. Over time, numerous implementation approaches have been developed. This paper reviews and summarizes recent advancements in personalized human modeling, categorizing them into scanning-based methods, standard model deformation techniques, template matching approaches, image-based model reconstruction, and wireframe-assisted deep learning methods. The study analyzes the strengths and limitations of existing methodologies while outlining future development trends.'}, {'id': 'cad_3d', 'title': 'CAD Model-Based 3D Scene Reconstruction', 'URL': 'https://www.repository.cam.ac.uk/handle/1810/379710', 'extra_urls': ['https://www.repository.cam.ac.uk/handle/1810/379710'], 'type': 'article', 'author': [{'family': 'Langer', 'given': 'Florian'}], 'abstract': 'Accurate scene reconstruction from an image or a video is essential for various applications in robotics and augmented reality. One common method involves retrieving the best-matching CAD model for each observed object from a database and aligning it with the corresponding input. This technique yields a CAD model-based 3D scene representation that is compact, contains realistic shapes, and is well-suited for a wide range of downstream tasks. This thesis addresses the challenges of deriving such a representation by answering four key research questions. First, we investigate how to retrieve and align a CAD model from a database for an object detected in an image, assuming that an exact match exists for the detected object. We show that retrieving CAD model renders from an embedding space and predicting cross-domain keypoint correspondences between the render and the input image enables accurate alignments. Next, we tackle the problem of adapting CAD models when their shapes do not perfectly match the observed objects. Here we show that the established keypoint correspondences can not only be used to align the CAD model but also to modify its shape, and thereby better represent a wider range of object shapes. The third challenge involves accurately aligning retrieved CAD models when discrep- ancies exist between their shapes and the observed objects. To this end, we introduce a learned render-and-compare framework for CAD model-based scene reconstruction. In this framework, a neural network receives dual input streams \u2014 information about the observed image and the CAD model rendered in an initial pose \u2014 and is trained to iteratively refine the object\u2019s pose. This method yields significantly more accurate alignments compared to existing approaches and improves further by jointly predicting alignments for multiple objects, leveraging regularities in the natural arrangement of objects in indoor scenes. Finally, we focus on achieving efficient, real-time CAD model-based scene reconstruction. For this purpose, we train a neural network to predict CAD model retrieval and alignment simultaneously and jointly for all objects present in a scene. This method significantly reduces the inference time by a factor of 50 compared to existing techniques. It can process both input point clouds and RGB videos, enabling real-time performance at 10 frames per second.'}, {'id': 'a', 'title': 'OrthoCAD-322K: A cross-modal approach for retrieving 3D CAD models from orthographic views using a graph-based framework on a developed large-scale dataset', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0097849325001980', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0097849325001980'], 'type': 'article', 'author': [{'family': 'Mahajan', 'given': 'Swapnil Nagnath'}, {'family': 'M.', 'given': 'Karthik Krishna'}, {'family': 'Muthuganapathy', 'given': 'Ramanathan'}], 'abstract': 'Despite the widespread adoption of 3D CAD systems, 2D orthographic drawings remain integral to engineering workflows. However, millions of legacy drawings lack corresponding 3D models, hindering their integration into modern simulation, manufacturing, and digital twin systems. Existing methods for 2D to 3D CAD retrieval often fall short of meeting the structural precision required for engineering-grade drawings. We propose a cross-modal retrieval framework that aligns vector-based 2D DXF (Drawing Exchange Format) views with 3D CAD models using contrastive learning. Our architecture integrates a Graphormer-based encoder for 2D input and a PointNet-based encoder for 3D CAD models. We introduce a novel proximity-based spatial encoding to enhance structural precision and robustness across varying view configurations. Using the filtered subset (\u223c283K) of the newly developed large-scale dataset OrthoCAD-322K, extensive ablation and comparison studies demonstrate the robustness and generalization of the model in different input conditions and architectures. Source code is available at https://github.com/Swapnil-Mahajan-MS/OrthoCAD-322K.'}, {'id': 'llms_driven_fusion', 'title': 'LLMs driven fusion AI-AD system for mechanical design: From understanding to generation', 'URL': 'https://www.sciencedirect.com/science/article/pii/S147403462500638X', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S147403462500638X'], 'type': 'article', 'author': [{'family': 'Xiaorui', 'given': 'Liu'}, {'family': 'Yuhao', 'given': 'Zhang'}, {'family': 'Leiqi', 'given': 'Wang'}, {'family': 'Lexiang', 'given': 'Gu'}, {'family': 'Yaning', 'given': 'Xu'}, {'family': 'Ke', 'given': 'Zheng'}, {'family': 'Qianqian', 'given': 'Cai'}, {'family': 'Gang', 'given': 'Zhou'}], 'abstract': 'The intelligentization of mechanical design CAD systems is still remarkably slow despite decades of development. Recently, the rapid advancement of LLMs offers new opportunities for enhancing CAD intelligence. However, the inherent illusions and black-box nature of LLMs compromise the reliability of design outcomes. To enhance the intelligence of mechanical design and integrate LLMs into CAD, this paper develops a novel fusion AI-AD (Artificial Intelligence-Aided Design) architecture that adheres to the concept of \u201cFrom Understanding to Generation\u201d. With LLMs as the intelligent core, integrating components and modules such as knowledge processing, cloud data exchange and secondary development of SolidWorks (SW), this architecture realizes the full-process intelligence from understanding of mechanical design knowledge to the generation of 3D models. In terms of knowledge understanding, a new approach which is distinct from the past is proposed that data is processed based on the categories of knowledge representation to eliminate the illusions of LLMs. On the generation side, workflows based on the chain-of-thought mechanism are developed, and the granularity of each workflow is refined to overcome the illusions of LLMs, ensuring the accuracy and precision of the generated model. Based on the understood knowledge and the natural language requirements from users, the design content is automatically generated and modeling files (VBA type) are automatically output to SW where the model is automatically completed. Compared with traditional programmatic CAD systems, AI-AD demonstrates its strong intelligent capabilities in mechanical part design, multi-agent collaborative design, and autonomous design. The AI-AD architecture uses NLP as an interactive interface and advocates a low-code model development, significantly reducing the technical obstacles for developers to promote the development of the intelligent CAD industry.'}, {'id': 'the', 'title': 'The status, evolution, and future challenges of multimodal large language models (LLMs) in parametric CAD', 'URL': 'https://www.sciencedirect.com/science/article/pii/S095741742501142X', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S095741742501142X'], 'type': 'article', 'author': [{'family': 'Zhou', 'given': 'Jiwei'}, {'family': 'Camba', 'given': 'Jorge D.'}], 'abstract': 'Parametric Computer-Aided Design (CAD) systems are fundamental tools in mechanical and product design to facilitate the precise generation of complex geometries. However, their steep learning curve restricts accessibility to non-experts, hindering collaboration and creativity in engineering workflows. Recent breakthroughs in Artificial Intelligence (AI), especially Large Language Models (LLMs), are providing new opportunities to redefine parametric CAD workflows. By enabling natural language and multimodal interactions, LLMs can reduce technical obstacles and allow users to intuitively convey design intents and requirements. This work critically examines the intersection between LLMs and parametric CAD modeling, emphasizing key advancements in automating tasks such as 2D sketching, 3D model generation, and design optimization. It also discusses progress in natural language interface development and identifies current challenges. Although LLMs exhibit the capacity to improve productivity and design accessibility, obstacles remain in understanding design intent and context, managing intricate geometries, optimizing model training with diverse datasets and benchmarking frameworks, guaranteeing interoperability, scalability, and security within CAD systems, and expanding industrial applications. Through a thorough analysis, this review identifies essential areas for future research to enable the practical integration of LLMs and parametric CAD modeling. The results highlight the potential of LLMs to simplify design processes, stimulate creativity, and reshape engineering design practices across applications in mechanical product development.'}, {'id': 'doi_10_1007_s10462-025-11290-y', 'title': 'From concept to manufacturing: evaluating vision-language models for engineering design', 'URL': 'https://doi.org/10.1007/s10462-025-11290-y', 'extra_urls': ['https://doi.org/10.1007/s10462-025-11290-y'], 'type': 'article', 'author': [{'family': 'Picard', 'given': 'Cyril'}, {'family': 'Edwards', 'given': 'Kristen M.'}, {'family': 'Doris', 'given': 'Anna C.'}, {'family': 'Man', 'given': 'Brandon'}, {'family': 'Giannone', 'given': 'Giorgio'}, {'family': 'Alam', 'given': 'Md Ferdous'}, {'family': 'Ahmed', 'given': 'Faez'}], 'abstract': 'Engineering design is undergoing a transformative shift with the advent of AI, marking a new era in how we approach product, system, and service planning. Large language models have demonstrated impressive capabilities in enabling this shift. Yet, with text as their only input modality, they cannot leverage the large body of visual artifacts that engineers have used for centuries and are accustomed to. This gap is addressed with the release of multimodal vision-language models (VLMs), such as GPT-4V, enabling AI to impact many more types of tasks. Our work presents a comprehensive evaluation of VLMs across a spectrum of engineering design tasks, categorized into four main areas: Conceptual Design, System-Level and Detailed Design, Manufacturing and Inspection, and Engineering Education Tasks. Specifically in this paper, we assess the capabilities of two VLMs, GPT-4V and LLaVA 1.6 34B, in design tasks such as sketch similarity analysis, CAD generation, topology optimization, manufacturability assessment, and engineering textbook problems. Through this structured evaluation, we not only explore VLMs\u2019 proficiency in handling complex design challenges but also identify their limitations in complex engineering design applications. Our research establishes a foundation for future assessments of vision language models. It also contributes a set of benchmark testing datasets, with more than 1000 queries, for ongoing advancements and applications in this field.', 'DOI': '10.1007/s10462-025-11290-y'}, {'id': 'synthesising_cad', 'title': 'CAD-GPT: Synthesising CAD Construction Sequence with Spatial Reasoning-Enhanced Multimodal LLMs', 'URL': 'https://ojs.aaai.org/index.php/AAAI/article/view/32849', 'extra_urls': ['https://ojs.aaai.org/index.php/AAAI/article/view/32849'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Siyu'}, {'family': 'Chen', 'given': 'Cailian'}, {'family': 'Le', 'given': 'Xinyi'}, {'family': 'Xu', 'given': 'Qimin'}, {'family': 'Xu', 'given': 'Lei'}, {'family': 'Zhang', 'given': 'Yanzhou'}, {'family': 'Yang', 'given': 'Jie'}], 'abstract': 'Computer-aided design (CAD) significantly enhances the efficiency, accuracy, and innovation of design processes by enabling precise 2D and 3D modeling, extensive analysis, and optimization. Existing methods for creating CAD models rely on latent vectors or point clouds, which are difficult to obtain, and storage costs are substantial. Recent advances in Multimodal Large Language Models (MLLMs) have inspired researchers to use natural language instructions and images for CAD model construction. However, these models still struggle with inferring accurate 3D spatial location and orientation, leading to inaccuracies in determining the spatial 3D starting points and extrusion directions for constructing geometries. This work introduces CAD-GPT, a CAD synthesis method with spatial reasoning-enhanced MLLM that takes either a single image or a textual description as input. To achieve precise spatial inference, our approach introduces a 3D Modeling Spatial Mechanism. This method maps 3D spatial positions and 3D sketch plane rotation angles into a 1D linguistic feature space using a specialized spatial unfolding mechanism, while discretizing 2D sketch coordinates into an appropriate planar space to enable precise determination of spatial starting position, sketch orientation, and 2D sketch coordinate translations. Extensive experiments demonstrate that CAD-GPT consistently outperforms existing state-of-the-art methods in CAD model synthesis, both quantitatively and qualitatively.'}, {'id': 'a_multimodal', 'title': 'CADInstruct: A multimodal dataset for natural language-guided CAD program synthesis', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0010448525000879', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0010448525000879'], 'type': 'article', 'author': [{'family': 'Lv', 'given': 'Chaofan'}, {'family': 'Bao', 'given': 'Jinsong'}], 'abstract': 'While large language models (LLMs) have demonstrated remarkable success in general-purpose code generation, their application in computer-aided design (CAD) program synthesis remains constrained by the scarcity of high-quality natural language-annotated datasets. To address this challenge, we propose CADInstruct, a novel approach aimed at constructing a multimodal CAD instruction dataset to enhance the CAD program synthesis capabilities of LLMs. First, we introduce a parametric modification module for modeling sequences, which extracts geometric constraints and critical dimensions from sketches, transforming CAD construction sequences into design-intent-oriented instructions. Second, we incorporate a shape semantic recognition module that leverages model names and visually enriched rendered views to generate precise shape descriptions using multimodal large models, enabling accurate semantic representation of complex geometries. Lastly, a modeling instruction semantic alignment module utilizes the extracted shape descriptions and modeling instructions to generate hierarchical natural language descriptions, encompassing geometric forms and detailed modeling steps, ensuring consistency between textual descriptions and CAD instructions. We fine-tuned the Qwen2.5-Coder-7B model using the CADInstruct dataset to evaluate the effectiveness of this framework. Experimental results demonstrated its capability to significantly enhance CAD program synthesis. The code and dataset will be made publicly available at https://github.com/dxlcf/CADInstruct.'}, {'id': 'revisiting_cad_model', 'title': 'Revisiting CAD Model Generation by Learning Raster Sketch', 'URL': 'https://ojs.aaai.org/index.php/AAAI/article/view/32515', 'extra_urls': ['https://ojs.aaai.org/index.php/AAAI/article/view/32515'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Pu'}, {'family': 'Zhang', 'given': 'Wenhao'}, {'family': 'Guo', 'given': 'Jianwei'}, {'family': 'Chen', 'given': 'Jinglu'}, {'family': 'Yan', 'given': 'Dong-Ming'}], 'abstract': 'The integration of deep generative networks into generating Computer-Aided Design (CAD) models has garnered increasing attention over recent years. Traditional methods often rely on discrete sequences of parametric line/curve segments to represent sketches. Differently, we introduce RECAD, a novel framework that generates Raster sketches and 3D Extrusions for CAD models. Representing sketches as raster images offers several advantages over discrete sequences: 1) it breaks the limitations on the types and numbers of lines/curves, providing enhanced geometric representation capabilities; 2) it enables interpolation within a continuous latent space; and 3) it allows for more intuitive user control over the output. Technically, RECAD employs two diffusion networks: the first network generates extrusion boxes conditioned on the number and types of extrusions, while the second network produces sketch images conditioned on these extrusion boxes. By combining these two networks, RECAD effectively generates sketch-and-extrude CAD models, offering a more robust and intuitive approach to CAD model generation. Experimental results indicate that RECAD achieves strong performance in unconditional generation, while also demonstrating effectiveness in conditional generation and output editing.'}, {'id': 'pose_estimation', 'title': '6-DoF Pose Estimation from Single RGB Image and CAD Model Retrieval Using Feature Similarity Measurement.', 'URL': 'https://openurl.ebsco.com/contentitem/doi:10.3390%2Fapp15031501?sid=ebsco:plink:crawler&amp;id=ebsco:doi:10.3390%2Fapp15031501', 'extra_urls': ['https://openurl.ebsco.com/contentitem/doi:10.3390%2Fapp15031501?sid=ebsco:plink:crawler&amp;id=ebsco:doi:10.3390%2Fapp15031501'], 'type': 'article', 'author': [{'family': 'Park', 'given': 'Sieun'}, {'family': 'Jeong', 'given': 'Won-Je'}, {'family': 'Manawadu', 'given': 'Mayura'}, {'family': 'Park', 'given': 'Soon-Yong'}], 'abstract': "Discover this 2025 paper in Applied Sciences (2076-3417) by Park, Sieun; Jeong, Won-Je; Manawadu, Mayura; et. al. focusing on: WEB search engines; SINGLE-degree-of-freedom systems; COMPUTER vision; IMAGE retrieval; DEEP learning Abstract: This study presents six degrees of freedom (6-DoF) pose estimation of an object from a single RGB image and retrieval of the matching CAD model by measuring the similarity between RGB and CAD rendering images. The 6-DoF pose estimation of an RGB object is one of the important techniques in 3D computer vision. However, in addition to 6-DoF pose estimation, retrieval and alignment of the matching CAD model with the RGB object should be performed for various industrial applications such as eXtended Reality (XR), Augmented Reality (AR), robot's pick and place, and so on. This paper addresses 6-DoF pose estimation and CAD model retrieval problems simultaneously and quantitatively analyzes how much the 6-DoF pose estimation affects the CAD model retrieval performance. This study consists of two main steps. The first step is 6-DoF pose estimation based on the PoseContrast network. We enhance the structure of PoseConstrast by adding variance uncertainty weight and feature attention modules. The second step is the retrieval of the matching CAD model by an image similarity measurement between the CAD rendering and the RGB object. In our experiments, we used 2000 RGB images collected from Google and Bing search engines and 100 CAD models from ShapeNetCore. The Pascal3D dataset is used to train the pose estimation network and DELF features are used for the similarity measurement. Comprehensive ablation studies about the proposed network show the quantitative performance analysis with respect to the baseline model. Experimental results show that the pose estimation performance has a positive correlation with the CAD retrieval performance."}, {'id': 'toward_ai', 'title': 'Toward Knowledge-Guided AI for Inverse Design in Manufacturing: A Perspective on Domain, Physics, and Human\u2013AI Synergy', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1002/aidi.202500107', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1002/aidi.202500107'], 'type': 'article', 'author': [{'family': 'Lee', 'given': 'Hugon'}, {'family': 'Moon', 'given': 'Hyeonbin'}, {'family': 'Lee', 'given': 'Junhyeong'}, {'family': 'Ryu', 'given': 'Seunghwa'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Artificial intelligence (AI) is reshaping inverse design in manufacturing, enabling high-performance discovery in materials, products, and processes. However, purely data-driven approaches often struggle in realistic manufacturing settings characterized by sparse data, high-dimensional design spaces, and complex constraints. This perspective proposes an integrated framework built on three complementary pillars: domain knowledge to establish physically meaningful objectives and constraints while removing variables with limited relevance, physics-informed machine learning to enhance generalization under limited or biased data, and large language model-based interfaces to support intuitive, human\u2013centered interaction. Using injection molding as an illustrative example, we demonstrate how these components can operate in practice and conclude by highlighting key challenges for applying such approaches in realistic manufacturing environments.'}, {'id': 'automated_bim_generation', 'title': 'Automated BIM generation for MEP systems from CAD data using multi-drawing graph integration', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0926580525005825', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0926580525005825'], 'type': 'article', 'author': [{'family': 'Zhao', 'given': 'Qian'}, {'family': 'Shi', 'given': 'Hao'}, {'family': 'Zhou', 'given': 'Liangchen'}, {'family': 'Lv', 'given': 'Guonian'}], 'abstract': 'Building information modeling (BIM) of mechanical, electrical, and plumbing (MEP) systems is essential for building facility management. Computer-aided-design (CAD) data are detailed sources for MEP BIM modeling. However, existing methods for MEP BIM are complex, leading to heavy reliance on manual intervention. This paper addresses this challenge by proposing an approach for generating MEP BIM models from CAD data. Graph structures are introduced to represent MEP systems, and multiple graph structures converted from CAD drawings are utilized to match pipeline components and aggregate dispersed information across various drawings. Based on the integrated pipeline graph, missing information is inferred and completed considering the relationships between components, ensuring detailed and accurate modeling results. Experiments on an actual factory case demonstrate the reliability and efficiency of this approach. This paper contributes to the MEP BIM theory by providing a perspective on interpreting MEP CAD data and a robust technical route of CAD-to-BIM conversion for MEP systems.'}, {'id': 'from_2d_cad', 'title': 'From 2D CAD Drawings to 3D Parametric Models: A Vision-Language Approach', 'URL': 'https://ojs.aaai.org/index.php/AAAI/article/view/32858', 'extra_urls': ['https://ojs.aaai.org/index.php/AAAI/article/view/32858'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Xilin'}, {'family': 'Zheng', 'given': 'Jia'}, {'family': 'Hu', 'given': 'Yuanchao'}, {'family': 'Zhu', 'given': 'Hao'}, {'family': 'Yu', 'given': 'Qian'}, {'family': 'Zhou', 'given': 'Zihan'}], 'abstract': 'In this paper, we present CAD2Program, a new method for reconstructing 3D parametric models from 2D CAD drawings. Our proposed method is inspired by recent successes in vision-language models (VLMs), and departs from traditional methods which rely on task-specific data representations and/or algorithms. Specifically, on the input side, we simply treat the 2D CAD drawing as a raster image, regardless of its original format, and encode the image with a standard ViT model. We show that such an encoding scheme achieves competitive performance against existing methods that operate on vector-graphics inputs, while imposing substantially fewer restrictions on the 2D drawings. On the output side, our method auto-regressively predicts a general-purpose language describing 3D parametric models in text form. Compared to other sequence modeling methods for CAD which use domain-specific sequence representations with fixed-size slots, our text-based representation is more flexible, and can be easily extended to arbitrary geometric entities and semantic or functional properties. Experimental results on a large-scale dataset of cabinet models demonstrate the effectiveness of our method.'}, {'id': 'a_lightweight', 'title': 'GuideCAD: A Lightweight Multimodal Framework for 3D CAD Model Generation via Prefix Embedding', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11146789', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11146789'], 'type': 'article', 'author': [{'family': 'Kim', 'given': 'Minseong'}, {'family': 'Park', 'given': 'Jinyeong'}, {'family': 'Park', 'given': 'Sungho'}, {'family': 'Kim', 'given': 'Jibum'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Multi-modal approaches used for 3D CAD generation require substantial computational resources, necessitating efficient training. To address this, we propose GuideCAD, which leverages semantically rich visual-textual representations having only a small number of trainable parameters to generate 3D CAD models. Specifically, GuideCAD uses a mapping network that converts image embeddings into prefix embeddings, enabling a pretrained large language model to integrate visual and textual information. As a result, a transformer-based decoder predicts the construction sequence using the visual-textual embeddings in order to generate the 3D CAD model. For experimental evaluation, we construct a new dataset, referred to as GuideCAD, which consists of text-image pairs. Each pair includes a text prompt that represents a 3D CAD construction sequence and its corresponding 3D CAD image. Our experimental results show that GuideCAD generates comparably high-quality 3D CAD models while using approximately four times fewer parameters and achieving twice the training efficiency compared to fine-tuning approaches. We have released the source code and dataset for our method at: https://github.com/mskimS2/GuideCAD'}, {'id': 'adaptive_method_of', 'title': 'Adaptive method of designing a swimsuit bra', 'URL': 'https://c-bulletin.com.ua/en/journals/tom-18-1-2025/adaptivny-metod-konstruyuvannya-byustgaltera-dlya-kupalnika', 'extra_urls': ['https://c-bulletin.com.ua/en/journals/tom-18-1-2025/adaptivny-metod-konstruyuvannya-byustgaltera-dlya-kupalnika'], 'type': 'article', 'author': [{'family': 'Slavinska', 'given': 'Alla'}, {'family': 'Matiukh', 'given': 'Serhii'}, {'family': 'Mytsa', 'given': 'Viktoriia'}, {'family': 'Dombrovska', 'given': '\u041eksana'}, {'family': 'Syrotenko', 'given': 'Oksana'}], 'abstract': 'The relevance of the research lies in the need to develop accurate and effective methods for designing swimwear bras, considering the elastic properties of modern knitted fabrics, which will enhance the comfort and quality of the products. The purpose of the study was to develop a method of adjusting the size of the bra cup to the amount of stretching using the method of geodetic parallels. The study employed methods of mathematical modelling for the development and optimisation of swimsuit bra cups design and analysed the mechanical properties of knitted materials. The study identified representative groups of elastic knitted fabrics based on the analysis of their tensile characteristics. Two primary groups of fabrics were identified based on their fibrous composition: the first group consisted of polyamide threads blended with elastane, while the second group comprised polyester threads combined with elastane. Anthropomorphic factors affecting the inaccuracies in the unfolding of the hard surface of the cup have been identified. Recommendations have been developed for transforming the rigid unfolding into a soft shell of moulded cup parts, considering discrete elongations of knitted materials. The soft-shell construction method was based on recalculating the main dimensions of the cup, taking into account the deformation coefficients of the materials. The effectiveness of the proposed method was confirmed by comparing the deviation&amp;nbsp;&amp;nbsp;areas of the moulded cup sweeps of the basic design. The deviation of the area of 3.56% indicated the compliance of the rigid sweep with the breast surface. Mathematical models of modification methods for four types of bra cup separation have been developed. The practical value lies in the use of an effective method of designing swimwear bras that ensures precise fit and comfort by considering the elastic properties of knitted materials'}, {'id': 'doi_10_1177_14780771251353791', 'title': 'From NURBS to neural networks: Efficient geometry encoding for generative AI in architectural design', 'URL': 'https://doi.org/10.1177/14780771251353791', 'extra_urls': ['https://doi.org/10.1177/14780771251353791'], 'type': 'article', 'author': [{'family': 'Sebestyen', 'given': 'Adam'}, {'family': 'Wiltsche', 'given': 'Albert'}, {'family': 'Stavric', 'given': 'Milena'}, {'family': '\xd6zdenizci', 'given': 'Ozan'}], 'abstract': 'The existing 3D representations for AI models, such as meshes, voxels, signed distance functions, and point clouds, are not compatible with architectural design workflows that rely on NURBS geometry, which is mainly used in CAD programs. \u200bThese formats lead to large datasets, high computational costs, and loss of geometric precision, limiting further usability in CAD software. This research introduces a novel methodology for encoding NURBS geometries into compact, tensor-based NumPy data for training generative AI models and vice versa. Our methodology involves the design of comparative experiments, the comparison of NURBS tensor representations with other 3D representations, and the use of reconstruction accuracy as a key metric to evaluate performance. \u200bCustom components for the Rhinoceros 3D parametric environment Grasshopper were developed enabling bidirectional conversion between NURBS geometry and NumPy tensors. These components are being released as a Grasshopper plugin under the name Wiener Dog as a free download. \u200bOur approach maintains geometric accuracy, reduces data size, and integrates seamlessly with existing deep learning libraries. \u200bThe proposed methodology was tested on datasets of helicoid surfaces and lofted polysurfaces, demonstrating high reconstruction accuracy and generative potential. The ultimate aim is to build an AI tool that aids in exploring the great variety of geometric forms for architectural design.', 'DOI': '10.1177/14780771251353791'}, {'id': 'implicit_relevance_inference', 'title': 'Implicit relevance inference for assembly CAD model retrieval based on design correlation representation', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0097849325000615', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0097849325000615'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Yixuan'}, {'family': 'Ji', 'given': 'Baoning'}, {'family': 'Zhang', 'given': 'Jie'}, {'family': 'Pang', 'given': 'Jiazhen'}, {'family': 'Li', 'given': 'Weibo'}], 'abstract': 'Assembly retrieval is a crucial technology for leveraging the extensive design knowledge embedded in CAD product instances. Current methods predominantly employ pairwise similarity measurements, which treat each product model as an isolated entity and overlook the intricate design correlations that reveal high-level design development relationships. To enhance the comprehension of product design correlations within retrieval systems, this paper introduces a novel method for implicit relevance inference in assembly retrieval based on design correlation. We define a part co-occurring relationship to capture the design correlations among assemblies by clustering parts based on shape similarity. At a higher level, all assemblies in the database are constructed as a multiple correlation network based on hypergraph, where the hyperedges represent the part co-occurring relationships. For a given query assembly, the implicit relevance between the query and other assemblies can be calculated by network structure inference. The problem is solved by using a random walk algorithm on the assembly hypergraph network. Comprehensive experiments have shown the effectiveness of the proposed assembly retrieval approach. The proposed method can be seen as an extension of existing pairwise similarity retrieval by further considering assembly relevance, which shows it has versatility and can enhance the effectiveness of existing pairwise similarity retrieval methods.'}, {'id': 'harnessing_unsupervised_learning', 'title': 'Harnessing unsupervised learning for retrieving CAD assembly models from public datasets', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1474034625000758', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1474034625000758'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Yixuan'}, {'family': 'Zhang', 'given': 'Jie'}, {'family': 'Pang', 'given': 'Jiazhen'}, {'family': 'Yao', 'given': 'Ya'}], 'abstract': 'Retrieving assembly models from public datasets can yield enriched outcomes and broaden the spectrum of insights. However, public datasets often present unique challenges, such as variance in quality and granularity of assembly models, lack of standardized methods for organizing and labeling, which hinder efficient and accurate retrieval. To address these issues, this paper presents a robust two-step retrieval method tailored for CAD assembly models from public datasets. The first phase utilizes hierarchical clustering in an unsupervised learning framework to systematically organize CAD assembly models. Each assembly model is represented by a feature vector that encapsulates geometrical and topological features derived from its Boundary Representation (B-rep), and reflects hierarchical relationships among parts and components. These feature vectors serve as the basis for systematic indexing via hierarchical clustering, grouping models based on similarity measurement. Each cluster\u2019s centroid, representing the collective feature vector, facilitates efficient and targeted retrieval. In the second phase, the query model is directly compared to cluster centroids, enabling rapid identification of similar assembly collections. To enhance precision within identified clusters, we introduce a fine-grained retrieval technique that integrates Optimal Subsequence Bijection (OSB) with Maximum Mean Discrepancy (MMD). Evaluations on a heterogeneous dataset demonstrate that our method not only streamlines dataset organization but also effectively addresses quality variations, significantly improving retrieval efficiency across extensive collections.'}, {'id': 'geometric_deep_learning', 'title': 'Geometric Deep Learning for Computer-Aided Design: A Survey', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11075586', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11075586'], 'type': 'article', 'author': [{'family': 'Heidari', 'given': 'Negar'}, {'family': 'Iosifidis', 'given': 'Alexandros'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Geometric Deep Learning techniques have become a transformative force in the field of Computer-Aided Design (CAD), and have the potential to revolutionize how designers and engineers approach and enhance the design process. By harnessing the power of machine learning-based methods, CAD designers can optimize their workflows, save time and effort while making better informed decisions, and create designs that are both innovative and practical. The ability to process the CAD designs represented by geometric data and to analyze their encoded features enables the identification of similarities among diverse CAD models, the proposition of alternative designs and enhancements, and even the generation of novel design alternatives. This survey offers a comprehensive overview of learning-based methods in computer-aided design across various categories, including similarity analysis and retrieval, 2D and 3D CAD model synthesis, and CAD generation from point clouds, and single/multi-view images. Additionally, it provides a complete list of benchmark datasets and their characteristics, along with open-source codes that have propelled research in this domain. The final discussion delves into the challenges prevalent in this field, followed by potential future research directions in this rapidly evolving field.'}, {'id': 'doi_10_1115_1_4069276', 'title': 'GenCAD-Three-Dimensional: Computer-Aided Design Program Generation Using Multimodal Latent Space Alignment and Synthetic Dataset Balancing', 'URL': 'https://doi.org/10.1115/1.4069276', 'extra_urls': ['https://doi.org/10.1115/1.4069276'], 'type': 'article', 'author': [{'family': 'Yu', 'given': 'Nomi'}, {'family': 'Ferdous Alam', 'given': 'Md'}, {'family': 'Hart', 'given': 'A. John'}, {'family': 'Ahmed', 'given': 'Faez'}], 'abstract': 'Computer-aided design (CAD) programs, structured as parametric sequences of commands that compile into precise 3D geometries, are fundamental to accurate and efficient engineering design processes. Generating these programs from nonparametric data such as point clouds and meshes remains a crucial yet challenging task, typically requiring extensive manual intervention. Current deep generative models aimed at automating CAD generation are significantly limited by imbalanced and insufficiently large datasets, particularly those lacking representation for complex CAD programs. To address this, we introduce GenCAD-3D, a multimodal generative framework utilizing contrastive learning for aligning latent embeddings between CAD and geometric encoders, combined with latent diffusion models for CAD sequence generation and retrieval. In addition, we present SynthBal, a synthetic data augmentation strategy specifically designed to balance and expand datasets, notably enhancing representation of complex CAD geometries. Our experiments show that SynthBal significantly boosts reconstruction accuracy, reduces the generation of invalid CAD models, and markedly improves performance on high-complexity geometries, surpassing existing benchmarks. These advancements hold substantial implications for streamlining reverse engineering and enhancing automation in engineering design. We will publicly release our datasets and code, including a set of 51 3D-printed and laser-scanned parts on our project site.', 'DOI': '10.1115/1.4069276'}, {'id': 'doi_10_1145_3730842', 'title': 'HoLa: B-Rep Generation using a Holistic Latent Representation', 'URL': 'https://doi.org/10.1145/3730842', 'extra_urls': ['https://doi.org/10.1145/3730842'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Yilin'}, {'family': 'Xu', 'given': 'Duoteng'}, {'family': 'Yu', 'given': 'Xingyao'}, {'family': 'Xu', 'given': 'Xiang'}, {'family': 'Cohen-Or', 'given': 'Daniel'}, {'family': 'Zhang', 'given': 'Hao'}, {'family': 'Huang', 'given': 'Hui'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'We introduce a novel representation for learning and generating Computer-Aided Design (CAD) models in the form of boundary representations (B-Reps). Our representation unifies the continuous geometric properties of B-Rep primitives in different orders (e.g., surfaces and curves) and their discrete topological relations in a holistic latent (HoLa) space. This is based on the simple observation that the topological connection between two surfaces is intrinsically tied to the geometry of their intersecting curve. Such a prior allows us to reformulate topology learning in B-Reps as a geometric reconstruction problem in Euclidean space. Specifically, we eliminate the presence of curves, vertices, and all the topological connections in the latent space by learning to distinguish and derive curve geometries from a pair of surface primitives via a neural intersection network. To this end, our holistic latent space is only defined on surfaces but encodes a full B-Rep model, including the geometry of surfaces, curves, vertices, and their topological relations. Our compact and holistic latent space facilitates the design of a first diffusion-based generator to take on a large variety of inputs including point clouds, single/multi-view images, 2D sketches, and text prompts. Our method significantly reduces ambiguities, redundancies, and incoherences among the generated B-Rep primitives, as well as training complexities inherent in prior multi-step B-Rep learning pipelines, while achieving greatly improved validity rate over current state of the art: 82% vs. \u224850%.', 'DOI': '10.1145/3730842'}, {'id': 'doi_10_1177_00405175251360399', 'title': 'Transformative effect of 3D sampling technology for the ready-made garment industry: A review', 'URL': 'https://doi.org/10.1177/00405175251360399', 'extra_urls': ['https://doi.org/10.1177/00405175251360399'], 'type': 'article', 'author': [{'family': 'Baria', 'given': 'Badhon'}, {'family': 'Shahid', 'given': 'Md Abdus'}, {'family': 'Misra', 'given': 'Aditi'}, {'family': 'Hoque', 'given': 'Mohammad Bellal'}, {'family': 'Rahman', 'given': 'Md Mostafizur'}, {'family': 'Hossain', 'given': 'Md Delwar'}, {'family': 'Das', 'given': 'Dip'}], 'abstract': 'The increasing demand for sustainable and efficient manufacturing in the ready-made garment (RMG) industry has driven interest in digital solutions. This review article explores the effect of 3D sampling technology (i.e., CLO 3D, Optitex, Lectra, and Browzwear) over traditional physical sampling on reducing material waste, improving efficiency, and reducing costs. This study examines the role of digital sampling in addressing critical challenges within the garment manufacturing process, specifically focusing on efficiency, sustainability, and lead time. In the RMG sector of Bangladesh, these technologies have great potential due to their proven effectiveness in enhancing design precision and optimizing production workflows. However, challenges such as expensive setup costs, a lack of realistic materials, and training needs continue to be major problems. The current article offers a thorough review of the economic and environmental effects linked to 3D sampling. It also highlights key obstacles to adopting this technology and provides strategic recommendations aimed at industry 4.0 stakeholders.', 'DOI': '10.1177/00405175251360399'}, {'id': 'doi_10_1177_00405175251339102', 'title': 'Application of 3D digital technology in design practices within the circular fashion system: Implications for sustainability', 'URL': 'https://doi.org/10.1177/00405175251339102', 'extra_urls': ['https://doi.org/10.1177/00405175251339102'], 'type': 'article', 'author': [{'family': 'Liang', 'given': 'Jiaqi'}, {'family': 'Dong', 'given': 'Wentong'}, {'family': 'Suh', 'given': 'Seunghee'}], 'abstract': 'This study provides a systematic review of the application of 3D digital technologies (3DDT) in fashion design practice. The aim is to analyze how 3DDT alters traditional design processes and its effect on sustainability within the circular fashion system (CFS), exploring its core role and offering theoretical support and practical guidance for decision-makers and stakeholders in the fashion industry. The study addresses two key questions. 1. How does 3DDT apply to change design practices processes and enhance sustainability? 2. Within the CFS, what key challenges can 3DDT address to advance sustainability? Through a review of 30 peer-reviewed studies published between 2011 and 2024, the research highlights how 3DDT facilitating the advancement of different CFS prototypes by facilitating design\u2013production integration, diverse applications of sustainable materials, optimizing resource utilization, improving design accuracy, and enhancing communication. It demonstrates 3DDT\u2019s unique ability to break down barriers between the barrier between abstract thinking and visualized feedback, bridging the gap between creative visions, actual production materials and techniques, and consumption realities, thus fostering collaboration and communication among participants such designers, manufacturers, and consumers. By, 3DDT enhances the sustainable effect of design practices within the CFS, providing strong technical support for sustainable design\u2013production decision-making in the fashion industry.', 'DOI': '10.1177/00405175251339102'}, {'id': 'amazon_1138021016', 'title': 'Craft of Use: Post-Growth Fashion', 'URL': 'https://www.amazon.de/-/en/Craft-Use-Post-Growth-Kate-Fletcher/dp/1138021016', 'extra_urls': ['https://www.amazon.de/-/en/Craft-Use-Post-Growth-Kate-Fletcher/dp/1138021016'], 'type': 'book', 'author': [{'family': 'Fletcher', 'given': 'Kate'}], 'issued': {'date-parts': [[2016]]}, 'publisher': 'Routledge', 'abstract': "This book explores the 'craft of use', the cultivated, ordinary and ingenious ideas and practices that promote satisfying and resourceful use of garments, presenting them as an alternative, dynamic, experiential frame with which to articulate and foster sustainability in the fashion sector.Here Kate Fletcher provides a broad imagination of sustainability in fashion that gives attention to tending and wearing garments, and favors their use as much as their creation. She offers a diversified view of fashion beyond the market and the market's purpose and reveals fashion provision and expression in a world not dependent on continuous consumption.Framing design and use as a single whole, the book uncovers a more contingent and time-dependent role for design in sustainability, recognizing that garments, while sold as a product, are lived as a process. Drawing from stories and portrait photography that document the ways in which members of the public from across three continents use their clothes, and the work of seven international design teams seeking to amplify these use practices, Craft of Use presents a changed social narrative for fashion, borne out of ideas of satisfaction and interdependence, of action, knowledge and human agency, that glimpses fashion post-growth."}, {'id': 'and', 'title': 'France\u2019s Anti-waste and Circular Economy Law', 'URL': 'https://www.ellenmacarthurfoundation.org/circular-examples/frances-anti-waste-and-circular-economy-law', 'extra_urls': ['https://www.ellenmacarthurfoundation.org/circular-examples/frances-anti-waste-and-circular-economy-law'], 'type': 'webpage', 'author': [{'family': 'Ellen MacArthur Foundation'}], 'abstract': 'France is shaping a system-wide transition towards a circular economy with an ambitious law'}, {'id': 'doi_10_1145_3731205', 'title': 'Offset Geometric Contact', 'URL': 'https://doi.org/10.1145/3731205', 'extra_urls': ['https://doi.org/10.1145/3731205'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Anka He'}, {'family': 'Hsu', 'given': 'Jerry'}, {'family': 'Liu', 'given': 'Ziheng'}, {'family': 'Macklin', 'given': 'Miles'}, {'family': 'Yang', 'given': 'Yin'}, {'family': 'Yuksel', 'given': 'Cem'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1145/3731205'}, {'id': 'reconstructing_inner', 'title': 'ClothingTwin: Reconstructing Inner and Outer Layers of Clothing Using 3D Gaussian Splatting', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.70240', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.70240'], 'type': 'article', 'author': [{'family': 'Jung', 'given': 'Munkyung'}, {'family': 'Lee', 'given': 'Dohae'}, {'family': 'Lee', 'given': 'In-Kwon'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'We introduce ClothingTwin, a novel end-to-end framework for reconstructing 3D digital twins of clothing that capture both the outer and inner fabric \u2014without the need for manual mannequin removal. Traditional 2D \u201cghost mannequin\u201d photography techniques remove the mannequin and composite partial inner textures to create images in which the garment appears as if it were worn by a transparent model. However, extending such method to photorealistic 3D Gaussian Splatting (3DGS) is far more challenging. Achieving consistent inner-layer compositing across the large sets of images used for 3DGS optimization quickly becomes impractical if done manually. To address these issues, ClothingTwin introduces three key innovations. First, a specialized image acquisition protocol captures two sets of images for each garment: one worn normally on the mannequin (outer layer exposed) and one worn inside-out (inner layer exposed). This eliminates the need to painstakingly edit out mannequins in thousands of images and provides full coverage of all fabric surfaces. Second, we employ a mesh-guided 3DGS reconstruction for each layer and leverage Non-Rigid Iterative Closest Point (ICP) to align outer and inner point-clouds despite distinct geometries. Third, our enhanced rendering pipeline\u2014featuring mesh-guided back-face culling, back-to-front alpha blending, and recalculated spherical harmonic angles\u2014ensures photorealistic visualization of the combined outer and inner layers without inter-layer artifacts. Experimental evaluations on various garments show that ClothingTwin outperforms conventional 3DGS-based methods, and our ablation study validates the effectiveness of each proposed component.'}, {'id': 'summoning', 'title': 'We\u2019re summoning ghosts, not building animals', 'URL': 'https://www.youtube.com/watch?v=lXUZvyajciY', 'extra_urls': ['https://www.youtube.com/watch?v=lXUZvyajciY'], 'type': 'article', 'abstract': 'The Andrej Karpathy episode. During this interview, Andrej explains why reinforcement learning is terrible (but everything else is much worse), why AGI will just blend into the previous ~2.5 centuries of 2% GDP growth, why self driving took so long to crack, and what he sees as the future of education. It was a pleasure chatting with him.'}, {'id': 'managing_large', 'title': 'LLMOps: Managing Large Language Models in Production', 'URL': 'urn:isbn:978-1-0981-5420-2', 'type': 'book', 'author': [{'family': 'Aryan', 'given': 'Abi'}, {'family': 'Meyer', 'given': 'Lucas'}], 'issued': {'date-parts': [[2025]]}, 'publisher': "O'Reilly Media", 'abstract': "Here's the thing about large language models: they don't play by the old rules. Traditional MLOps completely falls apart when you're dealing with GenAI. The model hallucinates, security assumptions crumble, monitoring breaks, and agents can't operate. Suddenly you're in uncharted territory. That's exactly why LLMOps has emerged as its own discipline.   LLMOps: Managing Large Language Models in Production is your guide to actually running these systems when real users and real money are on the line. This book isn't about building cool demos. It's about keeping LLM systems running smoothly in the real world.Navigate the new roles and processes that LLM operations require Monitor LLM performance when traditional metrics don't tell the whole story Set up evaluations, governance, and security audits that actually matter for GenAI Wrangle the operational mess of agents, RAG systems, and evolving prompts Scale infrastructure without burning through your compute budget"}, {'id': 'doi_10_1016_j_bcra_2024_100266', 'title': 'Blockchain-driven innovation in fashion supply chain contractual party evaluations as an emerging collaboration model', 'URL': 'https://doi.org/10.1016/j.bcra.2024.100266', 'extra_urls': ['https://doi.org/10.1016/j.bcra.2024.100266'], 'type': 'article', 'author': [{'family': 'Qiao', 'given': 'Minhao'}, {'family': 'Chen', 'given': 'Xuanchang'}, {'family': 'Zhou', 'given': 'Yangping'}, {'family': 'Mok', 'given': 'P.Y.'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1016/j.bcra.2024.100266'}, {'id': 'doi_10_1080_21681015_2016_1172124', 'title': 'Product design and business model strategies for a circular economy', 'URL': 'https://doi.org/10.1080/21681015.2016.1172124', 'extra_urls': ['https://doi.org/10.1080/21681015.2016.1172124'], 'type': 'article', 'author': [{'family': 'Bocken', 'given': 'Nancy M. P.'}, {'family': 'de Pauw', 'given': 'Ingrid'}, {'family': 'Bakker', 'given': 'Conny'}, {'family': 'van der Grinten', 'given': 'Bram'}], 'issued': {'date-parts': [[2016]]}, 'DOI': '10.1080/21681015.2016.1172124'}, {'id': 'doi_10_1016_j_buildenv_2023_110432', 'title': "Modular construction's capacity to reduce embodied carbon emissions in California's housing sector", 'URL': 'https://doi.org/10.1016/j.buildenv.2023.110432', 'extra_urls': ['https://doi.org/10.1016/j.buildenv.2023.110432'], 'type': 'article', 'author': [{'family': 'Greer', 'given': 'Fiona'}, {'family': 'Horvath', 'given': 'Arpad'}], 'issued': {'date-parts': [[2023]]}, 'DOI': '10.1016/j.buildenv.2023.110432'}, {'id': 'doi_10_1007_s10551-023-05569-9', 'title': 'Exercising the \u201cRight to Repair\u201d: A Customer\u2019s Perspective', 'URL': 'https://doi.org/10.1007/s10551-023-05569-9', 'extra_urls': ['https://doi.org/10.1007/s10551-023-05569-9'], 'type': 'article', 'author': [{'family': 'Marikyan', 'given': 'Davit'}, {'family': 'Papagiannidis', 'given': 'Savvas'}], 'issued': {'date-parts': [[2023]]}, 'DOI': '10.1007/s10551-023-05569-9'}, {'id': 'doi_10_1016_j_joi_2020_101094', 'title': 'The pace of artificial intelligence innovations: Speed, talent, and trial-and-error', 'URL': 'https://doi.org/10.1016/j.joi.2020.101094', 'extra_urls': ['https://doi.org/10.1016/j.joi.2020.101094'], 'type': 'article', 'author': [{'family': 'Tang', 'given': 'Xuli'}, {'family': 'Li', 'given': 'Xin'}, {'family': 'Ding', 'given': 'Ying'}, {'family': 'Song', 'given': 'Min'}, {'family': 'Bu', 'given': 'Yi'}], 'issued': {'date-parts': [[2020]]}, 'DOI': '10.1016/j.joi.2020.101094'}, {'id': 'doi_10_1145_3706598_3714001', 'title': 'Exploring Assumptions about Sustainability: Towards a Constructive Framework for Action in Sustainable HCI', 'URL': 'https://doi.org/10.1145/3706598.3714001', 'extra_urls': ['https://doi.org/10.1145/3706598.3714001'], 'type': 'article', 'author': [{'family': 'Laurell Thorslund', 'given': 'Minna'}, {'family': 'Leifler', 'given': 'Ola'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1145/3706598.3714001'}, {'id': 'doi_10_1145_3706598_3713663', 'title': 'Sustainability, Development, and Human\u2013Computer Interaction', 'URL': 'https://doi.org/10.1145/3706598.3713663', 'extra_urls': ['https://doi.org/10.1145/3706598.3713663'], 'type': 'article', 'author': [{'family': 'Sharma', 'given': 'Vishal'}, {'family': 'Kumar', 'given': 'Neha'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1145/3706598.3713663'}, {'id': 'doi_10_1007_978-3-031-84628-1_12', 'title': 'The Role of Platform Economies in Contributing to Innovation and Entrepreneurship Within Digital Ecosystems: A Systematic Literature Review', 'URL': 'https://doi.org/10.1007/978-3-031-84628-1_12', 'extra_urls': ['https://doi.org/10.1007/978-3-031-84628-1_12'], 'type': 'article', 'author': [{'family': 'Ayob', 'given': 'Muhammad'}, {'family': 'Hattingh', 'given': 'Marie'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1007/978-3-031-84628-1_12'}, {'id': 'doi_10_3390_su9010039', 'title': 'The Effect of Elite Polarization: A Comparative Perspective on How Party Elites Influence Attitudes and Behavior on Climate Change in the European Union', 'URL': 'https://doi.org/10.3390/su9010039', 'extra_urls': ['https://doi.org/10.3390/su9010039'], 'type': 'article', 'author': [{'family': 'Sohlberg', 'given': 'Jacob'}], 'issued': {'date-parts': [[2016]]}, 'DOI': '10.3390/su9010039'}, {'id': 'doi_10_1038_s43017-020-0039-9', 'title': 'The environmental price of fast fashion', 'URL': 'https://doi.org/10.1038/s43017-020-0039-9', 'extra_urls': ['https://doi.org/10.1038/s43017-020-0039-9'], 'type': 'article', 'author': [{'family': 'Niinim\xe4ki', 'given': 'Kirsi'}, {'family': 'Peters', 'given': 'Greg'}, {'family': 'Dahlbo', 'given': 'Helena'}, {'family': 'Perry', 'given': 'Patsy'}, {'family': 'Rissanen', 'given': 'Timo'}, {'family': 'Gwilt', 'given': 'Alison'}], 'issued': {'date-parts': [[2020]]}, 'DOI': '10.1038/s43017-020-0039-9'}, {'id': 'doi_10_1007_s11280-024-01276-1', 'title': 'When large language models meet personalization: perspectives of challenges and opportunities', 'URL': 'https://doi.org/10.1007/s11280-024-01276-1', 'extra_urls': ['https://doi.org/10.1007/s11280-024-01276-1'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Jin'}, {'family': 'Liu', 'given': 'Zheng'}, {'family': 'Huang', 'given': 'Xu'}, {'family': 'Wu', 'given': 'Chenwang'}, {'family': 'Liu', 'given': 'Qi'}, {'family': 'Jiang', 'given': 'Gangwei'}, {'family': 'Pu', 'given': 'Yuanhao'}, {'family': 'Lei', 'given': 'Yuxuan'}, {'family': 'Chen', 'given': 'Xiaolong'}, {'family': 'Wang', 'given': 'Xingmei'}, {'family': 'Zheng', 'given': 'Kai'}, {'family': 'Lian', 'given': 'Defu'}, {'family': 'Chen', 'given': 'Enhong'}], 'abstract': 'The advent of large language models marks a revolutionary breakthrough in artificial intelligence. With the unprecedented scale of training and model parameters, the capability of large language models has been dramatically improved, leading to human-like performances in understanding, language synthesizing, common-sense reasoning, etc. Such a major leap forward in general AI capacity will fundamentally change the pattern of how personalization is conducted. For one thing, it will reform the way of interaction between humans and personalization systems. Instead of being a passive medium of information filtering, like conventional recommender systems and search engines, large language models present the foundation for active user engagement. On top of such a new foundation, users\u2019 requests can be proactively explored, and users\u2019 required information can be delivered in a natural, interactable, and explainable way. For another thing, it will also considerably expand the scope of personalization, making it grow from the sole function of collecting personalized information to the compound function of providing personalized services. By leveraging large language models as a general-purpose interface, the personalization systems may compile user\u2019s requests into plans, calls the functions of external tools (e.g., search engines, calculators, service APIs, etc.) to execute the plans, and integrate the tools\u2019 outputs to complete the end-to-end personalization tasks. Today, large language models are still being rapidly developed, whereas the application in personalization is largely unexplored. Therefore, we consider it to be right the time to review the challenges in personalization and the opportunities to address them with large language models. In particular, we dedicate this perspective paper to the discussion of the following aspects: the development and challenges for the existing personalization system, the newly emerged capabilities of large language models, and the potential ways of making use of large language models for personalization.', 'DOI': '10.1007/s11280-024-01276-1'}, {'id': 'doi_10_1177_23794607251347020', 'title': 'The governance &amp; behavioral challenges of generative artificial intelligence\u2019s hypercustomization capabilities', 'URL': 'https://doi.org/10.1177/23794607251347020', 'extra_urls': ['https://doi.org/10.1177/23794607251347020'], 'type': 'article', 'author': [{'family': 'Abels', 'given': 'Christoph M.'}, {'family': 'Lopez-Lopez', 'given': 'Ezequiel'}, {'family': 'Burton', 'given': 'Jason W.'}, {'family': 'Holford', 'given': 'Dawn L.'}, {'family': 'Brinkmann', 'given': 'Levin'}, {'family': 'Herzog', 'given': 'Stefan M.'}, {'family': 'Lewandowsky', 'given': 'Stephan'}], 'abstract': 'Generative artificial intelligence (GenAI) is changing human\u2013machine interactions and the broader information ecosystem. Much as social media algorithms personalize online experiences, GenAI applications can align with user preferences to customize the way individuals interact with information. However, through training, fine-tuning, and prompting, GenAI applications can introduce a new level of customization: hypercustomization. By dynamically tailoring responses to an individual\u2019s explicit and implicit preferences, hypercustomization can reinforce biases, false beliefs, or misconceptions. As a result, it can heighten significant societal challenges, such as the spread of misinformation and political and social polarization. In this article, we explore the risks associated with hypercustomization and the governance and behavioral challenges that might impede effective risk mitigation. These challenges include a lack of transparency in GenAI applications, opacity of the nature of their interactions with users, users\u2019 overreliance on these systems, and the inefficacy of warning messages. We also provide recommendations for overcoming these challenges.', 'DOI': '10.1177/23794607251347020'}, {'id': 'data_harmonization_and', 'title': 'Data harmonization and federated learning for multi-cohort dementia research using the OMOP common data model: A Netherlands consortium of dementia cohorts case study', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1532046424000790', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1532046424000790'], 'type': 'article', 'author': [{'family': 'Mateus', 'given': 'Pedro'}, {'family': 'Moonen', 'given': 'Justine'}, {'family': 'Beran', 'given': 'Magdalena'}, {'family': 'Jaarsma', 'given': 'Eva'}, {'family': 'van der Landen', 'given': 'Sophie M.'}, {'family': 'Heuvelink', 'given': 'Joost'}, {'family': 'Birhanu', 'given': 'Mahlet'}, {'family': 'Harms', 'given': 'Alexander G. J.'}, {'family': 'Bron', 'given': 'Esther'}, {'family': 'Wolters', 'given': 'Frank J.'}, {'family': 'Cats', 'given': 'Davy'}, {'family': 'Mei', 'given': 'Hailiang'}, {'family': 'Oomens', 'given': 'Julie'}, {'family': 'Jansen', 'given': 'Willemijn'}, {'family': 'Schram', 'given': 'Miranda T.'}, {'family': 'Dekker', 'given': 'Andre'}, {'family': 'Bermejo', 'given': 'Inigo'}], 'abstract': 'Background\nEstablishing collaborations between cohort studies has been fundamental for progress in health research. However, such collaborations are hampered by heterogeneous data representations across cohorts and legal constraints to data sharing. The first arises from a lack of consensus in standards of data collection and representation across cohort studies and is usually tackled by applying data harmonization processes. The second is increasingly important due to raised awareness for privacy protection and stricter regulations, such as the GDPR. Federated learning has emerged as a privacy-preserving alternative to transferring data between institutions through analyzing data in a decentralized manner.\nMethods\nIn this study, we set up a federated learning infrastructure for a consortium of nine Dutch cohorts with appropriate data available to the etiology of dementia, including an extract, transform, and load (ETL) pipeline for data harmonization. Additionally, we assessed the challenges of transforming and standardizing cohort data using the Observational Medical Outcomes Partnership (OMOP) common data model (CDM) and evaluated our tool in one of the cohorts employing federated algorithms.\nResults\nWe successfully applied our ETL tool and observed a complete coverage of the cohorts\u2019 data by the OMOP CDM. The OMOP CDM facilitated the data representation and standardization, but we identified limitations for cohort-specific data fields and in the scope of the vocabularies available. Specific challenges arise in a multi-cohort federated collaboration due to technical constraints in local environments, data heterogeneity, and lack of direct access to the data.\nConclusion\nIn this article, we describe the solutions to these challenges and limitations encountered in our study. Our study shows the potential of federated learning as a privacy-preserving solution for multi-cohort studies that enhance reproducibility and reuse of both data and analyses.'}, {'id': 'federated_graph_neural', 'title': 'Federated graph neural network for privacy-preserved supply chain data sharing', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1568494624012493', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1568494624012493'], 'type': 'article', 'author': [{'family': 'Tang', 'given': 'Xiaochuan'}, {'family': 'Wang', 'given': 'Yu'}, {'family': 'Liu', 'given': 'Xin'}, {'family': 'Yuan', 'given': 'Xiaojun'}, {'family': 'Fan', 'given': 'Chao'}, {'family': 'Hu', 'given': 'Yanmei'}, {'family': 'Miao', 'given': 'Qiang'}], 'abstract': 'Machine learning plays an increasingly important role in supply chain management. Due to privacy and security concerns, enterprises are reluctant to share their raw data, which leads to missing links in supply chains. To address privacy issue and promote data sharing in supply chain, we propose a new federated graph neural network named Isomorphic Federated Graph Neural Network (IFGNN) for supply chain data sharing. IFGNN consists of a server and multiple clients. The server is a lightweight parameter server with an efficient parameter updating algorithm. A client is assigned to each node in the supply chain network. Every supplier client is linked to its first-order neighbors, which means they have supply\u2013demand relationship. The topology of the input network is identical to that of the supplier clients. Experimental results on a newly collected vehicle supply chain dataset show that the performance of IFGNN is close to its centralized counterpart. This work demonstrates that it is feasible to protect supply chain data privacy without a significant loss of prediction accuracy. Federated learning provides a new solution for promoting data sharing and collaborative machine learning in supply chain.'}, {'id': 'arxiv_2505.10468', 'title': 'AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges', 'URL': 'http://arxiv.org/abs/2505.10468', 'extra_urls': ['http://arxiv.org/abs/2505.10468'], 'type': 'article', 'author': [{'family': 'Sapkota', 'given': 'Ranjan'}, {'family': 'Roumeliotis', 'given': 'Konstantinos I.'}, {'family': 'Karkee', 'given': 'Manoj'}], 'abstract': 'This review critically distinguishes between AI Agents and Agentic AI, offering a structured, conceptual taxonomy, application mapping, and analysis of opportunities and challenges to clarify their divergent design philosophies and capabilities. We begin by outlining the search strategy and foundational definitions, characterizing AI Agents as modular systems driven and enabled by LLMs and LIMs for task-specific automation. Generative AI is positioned as a precursor providing the foundation, with AI agents advancing through tool integration, prompt engineering, and reasoning enhancements. We then characterize Agentic AI systems, which, in contrast to AI Agents, represent a paradigm shift marked by multi-agent collaboration, dynamic task decomposition, persistent memory, and coordinated autonomy. Through a chronological evaluation of architectural evolution, operational mechanisms, interaction styles, and autonomy levels, we present a comparative analysis across both AI agents and agentic AI paradigms. Application domains enabled by AI Agents such as customer support, scheduling, and data summarization are then contrasted with Agentic AI deployments in research automation, robotic coordination, and medical decision support. We further examine unique challenges in each paradigm including hallucination, brittleness, emergent behavior, and coordination failure, and propose targeted solutions such as ReAct loops, retrieval-augmented generation (RAG), automation coordination layers, and causal modeling. This work aims to provide a roadmap for developing robust, scalable, and explainable AI-driven systems.'}, {'id': 'doi_10_1145_3686803', 'title': 'Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap', 'URL': 'https://doi.org/10.1145/3686803', 'extra_urls': ['https://doi.org/10.1145/3686803'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Jialong'}, {'family': 'Zhang', 'given': 'Mingyue'}, {'family': 'Li', 'given': 'Nianyu'}, {'family': 'Weyns', 'given': 'Danny'}, {'family': 'Jin', 'given': 'Zhi'}, {'family': 'Tei', 'given': 'Kenji'}], 'issued': {'date-parts': [[2024]]}, 'abstract': 'Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this article aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI\u2019s within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.\u2020', 'DOI': '10.1145/3686803'}, {'id': 'doi_10_1007_s10458-020-09489-0', 'title': 'Enabling scalable and fault-tolerant multi-agent systems by utilizing cloud-native computing', 'URL': 'https://doi.org/10.1007/s10458-020-09489-0', 'extra_urls': ['https://doi.org/10.1007/s10458-020-09489-0'], 'type': 'article', 'author': [{'family': 'D\xe4hling', 'given': 'Stefan'}, {'family': 'Razik', 'given': 'Lukas'}, {'family': 'Monti', 'given': 'Antonello'}], 'abstract': 'Multi-agent systems (MAS) represent a distributed computing paradigm well suited to tackle today\u2019s challenges in the field of the Internet of Things (IoT). Both share many similarities such as the interconnection of distributed devices and their cooperation. The combination of MAS and IoT would allow the transfer of the experience gained in MAS research to the broader range of IoT applications. The key enabler for utilizing MAS in the IoT is the ability to build large-scale and fault-tolerant MASs since IoT concepts comprise possibly thousands or even millions of devices. However, well known multi-agent platforms (MAP), e.\xa0g., Java Agent DE-velopment Framework (JADE), are not able to deal with these challenges. To this aim, we present a cloud-native Multi-Agent Platform (cloneMAP) as a modern MAP based on cloud-computing techniques to enable scalability and fault-tolerance. A microservice architecture is used to implement it in a distributed way utilizing the open-source container orchestration system Kubernetes. Thereby, bottlenecks and single-points of failure are conceptually avoided. A comparison with JADE via relevant performance metrics indicates the massively improved scalability. Furthermore, the implementation of a large-scale use case verifies cloneMAP\u2019s suitability for IoT applications. This leads to the conclusion that cloneMAP extends the range of possible MAS applications and enables the integration with IoT concepts.', 'DOI': '10.1007/s10458-020-09489-0'}, {'id': 'doi_10_1186_s40537-025-01099-5', 'title': 'Adapting security and decentralized knowledge enhancement in federated learning using blockchain technology: literature review', 'URL': 'https://doi.org/10.1186/s40537-025-01099-5', 'extra_urls': ['https://doi.org/10.1186/s40537-025-01099-5'], 'type': 'article', 'author': [{'family': 'Orabi', 'given': 'Menna Mamdouh'}, {'family': 'Emam', 'given': 'Osama'}, {'family': 'Fahmy', 'given': 'Hanan'}], 'abstract': 'Federated Learning (FL) is a promising form of distributed machine learning that preserves privacy by training models locally without sharing raw data. While FL ensures data privacy through collaborative learning, it faces several critical challenges. These include vulnerabilities to reverse engineering, risks to model architecture privacy, susceptibility to model poisoning attacks, threats to data integrity, and the high costs associated with communication and connectivity. This paper presents a comprehensive review of FL, categorizing data partitioning formats into horizontal federated learning, vertical federated learning, and federated transfer learning. Furthermore, it explores the integration of FL with blockchain, leveraging blockchain\u2019s decentralized nature to enhance FL\u2019s security, reliability, and performance. The study reviews existing FL models, identifying key challenges such as privacy risks, communication overhead, model poisoning vulnerabilities, and ethical dilemmas. It evaluates privacy-preserving mechanisms and security strategies in FL, particularly those enabled by blockchain, such as cryptographic methods, decentralized consensus protocols, and tamper-proof data logging. Additionally, the research analyzes regulatory and ethical considerations for adopting blockchain-based FL solutions. Key findings highlight the effectiveness of blockchain in addressing FL challenges, particularly in mitigating model poisoning, ensuring data integrity, and reducing communication costs. The paper concludes with future directions for integrating blockchain and FL, emphasizing areas such as interoperability, lightweight consensus mechanisms, and regulatory compliance.', 'DOI': '10.1186/s40537-025-01099-5'}, {'id': 'arxiv_2207.09708', 'title': 'RV4JaCa -- Runtime Verification for Multi-Agent Systems', 'URL': 'http://arxiv.org/abs/2207.09708', 'extra_urls': ['http://arxiv.org/abs/2207.09708'], 'type': 'article', 'author': [{'family': 'Engelmann', 'given': 'Debora C.'}, {'family': 'Ferrando', 'given': 'Angelo'}, {'family': 'Panisson', 'given': 'Alison R.'}, {'family': 'Ancona', 'given': 'Davide'}, {'family': 'Bordini', 'given': 'Rafael H.'}, {'family': 'Mascardi', 'given': 'Viviana'}], 'abstract': 'This paper presents a Runtime Verification (RV) approach for Multi-Agent Systems (MAS) using the JaCaMo framework. Our objective is to bring a layer of security to the MAS. This layer is capable of controlling events during the execution of the system without needing a specific implementation in the behaviour of each agent to recognise the events. MAS have been used in the context of hybrid intelligence. This use requires communication between software agents and human beings. In some cases, communication takes place via natural language dialogues. However, this kind of communication brings us to a concern related to controlling the flow of dialogue so that agents can prevent any change in the topic of discussion that could impair their reasoning. We demonstrate the implementation of a monitor that aims to control this dialogue flow in a MAS that communicates with the user through natural language to aid decision-making in hospital bed allocation.'}, {'id': 'doi_10_1007_s10845-024-02424-0', 'title': 'A reference framework for the digital twin smart factory based on cloud-fog-edge computing collaboration', 'URL': 'https://doi.org/10.1007/s10845-024-02424-0', 'extra_urls': ['https://doi.org/10.1007/s10845-024-02424-0'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Zhiyuan'}, {'family': 'Mei', 'given': 'Xuesong'}, {'family': 'Sun', 'given': 'Zheng'}, {'family': 'Xu', 'given': 'Jun'}, {'family': 'Zhang', 'given': 'Jianchen'}, {'family': 'Zhang', 'given': 'Dawei'}, {'family': 'Zhu', 'given': 'Jingyi'}], 'abstract': 'Digital twin (DT) is an important approach for the factory to achieve intelligence. Due to the different scenarios and definitions, the generalization of frameworks for DT-based smart factories is weak, slowing down the overall process of industrial intelligence. Meanwhile, the pressure of data transmission and processing increases dramatically because of data explosion, which poses a challenge to the rational allocation of computing resources. In addition, more advanced strategies for training and running models are needed to support more sophisticated services. This paper proposes a reference framework that combines DT and cloud-fog-edge computing collaboration (CFE). First, the DT fuses physical and virtual spaces. The virtual-real fusion provides more information for operations, and the virtual space gives more accurate and timely decisions based on the constantly refreshed state. Secondly, by introducing CFE, suitable operating platforms for each layer of the DT-based smart factory are set, which enhances data interaction and reduces the dependence on cloud computing. The DT-CFE framework is well generalized. This paper first introduces the definition of the DT-based smart factory and its components. Then the methodology of the DT-CFE-based smart factory is proposed, and the network topology and operation mechanism are introduced. In this framework, the transmission and response performance of its data interaction is tested, and the interference of dynamic events occurring through scheduling is studied to illustrate the effectiveness and superiority of the framework.', 'DOI': '10.1007/s10845-024-02424-0'}, {'id': 'big_data_driven', 'title': 'Big data driven Hierarchical Digital Twin Predictive Remanufacturing paradigm: Architecture, control mechanism, application scenario and benefits', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0959652619341691', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0959652619341691'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Yankai'}, {'family': 'Wang', 'given': 'Shilong'}, {'family': 'Yang', 'given': 'Bo'}, {'family': 'Zhu', 'given': 'Lingzi'}, {'family': 'Liu', 'given': 'Feng'}], 'abstract': 'Remanufacturing is deemed to be an effective method for recycling resources, achieving sustainable production. However, little importance of remanufacturing has been attached in PLM. Surely, there are many problems in implementation of the remanufacturing strategy, such as inability to effectively reduce uncertainty, lack of product multi-life-cycle remanufacturing process tracking management, lack of smart enabling technology application in the full lifecycle that focusing on multi-life-cycle remanufacturing. After analyzing the reasons, through integrating smart enabling technologies, a new PLM paradigm focusing on the multi-life-cycle remanufacturing process: Big Data driven Hierarchical Digital Twin Predictive Remanufacturing (BDHDTPREMfg) is proposed. And the definition of BDHDTPREMfg is proposed. A big data driven layered architecture and the hierarchical CPS-Digital-Twin(CPSDT) reconfiguration control mechanism of BDHDTPREMfg are respectively developed. Then, this paper presents an application scenario of BDHDTPREMfg to validate the feasibility and effectiveness. Based on the above application analysis, the benefits of penetrating BDHDTPREMfg into the entire lifecycle are demonstrated. The summary of this paper and future research work is discussed in the end.'}, {'id': 'the_role_of', 'title': 'The role of complexity for digital twins of cities', 'URL': 'https://www.nature.com/articles/s43588-023-00431-4', 'extra_urls': ['https://www.nature.com/articles/s43588-023-00431-4'], 'type': 'article', 'author': [{'family': 'Caldarelli', 'given': 'G.'}, {'family': 'Arcaute', 'given': 'E.'}, {'family': 'Barthelemy', 'given': 'M.'}, {'family': 'Batty', 'given': 'M.'}, {'family': 'Gershenson', 'given': 'C.'}, {'family': 'Helbing', 'given': 'D.'}, {'family': 'Mancuso', 'given': 'S.'}, {'family': 'Moreno', 'given': 'Y.'}, {'family': 'Ramasco', 'given': 'J. J.'}, {'family': 'Rozenblat', 'given': 'C.'}, {'family': 'S\xe1nchez', 'given': 'A.'}, {'family': 'Fern\xe1ndez-Villaca\xf1as', 'given': 'J. L.'}], 'abstract': 'We argue that theories and methods drawn from complexity science are urgently needed to guide the development and use of digital twins for cities. The theoretical framework from complexity science takes into account both the short-term and the long-term dynamics of cities and their interactions. This is the foundation for a new approach that treats cities not as large machines or logistic systems but as mutually interwoven self-organizing phenomena, which evolve, to an extent, like living systems.'}, {'id': 'doi_10_1038_s43588-024-00603-w', 'title': 'Advancements and challenges of digital twins in industry', 'URL': 'https://doi.org/10.1038/s43588-024-00603-w', 'extra_urls': ['https://doi.org/10.1038/s43588-024-00603-w'], 'type': 'article', 'author': [{'family': 'Tao', 'given': 'Fei'}, {'family': 'Zhang', 'given': 'He'}, {'family': 'Zhang', 'given': 'Chenyuan'}], 'abstract': 'Digital twins, which are considered an effective approach to realize the fusion between virtual and physical spaces, have attracted a substantial amount of attention in the past decade. With their rapid development in recent years, digital twins have been applied in various fields, particularly in industry. However, there are still some gaps to be filled and some limitations to be addressed. Here we provide a brief overview of digital twin advancements in industry and highlight the main pitfalls to avoid and challenges to overcome, to improve the maturity of digital twins and facilitate large-scale industrial applications in the future.', 'DOI': '10.1038/s43588-024-00603-w'}, {'id': 'doi_10_1186_s42162-024-00385-5', 'title': 'Digital Twins of smart energy systems: a systematic literature review on enablers, design, management and computational challenges', 'URL': 'https://doi.org/10.1186/s42162-024-00385-5', 'extra_urls': ['https://doi.org/10.1186/s42162-024-00385-5'], 'type': 'article', 'author': [{'family': 'Aghazadeh Ardebili', 'given': 'Ali'}, {'family': 'Zappatore', 'given': 'Marco'}, {'family': 'Ramadan', 'given': 'Amro Issam Hamed Attia'}, {'family': 'Longo', 'given': 'Antonella'}, {'family': 'Ficarella', 'given': 'Antonio'}], 'abstract': 'Energy systems, as critical infrastructures (CI), constitute Cyber-Physical-Social Systems (CPSS). Due to their inherent complexity and the importance of service continuity of CIs, digitization in this context encounters significant practical challenges. Digital Twins (DT) have emerged over the recent years as a promising solution for managing CPSSs by facilitating real-time interaction, synchronization, and control of physical assets. The selection of an appropriate architectural framework is crucial in constructing a DT, to ensure integration of enabling technologies and data from diverse sources.', 'DOI': '10.1186/s42162-024-00385-5'}, {'id': 'use_case_scenarios', 'title': 'Use Case Scenarios for Digital Twin Implementation Based on ISO 23247', 'URL': 'https://www.nist.gov/publications/use-case-scenarios-digital-twin-implementation-based-iso-23247', 'extra_urls': ['https://www.nist.gov/publications/use-case-scenarios-digital-twin-implementation-based-iso-23247'], 'type': 'article', 'author': [{'family': 'Shao', 'given': 'Guodong'}], 'abstract': 'As a key part of digital transformation, digital twin is an important concept for achieving smart manufacturing'}, {'id': 'interoperability_of_digital', 'title': 'Interoperability of Digital Twins: Challenges, Success Factors, and Future Research Directions', 'URL': 'https://www.nist.gov/publications/interoperability-digital-twins-challenges-success-factors-and-future-research', 'extra_urls': ['https://www.nist.gov/publications/interoperability-digital-twins-challenges-success-factors-and-future-research'], 'type': 'article', 'author': [{'family': 'David', 'given': 'Istvan'}, {'family': 'Shao', 'given': 'Guodong'}, {'family': 'Tilbury', 'given': 'Dawn'}, {'family': 'Gomes', 'given': 'Claudio'}, {'family': 'Zarkhout', 'given': 'Bassam'}], 'abstract': 'The widespread adoption of digital twins gave rise to emerging systems of interconnected digital twins, often dubbed aggregated or hierarchical digital twins'}, {'id': 'privacy_preservation_in', 'title': 'Privacy preservation in federated learning: An insightful survey from the GDPR perspective', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0167404821002261', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0167404821002261'], 'type': 'article', 'author': [{'family': 'Truong', 'given': 'Nguyen'}, {'family': 'Sun', 'given': 'Kai'}, {'family': 'Wang', 'given': 'Siyao'}, {'family': 'Guitton', 'given': 'Florian'}, {'family': 'Guo', 'given': 'YiKe'}], 'abstract': 'In recent years, along with the blooming of Machine Learning (ML)-based applications and services, ensuring data privacy and security have become a critical obligation. ML-based service providers not only confront with difficulties in collecting and managing data across heterogeneous sources but also challenges of complying with rigorous data protection regulations such as EU/UK General Data Protection Regulation (GDPR). Furthermore, conventional centralised ML approaches have always come with long-standing privacy risks to personal data leakage, misuse, and abuse. Federated learning (FL) has emerged as a prospective solution that facilitates distributed collaborative learning without disclosing original training data. Unfortunately, retaining data and computation on-device as in FL are not sufficient for privacy-guarantee because model parameters exchanged among participants conceal sensitive information that can be exploited in privacy attacks. Consequently, FL-based systems are not naturally compliant with the GDPR. This article is dedicated to surveying of state-of-the-art privacy-preservation techniques in FL in relations with GDPR requirements. Furthermore, insights into the existing challenges are examined along with the prospective approaches following the GDPR regulatory guidelines that FL-based systems shall implement to fully comply with the GDPR.'}, {'id': 'doi_10_2196_41588', 'title': 'Federated Machine Learning, Privacy-Enhancing Technologies, and Data Protection Laws in Medical Research: Scoping Review', 'URL': 'https://doi.org/10.2196/41588', 'extra_urls': ['https://doi.org/10.2196/41588'], 'type': 'article', 'author': [{'family': 'Brauneck', 'given': 'Alissa'}, {'family': 'Schmalhorst', 'given': 'Louisa'}, {'family': 'Majdabadi', 'given': 'Mohammad Mahdi Kazemi'}, {'family': 'Bakhtiari', 'given': 'Mohammad'}, {'family': 'V\xf6lker', 'given': 'Uwe'}, {'family': 'Baumbach', 'given': 'Jan'}, {'family': 'Baumbach', 'given': 'Linda'}, {'family': 'Buchholtz', 'given': 'Gabriele'}], 'abstract': 'Background: The collection, storage, and analysis of large data sets are relevant in many sectors. Especially in the medical field, the processing of patient data promises great progress in personalized health care. However, it is strictly regulated, such as by the General Data Protection Regulation (GDPR). These regulations mandate strict data security and data protection and, thus, create major challenges for collecting and using large data sets. Technologies such as federated learning (FL), especially paired with differential privacy (DP) and secure multiparty computation (SMPC), aim to solve these challenges.\nObjective: This scoping review aimed to summarize the current discussion on the legal questions and concerns related to FL systems in medical research. We were particularly interested in whether and to what extent FL applications and training processes are compliant with the GDPR data protection law and whether the use of the aforementioned privacy-enhancing technologies (DP and SMPC) affects this legal compliance. We placed special emphasis on the consequences for medical research and development.\nMethods: We performed a scoping review according to the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews). We reviewed articles on Beck-Online, SSRN, ScienceDirect, arXiv, and Google Scholar published in German or English between 2016 and 2022. We examined 4 questions: whether local and global models are \u201cpersonal data\u201d as per the GDPR; what the \u201croles\u201d as defined by the GDPR of various parties in FL are; who controls the data at various stages of the training process; and how, if at all, the use of privacy-enhancing technologies affects these findings.\nResults: We identified and summarized the findings of 56 relevant publications on FL. Local and likely also global models constitute personal data according to the GDPR. FL strengthens data protection but is still vulnerable to a number of attacks and the possibility of data leakage. These concerns can be successfully addressed through the privacy-enhancing technologies SMPC and DP.\nConclusions: Combining FL with SMPC and DP is necessary to fulfill the legal data protection requirements (GDPR) in medical research dealing with personal data. Even though some technical and legal challenges remain, for example, the possibility of successful attacks on the system, combining FL with SMPC and DP creates enough security to satisfy the legal requirements of the GDPR. This combination thereby provides an attractive technical solution for health institutions willing to collaborate without exposing their data to risk. From a legal perspective, the combination provides enough built-in security measures to satisfy data protection requirements, and from a technical perspective, the combination provides secure systems with comparable performance with centralized machine learning applications.', 'DOI': '10.2196/41588'}, {'id': 'federated_learning_for', 'title': 'Federated learning for digital twin applications: a privacy-preserving and low-latency approach', 'URL': 'https://peerj.com/articles/cs-2877', 'extra_urls': ['https://peerj.com/articles/cs-2877'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Jie'}, {'family': 'Wang', 'given': 'Dong'}], 'abstract': 'The digital twin (DT) concept has recently gained widespread application for mapping the state of physical entities, enabling real-time analysis, prediction, and optimization, thereby enhancing the management and control of physical systems. However, when sensitive information is extracted from physical entities, it faces potential leakage risks, as DT service providers are typically honest yet curious. Federated learning (FL) offers a new distributed learning paradigm that protects privacy by transmitting model updates from edge servers to local devices, allowing training on local datasets. Nevertheless, the training parameters communicated between local mobile devices and edge servers may contain raw data that malicious adversaries could exploit. Furthermore, variations in mapping bias across local devices and the presence of malicious clients can degrade FL training accuracy. To address these security and privacy threats, this paper proposes the FL-FedDT scheme\u2014a privacy-preserving and low-latency FL method that employs an enhanced Paillier homomorphic encryption algorithm to safeguard the privacy of local device parameters without transmitting data to the server. Our approach introduces an improved Paillier encryption method with a new hyperparameter and pre-calculates multiple random intermediate values during the key generation stage, significantly reducing encryption time and thereby expediting model training. Additionally, we implement a trusted FL global aggregation method that incorporates learning quality and interaction records to identify and mitigate malicious updates, dynamically adjusting weights to counteract the threat of malicious clients. To evaluate the efficiency of our proposed scheme, we conducted extensive experiments, with results validating that our approach achieves training accuracy and security on par with baseline methods, while substantially reducing FL iteration time. This enhancement contributes to improved DT mapping and service quality for physical entities. (The code for this study is publicly available on GitHub at: https://github.com/fujianU/federated-learning. The URL address of the MNIST dataset is: https://gitcode.com/Resource-Bundle-Collection/d47b0/overview?utm_source=pan_gitcode&amp;index=top&amp;type=href&amp;;.)'}, {'id': 'doi_10_1007_s42979-024-03413-z', 'title': 'Mirroring Privacy Risks with Digital Twins: When Pieces of Personal Data Suddenly Fit Together', 'URL': 'https://doi.org/10.1007/s42979-024-03413-z', 'extra_urls': ['https://doi.org/10.1007/s42979-024-03413-z'], 'type': 'article', 'author': [{'family': 'B\xe4umer', 'given': 'Frederik Simon'}, {'family': 'Schultenk\xe4mper', 'given': 'Sergej'}, {'family': 'Geierhos', 'given': 'Michaela'}, {'family': 'Lee', 'given': 'Yeong Su'}], 'abstract': 'With the proliferation of social media, more personal information is being shared online than ever before, raising significant privacy concerns. This paper presents a novel approach to identify and mitigate privacy risks by generating digital twins from social media data. We propose a comprehensive framework that includes data collection, processing, and analysis, with special attention to data standardization, pseudonymization, and the use of synthetic data to ensure privacy compliance. We apply and evaluate state-of-the-art techniques such as Large Language Models, Generative Adversarial Networks, and Vision-Language Models to generate synthetic but realistic social media data that support the construction of accurate and representative digital twins while ensuring strict privacy compliance. Our approach demonstrates the potential for digital twins to help identify and mitigate privacy risks associated with social media use. We discuss the value and feasibility of this concept and suggest that further refinement of the techniques and conditions involved is needed.', 'DOI': '10.1007/s42979-024-03413-z'}, {'id': 'iterative_updating_of', 'title': 'Iterative updating of digital twin for equipment: Progress, challenges, and trends', 'URL': 'https://www.sciencedirect.com/science/article/pii/S147403462400421X', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S147403462400421X'], 'type': 'article', 'author': [{'family': 'Zhang', 'given': 'Bin'}, {'family': 'Ding', 'given': 'Guofu'}, {'family': 'Zheng', 'given': 'Qing'}, {'family': 'Zhang', 'given': 'Kai'}, {'family': 'Qin', 'given': 'Shengfeng'}], 'abstract': 'Digital twin (DT) technology enables the creation of DT that are synchronized with the state and behavior of physical entities. DT simulates physical entities, which can enable the evaluation, prediction, and optimal control of physical entities. During the operation and service of a physical equipment, its structure will change, and its performance will gradually decrease. The iterative update of the DT can maintain \u201cvirtual and real synchronization\u201d with the physical equipment, meeting the accuracy requirements for twin applications. Therefore, updating the DT model of an equipment based on the actual status of the physical equipment is a key challenge for DT applications in equipment health management (PHM). Scholars have studied many methods for updating DT iteratively. However, there is currently no systematic review of iterative updates for equipment DT, especially those focusing on updates. Therefore, two questions are raised by this study: (1) What is the latest state of the art in this research field? (2) What are the future research directions? In light of these inquiries, related research on the iterative renewal of equipment DT is systematically reviewed by this paper and potential development trends are discussed. Firstly, the research status of the iterative update method of the equipment DT was reviewed and summarized. Then, the high-fidelity evaluation methods of DT iterative update are reviewed. Thirdly, the challenges of iterative updating of DT models are analyzed. Finally, the potential development trend of iterative updating of equipment DT models is discussed. This study aims to sort out the research status of iterative updates of equipment DT. The iterative update technology system of DT is constructed to pave the way for further research in this field.'}, {'id': 'doi_10_1038_s41598-025-85457-6', 'title': 'Real-time update algorithms for digital twin models of distribution network equipment under internet of things and optical imaging technology', 'URL': 'https://doi.org/10.1038/s41598-025-85457-6', 'extra_urls': ['https://doi.org/10.1038/s41598-025-85457-6'], 'type': 'article', 'author': [{'family': 'Shen', 'given': 'Jian'}, {'family': 'Hu', 'given': 'Liang'}, {'family': 'Yang', 'given': 'Yang'}, {'family': 'Li', 'given': 'Yong'}, {'family': 'Lou', 'given': 'Peng'}], 'abstract': 'In order to achieve more efficient, accurate and intelligent substation equipment management and overall work efficiency of the substation, improve the work quality of the substation, innovate the data transmission mode and basic algorithm of the distribution network, and improve the traditional shortcomings and defects. With the increasing digitalization of distribution network equipment (DNE), real-time update algorithms for digital twin (DT) models have become a focus of research on digitalization of DNE. However, traditional real-time update algorithms for DT models still have problems such as poor real-time and accuracy, robustness, and scalability. The article first described the problems existing in the traditional DT model of DNE. Then it used IoT sensors and optical devices to collect data related to DNE; then it used the Savitzky\u2013Golay filtering algorithm to denoise the data. This article combined the IoT and optical imaging technology to construct a DT model; by using the recursive least squares method again, key parameters and state parameters were extracted from the constructed DT mechanism model, achieving real-time updates of the DNE DT model. Finally, to verify the application effect of the IoT and optical imaging technology in real-time update algorithms for DT models of DNE, this paper compared them with traditional parameter sensitivity analysis and state estimation. The research results showed that in the real-time and accuracy testing of test case 13, the algorithm used in this paper had a time of 0.014\xa0s and an accuracy of 93.2%. The parameter sensitivity analysis method had a time of 0.045\xa0s and an accuracy of 80.4%. The state estimation method took 0.056\xa0s and had an accuracy of 82.7%. In addition, the robustness and scalability of the real-time update algorithm for the DNE DT model using the method proposed in this article are significantly better than the other two traditional methods. The results show that the real-time update algorithm of the DT model of DNE based on the IoT and optical imaging technology has better real-time performance, higher accuracy, and better robustness and scalability. This study highlights the significant impact of the IoT and optical imaging technology on the accuracy, robustness, and real-time performance of real-time update algorithms for DT models. This provides more solutions for real-time monitoring, prediction, and control of DNE.', 'DOI': '10.1038/s41598-025-85457-6'}, {'id': 'doi_10_2308_HORIZONS-2023-060', 'title': 'Patience is Key: The Time It Takes to See Benefits from Continuous Auditing', 'URL': 'https://doi.org/10.2308/HORIZONS-2023-060', 'extra_urls': ['https://doi.org/10.2308/HORIZONS-2023-060'], 'type': 'article', 'author': [{'family': 'Eulerich', 'given': 'Marc'}, {'family': 'Fligge', 'given': 'Benjamin'}, {'family': 'L\xf3pez Kasper', 'given': 'Vanessa I.'}, {'family': 'Wood', 'given': 'David A.'}], 'abstract': 'Despite research showing numerous benefits of continuous auditing, uptake by internal audit functions has been quite slow. Using a case study approach and field data from a multinational company, we study two possible reasons for the slow uptake of continuous auditing: (1) the time it takes for continuous auditing to result in measurable reductions in audit risks and (2) that not every type of risk is equally likely to improve from continuous auditing. In our case company, it takes three years (on average) before observing significant risk reductions from implementing continuous auditing. We also find that the benefits of implementing continuous auditing vary by risk factor, ranging from no improvement to 51.6 percent for each additional year of continuous auditing use. These findings can provide internal auditors with a realistic expectation of the benefits and limitations, as well as the timetable for realizing benefits, when adopting continuous auditing.Data Availability: The data used in this study cannot be made publicly available due to confidentiality agreements with the participating organization.JEL Classifications: M42; G32.', 'DOI': '10.2308/HORIZONS-2023-060'}, {'id': 'compliance', 'title': 'RegTech: Technology-driven compliance and its effects on profitability, operations, and market structure', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0304405X24000151', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0304405X24000151'], 'type': 'article', 'author': [{'family': 'Charoenwong', 'given': 'Ben'}, {'family': 'Kowaleski', 'given': 'Zachary T.'}, {'family': 'Kwan', 'given': 'Alan'}, {'family': 'Sutherland', 'given': 'Andrew G.'}], 'abstract': 'Compliance-driven investments in technology\u2014or \u201cRegTech\u201d\u2014are growing rapidly. To understand the effects on the financial sector, we study firms\u2019 responses to new internal control requirements. Affected firms make significant investments in ERP and hardware. These expenditures then enable complementary investments that are leveraged for noncompliance purposes, leading to modest savings from avoided customer complaints and misconduct. IT budgets rise and profits fall, especially at small firms, and acquisition activity and market concentration increase. Our results illustrate how regulation can directly and indirectly affect technology adoption, which in turn affects noncompliance functions and market structure.'}, {'id': 'espr_crash_course', 'title': 'ESPR crash course - How the Ecodesign for Sustainable Products Regulation will impact apparel and footwear brands', 'URL': 'https://www.carbonfact.com/blog/policy/espr-textile', 'extra_urls': ['https://www.carbonfact.com/blog/policy/espr-textile'], 'type': 'article', 'author': [{'family': 'L\xfcttin', 'given': 'Lidia'}], 'issued': {'date-parts': [[2024]]}, 'abstract': "ESPR brief for apparel and footwear: This comprehensive guide delves into the ESPR's impact on textiles, from eco-design to information requirements."}, {'id': 'guide_to_ecodesign', 'title': 'Guide to Ecodesign for Sustainable Products Regulation (ESPR)', 'URL': 'https://oneclicklca.com/en/resources/articles/ecodesign-sustainable-products-regulation-guide', 'extra_urls': ['https://oneclicklca.com/en/resources/articles/ecodesign-sustainable-products-regulation-guide'], 'type': 'article', 'author': [{'family': 'Zacharia', 'given': 'Melina'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'The Ecodesign for Sustainable Products Regulation (ESPR) entered into force on July 18, 2024, enforcing stricter criteria for sustainable products.'}, {'id': 'doi_10_1108_jcm-07-2024-7005', 'title': 'How do transparency and traceability enhance purchasing behaviors via consumer trust? Insights for food supply chains', 'URL': 'https://doi.org/10.1108/jcm-07-2024-7005', 'extra_urls': ['https://doi.org/10.1108/jcm-07-2024-7005'], 'type': 'article', 'author': [{'family': 'Nguyen', 'given': 'Minh Hue'}, {'family': 'Nguyen', 'given': 'Duy Ha'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1108/jcm-07-2024-7005'}, {'id': 'doi_10_1002_mar_22048', 'title': 'Perceived brand transparency: A conceptualization and measurement scale', 'URL': 'https://doi.org/10.1002/mar.22048', 'extra_urls': ['https://doi.org/10.1002/mar.22048'], 'type': 'article', 'author': [{'family': 'Montecchi', 'given': 'Matteo'}, {'family': 'Plangger', 'given': 'Kirk'}, {'family': 'West', 'given': 'Douglas'}, {'family': 'de Ruyter', 'given': 'Ko'}], 'issued': {'date-parts': [[2024]]}, 'DOI': '10.1002/mar.22048'}, {'id': 'doi_10_1080_00207543_2025_2507112', 'title': 'Integrating digital twin and blockchain for responsive working capital management in supply chains facing financial disruptions', 'URL': 'https://doi.org/10.1080/00207543.2025.2507112', 'extra_urls': ['https://doi.org/10.1080/00207543.2025.2507112'], 'type': 'article', 'author': [{'family': 'Badakhshan', 'given': 'Ehsan'}, {'family': 'Ivanov', 'given': 'Dmitry'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1080/00207543.2025.2507112'}, {'id': 'doi_10_3390_logistics9010022', 'title': 'State of the Art of Digital Twins in Improving Supply Chain Resilience', 'URL': 'https://doi.org/10.3390/logistics9010022', 'extra_urls': ['https://doi.org/10.3390/logistics9010022'], 'type': 'article', 'author': [{'family': 'Roman', 'given': 'Eugenia-Alina'}, {'family': 'Stere', 'given': 'Armand-Serban'}, {'family': 'Ro\u0219ca', 'given': 'Eugen'}, {'family': 'Radu', 'given': 'Adriana-Valentina'}, {'family': 'Codroiu', 'given': 'Denis'}, {'family': 'Anamaria', 'given': 'Ilie'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.3390/logistics9010022'}, {'id': 'doi_10_1177_15589250241302435', 'title': 'Research on identification of wool and cashmere by ANN based on hyperspectral imaging technology', 'URL': 'https://doi.org/10.1177/15589250241302435', 'extra_urls': ['https://doi.org/10.1177/15589250241302435'], 'type': 'article', 'author': [{'family': 'Qiu', 'given': 'Yingjie'}, {'family': 'Jin', 'given': 'Xiaoke'}, {'family': 'Tian', 'given': 'Wei'}, {'family': 'Zhang', 'given': 'Huifang'}, {'family': 'Shao', 'given': 'Lingda'}, {'family': 'Feng', 'given': 'XuHuang'}, {'family': 'Zhu', 'given': 'Chengyan'}], 'issued': {'date-parts': [[2024]]}, 'DOI': '10.1177/15589250241302435'}, {'id': 'doi_10_1038_s41586-024-08109-1', 'title': 'A broadband hyperspectral image sensor with high spatio-temporal resolution', 'URL': 'https://doi.org/10.1038/s41586-024-08109-1', 'extra_urls': ['https://doi.org/10.1038/s41586-024-08109-1'], 'type': 'article', 'author': [{'family': 'Bian', 'given': 'Liheng'}, {'family': 'Wang', 'given': 'Zhen'}, {'family': 'Zhang', 'given': 'Yuzhe'}, {'family': 'Li', 'given': 'Lianjie'}, {'family': 'Zhang', 'given': 'Yinuo'}, {'family': 'Yang', 'given': 'Chen'}, {'family': 'Fang', 'given': 'Wen'}, {'family': 'Zhao', 'given': 'Jiajun'}, {'family': 'Zhu', 'given': 'Chunli'}, {'family': 'Meng', 'given': 'Qinghao'}, {'family': 'Peng', 'given': 'Xuan'}, {'family': 'Zhang', 'given': 'Jun'}], 'issued': {'date-parts': [[2024]]}, 'DOI': '10.1038/s41586-024-08109-1'}, {'id': 'doi_10_1155_2017_3154035', 'title': 'Comprehensive Study of a Handheld Raman Spectrometer for the Analysis of Counterfeits of Solid-Dosage Form Medicines', 'URL': 'https://doi.org/10.1155/2017/3154035', 'extra_urls': ['https://doi.org/10.1155/2017/3154035'], 'type': 'article', 'author': [{'family': 'D\xe9gardin', 'given': 'Klara'}, {'family': 'Guillemain', 'given': 'Aur\xe9lie'}, {'family': 'Roggo', 'given': 'Yves'}], 'issued': {'date-parts': [[2017]]}, 'DOI': '10.1155/2017/3154035'}, {'id': 'doi_10_1609_aaai_v38i18_30040', 'title': 'Bayesian Inference with Complex Knowledge Graph Evidence', 'URL': 'https://doi.org/10.1609/aaai.v38i18.30040', 'extra_urls': ['https://doi.org/10.1609/aaai.v38i18.30040'], 'type': 'article', 'author': [{'family': 'Toroghi', 'given': 'Armin'}, {'family': 'Sanner', 'given': 'Scott'}], 'issued': {'date-parts': [[2024]]}, 'DOI': '10.1609/aaai.v38i18.30040'}, {'id': 'doi_10_3390_su12062391', 'title': 'Overcoming the Blockchain Oracle Problem in the Traceability of Non-Fungible Products', 'URL': 'https://doi.org/10.3390/su12062391', 'extra_urls': ['https://doi.org/10.3390/su12062391'], 'type': 'article', 'author': [{'family': 'Caldarelli', 'given': 'Giulio'}, {'family': 'Rossignoli', 'given': 'Cecilia'}, {'family': 'Zardini', 'given': 'Alessandro'}], 'issued': {'date-parts': [[2020]]}, 'DOI': '10.3390/su12062391'}, {'id': 'doi_10_3390_info11110509', 'title': 'Understanding the Blockchain Oracle Problem: A Call for Action', 'URL': 'https://doi.org/10.3390/info11110509', 'extra_urls': ['https://doi.org/10.3390/info11110509'], 'type': 'article', 'author': [{'family': 'Caldarelli', 'given': 'Giulio'}], 'issued': {'date-parts': [[2020]]}, 'DOI': '10.3390/info11110509'}, {'id': 'doi_10_1145_3531146_3533231', 'title': 'Data Cards: Purposeful and Transparent Dataset Documentation for Responsible AI', 'URL': 'https://doi.org/10.1145/3531146.3533231', 'extra_urls': ['https://doi.org/10.1145/3531146.3533231'], 'type': 'article', 'author': [{'family': 'Pushkarna', 'given': 'Mahima'}, {'family': 'Zaldivar', 'given': 'Andrew'}, {'family': 'Kjartansson', 'given': 'Oddur'}], 'issued': {'date-parts': [[2022]]}, 'DOI': '10.1145/3531146.3533231'}, {'id': 'doi_10_1145_3287560_3287596', 'title': 'Model Cards for Model Reporting', 'URL': 'https://doi.org/10.1145/3287560.3287596', 'extra_urls': ['https://doi.org/10.1145/3287560.3287596'], 'type': 'article', 'author': [{'family': 'Mitchell', 'given': 'Margaret'}, {'family': 'Wu', 'given': 'Simone'}, {'family': 'Zaldivar', 'given': 'Andrew'}, {'family': 'Barnes', 'given': 'Parker'}, {'family': 'Vasserman', 'given': 'Lucy'}, {'family': 'Hutchinson', 'given': 'Ben'}, {'family': 'Spitzer', 'given': 'Elena'}, {'family': 'Raji', 'given': 'Inioluwa Deborah'}, {'family': 'Gebru', 'given': 'Timnit'}], 'issued': {'date-parts': [[2019]]}, 'DOI': '10.1145/3287560.3287596'}, {'id': 'doi_10_1371_journal_pone_0121221', 'title': 'Product Carbon Footprints and Their Uncertainties in Comparative Decision Contexts', 'URL': 'https://doi.org/10.1371/journal.pone.0121221', 'extra_urls': ['https://doi.org/10.1371/journal.pone.0121221'], 'type': 'article', 'author': [{'family': 'Henriksson', 'given': 'Patrik J. G.'}, {'family': 'Heijungs', 'given': 'Reinout'}, {'family': 'Dao', 'given': 'Hai M.'}, {'family': 'Phan', 'given': 'Lam T.'}, {'family': 'de Snoo', 'given': 'Geert R.'}, {'family': 'Guin\xe9e', 'given': 'Jeroen B.'}], 'issued': {'date-parts': [[2015]]}, 'DOI': '10.1371/journal.pone.0121221'}, {'id': 'doi_10_1145_3736575', 'title': 'Conformal Prediction: A Data Perspective', 'URL': 'https://doi.org/10.1145/3736575', 'extra_urls': ['https://doi.org/10.1145/3736575'], 'type': 'article', 'author': [{'family': 'Zhou', 'given': 'Xiaofan'}, {'family': 'Chen', 'given': 'Baiting'}, {'family': 'Gui', 'given': 'Yu'}, {'family': 'Cheng', 'given': 'Lu'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1145/3736575'}, {'id': 'doi_10_1016_j_patcog_2011_06_019', 'title': 'A unifying view on dataset shift in classification', 'URL': 'https://doi.org/10.1016/j.patcog.2011.06.019', 'extra_urls': ['https://doi.org/10.1016/j.patcog.2011.06.019'], 'type': 'article', 'author': [{'family': 'Moreno-Torres', 'given': 'Jose G.'}, {'family': 'Raeder', 'given': 'Troy'}, {'family': 'Alaiz-Rodr\xedguez', 'given': 'Roc\xedo'}, {'family': 'Chawla', 'given': 'Nitesh V.'}, {'family': 'Herrera', 'given': 'Francisco'}], 'issued': {'date-parts': [[2012]]}, 'DOI': '10.1016/j.patcog.2011.06.019'}, {'id': 'doi_10_1214_23-AOS2276', 'title': 'Conformal prediction beyond exchangeability', 'URL': 'https://doi.org/10.1214/23-AOS2276', 'extra_urls': ['https://doi.org/10.1214/23-AOS2276'], 'type': 'article', 'author': [{'family': 'Barber', 'given': 'Rina Foygel'}, {'family': 'Cand\xe8s', 'given': 'Emmanuel J.'}, {'family': 'Ramdas', 'given': 'Aaditya'}, {'family': 'Tibshirani', 'given': 'Ryan J.'}], 'issued': {'date-parts': [[2023]]}, 'DOI': '10.1214/23-AOS2276'}, {'id': 'doi_10_1561_2200000101', 'title': 'Conformal Prediction: A Gentle Introduction', 'URL': 'https://doi.org/10.1561/2200000101', 'extra_urls': ['https://doi.org/10.1561/2200000101'], 'type': 'article', 'author': [{'family': 'Angelopoulos', 'given': 'Anastasios N.'}, {'family': 'Bates', 'given': 'Stephen'}], 'issued': {'date-parts': [[2023]]}, 'DOI': '10.1561/2200000101'}, {'id': 'doi_10_1162_tacl_a_00638', 'title': 'Lost in the Middle: How Language Models Use Long Contexts', 'URL': 'https://doi.org/10.1162/tacl_a_00638', 'extra_urls': ['https://doi.org/10.1162/tacl_a_00638'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Nelson F.'}, {'family': 'Lin', 'given': 'Kevin'}, {'family': 'Hewitt', 'given': 'John'}, {'family': 'Paranjape', 'given': 'Ashwin'}, {'family': 'Bevilacqua', 'given': 'Michele'}, {'family': 'Petroni', 'given': 'Fabio'}, {'family': 'Liang', 'given': 'Percy'}], 'issued': {'date-parts': [[2024]]}, 'DOI': '10.1162/tacl_a_00638'}, {'id': 'doi_10_1002_widm_1555', 'title': 'A taxonomy of automatic differentiation pitfalls', 'URL': 'https://doi.org/10.1002/widm.1555', 'extra_urls': ['https://doi.org/10.1002/widm.1555'], 'type': 'article', 'author': [{'family': 'H\xfcckelheim', 'given': 'Jan'}, {'family': 'Menon', 'given': 'Harshitha'}, {'family': 'Moses', 'given': 'William'}, {'family': 'Christianson', 'given': 'Bruce'}, {'family': 'Hovland', 'given': 'Paul'}, {'family': 'Hasco\xebt', 'given': 'Laurent'}], 'issued': {'date-parts': [[2024]]}, 'DOI': '10.1002/widm.1555'}, {'id': 'doi_10_1145_3053600_3053653', 'title': 'Performance Engineering for Microservices', 'URL': 'https://doi.org/10.1145/3053600.3053653', 'extra_urls': ['https://doi.org/10.1145/3053600.3053653'], 'type': 'article', 'author': [{'family': 'Heinrich', 'given': 'Robert'}, {'family': 'van Hoorn', 'given': 'Andr\xe9'}, {'family': 'Knoche', 'given': 'Holger'}, {'family': 'Li', 'given': 'Fei'}, {'family': 'Lwakatare', 'given': 'Lucy Ellen'}, {'family': 'Pahl', 'given': 'Claus'}, {'family': 'Schulte', 'given': 'Stefan'}, {'family': 'Wettinger', 'given': 'Johannes'}], 'issued': {'date-parts': [[2017]]}, 'DOI': '10.1145/3053600.3053653'}, {'id': 'doi_10_1016_j_jss_2024_112232', 'title': 'Unveiling the microservices testing methods, challenges, solutions, and solutions gaps: A systematic mapping study', 'URL': 'https://doi.org/10.1016/j.jss.2024.112232', 'extra_urls': ['https://doi.org/10.1016/j.jss.2024.112232'], 'type': 'article', 'author': [{'family': 'Hui', 'given': 'Mingxuan'}, {'family': 'Wang', 'given': 'Lu'}, {'family': 'Li', 'given': 'Hao'}, {'family': 'Yang', 'given': 'Ren'}, {'family': 'Song', 'given': 'Yuxin'}, {'family': 'Zhuang', 'given': 'Huiying'}, {'family': 'Cui', 'given': 'Di'}, {'family': 'Li', 'given': 'Qingshan'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1016/j.jss.2024.112232'}, {'id': 'doi_10_1109_JIOT_2024_3407584', 'title': 'Decentralized Federated Learning: A Survey and Perspective', 'URL': 'https://doi.org/10.1109/JIOT.2024.3407584', 'extra_urls': ['https://doi.org/10.1109/JIOT.2024.3407584'], 'type': 'article', 'author': [{'family': 'Yuan', 'given': 'Liangqi'}, {'family': 'Wang', 'given': 'Ziran'}, {'family': 'Sun', 'given': 'Lichao'}, {'family': 'Yu', 'given': 'Philip S.'}, {'family': 'Brinton', 'given': 'Christopher G.'}], 'issued': {'date-parts': [[2024]]}, 'DOI': '10.1109/JIOT.2024.3407584'}, {'id': 'doi_10_1007_s10664-025-10646-w', 'title': 'A systematic review on smart contracts security design patterns', 'URL': 'https://doi.org/10.1007/s10664-025-10646-w', 'extra_urls': ['https://doi.org/10.1007/s10664-025-10646-w'], 'type': 'article', 'author': [{'family': 'Azimi', 'given': 'Sadaf'}, {'family': 'Golzari', 'given': 'Ali'}, {'family': 'Ivaki', 'given': 'Naghmeh'}, {'family': 'Laranjeiro', 'given': 'Nuno'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.1007/s10664-025-10646-w'}, {'id': 'doi_10_1257_aer_104_1_183', 'title': "Risk Sharing and Transactions Costs: Evidence from Kenya's Mobile Money Revolution", 'URL': 'https://doi.org/10.1257/aer.104.1.183', 'extra_urls': ['https://doi.org/10.1257/aer.104.1.183'], 'type': 'article', 'author': [{'family': 'Jack', 'given': 'William'}, {'family': 'Suri', 'given': 'Tavneet'}], 'issued': {'date-parts': [[2014]]}, 'DOI': '10.1257/aer.104.1.183'}, {'id': 'doi_10_1063_5_0123942', 'title': 'Solving the blockchain oracle problem to enable supply chain mass adoption', 'URL': 'https://doi.org/10.1063/5.0123942', 'extra_urls': ['https://doi.org/10.1063/5.0123942'], 'type': 'article', 'author': [{'family': 'Teoh', 'given': 'Bryan'}], 'issued': {'date-parts': [[2023]]}, 'DOI': '10.1063/5.0123942'}, {'id': 'doi_10_3389_fbloc_2025_1503595', 'title': 'Exploring the failure factors of blockchain adopting projects: a case study of tradelens through the lens of commons theory', 'URL': 'https://doi.org/10.3389/fbloc.2025.1503595', 'extra_urls': ['https://doi.org/10.3389/fbloc.2025.1503595'], 'type': 'article', 'author': [{'family': 'Najati', 'given': 'Issam'}], 'issued': {'date-parts': [[2025]]}, 'DOI': '10.3389/fbloc.2025.1503595'}, {'id': 'doi_10_1145_3567582', 'title': 'Connect API with Blockchain: A Survey on Blockchain Oracle Implementation', 'URL': 'https://doi.org/10.1145/3567582', 'extra_urls': ['https://doi.org/10.1145/3567582'], 'type': 'article', 'author': [{'family': 'Pasdar', 'given': 'Amirmohammad'}, {'family': 'Lee', 'given': 'Young Choon'}, {'family': 'Dong', 'given': 'Zhongli'}], 'issued': {'date-parts': [[2023]]}, 'DOI': '10.1145/3567582'}, {'id': 'doi_10_1108_SCM-04-2018-0152', 'title': 'Traceability for sustainability \u2013 literature review and conceptual framework', 'URL': 'https://doi.org/10.1108/SCM-04-2018-0152', 'extra_urls': ['https://doi.org/10.1108/SCM-04-2018-0152'], 'type': 'article', 'author': [{'family': 'Garcia-Torres', 'given': 'Sofia'}, {'family': 'Albareda', 'given': 'Laura'}, {'family': 'Rey-Garcia', 'given': 'Marta'}, {'family': 'Seuring', 'given': 'Stefan'}], 'issued': {'date-parts': [[2019]]}, 'DOI': '10.1108/SCM-04-2018-0152'}, {'id': 'alliance_for_bangladesh', 'title': 'Alliance for Bangladesh Worker Safety, 2024', 'URL': 'https://www.bangladeshworkersafety.org', 'extra_urls': ['https://www.bangladeshworkersafety.org'], 'type': 'webpage', 'author': [{'family': 'Alliance for Bangladesh Worker Safety'}], 'issued': {'date-parts': [[2024]]}}, {'id': 'doi_10_1108_SCM-10-2017-0336', 'title': 'Assessment of traditional food supply chain performance using triadic approach: the role of relationships quality', 'URL': 'https://doi.org/10.1108/SCM-10-2017-0336', 'extra_urls': ['https://doi.org/10.1108/SCM-10-2017-0336'], 'type': 'article', 'author': [{'family': 'Mesic', 'given': '\u017deljka'}, {'family': 'Moln\xe1r', 'given': 'Adrienn'}, {'family': 'Cerjak', 'given': 'Marija'}], 'issued': {'date-parts': [[2018]]}, 'DOI': '10.1108/SCM-10-2017-0336'}, {'id': 'doi_10_3390_en14082289', 'title': 'Towards a Digital Product Passport Fit for Contributing to a Circular Economy', 'URL': 'https://doi.org/10.3390/en14082289', 'extra_urls': ['https://doi.org/10.3390/en14082289'], 'type': 'article', 'author': [{'family': 'Adisorn', 'given': 'Thomas'}, {'family': 'Tholen', 'given': 'Lena'}, {'family': 'G\xf6tz', 'given': 'Thomas'}], 'issued': {'date-parts': [[2021]]}, 'DOI': '10.3390/en14082289'}, {'id': 'doi_10_1007_s10207-025-01043-x', 'title': 'Leveraging digital twins for advanced threat modeling in cyber-physical systems cybersecurity', 'URL': 'https://doi.org/10.1007/s10207-025-01043-x', 'extra_urls': ['https://doi.org/10.1007/s10207-025-01043-x'], 'type': 'article', 'author': [{'family': 'Erceylan', 'given': 'Gizem'}, {'family': 'Akbarzadeh', 'given': 'Aida'}, {'family': 'Gkioulos', 'given': 'Vasileios'}], 'abstract': 'Threat modeling is a critical proactive security technique for identifying threats and determining mitigations. However, traditional approaches often fall short for Industrial Control Systems (ICS), which automate operations in domains like manufacturing and energy and are a subset of Cyber-Physical Systems (CPS). CPS integrates computation, networking, and physical processes, with ICS requiring specialized cybersecurity approaches due to its operational and safety-critical nature. This study explores the use of digital twin technology as a promising cybersecurity tool for ICS, enabling testing and analysis without disrupting operations. By examining the capabilities of digital twins in analysis, simulation, and replication, the research evaluates their potential to enhance threat modeling across the CPS life-cycle. Insights from the European Cyber Security Organisation (ECSO) Technical Paper on Cybersecurity Scenarios and Digital Twins guide the exploration of their role in threat modeling. The study addresses four research questions: 1. What purposes do digital twins serve in cybersecurity? 2. What benefits do digital twins offer in cybersecurity? 3. How can digital twin technology be leveraged for threat modeling? 4. What advantages can the use of digital twins bring to threat modeling? Our findings reveal that digital twins enhance ICS threat modeling by enabling continuous, dynamic, and autonomous assessment, offering valuable insights for advancing cybersecurity strategies in ICS, CPS, and related domains.', 'DOI': '10.1007/s10207-025-01043-x'}, {'id': 'systematic_review_of', 'title': 'Systematic review of predictive maintenance and digital twin technologies challenges, opportunities, and best practices', 'URL': 'https://peerj.com/articles/cs-1943', 'extra_urls': ['https://peerj.com/articles/cs-1943'], 'type': 'article', 'author': [{'family': 'Wahab', 'given': 'Nur Haninie Abd'}, {'family': 'Hasikin', 'given': 'Khairunnisa'}, {'family': 'Lai', 'given': 'Khin Wee'}, {'family': 'Xia', 'given': 'Kaijian'}, {'family': 'Bei', 'given': 'Lulu'}, {'family': 'Huang', 'given': 'Kai'}, {'family': 'Wu', 'given': 'Xiang'}], 'abstract': 'Background Maintaining machines effectively continues to be a challenge for industrial organisations, which frequently employ reactive or premeditated methods. Recent research has begun to shift its attention towards the application of Predictive Maintenance (PdM) and Digital Twins (DT) principles in order to improve maintenance processes. PdM technologies have the capacity to significantly improve profitability, safety, and sustainability in various industries. Significantly, precise equipment estimation, enabled by robust supervised learning techniques, is critical to the efficacy of PdM in conjunction with DT development. This study underscores the application of PdM and DT, exploring its transformative potential across domains demanding real-time monitoring. Specifically, it delves into emerging fields in healthcare, utilities (smart water management), and agriculture (smart farm), aligning with the latest research frontiers in these areas. Methodology Employing the Preferred Reporting Items for Systematic Review and Meta-Analyses (PRISMA) criteria, this study highlights diverse modeling techniques shaping asset lifetime evaluation within the PdM context from 34 scholarly articles. Results The study revealed four important findings: various PdM and DT modelling techniques, their diverse approaches, predictive outcomes, and implementation of maintenance management. These findings align with the ongoing exploration of emerging applications in healthcare, utilities (smart water management), and agriculture (smart farm). In addition, it sheds light on the critical functions of PdM and DT, emphasising their extraordinary ability to drive revolutionary change in dynamic industrial challenges. The results highlight these methodologies\u2019 flexibility and application across many industries, providing vital insights into their potential to revolutionise asset management and maintenance practice for real-time monitoring. Conclusions Therefore, this systematic review provides a current and essential resource for academics, practitioners, and policymakers to refine PdM strategies and expand the applicability of DT in diverse industrial sectors.'}, {'id': 'a_conceptual_framework', 'title': 'A conceptual framework for supply chain digital twins \u2013 development and evaluation', 'URL': 'https://www.tandfonline.com/doi/full/10.1080/13675567.2024.2324895', 'extra_urls': ['https://www.tandfonline.com/doi/full/10.1080/13675567.2024.2324895'], 'type': 'article', 'author': [{'family': 'Freese', 'given': 'Falk'}, {'family': 'Ludwig', 'given': 'Andr\xe9'}]}, {'id': 'doi_10_1007_978-981-96-7734-4', 'title': 'Sustainable Enterprise Resource Planning', 'URL': 'https://doi.org/10.1007/978-981-96-7734-4', 'type': 'book', 'author': [{'family': 'Anjaria', 'given': 'Kushal'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Springer', 'abstract': 'This book delves into integrating sustainable practices within enterprise resource planning (S-ERP) systems framework, particularly in the context of Industry 4.0. It offers a comprehensive exploration of how S-ERP systems can be developed and implemented to enhance operational efficiency and promote environmental and social sustainability, which is achieved by incorporating cutting-edge technologies such as the internet of things (IoT), artificial intelligence (AI), and cloud computing, which are instrumental in Industry 4.0. Targeted primarily at professionals and academics in business management, information technology, and sustainability, the book will be a crucial resource for those seeking to understand and implement S-ERP solutions. It is particularly beneficial for MBA students, business strategists, ERP consultants, and IT professionals involved in planning, developing, and managing ERP systems.Key topics include the principles of sustainable business practices, the role of digital technologies in enhancing ERP systems, and the challenges and opportunities presented by Industry 4.0. The book also provides practical insights into implementing S-ERP systems, offering case studies and real-world examples to illustrate key concepts. It is thus not just an academic treatise, but a practical guide that addresses the need for a new ERP approach in the digital transformation age. It seeks to equip its readers with the knowledge and tools required to successfully navigate the complexities of modern business environments, emphasising the importance of sustainability in achieving long-term success. In summary, this book is a vital addition to the literature on ERP systems, offering a fresh perspective on how businesses can evolve to meet the demands of the 21st century while maintaining a commitment to sustainability.', 'DOI': '10.1007/978-981-96-7734-4'}, {'id': 'machine_learning_and', 'title': 'Machine learning and internet of things applications in enterprise architectures: Solutions, challenges, and open issues', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13467', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13467'], 'type': 'article', 'author': [{'family': 'Rehman', 'given': 'Zubaida'}, {'family': 'Tariq', 'given': 'Noshina'}, {'family': 'Moqurrab', 'given': 'Syed Atif'}, {'family': 'Yoo', 'given': 'Joon'}, {'family': 'Srivastava', 'given': 'Gautam'}], 'issued': {'date-parts': [[2024]]}, 'abstract': 'The rapid growth of the Internet of Things (IoT) has led to its widespread adoption in various industries, enabling enhanced productivity and efficient services. Integrating IoT systems with existing enterprise application systems has become common practice. However, this integration necessitates reevaluating and reworking current Enterprise Architecture (EA) models and Expert Systems (ES) to accommodate IoT and cloud technologies. Enterprises must adopt a multifaceted view and automate various aspects, including operations, data management, and technology infrastructure. Machine Learning (ML) is a powerful IoT and smart automation tool within EA. Despite its potential, a need for dedicated work focuses on ML applications for IoT services and systems. With IoT being a significant field, analyzing IoT-generated data and IoT-based networks is crucial. Many studies have explored how ML can solve specific IoT-related challenges. These mutually reinforcing technologies allow IoT applications to leverage sensor data for ML model improvement, leading to enhanced IoT operations and practices. Furthermore, ML techniques empower IoT systems with knowledge and enable suspicious activity detection in smart systems and objects. This survey paper conducts a comprehensive study on the role of ML in IoT applications, particularly in the domains of automation and security. It provides an in-depth analysis of the state-of-the-art ML approaches within the context of IoT, highlighting their contributions, challenges, and potential applications.'}, {'id': 'integrated_and', 'title': 'Integrated data-driven and artificial intelligence framework to develop digital twins in distribution system of supply chains: A real industrial case', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0925527325002282', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0925527325002282'], 'type': 'article', 'author': [{'family': 'Ziari', 'given': 'Matineh'}, {'family': 'Taleizadeh', 'given': 'Ata Allah'}], 'abstract': 'The development of digital twins and the application of industry 4.0, Artificial Intelligence (AI), and recent Machine Learning (ML) approaches have significantly advanced supply chain management and garnered considerable attention. The importance of digital twins in the supply chain became specifically clear following the outbreak of the COVID-19 pandemic, demonstrating substantial benefits in risk and disruption management. We propose an integrated framework for developing digital twins in distribution systems for managing demand risks, and it designs a decision support system for data-driven modeling to respond to two scenarios: (1) proactive design for managing future demand risks and (2) reactive design for managing real-time demand risks. This research aims to provide a more comprehensive study compared to previous investigations by designing this conceptual framework for development of digital twin in distribution systems and creating a support system using technical analysis and demand data via Regression algorithm in machine learning based on a real industrial case problem. The results of the current paper contribute to practical actions and research in demand risk management and the discovery of patterns, trends, and potential changes, enhancing both proactive and reactive decision-making. By integrating the visualization of the distribution system, analyzing historical and online demand data, implementing exogenous variables and connecting it to Enterprise Resource Planning (ERP) systems, this approach ensures the resilience and agility of systems, as well as the continuity of business operations in global companies.'}, {'id': 'are_retail_consumers', 'title': 'Are Retail Consumers Willing to Pay for All Circular Products? A Study on Consumer Perception of the Circular Economy in Retail', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1002/bse.4269', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1002/bse.4269'], 'type': 'article', 'author': [{'family': 'Toth-Peter', 'given': 'Agnes'}, {'family': 'Cheema', 'given': 'Sadia'}, {'family': 'Torres de Oliveira', 'given': 'Rui'}, {'family': 'Nguyen', 'given': 'Tam'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'The planetary crisis, stemming from overconsumption and unsustainable production patterns, necessitates a shift towards balanced economic, environmental and social growth. The circular economy presents a promising solution by promoting material recirculation. While its success relies on collaboration among various stakeholders, consumers are crucial for accepting circular economy products and business models. However, despite increasing environmental awareness, the literature shows that many consumers resist purchasing previously used products due to perceived inferiority, risk and low quality, which could hinder the adoption of circular economy products. Understanding consumer behaviour, particularly their willingness to buy and pay for circular economy products, is essential for businesses seeking to promote sustainable consumption and achieve market growth. This study investigates consumer perceptions of circular economy, using simplified terms of reused, recycled and recovered, across 11 product categories through a quantitative survey of 607 Australian respondents. The results indicate that personal financial benefits are prioritised over ecological reasons, and there is variability in perceived product performance across categories. Additionally, price sensitivity and affordability play a key role in consumer decision-making. Notably, while younger and male consumers show a greater inclination to purchase circular economy products, the broader consumer base remains unwilling to pay a premium. These insights can guide businesses and policymakers in developing targeted strategies emphasising price, functionality and quality to enhance consumer acceptance and adoption of circular economy products. We advance theory by demonstrating that consumer decisions are primarily driven by personal financial savings, rather than ecological or social benefits, challenging the prevailing assumption in literature that environmental and social motivations are the key drivers of sustainable consumption, even in developed economies. We also emphasise the need for theories to account for significant variability in perceived product performance across categories when investigating willingness to pay for circular economy products.'}, {'id': 'collaborative_fashion', 'title': 'Collaborative fashion forecasting: Integrating demand and supply-chain forecasting into the fashion industry', 'URL': '#item_20165', 'type': 'article', 'author': [{'family': 'Hur', 'given': 'Eunsuk'}, {'family': 'Sinha', 'given': 'Pammi'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Routledge', 'abstract': "The fashion industry is known for its complex supply-chain systems involving multiple actors and producing trend-sensitive items that are often seasonal or have short product life cycles. Incorrect forecasting can have a direct influence not only on financial losses due to overstocking or understocking but also on the increasing environmental impact of unsold stock, consumer returns and dead stock. It is imperative that forecasters effectively capture consumer demand and expectations to facilitate effective inventory and waste management as well as circular fashion practices. This chapter aims to examine how different actors in the fashion supply chain are involved in the complex fashion system and how this system works in relation to the fashion forecasting timeline. The chapter discusses the challenges of the current supply and demand forecasting process, the role of forecasters in guiding a business's strategic direction and the importance of understanding consumer segmentation for fashion trend forecasting. Finally, the chapter reviews how forecasters support multiple stakeholders in the fashion system, including design, production, buying, merchandising, marketing and sales teams."}, {'id': 'doi_10_1080_13675567_2020_1803246', 'title': 'Machine learning demand forecasting and supply chain performance', 'URL': 'https://doi.org/10.1080/13675567.2020.1803246', 'extra_urls': ['https://doi.org/10.1080/13675567.2020.1803246'], 'type': 'article', 'author': [{'family': 'Feizabadi', 'given': 'Javad'}], 'abstract': 'In many supply chains, firms staged in upstream of the chain suffer from variance amplification emanating from demand information distortion in a multi-stage supply chain and, consequently, their operation inefficiency. Prior research suggest that employing advanced demand forecasting, such as machine learning, could mitigate the effect and improve the performance; however, it is less known what is the extent and magnitude of savings as tangible supply chain performance outcomes. In this research, hybrid demand forecasting methods grounded on machine learning i.e. ARIMAX and Neural Network is developed. Both time series and explanatory factors are feed into the developed method. The method was applied and evaluated in the context of functional product and a steel manufacturer. The statistically significant supply chain performance improvement differences were found across traditional and ML-based demand forecasting methods. The implications for the theory and practice are also presented.', 'DOI': '10.1080/13675567.2020.1803246'}, {'id': 'doi_10_1186_s41072-022-00110-z', 'title': 'Internet of Things enabled real time cold chain monitoring in a container port', 'URL': 'https://doi.org/10.1186/s41072-022-00110-z', 'extra_urls': ['https://doi.org/10.1186/s41072-022-00110-z'], 'type': 'article', 'author': [{'family': 'Cil', 'given': 'Ahmet Yunus'}, {'family': 'Abdurahman', 'given': 'Dini'}, {'family': 'Cil', 'given': 'Ibrahim'}], 'abstract': 'Seaports are regarded as significant actors in global logistics and supply chains since a large part of the cargoes carried over the globe are being processed there. When the cold chain broken down during transport and storage in the ports, the humidity, nutrition, temperature and time conditions to be required for the growth of the bacteria occur, and rapid reproduction occurs and the properties of the products are rapidly deteriorating. It is imperative that especially medicines, some chemical substances and foodstuffs need to be transported without breaking the cold chain in the logistics. The monitoring and control of the temperature and humidity level is important in the time period between the loading of these containers in special areas in ports, the loading of freight in open areas, or the loading of freight on roads and railway carriages. For this reason, precise monitoring and control of the system is vital in the port logistics management.', 'DOI': '10.1186/s41072-022-00110-z'}, {'id': 'unlocking_the_potential', 'title': 'Unlocking the potential of digital twins in supply chains: A systematic review', 'URL': 'https://www.sciencedirect.com/science/article/pii/S2949863524000189', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S2949863524000189'], 'type': 'article', 'author': [{'family': 'Zaidi', 'given': 'Syed Adeel Haneef'}, {'family': 'Khan', 'given': 'Sharfuddin Ahmed'}, {'family': 'Chaabane', 'given': 'Amin'}], 'abstract': 'Digital Twins (DTs) developments are still in the pilot stages of deployment in supply chain management (SCM), and their full integration with real-time synchronization and autonomous decision-making poses many challenges. This paper aims to identify these common challenges and provide a conceptual framework for establishing a Digital Twin (DT) system to improve supply chain management performance. The paper presents a systematic literature review of 129 research papers on DT applications for SCM improvement. The selected papers were reviewed and classified into three categories: manufacturing and production, supply chain, and logistics. The development of digital technologies such as the Internet of Things (IoT), Radio Frequency Identification (RFID) devices, cloud computing, cyber-physical systems (CPSs), cybersecurity (CS), and simulation modeling has increased the opportunities to explore the creation of supply chain DTs. However, there are limitations and various challenges due to the complexity of most systems. The results indicate that DT for SCM should include external links (i.e. suppliers, distributors) and internal links (i.e. procurement, production, logistics) to deal with any disruption through data-driven modeling with real-time synchronization. Based on the review findings, this study proposes a three-layered conceptual framework to improve supply chain management performance. The proposed framework provides future directions for DT research in SCM. It provides a holistic and integrated approach to DT implementation, the common DT technologies, and data analytics techniques for improved supply chain performance.'}, {'id': 'doi_10_1007_978-3-319-38756-7_4', 'title': 'Digital Twin: Mitigating Unpredictable, Undesirable Emergent Behavior in Complex Systems', 'URL': 'https://doi.org/10.1007/978-3-319-38756-7_4', 'type': 'article', 'author': [{'family': 'Grieves', 'given': 'Michael'}, {'family': 'Vickers', 'given': 'John'}], 'issued': {'date-parts': [[2017]]}, 'publisher': 'Springer International Publishing', 'abstract': 'Systems do not simply pop into existence. They progress through lifecycle phases of creation, production, operations, and disposal. The issues leading to undesirable and unpredicted emergent behavior are set in place during the phases of creation and production and realized during the operational phase, with many of those problematic issues due to human interaction. We propose that the idea of the Digital Twin, which links the physical system with its virtual equivalent can mitigate these problematic issues. We describe the Digital Twin concept and its development, show how it applies across the product lifecycle in defining and understanding system behavior, and define tests to evaluate how we are progressing. We discuss how the Digital Twin relates to Systems Engineering and how it can address the human interactions that lead to \u201cnormal accidents.\u201d We address both Digital Twin obstacles and opportunities, such as system replication and front running. We finish with NASA\u2019s current work with the Digital Twin.', 'DOI': '10.1007/978-3-319-38756-7_4'}, {'id': 'doi_10_1108_JFMM-07-2024-0275', 'title': 'Communicating Australian cotton\u2019s sustainable value in the cotton value chain', 'URL': 'https://doi.org/10.1108/JFMM-07-2024-0275', 'extra_urls': ['https://doi.org/10.1108/JFMM-07-2024-0275'], 'type': 'article', 'author': [{'family': 'Mellick', 'given': 'Zoe'}, {'family': 'Street', 'given': 'Paige'}, {'family': 'Payne', 'given': 'Alice Ruth'}], 'abstract': 'This qualitative study explores the dynamics of communicating Australian cotton\u2019s on-farm sustainability to actors throughout global value chains. The research is guided by two objectives: first, to understand how sustainability in Australian cotton is perceived by value chain members, and second, to pinpoint strategies for cultivating a shared understanding of on-farm sustainability within the Australian cotton value chain (ACVC).Employing qualitative research methods, the study conducts interviews with 21 participants from two distinct ACVCs.Effectively communicating the sustainability of clothing fibre demands thoughtful consideration of how knowledge is translated from farmer to retailer. The diverse nature of cotton production practices leads to varied understandings of sustainability, making it challenging to establish a consistent narrative. The study found that clear information and visual storytelling of on-farm practices enhance stakeholders\u2019 understanding. The use of complex technical information was a barrier to effective communication, and there was general scepticism among retailers regarding industry-funded sustainability credentials. These findings underscore the importance of building trust through two-way communication between retailers and farmers.This study highlights the need for more collaborative efforts to foster a shared understanding of sustainability across the value chain. The findings of this study may not be broadly representative of the entire Australian or global cotton industry, but the depth of insights and methodological approach may be applied to other value chains.This research advances the literature on sustainability communication in the context of fashion production and consumption. It takes a unique perspective by focussing on how sustainability is communicated by different stakeholders working with Australian cotton.', 'DOI': '10.1108/JFMM-07-2024-0275'}, {'id': 'doi_10_1007_978-3-030-22018-1_14', 'title': 'Labels in the Textile and Fashion Industry: Communicating Sustainability to Effect Sustainable Consumption', 'URL': 'https://doi.org/10.1007/978-3-030-22018-1_14', 'type': 'article', 'author': [{'family': 'Morris', 'given': 'Jonathan'}, {'family': 'Koep', 'given': 'Lisa'}, {'family': 'Damert', 'given': 'Matthias'}], 'issued': {'date-parts': [[2021]]}, 'publisher': 'Springer International Publishing', 'abstract': 'The textile and fashion industry is associated with numerous ethical problems such as poor labour conditions, low wages, long hours and unsafe working conditions, as well as a range of negative environmental impacts. A key challenge is to reconcile the behavioural impacts across the value chain, from producers and manufacturers to consumers. Achieving real change requires organizational shifts across multiple levels of the textile and fashion value chain, away from focusing on the focal firm but across the entire value chain, as well as overcoming the information and knowledge deficits held by consumers and professionals alike. Awareness and information strategies such as sustainability labelling are a crucial step in promoting sustainable consumption through improved information provision which may facilitate an institutionalized shift towards embedding sustainability criteria into consumer decision-making processes.', 'DOI': '10.1007/978-3-030-22018-1_14'}, {'id': 'can_we_play', 'title': 'Can we play our way to a more circular fashion world? : A quantitative study about the impact of gamification on consumer attitudes and intentions to use C2C apps', 'URL': 'https://urn.kb.se/resolve?urn=urn:nbn:se:umu:diva-197002', 'extra_urls': ['https://urn.kb.se/resolve?urn=urn:nbn:se:umu:diva-197002'], 'type': 'thesis', 'author': [{'family': 'Arnesson', 'given': 'Amanda'}, {'family': 'Westman', 'given': 'Sofia'}], 'issued': {'date-parts': [[2022]]}, 'publisher': 'Ume\xe5 University', 'abstract': 'DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.'}, {'id': 'platform_to', 'title': 'Eco-Gamification Platform to Promote Consumers\u2019 Engagement in the Textile and Clothing Circular Value Chain', 'URL': 'https://www.mdpi.com/2071-1050/15/6/5398', 'extra_urls': ['https://www.mdpi.com/2071-1050/15/6/5398'], 'type': 'article', 'author': [{'family': 'Alves', 'given': 'Lu\xeds'}, {'family': 'Faria', 'given': 'Pedro Miguel'}, {'family': 'Cruz', 'given': 'Estrela Ferreira'}, {'family': 'Lopes', 'given': 'S\xe9rgio Ivan'}, {'family': 'Rosado da Cruz', 'given': 'Ant\xf3nio Miguel'}], 'abstract': 'The textile and clothing (T&amp;C) value chain is one of the most polluting in the world and one that produces the most waste. It is, therefore, important to encourage the circular economy (CE) model in this sector to reduce pollution, mitigate the effects of waste production, and, consequently, increase environmental sustainability. Leveraging end-consumer engagement in a CE mindset in the T&amp;C sector is crucial, as they are the last player in a typical linear value chain. Therefore, a platform that supports and promotes sustainable tasks to manage one\u2019s fashion products, through the use of gamification techniques, can be of utmost importance. In this article, we identify impactful carbon footprint consumer actions and solutions for the T&amp;C consumer phase. After that, we survey gamification frameworks for analyzing techniques, at the system design level, which enable the engagement of the final consumer in the CE process. Then, we select and use one of such frameworks, Gameful Design Heuristics (GDH), for defining the gamification structure needed to implement on a business-to-consumer-to-consumer (B2C2C) context of a circular economy process, linking it to the aforementioned actions and solutions. As result, we present a B2C2C circular business process model for the T&amp;C value chain and propose the design model of a gamified platform for the final consumers, which allows them to register the consumer-to-business (C2B) and consumer-to-consumer (C2C) activities, from the circular value chain\u2019s business process, and benefit from a game-like experience. All the model features have been mapped to the GDH framework heuristics, validating that it is possible to support a set of defined heuristics of applied gamification for promoting CE in the T&amp;C value chain.'}, {'id': 'gamifying_evaluating', 'title': 'Gamifying Green: Evaluating the Impact of Gamification on Zero-Waste Product Use - ProQuest', 'URL': 'https://www.proquest.com/openview/3de02f26fd7ba740b9ec9a5bc194603f/1?pq-origsite=gscholar&amp;cbl=18750&amp;diss=y', 'extra_urls': ['https://www.proquest.com/openview/3de02f26fd7ba740b9ec9a5bc194603f/1?pq-origsite=gscholar&amp;cbl=18750&amp;diss=y'], 'type': 'thesis', 'author': [{'family': 'Bouchillon', 'given': 'Natasha'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Capella University', 'abstract': 'Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.'}, {'id': 'doi_10_1007_s43681-025-00725-5', 'title': 'Transparency requirements across AI legislative acts, frameworks and organizations: shaping a sample transparency card', 'URL': 'https://doi.org/10.1007/s43681-025-00725-5', 'extra_urls': ['https://doi.org/10.1007/s43681-025-00725-5'], 'type': 'article', 'author': [{'family': 'Cousineau', 'given': 'Carter'}, {'family': 'Herger', 'given': 'Nadja'}, {'family': 'Dara', 'given': 'Rozita'}], 'abstract': 'As AI-driven solutions become increasingly common, end users of those systems continue to lack transparency in understanding the AI system\u2019s functionality leading to a lack of trust, and AI systems not reaching their full potential. Our research aims to address this research gap by developing a novel sample transparency card. This transparency card is grounded in key transparency requirements from the prominent AI legislation (the European Union\u2019s (EU) AI Act), the international standards (national institute of standards and technology (NIST) and international organization for standardization (ISO)), and public transparency principles from 25 global organizations. The research follows a 2-phase research approach. First, we analyze the transparency requirements to gain a greater understanding of the legislative and organizational requirements. Second, based on transparency requirements, create common categories and develop a proposed sample transparency card. This research offers a novel contribution by developing a sample transparency card that can be seen by the AI end users and aligns with legislative acts and frameworks, promoting trust in AI systems.', 'DOI': '10.1007/s43681-025-00725-5'}, {'id': 'programming_parametric', 'title': 'GarmentCode: Programming Parametric Sewing Patterns', 'URL': 'https://dl.acm.org/doi/10.1145/3618351', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3618351'], 'type': 'article', 'author': [{'family': 'Korosteleva', 'given': 'Maria'}, {'family': 'Sorkine-Hornung', 'given': 'Olga'}], 'issued': {'date-parts': [[2023]]}, 'abstract': 'Garment modeling is an essential task of the global apparel industry and a core part of digital human modeling. Realistic representation of garments with valid sewing patterns is key to their accurate digital simulation and eventual fabrication. However, little-to-no computational tools provide support for bridging the gap between high-level construction goals and low-level editing of pattern geometry, e.g., combining or switching garment elements, semantic editing, or design exploration that maintains the validity of a sewing pattern. We suggest the first DSL for garment modeling - GarmentCode - that applies principles of object-oriented programming to garment construction and allows designing sewing patterns in a hierarchical, component-oriented manner. The programming-based paradigm naturally provides unique advantages of component abstraction, algorithmic manipulation, and free-form design parametrization. We additionally support the construction process by automating typical low-level tasks like placing a dart at a desired location. In our prototype garment configurator, users can manipulate meaningful design parameters and body measurements, while the construction of pattern geometry is handled by garment programs implemented with GarmentCode. Our configurator enables the free exploration of rich design spaces and the creation of garments using interchangeable, parameterized components. We showcase our approach by producing a variety of garment designs and retargeting them to different body shapes using our configurator. The library and garment configurator are available at https://github.com/maria-korosteleva/GarmentCode.'}, {'id': 'computational_pattern_making', 'title': 'Computational pattern making from 3D garment models', 'URL': 'https://dl.acm.org/doi/10.1145/3528223.3530145', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3528223.3530145'], 'type': 'article', 'author': [{'family': 'Pietroni', 'given': 'Nico'}, {'family': 'Dumery', 'given': 'Corentin'}, {'family': 'Falque', 'given': 'Raphael'}, {'family': 'Liu', 'given': 'Mark'}, {'family': 'Vidal-Calleja', 'given': 'Teresa'}, {'family': 'Sorkine-Hornung', 'given': 'Olga'}], 'issued': {'date-parts': [[2022]]}, 'abstract': 'We propose a method for computing a sewing pattern of a given 3D garment model. Our algorithm segments an input 3D garment shape into patches and computes their 2D parameterization, resulting in pattern pieces that can be cut out of fabric and sewn together to manufacture the garment. Unlike the general state-of-the-art approaches for surface cutting and flattening, our method explicitly targets garment fabrication. It accounts for the unique properties and constraints of tailoring, such as seam symmetry, the usage of darts, fabric grain alignment, and a flattening distortion measure that models woven fabric deformation, respecting its anisotropic behavior. We bootstrap a recent patch layout approach developed for quadrilateral remeshing and adapt it to the purpose of computational pattern making, ensuring that the deformation of each pattern piece stays within prescribed bounds of cloth stress. While our algorithm can automatically produce the sewing patterns, it is fast enough to admit user input to creatively iterate on the pattern design. Our method can take several target poses of the 3D garment into account and integrate them into the sewing pattern design. We demonstrate results on both skintight and loose garments, showcasing the versatile application possibilities of our approach.'}, {'id': 'doi_10_1093_jcde_qwaf065', 'title': 'Real-to-sim high-resolution cloth modeling: Physical parameter optimization using particle-based simulation with robot manipulation data', 'URL': 'https://doi.org/10.1093/jcde/qwaf065', 'extra_urls': ['https://doi.org/10.1093/jcde/qwaf065'], 'type': 'article', 'author': [{'family': 'Yoon', 'given': 'Kang-il'}, {'family': 'Lim', 'given': 'Soo-Chul'}], 'abstract': 'This study proposes an optimized real-to-sim model that reflects the physical properties of real cloth to replicate realistic cloth behavior in simulation environments. While previous research has used data-driven or physics-guided methods to build simulation environments, those approaches are significantly limited due to reliance on data and restricted accuracy. In this study, we collect data from real robots manipulating cloth samples of various size and material, and develop a particle system-based cloth simulation model. By optimizing parameters based on real-world data, such as stretching, bending, friction, and damping, the simulation model reproduces the shapes of real cloth. In consequence, in comparison to previous studies that used physical parameter estimation, the proposed methodology demonstrates accuracy and generalization performance. Notably, the model maintains consistent similarity in unseen tasks, proving its adaptability across diverse tasks. This study presents a crucial step towards enhancing the practical applicability of simulation-based robotic learning and improving robot abilities to manipulate deformable objects.', 'DOI': '10.1093/jcde/qwaf065'}, {'id': 'clothed', 'title': 'PICA: Physics-Integrated Clothed Avatar', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11180929', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11180929'], 'type': 'article', 'author': [{'family': 'Peng', 'given': 'Bo'}, {'family': 'Tao', 'given': 'Yunfan'}, {'family': 'Zhan', 'given': 'Haoyu'}, {'family': 'Guo', 'given': 'Yudong'}, {'family': 'Zhang', 'given': 'Juyong'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'We introduce PICA, a novel representation for high-fidelity animatable clothed human avatars with physics-plausible dynamics, even for loose clothing. Previous neural rendering-based representations of animatable clothed humans typically employ a single model to represent both the clothing and the underlying body. While efficient, these approaches often fail to represent complex garment dynamics, leading to incorrect deformations and noticeable rendering artifacts, especially for sliding or loose garments. Furthermore, most previous works represent garment dynamics as pose-dependent deformations and facilitate novel pose animations in a data-driven manner. This often results in outcomes that do not faithfully represent the mechanics of motion and are prone to generating artifacts in out-of-distribution poses. To address these issues, we employ two individual 2D Gaussian Splatting (2DGS) models with different deformation characteristics, modeling the human body and clothing separately. This distinction allows for better handling of their respective motion characteristics. With this representation, we integrate a graph neural network (GNN)-based clothing physics simulation module to ensure a better representation of clothing dynamics. Our method, through its carefully designed features, achieves high-fidelity rendering of clothed human bodies in complex and novel driving poses, outperforming previous methods under the same settings. The source code will be available on our project page: https://ustc3dv.github.io/PICA/'}, {'id': 'doi_10_1177_00405175251358497', 'title': 'Example-based approach for automatic garment pattern generation', 'URL': 'https://doi.org/10.1177/00405175251358497', 'extra_urls': ['https://doi.org/10.1177/00405175251358497'], 'type': 'article', 'author': [{'family': 'Hong', 'given': 'Roujia'}, {'family': 'Zhang', 'given': 'Yarui'}, {'family': 'Zhang', 'given': 'Qi'}, {'family': 'Qian', 'given': 'Diqing'}, {'family': 'Jin', 'given': 'Yao'}, {'family': 'Zhang', 'given': 'Huaxiong'}, {'family': 'He', 'given': 'Lili'}], 'abstract': 'This paper proposes an example-based method for automated garment pattern generation, addressing challenges in craftsmanship standardization and geometric fidelity in existing 2D pattern techniques. This approach integrates graph neural network (GNN)-based garment panel segmentation with manufacturing-constrained flat pattern modeling to establish a seamless bridge between digital fashion design and traditional garment craftsmanship. More specifically, a sparse graph transformer is employed to efficiently segment 3D garment meshes into individual panels. Leveraging the technique of virtual node sparsification, this method remarkably reduces the computational complexity, enabling a more efficient segmentation process. To ensure its practical viability in industrial applications, the methodology incorporates two critical types of manufacturing constraints. Symmetry constraints are imposed on the internal boundaries of panels and seams, while boundary constraints are applied to guarantee smooth and production-friendly edges. A hybrid boundary optimization strategy, which combines geometric constraints with B-spline fitting, is then utilized to refine the generated 2D patterns. Comprehensive experimental evaluations demonstrate the superiority of the proposed method. On a self-constructed dataset, it achieves an impressive 99.99% segmentation accuracy, and on cross-domain models, the accuracy reaches 99.91%. Moreover, compared with conventional approaches, the training time is reduced by 34%. For dresses and T-shirts, the generated patterns exhibit 100% structural similarity to template patterns, significantly outperforming the compared methods. Although the proposed method results in a slightly higher stretching ratio (ranging from 0.0157 to 0.0378) compared with the baseline methods (0.0112\u20130.0189), it ensures well-organized panel layouts and smooth boundaries, strictly adhering to industry standards and effectively preventing cutting errors caused by irregular shapes. By maintaining regular panel layouts and enforcing geometric constraints explicitly, the generated patterns preserve high fidelity during 3D-to-2D flattening while meeting industrial production standards.', 'DOI': '10.1177/00405175251358497'}, {'id': 'doi_10_1177_00405175251335188', 'title': 'Deep learning for 3D garment generation: A review', 'URL': 'https://doi.org/10.1177/00405175251335188', 'extra_urls': ['https://doi.org/10.1177/00405175251335188'], 'type': 'article', 'author': [{'family': 'Sun', 'given': 'Yuexin'}, {'family': 'Hao', 'given': 'Zhenhua'}, {'family': 'Wang', 'given': 'Zhaohui'}, {'family': 'Jin', 'given': 'Jiping'}, {'family': 'Ye', 'given': 'Qinwen'}, {'family': 'Lyu', 'given': 'Yingrui'}], 'abstract': '3D garment models enhance the consumer experience by enabling virtual trying-on and personalized customization. Additionally, they streamline design and manufacturing processes, reduce resource waste, and drive the garment industry toward greater digitalization and sustainability. Nevertheless, the complexities of 3D garment modeling have impeded its widespread adoption. Recent significant advances in deep learning have catalyzed improvements in 3D garment model generation. This technology circumvents traditional time-consuming 3D modeling processes, enabling the direct generation of 3D garment models, and has garnered substantial attention. This paper presents a comprehensive and systematic review of advances in deep learning for 3D garment generation. It commences with an introduction to essential preliminaries, encompassing data representations, generation objectives and tasks, generative models, datasets, and evaluation methods. The review categorizes works in 3D garment generation into three distinct areas: mesh, texture, and pattern generation, providing an in-depth analysis of the most recent and advanced methods. Furthermore, the paper examines applications of 3D garment generation, discusses current challenges, and proposes directions for future research, offering valuable insights for continued exploration in this rapidly expanding field.', 'DOI': '10.1177/00405175251335188'}, {'id': 'doi_10_1007_s10489-025-06596-x', 'title': 'ClotheDreamer: Text-guided garment generation with 3D gaussians', 'URL': 'https://doi.org/10.1007/s10489-025-06596-x', 'extra_urls': ['https://doi.org/10.1007/s10489-025-06596-x'], 'type': 'article', 'author': [{'family': 'Liu', 'given': 'Yufei'}, {'family': 'Tang', 'given': 'Junshu'}, {'family': 'Zheng', 'given': 'Chu'}, {'family': 'Zhu', 'given': 'Junwei'}, {'family': 'Wang', 'given': 'Chengjie'}, {'family': 'Huang', 'given': 'Dongjin'}], 'abstract': 'High-fidelity 3D garment synthesis from text is desirable yet challenging for digital avatar creation. Recent diffusion-based approaches via Score Distillation Sampling (SDS) have enabled new possibilities but either intricately couple with human body or struggle to reuse. We introduce ClotheDreamer, a 3D Gaussian-based method for generating wearable, production-ready 3D garment assets from text prompts. We propose a novel representation Disentangled Clothe Gaussian Splatting (DCGS) to enable separate optimization. DCGS represents clothed avatar as one gaussian model but freezes body Gaussian splats. To enhance quality and completeness, we incorporate bidirectional SDS to supervise clothed avatar and garment RGBD renderings respectively with pose conditions and propose a new pruning strategy for loose clothing. Our approach can also support custom clothing templates as input. Benefiting from our design, the synthetic 3D garment can be easily applied to virtual try-on and support physically accurate animation. Extensive experiments showcase our method\u2019s superior and competitive performance. Our project page is at https://ggxxii.github.io/clothedreamer.', 'DOI': '10.1007/s10489-025-06596-x'}, {'id': 'autoregressively_sewing', 'title': 'DressCode: Autoregressively Sewing and Generating Garments from Text Guidance', 'URL': 'https://dl.acm.org/doi/10.1145/3658147', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3658147'], 'type': 'article', 'author': [{'family': 'He', 'given': 'Kai'}, {'family': 'Yao', 'given': 'Kaixin'}, {'family': 'Zhang', 'given': 'Qixuan'}, {'family': 'Yu', 'given': 'Jingyi'}, {'family': 'Liu', 'given': 'Lingjie'}, {'family': 'Xu', 'given': 'Lan'}], 'issued': {'date-parts': [[2024]]}, 'abstract': "Apparel's significant role in human appearance underscores the importance of garment digitalization for digital human creation. Recent advances in 3D content creation are pivotal for digital human creation. Nonetheless, garment generation from text guidance is still nascent. We introduce a text-driven 3D garment generation framework, DressCode, which aims to democratize design for novices and offer immense potential in fashion design, virtual try-on, and digital human creation. We first introduce SewingGPT, a GPT-based architecture integrating cross-attention with text-conditioned embedding to generate sewing patterns with text guidance. We then tailor a pre-trained Stable Diffusion to generate tile-based Physically-based Rendering (PBR) textures for the garments. By leveraging a large language model, our framework generates CG-friendly garments through natural language interaction. It also facilitates pattern completion and texture editing, streamlining the design process through user-friendly interaction. This framework fosters innovation by allowing creators to freely experiment with designs and incorporate unique elements into their work. With comprehensive evaluations and comparisons with other state-of-the-art methods, our method showcases superior quality and alignment with input prompts. User studies further validate our high-quality rendering results, highlighting its practical utility and potential in production settings. Our project page is https://IHe-KaiI.github.io/DressCode/."}, {'id': 'garment_pattern_generation', 'title': 'Garment pattern generation from image data', 'URL': 'https://patents.google.com/patent/US12198290B1/en', 'extra_urls': ['https://patents.google.com/patent/US12198290B1/en'], 'type': 'patent'}, {'id': 'image_generation', 'title': 'GenAI-Driven Image Generation Pipeline for Sustainable Garment Design and Waste Reduction in Fashion Production', 'URL': 'https://ojs.aaai.org/index.php/AAAI-SS/article/view/36056', 'extra_urls': ['https://ojs.aaai.org/index.php/AAAI-SS/article/view/36056'], 'type': 'article', 'author': [{'family': 'Ghori', 'given': 'Ilham'}, {'family': 'Karim', 'given': 'Kayvan'}, {'family': 'Alkawadri', 'given': 'Dima'}], 'abstract': 'The fashion industry\u2019s linear production model generates significant pre-consumer textile waste, especially during pattern cutting. In response to the environmental impact of fashion consumption, strategies such as reuse, recycling, and refashioning aim to divert textiles from landfills and promote sustainable practices. However, challenges in the textile sector\u2014such as raw material variability and complex manufacturing\u2014require more targeted solutions. Recent studies have identified Artificial Intelligence (AI) as a promising tool to enhance sustainability, streamline production, and enable personalised design. One such advancement is Generative AI (GenAI), which supports applications like virtual try-ons, fabric-to-garment transformations, and multimodal garment design via tools such as FashionGAN, StyleGAN, and Latent Diffusion Models. Despite these developments, current image generation methods struggle with preserving fabric detail and structural accuracy. This research proposes an image generation pipeline that accurately reflects specific fabric textures and visual attributes, offering designers greater creative control while reducing the need for physical samples\u2014thereby minimising process waste. The system is implemented using ComfyUI and LoRA-enhanced Stable Diffusion 1.5 models to overcome limitations found in existing methods. To evaluate performance, quantitative metrics such as FID, KID, SSIM, LPIPS, and CLIP-S were used to assess visual quality, structural similarity, and semantic alignment. A qualitative comparison was also conducted to evaluate fabric texture preservation and prompt consistency across models. Among the tested models, Realistic Vision v5.1 delivered the best results across most metrics and is recommended for photorealistic applications in sustainable fashion. DreamShaper v8 excelled in preserving fabric texture, while MajicMix v5 produced stylised outputs more suitable for conceptual design stages. This study aims to empower fashion designers with a flexible and sustainable design model, to reduce waste, accelerate prototyping, and explore AI-driven innovation in digital fashion.'}, {'id': 'doi_10_1108_IJCST-05-2024-0104', 'title': 'Development of garment design system using random polygon pattern generator', 'URL': 'https://doi.org/10.1108/IJCST-05-2024-0104', 'extra_urls': ['https://doi.org/10.1108/IJCST-05-2024-0104'], 'type': 'article', 'author': [{'family': 'Oh', 'given': 'Jihyun'}, {'family': 'Kim', 'given': 'Sungmin'}], 'abstract': 'This study aims to develop a random polygon garment pattern generator and a drape simulation system to automate the garment design process.Garments were categorized into four groups based on the geometric features of the human body. Garment patterns in each group consisted of basic points, and the patterns were automatically placed, sewn and simulated around the body in three-dimensional space. Additional pattern manipulation functions were developed to modify the shapes of patterns by adding darts and cuts, either manually or randomly.Users can produce new designs they had not considered before using the random manipulation functions. Since the three-dimensional simulation process is automated, users can focus solely on the design process.Garments composed of multiple layers were not considered.This system differs from existing clothing computer-aided design systems in that even users lacking prior knowledge of garment design can generate various examples. It can help users understand the relationship between 2D patterns and 3D garments without the need for a pattern drafting process.', 'DOI': '10.1108/IJCST-05-2024-0104'}, {'id': 'doi_10_1007_s00371-025-03876-y', 'title': 'Controllable fashion rendering via brownian bridge diffusion model with latent sketch encoding', 'URL': 'https://doi.org/10.1007/s00371-025-03876-y', 'extra_urls': ['https://doi.org/10.1007/s00371-025-03876-y'], 'type': 'article', 'author': [{'family': 'Wang', 'given': 'Zengmao'}, {'family': 'Li', 'given': 'Jituo'}, {'family': 'Gao', 'given': 'Wei'}], 'abstract': 'Generating fashion designs from sketches and textures can significantly enhance design efficiency. While existing image generation frameworks can produce desired images based on language or sketch prompts, generating fine-grained fashion designs, especially with intricate sketches and textures, remains challenging. This necessitates models that can comprehend features at various levels within sketches and texture images. In this work, we propose FashionBBDM, a controllable fashion design framework built upon the Brownian Bridge Diffusion Model. FashionBBDM generates fashion designs from either existing or synthesized textures without relying on textual prompts. Our model employs a pre-trained UNet as the backbone network and introduces a latent space sketch encoder to extract multi-scale features from conditional images. Unlike traditional diffusion models, our image generation process commences from conditional images rather than Gaussian noise. In each generation iteration, the encoder output is integrated with the backbone network features to predictively output the next step, culminating in high-quality fashion design images. We quantitatively and qualitatively evaluate FashionBBDM using clothing and shoe datasets, demonstrating its superior conditional generation performance compared to state-of-the-art methods. Ablation experiments and result analyses further underscore the effectiveness of our framework\u2019s various components. Code and trained models are available on https://github.com/wzm206/FashionBBDM.', 'DOI': '10.1007/s00371-025-03876-y'}, {'id': 'doi_10_1108_IJCST-05-2024-0115', 'title': 'Fashion-tile: a tiled clothing image generation model based on improved conditional generative adversarial network', 'URL': 'https://doi.org/10.1108/IJCST-05-2024-0115', 'extra_urls': ['https://doi.org/10.1108/IJCST-05-2024-0115'], 'type': 'article', 'author': [{'family': 'Gu', 'given': 'Meihua'}, {'family': 'Chu', 'given': 'Yalu'}, {'family': 'Dong', 'given': 'Xiaoxiao'}], 'abstract': 'Clothing retrieval and matching tasks require the use of model clothing images as input. Due to the limitation of shooting postures and angles, direct using of model images for clothing retrieval or matching often faces many challenges. In view of this, this paper aims to propose a novel tiled clothing image generation model based on improved conditional generative adversarial network (GAN) that can generate clear and accurate tiled clothing images from selected model images.Aiming at the problems of local information loss and overall structure inaccuracy in tile clothing image generation, this paper optimizes pix2pixHD network model from three aspects: using spatial transformer network (STN) for spatial invariance optimization, using atrous spatial pyramid pooling (ASPP) for feature extraction optimization, using self-attention (SA) for global context information acquisition optimization. The improved network model is called fashion-tile, which can improve the quality and fidelity of tile clothing image generation.The experimental results show that the proposed method is obviously superior to the existing methods not only in the evaluation metrics, but also in the generating clothing image quality and fidelity. The peak signal-to-noise ratio (PSNR) value is increased by at least 6.6%, the structural similarity (SSIM) value is increased by at least 2.1%, and the Fr\xe9chet inception distance (FID) value is reduced by at least 8.6% on the person2cloth dataset.This work generates high-quality tiled clothing images that enhance the preservation of clothing details and structures, providing consumers with a clearer and more realistic visual experience, thereby increasing shopping satisfaction and purchase intention. With continuous technological advancements and deeper application, the proposed method is expected to play a greater role in the future of clothing e-commerce, offering consumers a richer and more authentic shopping experience.The proposed method provides an effective solution for generating tiled clothing from model images, which will help to improve the accuracy of subsequent clothing retrieval and matching, and help to enhance the consumers shopping experience and effectively promote sales.', 'DOI': '10.1108/IJCST-05-2024-0115'}, {'id': 'doi_10_1080_21650349_2025_2529167', 'title': 'Qualitative-empirical insights into generative AI for textile design in the fashion design process', 'URL': 'https://doi.org/10.1080/21650349.2025.2529167', 'extra_urls': ['https://doi.org/10.1080/21650349.2025.2529167'], 'type': 'article', 'author': [{'family': 'Wu', 'given': 'Xiaopei'}, {'family': 'Li', 'given': 'Li'}], 'abstract': 'With the popularization of generative AI, its application in fashion design has become a heavily explored area. However, despite this trend, existing studies of AI applications in fashion design have predominantly concentrated on addressing style attributes, and given less attention toward textile attributes and real-world practical implications. This indicates an opportunity to explore the practical industry application of generative AI specifically toward the textile design component of the fashion design process. This study aims fill this gap by setting out to empirically evaluate the potential value of using generative AI to create textile designs in the fashion design process. It addresses this objective by conducting a series of qualitative semi-structured interviews with 10 fashion industry professionals. Through thematic analysis of the interviews, this study uncovers the potential advantages and obstacles associated with implementing generative AI for textile design in the fashion industry. The outcome of this study sheds light on the potential benefits and barriers of integrating generative AI as a creative tool to facilitate textile design in the fashion design process.', 'DOI': '10.1080/21650349.2025.2529167'}, {'id': 'doi_10_1093_jcde_qwaf037', 'title': 'StitchingNet and deep transfer learning method for sewing stitch defect detection', 'URL': 'https://doi.org/10.1093/jcde/qwaf037', 'extra_urls': ['https://doi.org/10.1093/jcde/qwaf037'], 'type': 'article', 'author': [{'family': 'Jung', 'given': 'Woo-Kyun'}, {'family': 'Kang', 'given': 'Jingu'}, {'family': 'Kwon', 'given': 'Woojin'}, {'family': 'Kim', 'given': 'Hyungjung'}], 'abstract': 'The clothing manufacturing industry has been slow to adopt new technologies due to its labor-intensive nature, resulting in persistent defect rates averaging around 10%. Deep learning models offer a promising solution for automated sewing defect detection, but their effectiveness relies heavily on large training datasets. This study addresses this challenge by introducing StitchingNet, a comprehensive dataset comprising over 14.5K images of sewing stitches categorized into normal and ten different defect classes. The dataset covers diverse sewing conditions by incorporating eleven fabric-thread combinations. Furthermore, we propose a novel deep transfer learning method that leverages pre-trained deep learning models, including both convolutional neural networks and vision transformers. This method employs a two-stage approach: wide-screening to identify promising candidate models, followed by systematic fine-tuning to optimize their performance for sewing defect detection. Implementing the deep transfer learning method with StitchingNet and evaluating it through on-site feasibility testing and Grad-CAM visualization, we demonstrate that the fine-tuned MobileNetV1-S.C model achieves exceptional performance with an F1-score of 0.99. This highlights the effectiveness of our proposed dataset and deep transfer learning method in developing high-performing models for sewing defect detection, achieving superior results in terms of both accuracy (F1-score) and speed (inference time).', 'DOI': '10.1093/jcde/qwaf037'}, {'id': 'artistic_fashion', 'title': 'FS-control: Artistic fashion design with discriminated and conditional diffusion model', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0097849325001451', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0097849325001451'], 'type': 'article', 'author': [{'family': 'Li', 'given': 'Hang'}, {'family': 'Wu', 'given': 'Jionghang'}, {'family': 'Chen', 'given': 'Zhengkui'}, {'family': 'Xu', 'given': 'Weiwei'}, {'family': 'He', 'given': 'Lili'}], 'abstract': 'Deep learning-driven approaches to image-based fashion design have garnered significant attention in recent years. As a burgeoning area within the field, integrating fashion design with reference styles from non-fashion domains has become a focus of scholarly investigation. However, current methods for style transfer face notable challenges. These include the absence of representative fashion-guided samples and the substantial discrepancies between the fashion source domain and the reference style domain. Such limitations frequently compromise the structural coherence of generated outputs, leading to results that lack realism and fail to meet practical application standards. To mitigate these issues, we propose an unsupervised generative framework, FS-Control. This framework synthesizes diffusion models, GANs, and ControlNet to ensure structural fidelity and effective style-aware transfer across significant domain differences. ControlNet is utilized to explicitly regulate the structural features of the source fashion item, while a foreground mask is incorporated to bridge the domain gap between the fashion item and the style image. A specialized discriminator is employed, trained to differentiate between real and fake samples within the latent space. This discriminator guides the generative process, ensuring effective style transfer from a single style image to the fashion item while preserving its structural integrity. Extensive qualitative and quantitative analyses, supported by comprehensive ablation studies, demonstrate the effectiveness of our approach. The results consistently show that our method outperforms existing baseline models, achieving a superior balance between content fidelity and authentic style transfer.'}, {'id': 'doi_10_1177_00405175241279976', 'title': 'AI-driven computational creativity in fashion design: a review', 'URL': 'https://doi.org/10.1177/00405175241279976', 'extra_urls': ['https://doi.org/10.1177/00405175241279976'], 'type': 'article', 'author': [{'family': 'Wu', 'given': 'Jennifer Xiaopei'}, {'family': 'Li', 'given': 'Li'}], 'abstract': 'The emergence of text-to-image generative AI tools has garnered significant attention, particularly in creative design applications. This review article explores the field of AI-driven computational creativity, which has witnessed advancements in computational methods, ranging from traditional programming-based techniques to machine learning algorithms, and now to deep learning models. These deep learning models, including the recent text-to-image generative AI tools, have demonstrated impressive capabilities in creative content generation. While previous studies have examined the application of AI in the fashion industry, this review aims to provide a unique perspective. First, it presents AI-driven creativity within the framework of computational creativity, offering historical context. Second, it focuses specifically on the creative design applications in the fashion industry, rather than other aspects such as retail or supply chain. Lastly, it evaluates the outcomes of these studies from the perspective of industry fashion designers, considering the creative and practical value, instead of solely focusing on technical and theoretical performance from a computer science standpoint. By incorporating these distinct perspectives, this review contributes to the understanding of AI applications in fashion design and highlights their relevance in the creative domain.', 'DOI': '10.1177/00405175241279976'}, {'id': 'an_immersive', 'title': 'Made-In: An immersive human-in-the-loop analytics platform for enhancing creative processes in fashion', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1077314225001778', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1077314225001778'], 'type': 'article', 'author': [{'family': 'Balloni', 'given': 'Emanuele'}, {'family': 'Pietrini', 'given': 'Rocco'}, {'family': 'Sasso', 'given': 'Michele'}, {'family': 'Frontoni', 'given': 'Emanuele'}, {'family': 'Paolanti', 'given': 'Marina'}], 'abstract': 'The fashion industry is undergoing a digital transformation, driven by growing demands for sustainability, personalization and immersive experiences. In this paper, we present Made-In (Multimodal and Collaborative Artificial Intelligence for the Design of Inclusive and Sustainable Fashion): an immersive, human-in-the-loop analytics system designed to support fashion professionals in exploring, comparing and contextualizing product data across digital and social platforms. Unlike generative or simulation-based approaches, Made-In provides creative decision support by aggregating real-world data from luxury brand websites and social media. This enables designers and merchandisers to make informed, context-aware choices. The system comprises three core modules: a 3D configurator for visualizing product assortments; a collection grid interface for the comparative analysis of e-commerce data; and a social media trend detector based on deep learning pipelines for image classification, object detection and color clustering. Two curated datasets, one derived from Instagram and the other from fashion e-tailers, provide the system with analytics. A user study with domain experts confirms the platform\u2019s usability and relevance for trend forecasting, sustainability evaluation and visual merchandising strategy. The results demonstrate that Made-In effectively bridges the gap between data analytics and human creativity in fashion, offering a scalable solution that aligns with EU goals for digital sustainability and inclusivity.'}, {'id': 'multimodal_enhancement', 'title': 'MEF-GD: Multimodal Enhancement and Fusion Network for Garment Designer', 'URL': 'https://ieeexplore.ieee.org/abstract/document/11145096', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/11145096'], 'type': 'article', 'author': [{'family': 'Song', 'given': 'Dan'}, {'family': 'Zhou', 'given': 'Juan'}, {'family': 'Zeng', 'given': 'Jianhao'}, {'family': 'Tian', 'given': 'HongShuo'}, {'family': 'Zheng', 'given': 'Bolun'}, {'family': 'Kang', 'given': 'Rongbao'}, {'family': 'Liu', 'given': 'An-An'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'In recent years, with advancements in generative models, an increasing number of garment design methods have been proposed. A generative model capable of generating garment images from text and sketches can provide designers with valuable visual references and creative inspiration to aid in the design process. Existing multimodal garment design methods face the challenge of lacking precise control over the generated results in relation to both sketches and text. In this paper, we propose Multimodal Enhancement and Fusion Network for Garment Design (MEF-GD). Our model inputs image conditions into Stable Diffusion based on ControlNet. On one hand, directly inputting image conditions can lead to feature forgetting, defined as the phenomenon in deep neural networks where previously learned feature representations are lost. To address this issue, we propose a multiple feature injection module to more effectively enhance image condition features. On the other hand, ControlNet fuses control features into Stable Diffusion through pointwise addition, which ignores the interaction between multimodal features and results in the fused features being biased towards the control features, overlooking Stable Diffusion features. To address this limitation, we introduce content-guided attention for more effective feature fusion and improve the expression of text features. Additionally, existing datasets often contain vague textual descriptions of garments. It is difficult to train the model on such a dataset to learn accurate alignment between generated image and the textual descriptions. To address this issue, we have designed a multimodal large model text optimization module to improve the quality and clarity of text generation. Compared to existing multimodal garment design methods, MEF-GD achieves more effective alignment with both textual and sketch-based inputs in generating garment images. Compared to MGD, MEF-GD achieves a decrease of 2.44 in FID and an increase of 0.83 in CLIP Score on Multi-VITON-HD dataset. The code will be available at https://github.com/fengyun691340/MEF-GD.'}, {'id': 'collaborative_garment_design', 'title': 'Collaborative garment design through group chatting with generative industrial large models', 'URL': 'https://www.sciencedirect.com/science/article/pii/S1474034625002599', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S1474034625002599'], 'type': 'article', 'author': [{'family': 'Rachana Harish', 'given': 'Arjun'}, {'family': 'Yuan', 'given': 'Zhaolin'}, {'family': 'Li', 'given': 'Ming'}, {'family': 'Yang', 'given': 'Hongxia'}, {'family': 'Huang', 'given': 'George Q.'}], 'abstract': 'The collaborative garment designing lifecycle involves stages such as designing, styling, and patterning. Some of these stages can be partially or fully automated using industrial large models (LMs), such as generative and large language models. The key to quick and cost-effective order fulfillment is the orchestration of group interactions, or a group chat, between the stakeholders and LMs in garment design. However, certain unaddressed aspects, such as knowledge retention, generalization, and complexity of group interaction, are critical to realizing group chat for garment design. This study proposes a framework called ChatFashion for group chat in garment design. Transformer, a core construct of the proposed framework, orchestrates interaction among stakeholders and industrial LMs. It undergoes an evolution with the intelligence it picks up from its interaction with diverse stakeholders and industrial LMs, allowing it to act as a one-stop solution for multidisciplinary design needs. This study contributes to theory in the following aspects. First, it proposes transformers to eliminate concerns about knowledge retention by industrial LMs. Second, while other studies focus on the benefits of industrial LMs to simplify individual stages in garment design, this study introduces the design and demonstration of a ChatFashion framework for collaborative garment designing using industrial LMs. Finally, this study advances the literature on prompt engineering of industrial LMs by utilizing collaborative learning (or models learning from each other) to capture and orchestrate the group chat among stakeholders, signifying its practicality and value for research in garment design.'}, {'id': 'fashion', 'title': 'DiffFashion: Reference-Based Fashion Design With Structure-Aware Transfer by Diffusion Models', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10261222', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10261222'], 'type': 'article', 'author': [{'family': 'Cao', 'given': 'Shidong'}, {'family': 'Chai', 'given': 'Wenhao'}, {'family': 'Hao', 'given': 'Shengyu'}, {'family': 'Zhang', 'given': 'Yanting'}, {'family': 'Chen', 'given': 'Hangyue'}, {'family': 'Wang', 'given': 'Gaoang'}], 'issued': {'date-parts': [[2024]]}, 'abstract': 'Image-based fashion design with AI techniques has attracted increasing attention in recent years. We focus on the reference-based fashion design task, where we aim to combine a reference appearance image and a clothing image to generate a new fashion clothing image. Although existing diffusion-based image translation methods have enabled flexible style transfer, it is often difficult to transfer the appearance of the image realistically during reverse diffusion. When the referenced appearance domain greatly differs from the source domain, it often leads to the collapse in the translation. To tackle this issue, we present a novel diffusion model-based unsupervised structure-aware transfer method, namely DiffFashion. Our method is free of model tuning and structure-preserving and has high flexibility in transferring from images with large domain gaps. Specifically, based on the optimal transport properties, we keep a shared latent across the clothing image and reference appearance image to bridge the gap between the two domains in the denoising process, and the latent of the reference image is gradually adapted to the clothing domain. Simultaneously, the structure is transferred from the source clothing to the output fashion image with mixed guidance, including pre-trained Vision Transformer (ViT) guidance and a foreground mask guidance, to further preserve the structure and appearance semantics from source and reference images. Our experimental results show that the proposed method outperforms state-of-the-art baseline models, generating more realistic images in the fashion design task.'}, {'id': 'display_your', 'title': 'FashionGAN: Display your fashion design using Conditional Generative Adversarial Nets', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13552', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13552'], 'type': 'article', 'author': [{'family': 'Cui', 'given': 'Y. R.'}, {'family': 'Liu', 'given': 'Q.'}, {'family': 'Gao', 'given': 'C. Y.'}, {'family': 'Su', 'given': 'Z.'}], 'issued': {'date-parts': [[2018]]}, 'abstract': 'Virtual garment display plays an important role in fashion design for it can directly show the design effect of the garment without having to make a sample garment like traditional clothing industry. In this paper, we propose an end-to-end virtual garment display method based on Conditional Generative Adversarial Networks. Different from existing 3D virtual garment methods which need complex interactions and domain-specific user knowledge, our method only need users to input a desired fashion sketch and a specified fabric image then the image of the virtual garment whose shape and texture are consistent with the input fashion sketch and fabric image can be shown out quickly and automatically. Moreover, it can also be extended to contour images and garment images, which further improves the reuse rate of fashion design. Compared with the existing image-to-image methods, the quality of images generated by our method is better in terms of color and shape.'}, {'id': 'ai_assisted_fashion', 'title': 'AI Assisted Fashion Design: A Review', 'URL': 'https://ieeexplore.ieee.org/abstract/document/10223039', 'extra_urls': ['https://ieeexplore.ieee.org/abstract/document/10223039'], 'type': 'article', 'author': [{'family': 'Guo', 'given': 'Ziyue'}, {'family': 'Zhu', 'given': 'Zongyang'}, {'family': 'Li', 'given': 'Yizhi'}, {'family': 'Cao', 'given': 'Shidong'}, {'family': 'Chen', 'given': 'Hangyue'}, {'family': 'Wang', 'given': 'Gaoang'}], 'issued': {'date-parts': [[2023]]}, 'abstract': 'This review explores the integration of enhanced personalization and seamless multimodal interfaces in the field of fashion design and recommendation. We examine the increasing demand for personalized fashion experiences and the potential of multimodal interfaces in facilitating effective communication between designers and users. By leveraging user preferences, body measurements, and style choices, artificial intelligence (AI) systems can deliver highly personalized fashion recommendations. The integration of various input modalities, including text, images and sketches, enables designers and users to communicate their design ideas with ease. The primary results highlight the transformative potential of enhanced personalization and seamless multimodal interfaces, empowering designers and consumers to co-create unique and personalized designs. This paradigm shift fosters a deeper level of engagement and creativity within the fashion industry. Embracing this advancement unlocks unprecedented opportunities for designers, brands, and consumers, ushering in a new era of innovation and creativity in fashion design.'}, {'id': 'doi_10_1080_00405000_2023_2236320', 'title': 'Textronics: a review of their technological aspects and applications', 'URL': 'https://doi.org/10.1080/00405000.2023.2236320', 'extra_urls': ['https://doi.org/10.1080/00405000.2023.2236320'], 'type': 'article', 'author': [{'family': 'Younes', 'given': 'Basel'}], 'abstract': 'The advancement of smart sensors, wireless communication technologies, embedded system and Nano-technologies makes Textronics possible to develop smart textiles to monitor activities in modern applications; in addition to form a significant of Internet of Things (IoT) by connecting smart electronic textiles securely for regular applications such as healthcare, sports, automobile, and defense. This paper reviews the recent advances in E-textiles and smart textile and Textronics, and identifies the relationship between Textronics and mechatronics, and nano-technologies, soft computing and signal lines, in addition to describe the connecting between Textronics system designs, developments, and evaluation techniques. Textronics react to physical parameters along with other features, and make combine between the electronic and smart textiles using textile-based sensors, electrodes and other smart devices and materials. Research and development investments will foster the adoption of novel Textronics applications as sustainable and cost-effective solutions with light-weight, high-performance wearable devices and products for monitoring a wide range of activities.', 'DOI': '10.1080/00405000.2023.2236320'}, {'id': 'doi_10_1080_16864360_2005_10738343', 'title': 'ClothAssembler: a CAD Module for Feature-based Garment Pattern Assembly', 'URL': 'https://doi.org/10.1080/16864360.2005.10738343', 'extra_urls': ['https://doi.org/10.1080/16864360.2005.10738343'], 'type': 'article', 'author': [{'family': 'Fontana', 'given': 'Marzia'}, {'family': 'Carubelli', 'given': 'Alberto'}, {'family': 'Rizzi', 'given': 'Caterina'}, {'family': 'Cugini', 'given': 'Umberto'}], 'abstract': 'This work presents a CAD prototype, named ClothAssembler, targeted at complex-shaped apparel design for real manufacturing. The intent is to fill a gap in the current CAD technology for garment design as it is mainly conceived for 2D/3D geometric modelling of cloth shapes, but generally does not provide high level operators that allow interactive and easy design of aesthetic/functional features that characterize the garment pieces, and relations/connections between parts. Though still an academic prototype, ClothAssembler allows to define/choose in an interactive way all the necessary geometric and functional information for the design and finishing of 2D pieces, such as insertion of textile layers, reinforcement lines, pockets, cut lines and pleats, as well as topological information about how pieces are pair-wise connected and assembled, by definition of seams, darts, zips, constraints such as buttons and hooks, etc. A taxonomy and parametrization of cloth tailoring features is discussed, and system functionalities are presented, with applications to garment models of real production.', 'DOI': '10.1080/16864360.2005.10738343'}, {'id': 'doi_10_1080_00405000_2024_2352183', 'title': 'Artificial intelligence-based precise prediction of anthropometric data for female garment pattern-making', 'URL': 'https://doi.org/10.1080/00405000.2024.2352183', 'extra_urls': ['https://doi.org/10.1080/00405000.2024.2352183'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Yuanjing'}, {'family': 'Shen', 'given': 'Hong'}, {'family': 'Shi', 'given': 'Yuyuan'}, {'family': 'Yang', 'given': 'Wenjing'}, {'family': 'Wang', 'given': 'Wei'}, {'family': 'Wan', 'given': 'Ruyu'}, {'family': 'Dodd', 'given': 'Linzi'}], 'abstract': 'Anthropometric data form the cornerstone of garment pattern-making. This article introduces an artificial intelligence-driven approach, employing a back-propagation artificial neural network (BP-ANN), to predict the anthropometric data essential for crafting patterns for women\u2019s upper tops. The model adeptly processes minimal critical data from women\u2019s upper bodies, yielding projected dimensions that are arduous to manually measure yet crucial for tailoring body-fitting tops. Utilising a three-dimensional body scanner for accurate anthropometric data collection from 196 women in Sichuan Province, China, our study compares the BP-ANN model with a Linear Regression (LR) model. Results demonstrate superior predictive accuracy for BP-ANN. Notably, the BP-ANN model excels in efficiency and accuracy, particularly in challenging anthropometric parameters. The findings underscore the transformative potential of AI-based models in optimizing garment production processes, offering a precise alternative to traditional methods. This research contributes valuable insights for the integration of AI technology in advancing pattern-making practices.', 'DOI': '10.1080/00405000.2024.2352183'}, {'id': 'doi_10_1080_17543261003689888', 'title': '3D CAD systems for the clothing industry', 'URL': 'https://doi.org/10.1080/17543261003689888', 'extra_urls': ['https://doi.org/10.1080/17543261003689888'], 'type': 'article', 'author': [{'family': 'Sayem', 'given': 'Abu Sadat Muhammad'}, {'family': 'Kennon', 'given': 'Richard'}, {'family': 'Clarke', 'given': 'Nick'}], 'abstract': 'The approaches for designing virtual garments may be categorised as \u20182D to 3D\u2019 and \u20183D to 2D\u2019. The former refers to draping flat digital pattern pieces on a virtual mannequin, and the later indicates the development of clothing design on a realistic body and subsequent flattening into 2D pattern pieces. Several computer-aided design (CAD) systems for garment visualisation in space from flat patterns have already been introduced into the clothing industry. Any industrial application of the pattern flattening technique is yet to be made, due to the non-availability of an appropriate CAD system on the market. This article reviews the historical developments of 3D CAD systems for the clothing industry, and assesses the features of currently available systems on market.', 'DOI': '10.1080/17543261003689888'}, {'id': 'doi_10_1080_00405000_2023_2249701', 'title': 'Automatic design-preserving virtual garment transfer', 'URL': 'https://doi.org/10.1080/00405000.2023.2249701', 'extra_urls': ['https://doi.org/10.1080/00405000.2023.2249701'], 'type': 'article', 'author': [{'family': 'Ye', 'given': 'Qinwen'}, {'family': 'Wang', 'given': 'Zhaohui'}, {'family': 'Huang', 'given': 'Rong'}, {'family': 'Liu', 'given': 'Huanhuan'}, {'family': 'Lyu', 'given': 'Yingrui'}], 'abstract': 'Design-preserving garment transfer which can transfer a garment from one body to another is a powerful technique in computer graphics. In this paper, we propose a novel method for automatic design-preserving garment transfer. Firstly, the correspondence between the source garment and the source body is automatically calculated by finding the nearest face\u2019s barycenter from the garment to the body. Secondly, the mesh deformation transfer algorithm is utilized to obtain the target garment. After aligning the target garment and body with the ICP algorithm, the virtual fitting result can finally be obtained by fitting the target garment onto the target body. For a new garment worn on the source body, our approach can quickly and effectively transfer the garment to the target body while preserving the designed details. Two experiments were carried out to validate the applicability and effectiveness of our method. The results showed that our method could be applied to different garments for human bodies with different shapes and poses. Additionally, we introduced a new method for evaluating our transferred garments based on similarity and fit. Moreover, our approach can be applied to garments with different particle distances and performs better than the \u2018Auto grading\u2019 technique of CLO 3D. Our proposed method is simple, effective, automated and fast. Therefore, it has a significant potential for improving personalized garment development efficiency.', 'DOI': '10.1080/00405000.2023.2249701'}, {'id': 'doi_10_1080_00405000_2024_2343120', 'title': 'Measurements-to-body: 3D human body reshaping based on anthropometric measurements', 'URL': 'https://doi.org/10.1080/00405000.2024.2343120', 'extra_urls': ['https://doi.org/10.1080/00405000.2024.2343120'], 'type': 'article', 'author': [{'family': 'Ye', 'given': 'Qinwen'}, {'family': 'Huang', 'given': 'Rong'}, {'family': 'Wang', 'given': 'Zhaohui'}, {'family': 'Lyu', 'given': 'Yingrui'}, {'family': 'Liu', 'given': 'Huanhuan'}, {'family': 'Sun', 'given': 'Yuexin'}], 'abstract': 'Accurate 3D human models are useful for many applications in virtual fitting, ergonomics, film and television, and video games. However, due to the limitations of 3D scanners and body privacy, creating a virtual human body that accurately represents a specific human body is challenging. Therefore, reshaping 3D human bodies based on anthropometric measurements has received extensive attention. However, the existing methods have some drawbacks, such as the inability of the reshaped body to change its posture, the lack of a good link between the real and virtual measurements, and unreasonable anthropometry definitions. In this paper, we propose a new framework for reshaping the 3D human body using five easily available measurements: height, weight, chest, waist, and hip. First, the STAR model was used to fit the SPRING dataset to obtain the SPRING-fitted dataset, where the shape parameters of the STAR model are used to characterize each 3D human body. Second, optimizing the virtual measurement algorithm constructed a good link between real and virtual measurements. Then, the measurements of the human bodies in the SPRING-fitted dataset were extracted. Finally, the semantic reshaping of the 3D human body can be achieved by constructing a neural network model that uses the five measurements to predict 20 shape parameters. The results show that the human body reconstructed by our method can keep its size close to the real human body and conform to the shape of the real human body. Thus, it can meet the needs of the garment industry. In addition, the reshaped human body can be adjusted to different postures, which is beneficial to virtual fitting.', 'DOI': '10.1080/00405000.2024.2343120'}, {'id': 'digital_tools_in', 'title': 'Digital Tools in Action: 3D Printing for Personalized Skincare in the Era of Beauty Tech', 'URL': 'https://www.mdpi.com/2079-9284/12/4/136', 'extra_urls': ['https://www.mdpi.com/2079-9284/12/4/136'], 'type': 'article', 'author': [{'family': 'Bom', 'given': 'Sara'}, {'family': 'Pinto', 'given': 'Pedro Contreiras'}, {'family': 'Ribeiro', 'given': 'Helena Margarida'}, {'family': 'Marto', 'given': 'Joana'}], 'abstract': '3D printing (3DP) enables the development of highly customizable skincare solutions, offering precise control over formulation, structure, and aesthetic properties. Therefore, this study explores the impact of patches\u2019 microstructure on hydration efficacy using conventional and advanced chemical/morphological confocal techniques. Moreover, it advances to the personalization of under-eye 3D-printed skincare patches and assesses consumer acceptability through emotional sensing, providing a comparative analysis against a non-3D-printed market option. The results indicate that increasing the patches\u2019 internal porosity enhances water retention in the stratum corneum (53.0 vs. 45.4% \xb5m). Additionally, patches were personalized to address individual skin needs/conditions (design and bioactive composition) and consumer preferences (color and fragrance). The affective analysis indicated a high level of consumer acceptance for the 3D-printed option, as evidenced by the higher valence (14.5 vs. 1.1 action units) and arousal (4.2 vs. 2.7 peaks/minute) scores. These findings highlight the potential of 3DP for personalized skincare, demonstrating how structural modifications can modulate hydration. Furthermore, the biometric-preference digital approach employed offers unparalleled versatility, enabling rapid customization to meet the unique requirements of different skin types. By embracing this advancement, a new era of personalized skincare emerges, where cutting-edge science powers solutions for enhanced skin health and consumer satisfaction.'}, {'id': 'doi_10_1177_15589250241254443', 'title': 'Development of a textile sheet mask design for facial care based on a 3D face model of an average woman', 'URL': 'https://doi.org/10.1177/15589250241254443', 'extra_urls': ['https://doi.org/10.1177/15589250241254443'], 'type': 'article', 'author': [{'family': 'Rudolf', 'given': 'Andreja'}, {'family': '\u0160terman', 'given': 'Sonja'}, {'family': 'Cupar', 'given': 'Andrej'}], 'abstract': 'Facial cosmetics moisturise the skin and remove sebum and impurities to maintain healthy skin. Face masks are available on the market in various forms such as gel, emulsion, sheet and paste. The textile sheet mask for facial care is used by all women, regardless of age. This study deals with 3D scanning of women\u2019s faces to create an average female 3D face model for the development of a textile sheet mask design for facial care. Screened Poisson surface reconstruction was used to create an average female 3D face model whose dimensions correspond to average dimensions of scanned female faces. A reliable average 3D face model of the women studied was therefore used to develop a textile sheet mask for facial care. A comparison of average facial measurements with the measurements of randomly selected masks on the market revealed differences. Therefore, a design for a textile sheet mask was developed based on average facial measurements and the average 3D face model of a woman and by using virtual prototyping. The use of software for prototyping and simulating the appearance of clothing has also proven to be effective in the development of a textile product such as a textile face mask. The developed pattern design of the textile sheet mask with optimal dimensions and shape adapts to the contours of an average woman\u2019s face. This fulfils all the requirements for wearing comfort of the textile sheet mask around the eyes, nose and lips during facial care and enables efficient transfer of the serum from the textile sheet mask to the skin.', 'DOI': '10.1177/15589250241254443'}, {'id': 'development_of_textile', 'title': 'Development of textile structures using 3D prototyping technologies', 'URL': 'https://journals.uran.ua/tarp/article/view/327068', 'extra_urls': ['https://journals.uran.ua/tarp/article/view/327068'], 'type': 'article', 'author': [{'family': 'Mytsa', 'given': 'Viktoriia'}, {'family': 'Riabchykov', 'given': 'Mykola'}, {'family': 'Popova', 'given': 'Tetyana'}, {'family': 'Nikulina', 'given': 'Anastasiia'}], 'abstract': 'The object of the research is pseudotextile mesh structures with three-dimensional hinged joints, manufactured by 3D prototyping methods. One of the main tasks in the field of 3D printing of textile materials is to ensure their flexibility, elasticity and adaptability to the shape of the human body. Materials produced by traditional 3D printing methods have high rigidity, which limits their application in the light industry. During the study, a concept for creating pseudotextile materials based on flexible network structures using spherical three-dimensional hinges was developed. The proposed structure allows for achieve the necessary flexibility and deformation capabilities characteristic of traditional textile materials. Modeling and experimental samples demonstrated that structures with three-layer hinged joints provide spatial variability of shape, while the use of eccentricity in the hinges allows to adjust the rigidity of the structures. The obtained results can be attributed to the use of three-level spherical hinge joints, which provide spatial mobility of individual elements of the structure, as well as numerical modeling to optimize the sizes of structural elements. The implemented models confirm that the mechanical properties of the synthesized structures can be controlled by changing their geometry. The developed structures can be utilized in the clothing production where high flexibility of the material is required, as well as in the creation of adaptive textile products for medical purposes, in particular for compression therapy or automated massage. Additionally, such materials can be used in the decorative design of fashion products.'}, {'id': 'the_impact_of', 'title': 'The Impact of Technological Advances on the Future of Counterfeiting', 'URL': '#item_20252', 'type': 'article', 'author': [{'family': 'Santos', 'given': 'Jo\xe3o Carlos Dias dos'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Routledge', 'abstract': 'This chapter examines the evolving landscape of counterfeiting, influenced by swift technological progress. It delves into the latest techniques employed in product counterfeiting, including 3D printing, digital manipulation, deepfake technologies, and advanced chemical synthesis. Various sectors are highlighted, such as pharmaceuticals, electronics, fashion, and food and beverages, providing insight into the strategies used by counterfeiters to create deceptively authentic replicas. The chapter also explores innovative countermeasures and leading-edge technologies, including blockchain, advanced authentication methods, artificial intelligence, and spectroscopy. Additionally, it addresses the prospective challenges posed by emerging technologies and the complexities involved in adapting legal frameworks to these changes. Through a thorough analysis, the chapter presents a forward-looking view on the implications of technological advancements on counterfeiting and the necessary strategies to effectively combat these illicit activities.'}, {'id': 'doi_10_1007_978-981-96-6530-3_2', 'title': 'Evolution and Engineering Concepts of Traditional Textiles', 'URL': 'https://doi.org/10.1007/978-981-96-6530-3_2', 'type': 'article', 'author': [{'family': 'Amjad', 'given': 'Akhtarul Islam'}, {'family': 'Sharma', 'given': 'Swati'}, {'family': 'Vaseem', 'given': 'Md.'}, {'family': 'Singh', 'given': 'J. P.'}, {'family': 'Pahuja', 'given': 'Bharti'}, {'family': 'Mukhopadhyay', 'given': 'Samrat'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Springer Nature', 'abstract': 'Textile has been part of human civilisation and culture since its inception and various cultural and geographical regions have had their methods and techniques of textile manufacturing. The textile methods and techniques in India have developed over time and have long historical and cultural importance. These techniques have been refined and optimised over time. The aim of this chapter is to explore the evolution and engineering advancements in traditional textiles and have an overview of the impact of these changes on stockholders. The first section of this chapter delves into traditional yarn manufacturing, focusing on hand-spinning techniques and the mechanics of the Indian spinning wheel (Charkha). This is followed by an in-depth review of traditional weaving, covering the various types of handlooms and their operational principles, as well as the materials and techniques employed in handloom weaving. The subsequent chapter examines recent innovations in handloom technology, highlighting their role in enhancing efficiency while preserving heritage. The next section explores India\u2019s natural dyeing and printing crafts, emphasising sustainable and traditional processes. Additionally, the chapter hand embroidery, showcasing the precision and skill involved in this intricate art form. The final section highlights the growing role of artificial intelligence (AI) in traditional textiles. It discusses AI-based applications that enhance design, improve weaving methods, and support sustainable practices.', 'DOI': '10.1007/978-981-96-6530-3_2'}, {'id': 'doi_10_1108_AA-07-2022-0183', 'title': 'The application of robotics and artificial intelligence in embroidery: challenges and benefits', 'URL': 'https://doi.org/10.1108/AA-07-2022-0183', 'extra_urls': ['https://doi.org/10.1108/AA-07-2022-0183'], 'type': 'article', 'author': [{'family': 'Chen', 'given': 'Ling'}, {'family': 'Su', 'given': 'Zhi'}, {'family': 'He', 'given': 'Xiaotong'}, {'family': 'Chen', 'given': 'Xiang'}, {'family': 'Dong', 'given': 'Lin'}], 'abstract': "Embroidery as a textile embellishment technique plays an important role in people's daily life. Esthetic embroidery artworks possess cultural values. With the development of robotics and artificial intelligence (AI), these technologies have been studied and applied in the embroidery process. This study aims to survey how these technologies facilitate embroidery from different aspects.This paper surveys how the technologies of robotics and AI are applied in the embroidery field. The applications are mainly reviewed from three aspects: computerized robotic embroidery systems has been widely used for the mass production of embroidered textiles, the advanced technological systems and techniques have greatly facilitated the development of smart textiles and the artificial intelligence plays an important role in the inheritance, innovation and protection of traditional handicraft artwork of embroidery.The programmable robotic embroidery machines have greatly improved the production efficiency of embroidered textiles and promoted the development of electronic textiles. The AI, mainly the deep learning technology, brings significant benefits to esthetic embroidery creation. Technology-based embroidery has become a hot research topic in the field of textiles.This paper summarizes the application of robotics and AI technologies in the field of embroidery, which provides readers a comprehensive and systematic understanding about the research progress of modern technology-oriented embroidery. This helps readers gain inspiration from the technology perspectives.", 'DOI': '10.1108/AA-07-2022-0183'}, {'id': 'knitting_a', 'title': 'Knitting Robots: A Deep Learning Approach for Reverse-Engineering Fabric Patterns', 'URL': 'https://www.mdpi.com/2079-9292/14/8/1605', 'extra_urls': ['https://www.mdpi.com/2079-9292/14/8/1605'], 'type': 'article', 'author': [{'family': 'Sheng', 'given': 'Haoliang'}, {'family': 'Cai', 'given': 'Songpu'}, {'family': 'Zheng', 'given': 'Xingyu'}, {'family': 'Lau', 'given': 'Mengcheng'}], 'abstract': 'Knitting, a cornerstone of textile manufacturing, is uniquely challenging to automate, particularly in terms of converting fabric designs into precise, machine-readable instructions. This research bridges the gap between textile production and robotic automation by proposing a novel deep learning-based pipeline for reverse knitting to integrate vision-based robotic systems into textile manufacturing. The pipeline employs a two-stage architecture, enabling robots to first identify front labels before inferring complete labels, ensuring accurate, scalable pattern generation. By incorporating diverse yarn structures, including single-yarn (sj) and multi-yarn (mj) patterns, this study demonstrates how our system can adapt to varying material complexities. Critical challenges in robotic textile manipulation, such as label imbalance, underrepresented stitch types, and the need for fine-grained control, are addressed by leveraging specialized deep-learning architectures. This work establishes a foundation for fully automated robotic knitting systems, enabling customizable, flexible production processes that integrate perception, planning, and actuation, thereby advancing textile manufacturing through intelligent robotic automation.'}, {'id': 'doi_10_1177_00405175241312407', 'title': 'Mesh-based simulation of knitted dresses with loop units', 'URL': 'https://doi.org/10.1177/00405175241312407', 'extra_urls': ['https://doi.org/10.1177/00405175241312407'], 'type': 'article', 'author': [{'family': 'Cheng', 'given': 'Bilian'}, {'family': 'Jiang', 'given': 'Gaoming'}, {'family': 'Zhang', 'given': 'Fanglue'}, {'family': 'Wan', 'given': 'Ailan'}, {'family': 'Peng', 'given': 'Jiajia'}, {'family': 'Liu', 'given': 'Haisang'}, {'family': 'Gao', 'given': 'Lizhong'}], 'abstract': 'The three-dimensional simulation of knitted garments is an integral part of the three-dimensional visualization of textile garments. To realize the three-dimensional structure simulation and dressing simulation of knitted dresses, this paper proposes a fast three-dimensional simulation method of knitted dresses based on mesh division and loop units. Based on studying the process characteristics of knitted dresses, the dress pattern is quantified and meshed, and the loop unit\u2019s geometric and mesh models are established. The spatial matrix is used to calculate the spatial transformation relationship of each pair of triangles in the flat model and surface model of the dress, and the spatial transformation relationship is used to calculate the position of the loop mesh point in the triangular mesh of the surface model, the three-dimensional coordinates of the loop unit control point are obtained, and the loop is drawn. Based on C# technology, the model data of the personalized human body model and knitted dress are read, and the three-dimensional graphics library OpenGL and loop drawing method are used to realize the three-dimensional simulation of the knitted dress based on loop structure. The simulation effect of a V-neck dress and high-neck dress under different particle spacing is used as an example to test the simulation method. The results show that when the mesh of the dress model is divided under the particle spacing of 20\u2009mm, the three-dimensional simulation of the dress based on the loop unit can be realized quickly and with high quality.', 'DOI': '10.1177/00405175241312407'}, {'id': 'doi_10_1177_00405175241306133', 'title': 'Topology, integrity, and stability analysis of weft-knitted textiles', 'URL': 'https://doi.org/10.1177/00405175241306133', 'extra_urls': ['https://doi.org/10.1177/00405175241306133'], 'type': 'article', 'author': [{'family': 'Maharaj', 'given': 'Levi Kapllani'}, {'family': 'Amantides', 'given': 'Chelsea'}, {'family': 'Dion', 'given': 'Genevieve'}, {'family': 'Shapiro', 'given': 'Vadim'}, {'family': 'Breen', 'given': 'David E.'}], 'abstract': 'Despite their long-time existence and significant capabilities, computational modeling, simulation, and design tools have been underutilized for textiles in general, specifically limiting the ability of knitted textiles to be widely deployed and to reach their full industrial potential in advanced functional fabrics and garments. These computational tools require a robust representation and efficient evaluation of the spatial, material, and physical properties of textile structures. An example of an efficient modeling method for knitted fabrics is TopoKnit, a process-oriented representation for capturing the topology of weft-knitted textiles. In this paper, we extend TopoKnit and present new algorithms that may be used to determine additional topological structures and assess the structural integrity and stability of knitted textiles modeled by this fundamental data structure. We compare our results with outputs from a commercial software system to confirm the effectiveness and validity of our algorithms. These new capabilities provide a foundation for open technologies that can accurately model and predict the geometric and mechanical properties/behaviors of knitted textiles. They will support the development of computational design and analysis tools that will obviate the expensive and wasteful trial-and-error process of knitting and testing actual fabrics in the preproduction phase of textile manufacturing.', 'DOI': '10.1177/00405175241306133'}, {'id': 'knit_deformation', 'title': 'Real-Time Knit Deformation and Rendering', 'URL': 'https://dl.acm.org/doi/10.1145/3731184', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3731184'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Tao'}, {'family': 'Shi', 'given': 'Haoyang'}, {'family': 'Wang', 'given': 'Mengdi'}, {'family': 'Qiu', 'given': 'Yuxing'}, {'family': 'Yang', 'given': 'Yin'}, {'family': 'Wu', 'given': 'Kui'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'The knit structure consists of interlocked yarns, with each yarn comprising multiple plies comprising tens to hundreds of twisted fibers. This intricate geometry and the large number of geometric primitives present substantial challenges for achieving high-fidelity simulation and rendering in real-time applications. In this work, we introduce the first real-time framework that takes an animated stitch mesh as input and enhances it with yarn-level simulation and fiber-level rendering. Our approach relies on a knot-based representation to model interlocked yarn contacts. The knot positions are interpolated from the underlying mesh, and associated yarn control points are optimized using a physically inspired energy formulation, which is solved through a GPU-based Gauss-Newton scheme for real-time performance. The optimized control points are sent to the GPU rasterization pipeline and rendered as yarns with fiber-level details. In real-time rendering, we introduce several decomposition strategies to enable realistic lighting effects on complex knit structures, even under environmental lighting, while maintaining computational and memory efficiency. Our simulation faithfully reproduces yarn-level structures under deformations, e.g., stretching and shearing, capturing interlocked yarn behaviors. The rendering pipeline achieves near-ground-truth visual quality while being 120,000\xd7 faster than path tracing reference with fiber-level geometries. The whole system provides real-time performance and has been evaluated through various application scenarios, including knit simulation for small patches and full garments and yarn-level relaxation in the design pipeline.'}, {'id': 'knittable_stitch_meshes', 'title': 'Knittable Stitch Meshes', 'URL': 'https://dl.acm.org/doi/10.1145/3292481', 'extra_urls': ['https://dl.acm.org/doi/10.1145/3292481'], 'type': 'article', 'author': [{'family': 'Wu', 'given': 'Kui'}, {'family': 'Swan', 'given': 'Hannah'}, {'family': 'Yuksel', 'given': 'Cem'}], 'issued': {'date-parts': [[2019]]}, 'abstract': 'We introduce knittable stitch meshes for modeling complex 3D knit structures that can be fabricated via knitting. We extend the concept of stitch mesh modeling, which provides a powerful 3D design interface for knit structures but lacks the ability to produce actually knittable models. Knittable stitch meshes ensure that the final model can be knitted. Moreover, they include novel representations for handling important shaping techniques that allow modeling more complex knit structures than prior methods. In particular, we introduce shift paths that connect the yarn for neighboring rows, general solutions for properly connecting pieces of knit fabric with mismatched knitting directions without introducing seams, and a new structure for representing short rows, a shaping technique for knitting that is crucial for creating various 3D forms, within the stitch mesh modeling framework. Our new 3D modeling interface allows for designing knittable structures with complex surface shapes and topologies, and our knittable stitch mesh structure contains all information needed for fabricating these shapes via knitting. Furthermore, we present a scheduling algorithm for providing step-by-step hand knitting instructions to a knitter, so that anyone who knows how to knit can reproduce the complex models that can be designed using our approach. We show a variety of 3D knit shapes and garment examples designed and knitted using our system.'}, {'id': 'fits_like_a', 'title': 'Fits like a glove? Knowledge and use of size finders and high-end fashion retail returns', 'URL': 'https://www.sciencedirect.com/science/article/pii/S2444569X25001246', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S2444569X25001246'], 'type': 'article', 'author': [{'family': 'Patel', 'given': 'Pankaj C.'}, {'family': 'Karlsson', 'given': 'Stefan'}, {'family': 'Oghazi', 'given': 'Pejvak'}], 'abstract': 'With returns imposing a growing burden on retail supply chains, major e-commerce platforms are increasingly implementing size recommendations to curb returns. Based on a fit valence and fit reference framework, we test whether customers using the size finder are more likely or less likely to return products. We use confidential data from a major fashion e-commerce platform in Sweden that introduced a size finder based on customer-supplied information on weight, build, hips, waist, shoulders, leg-to-torso length, and body shape. In a sample of 496,365 items ordered by 75,707 customers from 113 countries between July 2015 to April 2022, those using the size finder are 0.65% more likely to return an item. The findings are robust to a variety of econometrics tests. Furthermore, machine learning analysis based on gradient boosted trees shows that size finder is among the least important features in predicting returns. However, for each unit quarterly increase in the use of the size finder with purchased items, the customer lifetime value (CLV) increases by 7.51% in the next quarter and 5.53% in the subsequent quarter. Post-hoc interviews with executives in the e-commerce sector demonstrated that, when implementing size recommendation tools, managers in fashion retailers must weigh a small increase in returns against higher CLV from repeat customers.'}, {'id': 'intelligent_automation_in', 'title': 'Intelligent Automation in Knitting Manufacturing: Advanced Software Integration and Structural Optimisation for Complex Textile Design', 'URL': 'https://www.mdpi.com/2076-3417/15/10/5775', 'extra_urls': ['https://www.mdpi.com/2076-3417/15/10/5775'], 'type': 'article', 'author': [{'family': 'Angelova', 'given': 'Radostina A.'}, {'family': 'Sofronova', 'given': 'Daniela'}, {'family': 'Raycheva', 'given': 'Violina'}, {'family': 'Borisova', 'given': 'Elena'}], 'abstract': 'Automation in textile manufacturing plays a pivotal role in enhancing production efficiency, precision, and innovation. This study investigates the integration of intelligent technologies in the knitting sector, focusing on industrial flat knitting machines from a leading manufacturer and the use of the advanced software platform M1plus V7.5. The software\u2019s capabilities for the digital design and simulation of complex patterned and structural knits are explored through the development and production of five experimental knitted designs. Each sample is evaluated in terms of its structural characteristics and dimensional behaviour after washing. The results highlight the potential of software-driven optimisation to improve product accuracy, reduce shrinkage variability, and support smart manufacturing practices in the textile industry.'}, {'id': 'intelligent_and_precise', 'title': 'Intelligent and Precise Textile Drop-Off: A New Strategy for Integrating Soft Fingers and Machine Vision Technology', 'URL': 'https://www.mdpi.com/2673-7248/5/3/34', 'extra_urls': ['https://www.mdpi.com/2673-7248/5/3/34'], 'type': 'article', 'author': [{'family': 'Shen', 'given': 'Jinzhu'}, {'family': 'Ram\xedrez-G\xf3mez', 'given': '\xc1lvaro'}, {'family': 'Wang', 'given': 'Jianping'}, {'family': 'Zhang', 'given': 'Fan'}, {'family': 'Li', 'given': 'Yitong'}], 'abstract': 'This study presents a novel drop-off strategy for automated fabric handling in intelligent apparel manufacturing, addressing the critical challenge of drift-free placement of lightweight, flexible textiles. A pneumatically driven retractable plate is introduced as an auxiliary device, along with machine vision technology, to eliminate drop-off deviations inherent in traditional soft grippers. By synchronizing the retraction motion of the plate with soft gripper release, the fabric is transferred onto the target surface without free-fall drift, achieving sub-0.5 mm alignment accuracy across 15 fabric types. Machine vision-based inspection validates drop-off quality in real time. This work offers a low-cost, drift-free drop-off solution for pre-sewing automation.'}, {'id': 'doi_10_1108_RJTA-08-2021-0106', 'title': 'Industry 4.0 in textile and apparel sector: a systematic literature review', 'URL': 'https://doi.org/10.1108/RJTA-08-2021-0106', 'extra_urls': ['https://doi.org/10.1108/RJTA-08-2021-0106'], 'type': 'article', 'author': [{'family': 'Dal Forno', 'given': 'Ana Julia'}, {'family': 'Bataglini', 'given': 'Walakis Vieira'}, {'family': 'Steffens', 'given': 'Fernanda'}, {'family': 'Ulson de Souza', 'given': 'Antonio Augusto'}], 'abstract': 'This paper aims to present a systematic review of the development process of Industry 4.0 in the textile and apparel sector, as well as to show some concepts, examples found in the literature on the application of the principles and technologies involved like the internet of things (IoT), cloud computing, Big Data, autonomous robots, three-dimensional (3D) printing, augmented reality, virtual prototyping, horizontal and vertical system integration and cybersecurity.The methodology adopted in this study was a systematic literature review aided by the use of SciMAT, a scientific mapping software. Documents were collected from the Web of Science and Scopus database from 2011 to 2020 using the words \u201cTextile\u201d and \u201cIndustry 4.0\u201d that result in 865 documents and 115 were analyzed.The literature review showed that the textile industry in the international context is at an incipient stage of the implementation of Industry 4.0. The main aspects of Industry 4.0 that were identified in the textile industry initially focus on the implementation of technologies aimed at computerization and automation of processes, whose main focuses are increasing productivity and reducing costs. Projects for the implementation of augmented reality and 3D printing and simulation technologies in the textile industry, clothing and apparel area are still embryonic, normally implemented through tools and software oriented toward the creation and development of new models of processes, products and commerce.The search in the databases was carried out on October 17, 2020. Therefore, for future study, other combinations of search terms and time update are suggested, in addition to including more databases besides Scopus and Web of Science.This literature review served as the basis for the development of a questionnaire that was applied to 72 people in an industry in the clothing sector, located in the state of Santa Catarina, southern Brazil.The benefits of industry 4.0 are perceived in people with its implementation, such as a reduction in energy consumption of around 15%, an increase of up to 25% in work efficiency, in addition to more assertive decision-making, improvement of processes and balance between life and work.Machine learning, artificial intelligence, smart fabrics, IoT, supply chain management, environmental protection, Big Data, autonomation and cyber physics were the strongest terms found, consolidating as a prominent field for current and future studies. From emerging and/or still unexplored areas of Industry 4.0 in the textile sector, there is real-time communication, computer applications, carbon, fibers, health care and sustainable development. Some strategic actions that are taking place in some countries are summarized and in Brazil the adoption rate is 29% for this sector, revealing itself as a needy area and suitable for the development of studies that address the subject.', 'DOI': '10.1108/RJTA-08-2021-0106'}, {'id': 'stitching_competition_with', 'title': 'Stitching competition with digital threads: Unveiling the drivers of competitive success in the apparel sector', 'URL': 'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325945', 'extra_urls': ['https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325945'], 'type': 'article', 'author': [{'family': 'Susitha', 'given': 'Emmanuel'}, {'family': 'Jayarathne', 'given': 'Amila'}, {'family': 'Herath', 'given': 'H. M. R. P.'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'This study explores and validates the dimensions of digital capabilities and competitive performance within the apparel industry, aiming to develop a robust, multidimensional measurement instrument. Employing a sequential QUAL\u2192QUAN exploratory design, the research began with in-depth interviews with key industry experts to identify critical constructs. These insights informed the subsequent quantitative phase, in which exploratory factor analysis and confirmatory factor analysis were applied to confirm the factor structure and validate the instrument. The study identifies four key dimensions of competitive performance in the apparel supply chain: customer satisfaction, better utilisation of resources, collaboration to compete, and strategic advantage. Process and technical digitalisation emerged as essential components of digital capabilities, reflecting the dual role of digital infrastructure and operational integration in enhancing performance. Theoretically, this research contributes by introducing validated instruments grounded in the Resource-based view, the Dynamic capabilities view, and the Extended resource-based view, offering an empirical framework that links digital capabilities with competitive performance. Practically, the instrument provides apparel manufacturers with a diagnostic tool to assess digital maturity and strategically align digital initiatives with performance goals. These findings are particularly relevant for firms navigating rapid technological change and seeking sustained global apparel supply chain competitiveness.'}, {'id': 'doi_10_1108_RJTA-08-2020-0090', 'title': 'Technology adoption in the apparel industry: insight from literature review and research directions', 'URL': 'https://dx.doi.org/10.1108/RJTA-08-2020-0090', 'extra_urls': ['https://dx.doi.org/10.1108/RJTA-08-2020-0090'], 'type': 'article', 'author': [{'family': 'Hoque', 'given': 'Md Aynul'}, {'family': 'Rasiah', 'given': 'Rajah'}, {'family': 'Furuoka', 'given': 'Fumitaka'}, {'family': 'Kumar', 'given': 'Sameer'}], 'abstract': 'Purpose. This paper aims to identify key theoretical cornerstones and research trends in the apparel industry. It also compares theoretical bases with those of the general research domain in technology adoption literature and, thus, provides future policy guidelines for practitioners and research gaps for further studies.Design/methodology/approach. Documents were collected from the Web of Science (core collection) database using systematic methods. The bibliometric coupling and co-citation analyses were conducted using VOSviewer software to construct theoretical cornerstones and research trends in the apparel industry.Findings. Literature in the apparel industry focuses mainly on the diffusion of innovation and the theory of reasoned action. Hence, the literature lacks investigations of technology\u2013organization\u2013environment and institutional theories for technology adoption in the apparel industry. This study also traces six clusters of prevalent research trends: radiofrequency identification, virtual-try on technology for e-commerce, computer-aided design, Industry 4.0 technologies, virtual-try on technology in design and information technology.Originality/value. Little research is done on theoretical cornerstones on technology adoption in the apparel industry. This study looks into the theoretical bases for technology adoption, research trends in the apparel supply chain and calls for future research necessities.', 'DOI': '10.1108/RJTA-08-2020-0090'}, {'id': 'a_compiler_for', 'title': 'A compiler for 3D machine knitting', 'URL': 'https://dl.acm.org/doi/10.1145/2897824.2925940', 'extra_urls': ['https://dl.acm.org/doi/10.1145/2897824.2925940'], 'type': 'article', 'author': [{'family': 'McCann', 'given': 'James'}, {'family': 'Albaugh', 'given': 'Lea'}, {'family': 'Narayanan', 'given': 'Vidya'}, {'family': 'Grow', 'given': 'April'}, {'family': 'Matusik', 'given': 'Wojciech'}, {'family': 'Mankoff', 'given': 'Jennifer'}, {'family': 'Hodgins', 'given': 'Jessica'}], 'issued': {'date-parts': [[2016]]}, 'abstract': 'Industrial knitting machines can produce finely detailed, seamless, 3D surfaces quickly and without human intervention. However, the tools used to program them require detailed manipulation and understanding of low-level knitting operations. We present a compiler that can automatically turn assemblies of high-level shape primitives (tubes, sheets) into low-level machine instructions. These high-level shape primitives allow knit objects to be scheduled, scaled, and otherwise shaped in ways that require thousands of edits to low-level instructions. At the core of our compiler is a heuristic transfer planning algorithm for knit cycles, which we prove is both sound and complete. This algorithm enables the translation of high-level shaping and scheduling operations into needle-level operations. We show a wide range of examples produced with our compiler and demonstrate a basic visual design interface that uses our compiler as a backend.'}, {'id': 'doi_10_3389_ejcmp_2025_13875', 'title': 'Exploring the generative AI potential in the fashion design process: an experimental experience on the collaboration between fashion design practitioners and generative AI tools', 'URL': 'https://doi.org/10.3389/ejcmp.2025.13875', 'extra_urls': ['https://doi.org/10.3389/ejcmp.2025.13875'], 'type': 'article', 'author': [{'family': 'Rizzi', 'given': 'Greta'}, {'family': 'Bertola', 'given': 'Paola'}], 'abstract': 'Over recent years, the rise of Generative Artificial Intelligence (Gen AI) has led to the emergence of numerous tools for the creation of visual and textual content. This technological advancement, supported by increasingly robust data management systems and targeted research efforts in this direction, has driven the continuous refinement of Machine Learning and Deep Learning models. As a result, Gen AI tools have demonstrated ever-increasing performance, leading to their rapid adoption in various sectors, including the Cultural and Creative Industries (CCI). Here, they are being integrated into value-creation pipelines, potentially impacting both production processes and career prospects for creative professionals.As a consequence, critical questions have emerged about the widespread use of Gen AI, related to the nature of their generative capabilities, often encapsulated under the umbrella term of "computational creativity", which has begun to challenge the traditional conception of creativity as an intrinsic and exclusive capacity of human beings, with implications across all fields in which human creativity is central, such as the design disciplines.In light of the current scenario, the presented research aims to discuss the application of Gen AI tools for image, text, and video generation in fashion design. The analysis draws on the results of a didactic laboratory entitled Artificial A(i)rchive, which involved design practitioners from the Master\'s degree course in Design for the Fashion System at Politecnico di Milano.Within this workshop, the adoption of Gen AI was investigated, examining how AI was integrated at various stages of the design process and highlighting both the potential and shortcomings of applying Gen AI to support the activities of fashion designers. The article thus aims to contribute to the discussion and identification of collaborative models between fashion designers and AI, while situating the findings within a broader reflection on emerging creative practices and their potential implications.', 'DOI': '10.3389/ejcmp.2025.13875'}, {'id': 'doi_10_17918_00011002', 'title': 'Automating garment pattern making with AI: evaluating the performance and practical utility of fine-tuned large language models in fashion production', 'URL': 'https://doi.org/10.17918/00011002', 'extra_urls': ['https://doi.org/10.17918/00011002'], 'type': 'report', 'author': [{'family': 'Chen', 'given': 'Junyi'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Drexel University', 'abstract': 'This study investigates the effectiveness of machine learning models in automating garment pattern generation, addressing critical challenges in the fashion manufacturing industry. Traditional pattern-making methods, while refined through generations of practice, remain labor-intensive and constrained by human limitations in accommodating diverse body shapes and complex geometries. Through a comprehensive mixed-methods approach, this research develops and evaluates an AI-powered pattern generation system utilizing fine-tuned large language models (LLMs) including ChatGPT-4o, GPT-4o-mini, Gemini 1.5, and Llama 3.1. The methodology employed a two-stage AI pipeline architecture: (1) a vision model for extracting garment features from images and converting them to structured JSON format, and (2) specialized models for transforming JSON specifications into SVG pattern files. Training datasets were systematically constructed using over 10,000 garment patterns from industry partner URBN and the public GarmentCodeData repository. Three distinct fine-tuning approaches were evaluated: specialized training on 150 simple jumpsuit patterns, moderate training on 300 mixed-complexity pants patterns, and comprehensive training on 3,000 diverse garment types. Expert evaluation by professional pattern makers from URBN revealed counterintuitive findings regarding the relationship between training data characteristics and output quality. The specialized jumpsuit model achieved approximately 42% usability in manufacturing contexts, requiring only minor adjustments for production implementation. Conversely, models trained on larger, more diverse datasets (300 and 3,000 examples) produced patterns deemed unsuitable for real-world manufacturing, despite conventional machine learning expectations that larger datasets improve performance. The research identified an exponential relationship between pattern complexity and training data requirements, with simple patterns amenable to AI automation while complex designs continue to challenge current technological capabilities. Technical limitations included difficulties in capturing nuanced construction details, managing diverse human anatomical variations, and maintaining manufacturing-ready specifications. The vision component demonstrated robust performance in feature extraction, showing predictable scaling with dataset size. Key findings indicate that focused, application-specific AI models outperform general-purpose systems for pattern generation. The study provides empirical evidence that successful AI integration in pattern making requires strategic focus on specific garment categories with consistent construction principles rather than pursuing universal automation. These results suggest that AI should augment rather than replace human expertise, with optimal applications in standardized pattern production where consistency and efficiency are prioritized over creative complexity. This research contributes to understanding AI applications in creative industries by establishing performance benchmarks and identifying optimal training strategies for technical design automation. The findings offer practical guidance for fashion companies considering AI adoption, educators developing curricula that integrate AI literacy, and researchers advancing automated design technologies. Future work should explore hybrid human-AI approaches and specialized models for different garment categories while addressing material property integration and cultural design variations. Keywords: artificial intelligence, machine learning, garment pattern making, automated design, fashion technology, large language models, computer vision, human-AI collaboration.', 'DOI': '10.17918/00011002'}, {'id': 'doi_10_1088_1748-0221_20_05_C05006', 'title': 'New candidate polymeric wavelength shifters for noble liquid detectors', 'URL': 'https://doi.org/10.1088/1748-0221/20/05/C05006', 'extra_urls': ['https://doi.org/10.1088/1748-0221/20/05/C05006'], 'type': 'article', 'author': [{'family': 'Ku\u017aniak', 'given': 'M.'}, {'family': 'Choudhary', 'given': 'S.'}, {'family': 'Paw\u0142owski', 'given': 'S.'}, {'family': 'Cortez', 'given': 'A.F.V.'}, {'family': 'Kaczorowski', 'given': 'M.'}, {'family': 'Kumosi\u0144ski', 'given': 'M.'}, {'family': 'Abramowicz', 'given': 'A.'}, {'family': '\u0141\u0119cki', 'given': 'T.'}, {'family': 'Nieradka', 'given': 'G.'}, {'family': 'Sworobowicz', 'given': 'T.'}, {'family': 'Jamanek', 'given': 'D.'}], 'abstract': 'Polymeric wavelength shifters are of particular interest for large liquid argon detectors. Inspired by the success of polyethylene naphthalate (PEN), other new polymers exhibiting a similar type of excimer fluorescence were investigated. We report on the preliminary results of the first cryogenic wavelength shifting test of a solution-cast film of PVN, poly(2-vinyl naphthalene). Significant brittleness was identified as a factor potentially limiting the use of PVN. However, clear signs of wavelength shifting were observed, with the overall efficiency and time response comparable to those of PEN.', 'DOI': '10.1088/1748-0221/20/05/C05006'}, {'id': 'preparing_for_the', 'title': 'Preparing for the Digital Product Passport', 'URL': 'https://aaltodoc.aalto.fi/handle/123456789/137065', 'extra_urls': ['https://aaltodoc.aalto.fi/handle/123456789/137065'], 'type': 'thesis', 'author': [{'family': 'Siira', 'given': 'Salla'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'Aalto University', 'abstract': "Changes await the clothing industry as the European Union will soon require clothes to come with a digital product passport. A digital product passport is a system consisting of data, a digital platform, and a data carrier, which requires information about product responsibility, circularity, and legal compliance. The first requirements concerning digital product passports are likely to come into force in 2027. The textile digital product passport is introduced early, as textiles are one of the European Commission's priorities. For the digital product passport, companies will need to collect significant amounts of data about their supply chains and product sustainability. Clothing supply chains are known to be complex, so it is recommended to start preparations as early as possible. This thesis investigated the criteria that can be prepared for before the final requirements of the digital product passport are set. Additionally, the work examined the preparation and challenges of Finnish small and micro-sized clothing companies regarding the implementation of the digital product passport. The research was conducted by studying legislation and literature, as well as interviewing three experts. The experts worked in clothing companies and are involved in implementation process of the digital product passport. The literature revealed that there are several aspects of the digital product passport that companies can already prepare for. Companies can collect likely required data and centralize their data. Companies can also consider suitable data carriers as well as the execution of the digital platform. The research found that the examined companies are well prepared considering the current uncertainty in regulation. The companies have plenty of data from their supply chains. Moreover, two out of three companies would choose QR codes for the data carrier and two out of three would choose service providers to execute the digital platform. QR codes and service providers help implement the digital product passport faster. Companies still need to improve their data centralization, as data was stored on various platforms and not all data was accessible to all employees. One of the challenges identified in the work was the lack of resources. The companies do not have time, money, or employees to dedicate to studying digital product passports. The second challenge was collecting environmental impact data. Digital product passports and their impacts will need to be researched before and after the final implementation, since they will be required for almost all physical products, which results in a significant impact across industries."}, {'id': 'a_systematic_literature', 'title': 'A Systematic Literature Review on Digital Twins in Circular Supply Chain Management', 'URL': 'https://onlinelibrary.wiley.com/doi/abs/10.1002/bse.70038', 'extra_urls': ['https://onlinelibrary.wiley.com/doi/abs/10.1002/bse.70038'], 'type': 'article', 'author': [{'family': 'Polimetla', 'given': 'Jeremiah Sunadh'}, {'family': 'Sindhwani', 'given': 'Rahul'}, {'family': 'Bag', 'given': 'Surajit'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'This study presents a systematic literature review exploring the role of Digital Twins (DTs) in Circular Supply Chain Management (CSCM). Employing a structured methodology based on the PRISMA protocol and analyzed through the Theory, Context, Characteristics, and Method (TCCM) framework, the review synthesizes 109 peer-reviewed articles published between 2000 and 2024. Using bibliographic coupling, the research identifies six thematic clusters: (1) Integration of DT in Supply Chain; (2) DT and Industry 4.0; (3) Big Data, AI, and Circular Economy; (4) Risk Management and Supply Chain Resilience; (5) Additive Manufacturing and Spare Parts Logistics; and (6) Metaverse and Smart Factory Operations. Additionally, the study categorizes 86 unique theories applied in the DT-CSCM literature, with Resource-Based Theory, Complexity Theory, and Control Theory among the most cited. Key contributions include clarifying the intellectual structure of DT-CSCM research, highlighting emerging research directions, and offering practical recommendations for industry practitioners and policymakers seeking to enhance supply chain sustainability and digital transformation. These deeply meaningful findings considerably improve our comprehension of the rapid pace of technological improvement in DT and its significant implications for the development of resilient, sustainable supply chains.'}, {'id': 'and', 'title': "France's Anti-waste and Circular Economy Law", 'URL': 'https://content.ellenmacarthurfoundation.org/m/54c053dd73f80168/original/France-s-Anti-waste-and-Circular-Economy-Law.pdf', 'extra_urls': ['https://content.ellenmacarthurfoundation.org/m/54c053dd73f80168/original/France-s-Anti-waste-and-Circular-Economy-Law.pdf'], 'type': 'report', 'author': [{'family': 'Ellen MacArthur Foundation'}], 'issued': {'date-parts': [[2020]]}, 'publisher': 'Ellen MacArthur Foundation', 'abstract': "Overview of France's Anti-waste and Circular Economy Law (AGEC Law)"}, {'id': 'the_coasean', 'title': 'The Coasean Singularity? Demand, Supply, and Market Design with AI Agents', 'URL': '#item_20286', 'type': 'article', 'author': [{'family': 'Shahidi', 'given': 'Peyman'}, {'family': 'Rusak', 'given': 'Gili'}, {'family': 'Manning', 'given': 'Benjamin S'}, {'family': 'Fradkin', 'given': 'Andrey'}, {'family': 'Horton', 'given': 'John J'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'AI agents\u2014autonomous systems that perceive, reason, and act on behalf of human principals\u2014are poised to transform digital markets by dramatically reducing transaction costs. This chapter evaluates the economic implications of this transition, adopting a consumer-oriented view of agents as market participants that can search, negotiate, and transact directly. From the demand side, agent adoption reflects derived demand: users trade off decision quality against effort reduction, with outcomes mediated by agent capability and task context. On the supply side, firms will design, integrate, and monetize agents, with outcomes hinging on whether agents operate within or across platforms. At the market level, agents create efficiency gains from lower search, communication, and contracting costs, but also introduce frictions such as congestion and price obfuscation. By lowering the costs of preference elicitation, contract enforcement, and identity verification, agents expand the feasible set of market designs but also raise novel regulatory challenges. While the net welfare effects remain an empirical question, the rapid onset of AI-mediated transactions presents a unique opportunity for economic research to inform real-world policy and market design.'}, {'id': 'digital_product_passport', 'title': 'Digital product passport for the textile sector | Think Tank | European Parliament', 'URL': 'https://www.europarl.europa.eu/thinktank/en/document/EPRS_STU(2024)757808', 'extra_urls': ['https://www.europarl.europa.eu/thinktank/en/document/EPRS_STU(2024)757808'], 'type': 'webpage', 'author': [{'family': 'European Parliament'}], 'issued': {'date-parts': [[2024]]}, 'abstract': 'Digital product passport for the textile sector'}, {'id': 'security_attacks_in', 'title': 'Security attacks in Opportunistic Mobile Networks: A systematic literature review', 'URL': 'https://www.sciencedirect.com/science/article/abs/pii/S1084804523000917', 'extra_urls': ['https://www.sciencedirect.com/science/article/abs/pii/S1084804523000917'], 'type': 'article', 'author': [{'family': 'Altaweel', 'given': 'Ala'}, {'family': 'Aslam', 'given': 'Sidra'}, {'family': 'Kamel', 'given': 'Ibrahim'}], 'issued': {'date-parts': [[2024]]}}, {'id': 'walking_the', 'title': 'Zalando: Walking the talk | Zalando Corporate', 'URL': 'https://corporate.zalando.com/en/walking-talk', 'extra_urls': ['https://corporate.zalando.com/en/walking-talk'], 'type': 'webpage', 'author': [{'family': 'Zalando'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'All informations about \u201eWalking the talk\u201c at Zalando Corporate \u2713 Current information about Zalando SE'}, {'id': 'comply_or', 'title': 'Comply or Die, the future of fashion and the industry\u2019s potential mass extinction. | Dust Magazine', 'URL': 'https://dustmagazine.com/comply-or-die-the-future-of-fashion-and-the-industrys-potential-mass-extinction/', 'extra_urls': ['https://dustmagazine.com/comply-or-die-the-future-of-fashion-and-the-industrys-potential-mass-extinction/'], 'type': 'article', 'author': [{'family': 'Vitali', 'given': 'Luigi'}]}, {'id': 'doi_10_1080_0951192X_2025_2556440', 'title': 'From smart manufacturing in Industry 4.0 to industrial metaverse for Industry 5.0', 'URL': 'https://doi.org/10.1080/0951192X.2025.2556440', 'extra_urls': ['https://doi.org/10.1080/0951192X.2025.2556440'], 'type': 'article', 'author': [{'family': 'Jiang', 'given': 'Zhenhong'}, {'family': 'Ma', 'given': 'Nanfeng'}, {'family': 'Yao', 'given': 'Xifan'}, {'family': 'Zhou', 'given': 'Jiajun'}, {'family': 'Wang', 'given': 'Kesai'}, {'family': 'Xie', 'given': 'Tinbo'}, {'family': 'Meng', 'given': 'Junting'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'Manufacturing is currently experiencing a pivotal transition, characterized by increasing complexity, market dynamism, diverse performance objectives, and a surplus of data accompanied by a dearth of actionable knowledge. This study conducts a systematic literature review from 2012 to 2023 to examine the paradigm shift from technology-centric smart manufacturing to human-centric industrial metaverse, proposing a conceptual framework for manufacturing systems design in the context of Industry 5.0. The findings indicate that this transformation is marked by a progressive enhancement in the connectivity between real and cyber entities. To date, the integration has primarily involved physical entities with limited human inclusion, but the trajectory suggests a future where a comprehensive spectrum of physical, social, and cyber entities will be seamlessly integrated within the industrial metaverse. Furthermore, the research examines the burgeoning role of humans within the manufacturing landscape and the critical importance of incorporating human factors into manufacturing systems. A conceptual framework for the industrial metaverse is introduced, highlighting its potential to integrate human factors effectively. Concurrently, forthcoming challenges pertinent to the practical realization of the industrial metaverse are identified and directives are provided to guide subsequent scholarly endeavors.', 'DOI': '10.1080/0951192X.2025.2556440'}, {'id': 'how_to_make', 'title': 'How to make digital product passports cool', 'URL': 'https://www.voguebusiness.com/story/technology/how-to-make-digital-product-passports-cool', 'extra_urls': ['https://www.voguebusiness.com/story/technology/how-to-make-digital-product-passports-cool'], 'type': 'webpage', 'author': [{'family': 'Kotsoni', 'given': 'Elektra'}], 'abstract': 'Innovation agency IoDF and tech giant Epam are announcing a partnership today; its goal is to make DPPs customer friendly. Here\u2019s how.'}, {'id': 'doi_10_1080_0951192X_2025_2455655', 'title': 'Global initiatives for industry 4.0 implementation and progress within the textile and apparel manufacturing sector: a comprehensive review', 'URL': 'https://doi.org/10.1080/0951192X.2025.2455655', 'extra_urls': ['https://doi.org/10.1080/0951192X.2025.2455655'], 'type': 'article', 'author': [{'family': 'Haq', 'given': 'Upama Nasrin'}, {'family': 'Khan', 'given': 'Md. Mashiur Rahman'}, {'family': 'Khan', 'given': 'Adnan Maroof'}, {'family': 'Hasanuzzaman', 'given': 'Md.'}, {'family': 'Hossain', 'given': 'Md. Riaz'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'A comprehensive picture on global initiatives to Industry 4.0 (I4.0), technological evolution within fibre-to-apparel manufacturing and its progression so far are reported here. Germany is the global progression leader while other developed countries; France, Italy, Spain, Portugal, and even the UK and USA have generic initiatives for upgraded manufacturing. Their initiatives are I4.0 strategies, funding, platforms, and model projects. Developing countries like Indonesia, Malaysia, Thailand, Brazil, Turkey, Vietnam, India, etc. have also taken I4.0 national initiatives. However, the apparel and textile manufacturing industry lags far behind other sectors, although applying I4.0 technologies in this sector has started. CPS, IOT, Cloud computing, Automatic bobbin changing, RFID, Blockchain, augmented reality, and digital twins, are found in the textile production and fashion retailing. Moreover, advanced machineries offer incorporated automation, remote maintenance and operability, cloud systems, self-optimization, and predictive maintenance facilities. The review identifies that technological gaps between concept and reality hinder commercial application. The readiness evaluation is predominantly grounded in academic literature, which requires field investigation from the start to the end of textile processing. Hence, case studies for empirical data, sustainability mapping for the upgraded technologies and integrated policy development are the future direction in this domain.', 'DOI': '10.1080/0951192X.2025.2455655'}, {'id': 'doi_10_1080_09537325_2025_2525440', 'title': 'Stakeholders\u2019 collaborative strategies of intelligent manufacturing innovation consortium: a tripartite evolutionary game perspective', 'URL': 'https://doi.org/10.1080/09537325.2025.2525440', 'extra_urls': ['https://doi.org/10.1080/09537325.2025.2525440'], 'type': 'article', 'author': [{'family': 'Zhu', 'given': 'Mengshan'}, {'family': 'Zhou', 'given': 'Wenyong'}, {'family': 'Zhou', 'given': 'Xinye'}, {'family': 'Duan', 'given': 'Chunyan'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'The Intelligent Manufacturing Innovation Consortium (IMIC) provides a framework for technological advancement in manufacturing by integrating efforts from industries, universities, and research institutes under enterprise leadership. However, these consortia face challenges, including technological spillovers and collaborative inertia. This paper develops a tripartite evolutionary game model examining interactions between the core intelligent manufacturing enterprise (IME), the complementary innovation entity (CIE), and the supplementary innovation organisation (SIO). The research analyzes stakeholder strategy evolution and identifies factors that affect collaboration stability. Findings indicate that higher initial probabilities accelerate collaborative innovation adoption. IME and CIE demonstrate greater risk sensitivity than SIO. Enhanced trust and cooperation within the consortium lead to greater information sharing and increased synergy motivation. There is an optimal range for the revfenue distribution coefficient from technological innovation, and excessive subsidy intensity may be counterproductive. Appropriate penalty mechanisms effectively discourage opportunistic behaviour and promote active cooperation. These insights offer practical guidance for policymakers to design effective governance mechanisms for innovation consortia, ultimately supporting technological breakthroughs in intelligent manufacturing.', 'DOI': '10.1080/09537325.2025.2525440'}, {'id': 'doi_10_1016_j_jclepro_2013_11_012', 'title': 'Transparency and value chain sustainability', 'URL': 'https://doi.org/10.1016/j.jclepro.2013.11.012', 'extra_urls': ['https://doi.org/10.1016/j.jclepro.2013.11.012'], 'type': 'article', 'author': [{'family': 'Mol', 'given': 'Arthur P. J.'}], 'abstract': 'The rise of transparency on the public and political agendas is not an accident or fad, soon to be replaced by another timely topic in sustainability politics and governance. Transparency will remain a key topic in global value chains and will further develop as it piggy-backs on wider social developments such as globalization, the information age, and the shifting role of states in environmental governance. Transparency in value chains is bound up with positive connotations: the more transparency the better it is for the sustainability of chains and for the empowerment of consumers and civil society. But an overall positive past assessment of value chain transparency does not automatically extend into the future as new challenges lie ahead. This paper investigates the new challenges for value chain transparency and their consequences. Due to the growing importance attached to transparency in value chains it becomes a central object of power struggles, with uncertain outcomes. Markets and states seek to capture transparency arrangements for their own goals, which may not be in line with the assumed normative linkages between value chain transparency and increased power for consumers and civil society. In that sense, transparency is losing its innocence: more transparency is no longer always the best for citizen-consumer empowerment and for the sustainability of value chains. But value chain secrecy is not an attractive alternative. This opens a new research agenda on how transparency should be organized and arranged in value chains to live up to the promises of democracy and sustainability.', 'DOI': '10.1016/j.jclepro.2013.11.012'}, {'id': 'implementing_the_digital', 'title': 'Implementing the digital product passport - A guidebook for businesses', 'URL': '#item_20299', 'type': 'book', 'author': [{'family': 'Ker\xe4nen', 'given': 'Jaana'}, {'family': 'Orko', 'given': 'Inka'}, {'family': 'Valtanen', 'given': 'Kristiina'}, {'family': '\xc5kerman', 'given': 'Maria'}], 'issued': {'date-parts': [[2025]]}, 'publisher': 'VTT Technical Research Centre of Finland', 'abstract': 'A digital product passport (DPP) is a digital description of a physical product. It includes information on the materials, manufacturing, repair, use and disposal of the product, defined by the type of product. The goal of the DPP is to extend the lifespan of products and promote their circular economy by providing standardised product data. The DPP will be mandatory for a large part of the products manufactured in and imported into the EU, with a phased rollout schedule for different product groups. The EU Ecodesign of Sustainable Products Regulation sets the frame for the DPP requirements and will be complemented by product-specific delegated acts. The first DPPs should be available by 2026-27.\n\nThe DPP requirements will impact the product manufacturers and importers as well as their value chains in many ways. They are required to provide data for further support more sustainable product designs and use patterns over the product life cycle, for improved supply chain management, and for new business opportunities. While mandatory, the DPP opens multiple new business opportunities and business models in the form of sharing platforms, predictive maintenance services, refurbishing etc. On the other hand, the increased information demand will require planning, management and collaboration internally and through the value network and will also take up resources, especially in the first implementation phases. Thus, it is advantageous to take charge of the DPP and start preparing and piloting early on.\n\nThis guidebook will complement other DPP publications already available, with the emphasis of providing considerations and a practical roadmap for the implementation. A particular target group are small and medium size businesses that may have limited resources for the DPP. A collective understanding and shared goals and collaboration are needed across the ecosystem, including the DPP beneficiaries, product owners, data management and service providers to build a coherent, reliable and relevant DPP system.'}, {'id': 'lightweight', 'title': 'SketchTailor: Lightweight sketch-driven modeling for high-fidelity garment pattern reconstruction', 'URL': 'https://www.sciencedirect.com/science/article/pii/S0097849325001864', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S0097849325001864'], 'type': 'article', 'author': [{'family': 'Huang', 'given': 'Dongjin'}, {'family': 'Wang', 'given': 'Yanli'}, {'family': 'Qu', 'given': 'Jiantao'}, {'family': 'Wang', 'given': 'Ansheng'}, {'family': 'Tang', 'given': 'Yixiang'}], 'abstract': 'As a standard technical paradigm in the fashion industry, garment patterns serve as the core component throughout the entire process\u2014from conceptual design and digital pattern making to virtual garment simulation. Current mainstream approaches for generating garment patterns \u2013 such as those based on RGB images, 3D point clouds, textual inputs, or multimodal fusion techniques \u2013 have improved modeling capabilities but still face challenges including strong dependence on high-quality input data, complex data acquisition processes, limited semantic expressiveness, and high computational costs, which hinder their efficient and lightweight deployment. To address these limitations, we propose SketchTailor, a lightweight sketch-driven framework for generating 3D garment patterns with high efficiency and accuracy. We employ a vision prompt-tuned Vision Mamba (Vim) as the encoder to leverage its superior performance in processing abstract visual information and enhance the model\u2019s adaptability to input sketches. Within the Transformer decoder, we replace global attention with deformable attention to overcome the efficiency bottleneck of conventional Transformers in handling long sequences. This enables our model to progressively convert high-level semantic features extracted by the encoder into detailed 3D garment patterns that accurately represent both topological structures and geometric details. Experimental results on our extended large-scale, high-quality and diverse sketch-to-3D garment sewing pattern dataset demonstrate that our method significantly improves the quality of predicted garment patterns while substantially reducing computational and memory overhead. Our approach outperforms state-of-the-art methods across multiple metrics, including geometric error, edge accuracy, and inference time. Furthermore, user studies indicate that the generated patterns exhibit superior visual plausibility, detail fidelity, and overall aesthetics compared to existing baseline models, highlighting the practical applicability of our framework.'}, {'id': 'hierarchical_federated_transfer', 'title': 'Hierarchical federated transfer learning in digital twin-based vehicular networks', 'URL': 'https://www.sciencedirect.com/science/article/pii/S2667295225000078', 'extra_urls': ['https://www.sciencedirect.com/science/article/pii/S2667295225000078'], 'type': 'article', 'author': [{'family': 'Zia', 'given': 'Qasim'}, {'family': 'Zhu', 'given': 'Saide'}, {'family': 'Wang', 'given': 'Haoxin'}, {'family': 'Iqbal', 'given': 'Zafar'}, {'family': 'Li', 'given': 'Yingshu'}], 'abstract': 'In recent research on the Digital Twin-based Vehicular Ad hoc Network (DT-VANET), Federated Learning (FL) has shown its ability to provide data privacy. However, Federated learning struggles to adequately train a global model when confronted with data heterogeneity and data sparsity among vehicles, which ensure suboptimal accuracy in making precise predictions for different vehicle types. To address these challenges, this paper combines Federated Transfer Learning (FTL) to conduct vehicle clustering related to types of vehicles and proposes a novel Hierarchical Federated Transfer Learning (HFTL). We construct a framework for DT-VANET, along with two algorithms designed for cloud server model updates and intra-cluster federated transfer learning, to improve the accuracy of the global model. In addition, we developed a data quality score-based mechanism to prevent the global model from being affected by malicious vehicles. Lastly, detailed experiments on real-world datasets are conducted, considering different performance metrics that verify the effectiveness and efficiency of our algorithm.'}, {'id': 'a_new_textiles', 'title': "A new textiles economy: Redesigning fashion's future", 'URL': 'https://ellenmacarthurfoundation.org/a-new-textiles-economy', 'extra_urls': ['https://ellenmacarthurfoundation.org/a-new-textiles-economy'], 'type': 'report', 'author': [{'family': 'Ellen MacArthur Foundation'}], 'issued': {'date-parts': [[2017]]}, 'publisher': 'Ellen MacArthur Foundation'}, {'id': 'the_performance_economy', 'title': 'The performance economy', 'URL': 'urn:isbn:978-0-230-27490-7', 'type': 'book', 'author': [{'family': 'Stahel', 'given': 'Walter R.'}], 'issued': {'date-parts': [[2010]]}, 'publisher': 'Palgrave Macmillan'}, {'id': 'narrative_building', 'title': 'Narrative processing: Building consumer connections to brands', 'URL': '#item_20341', 'type': 'article', 'author': [{'family': 'Escalas', 'given': 'Jennifer Edson'}], 'issued': {'date-parts': [[2004]]}}, {'id': 'fiber_degradation_during', 'title': 'Fiber degradation during textile recycling', 'URL': '#item_20344', 'type': 'article', 'author': [{'family': 'Sandvik', 'given': 'Ingvild M\xf8rch'}, {'family': 'others'}], 'issued': {'date-parts': [[2018]]}}, {'id': 'environmental_impact_of', 'title': 'Environmental impact of textile reuse and recycling: A review', 'URL': '#item_20345', 'type': 'article', 'author': [{'family': 'Sandin', 'given': 'Gustav'}, {'family': 'Peters', 'given': 'Greg M.'}], 'issued': {'date-parts': [[2018]]}}, {'id': 'what_a_waste', 'title': 'What a waste 2.0: A global snapshot of solid waste management to 2050', 'URL': 'https://openknowledge.worldbank.org/handle/10986/30317', 'extra_urls': ['https://openknowledge.worldbank.org/handle/10986/30317'], 'type': 'report', 'author': [{'family': 'World Bank'}], 'issued': {'date-parts': [[2022]]}, 'publisher': 'World Bank Group'}, {'id': 'recent_trends_in', 'title': 'Recent trends in sustainable textile waste recycling methods: Current situation and future prospects', 'URL': '#item_20347', 'type': 'article', 'author': [{'family': 'Pensupa', 'given': 'Natthanon'}, {'family': 'Leu', 'given': 'Shao-Yuan'}, {'family': 'Hu', 'given': 'Yun'}, {'family': 'Du', 'given': 'Chenyu'}, {'family': 'Liu', 'given': 'Hongbo'}, {'family': 'Jing', 'given': 'Huirong'}, {'family': 'Wang', 'given': 'Hao'}, {'family': 'Lin', 'given': 'Carol Sze Ki'}], 'issued': {'date-parts': [[2017]]}}, {'id': 'understanding_the_blockchain', 'title': 'Understanding the blockchain oracle problem: A call for action', 'URL': '#item_20348', 'type': 'article', 'author': [{'family': 'Caldarelli', 'given': 'Giulio'}, {'family': 'Ellul', 'given': 'Joshua'}], 'issued': {'date-parts': [[2021]]}}, {'id': 'blockchain_oracle_design', 'title': 'Blockchain oracle design patterns', 'URL': '#item_20350', 'type': 'article', 'author': [{'family': 'Pasdar', 'given': 'Amirhossein'}, {'family': 'Dong', 'given': 'Zheng'}, {'family': 'Lee', 'given': 'Young Choon'}], 'issued': {'date-parts': [[2021]]}}, {'id': 'bayesian_knowledge_graphs', 'title': 'Bayesian knowledge graphs for supply chain verification under uncertainty', 'URL': '#item_20351', 'type': 'article', 'author': [{'family': 'Nafar', 'given': 'Mohsen'}, {'family': 'others'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'probabilistic_inference_in', 'title': 'Probabilistic inference in supply chain knowledge graphs', 'URL': '#item_20353', 'type': 'article', 'author': [{'family': 'Toroghi', 'given': 'Reza'}, {'family': 'Sanner', 'given': 'Scott'}], 'issued': {'date-parts': [[2024]]}}, {'id': 'digital_twins_for', 'title': 'Digital twins for circular supply chains: Architecture and implementation', 'URL': '#item_20354', 'type': 'article', 'author': [{'family': 'Roman', 'given': 'Dumitru'}, {'family': 'Stefanescu', 'given': 'Diana'}, {'family': 'Soylu', 'given': 'Ahmet'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'digital_supply', 'title': 'Digital twin-driven supply chain resilience and optimization', 'URL': '#item_20356', 'type': 'article', 'author': [{'family': 'Kim', 'given': 'Minkyun'}, {'family': 'Lee', 'given': 'Juhyun'}, {'family': 'Park', 'given': 'Sangwon'}], 'issued': {'date-parts': [[2025]]}}, {'id': 'consumer_awareness_and', 'title': 'Consumer awareness and understanding of digital product passports: Survey results', 'URL': '#item_20358', 'type': 'report', 'author': [{'family': 'European Commission'}], 'issued': {'date-parts': [[2024]]}, 'publisher': 'European Commission, Directorate-General for Internal Market, Industry, Entrepreneurship and SMEs'}, {'id': 'how_to_shift', 'title': 'How to SHIFT consumer behaviors to be more sustainable: A literature review and guiding framework', 'URL': '#item_20360', 'type': 'article', 'author': [{'family': 'White', 'given': 'Katherine'}, {'family': 'Habib', 'given': 'Rishad'}, {'family': 'Hardisty', 'given': 'David J.'}], 'issued': {'date-parts': [[2019]]}}, {'id': 'synthetics_fashion', 'title': "Synthetics anonymous: Fashion brands' addiction to fossil fuels", 'URL': 'https://changingmarkets.org/portfolio/fossil-fashion/', 'extra_urls': ['https://changingmarkets.org/portfolio/fossil-fashion/'], 'type': 'report', 'author': [{'family': 'Changing Markets Foundation'}], 'issued': {'date-parts': [[2021]]}, 'publisher': 'Changing Markets Foundation'}, {'id': '2023_resale_report', 'title': '2023 resale report', 'URL': 'https://www.thredup.com/resale/', 'extra_urls': ['https://www.thredup.com/resale/'], 'type': 'report', 'author': [{'family': 'ThredUp'}], 'issued': {'date-parts': [[2023]]}, 'publisher': 'ThredUp Inc.'}, {'id': 'mine_is', 'title': "What's mine is yours: The rise of collaborative consumption", 'URL': 'urn:isbn:978-0-06-196354-4', 'type': 'book', 'author': [{'family': 'Botsman', 'given': 'Rachel'}, {'family': 'Rogers', 'given': 'Roo'}], 'issued': {'date-parts': [[2010]]}, 'publisher': 'HarperBusiness'}, {'id': 'something_something', 'title': "Something old, something used: Determinants of women's purchase of vintage fashion vs second-hand fashion", 'URL': '#item_20364', 'type': 'article', 'author': [{'family': 'Cervellon', 'given': 'Marie-C\xe9cile'}, {'family': 'Carey', 'given': 'Lindsey'}, {'family': 'Harms', 'given': 'Trine'}], 'issued': {'date-parts': [[2012]]}}, {'id': 'cradle_to', 'title': 'Cradle to cradle: Remaking the way we make things', 'URL': 'urn:isbn:978-0-86547-587-8', 'type': 'book', 'author': [{'family': 'McDonough', 'given': 'William'}, {'family': 'Braungart', 'given': 'Michael'}], 'issued': {'date-parts': [[2002]]}, 'publisher': 'North Point Press'}, {'id': 'regenerative_how', 'title': 'Regenerative capitalism: How universal principles and patterns will shape our new economy', 'URL': 'https://capitalinstitute.org/regenerative-capitalism/', 'extra_urls': ['https://capitalinstitute.org/regenerative-capitalism/'], 'type': 'book', 'author': [{'family': 'Fullerton', 'given': 'John'}], 'issued': {'date-parts': [[2015]]}, 'publisher': 'Capital Institute'}, {'id': 'clarifying_the_concept', 'title': 'Clarifying the concept of product-service system', 'URL': '#item_20367', 'type': 'article', 'author': [{'family': 'Mont', 'given': 'Oksana K.'}], 'issued': {'date-parts': [[2002]]}}, {'id': 'eight_types_of', 'title': 'Eight types of product\u2013service system: Eight ways to sustainability? Experiences from SusProNet', 'URL': '#item_20368', 'type': 'article', 'author': [{'family': 'Tukker', 'given': 'Arnold'}], 'issued': {'date-parts': [[2004]]}}, {'id': 'the_naked', 'title': 'The naked corporation: How the age of transparency will revolutionize business', 'URL': 'urn:isbn:978-0-7432-2475-8', 'type': 'book', 'author': [{'family': 'Tapscott', 'given': 'Don'}, {'family': 'Ticoll', 'given': 'David'}], 'issued': {'date-parts': [[2003]]}, 'publisher': 'Free Press'}, {'id': 'circular_a', 'title': 'Circular transitions: A designerly approach to circular economy innovation in the textiles and clothing sector', 'URL': 'https://circularfashion.com/circular-transitions/', 'extra_urls': ['https://circularfashion.com/circular-transitions/'], 'type': 'report', 'author': [{'family': 'Earley', 'given': 'Rebecca'}, {'family': 'Goldsworthy', 'given': 'Kate'}], 'issued': {'date-parts': [[2019]]}, 'publisher': 'Circular Transitions Research Project, University of the Arts London'}, {'id': 'how_mcp_and', 'title': 'How MCP and AI are Modernizing Legacy Systems', 'URL': 'https://thenewstack.io/how-mcp-and-ai-are-modernizing-legacy-systems/', 'extra_urls': ['https://thenewstack.io/how-mcp-and-ai-are-modernizing-legacy-systems/'], 'type': 'article', 'author': [{'family': 'Saqib', 'given': 'Jan'}], 'abstract': 'A new strategy uses MCP, agentic AI and an intelligent abstraction layer to bridge the gap between old and new systems \u2014 no risky rewrite required.'}, {'id': 'burberry_burns', 'title': 'Burberry burns bags, clothes and perfume worth millions', 'URL': 'https://www.bbc.com/news/business-44885983', 'extra_urls': ['https://www.bbc.com/news/business-44885983'], 'type': 'article', 'author': [{'family': 'BBC'}], 'abstract': 'The fashion firm destroyed \xa328m of unwanted stock last year in a bid to protect its brand.'}, {'id': 'pile_of', 'title': "H&amp;M's Pile of Unsold Garments Grows as Earnings Plunge", 'URL': 'https://www.bloomberg.com/news/articles/2018-03-27/h-m-profit-plunges-to-16-year-low-as-clothing-chain-loses-allure', 'extra_urls': ['https://www.bloomberg.com/news/articles/2018-03-27/h-m-profit-plunges-to-16-year-low-as-clothing-chain-loses-allure'], 'type': 'article', 'author': [{'family': 'Molin', 'given': 'Anna'}], 'abstract': 'Swedish fashion retailer Hennes &amp;amp; Mauritz AB said it\u2019s increasing markdowns this quarter after accumulating a record pile of unsold garments worth more than $4 billion.'}, {'id': 'doi_10_1453_1614-0885-2-2025-16677', 'title': 'From Cyberfeminism to Code Control: Cyborg Fashion under the Technological Gaze', 'URL': 'https://doi.org/10.1453/1614-0885-2-2025-16677', 'extra_urls': ['https://doi.org/10.1453/1614-0885-2-2025-16677'], 'type': 'article', 'author': [{'family': 'Wagemans', 'given': 'Esmay'}], 'issued': {'date-parts': [[2025]]}, 'abstract': 'In the late 20th century, Donna Haraway\u2019s Cyborg Manifesto (1985) introduced the \u201ccyborg\u201d as a hybrid figure of disruption, blurring boundaries between human and machine, nature and culture, body and code. Today, \u2018cyborg fashion\u2019, characterized by prosthetics, coded materials, and speculative aesthetics, is more visible than ever, largely due to its circulation within digital media ecosystems and the rise of AI-driven design. Yet this visibility is shaped by a new kind of control: the technological gaze of algorithmic moderation, platform standards, and commercial optimization.', 'DOI': '10.1453/1614-0885-2-2025-16677'}])</failure></testcase><testcase classname="tests.test_rdf_parser_emergency_mode" name="test_rdf_parser_includes_arxiv_entries" time="0.178" /><testcase classname="tests.test_rdf_parser_emergency_mode" name="test_rdf_parser_includes_doi_entries" time="0.168" /><testcase classname="tests.test_rdf_parser_emergency_mode" name="test_rdf_parser_includes_book_entries" time="0.159" /><testcase classname="tests.test_rdf_parser_emergency_mode" name="test_rdf_parser_entry_quality" time="0.163" /><testcase classname="tests.test_rdf_parser_emergency_mode" name="test_rdf_parser_no_attachments" time="0.164" /><testcase classname="tests.test_rdf_parser_emergency_mode" name="test_rdf_parser_no_metadata" time="0.159" /></testsuite></testsuites>