"""Zotero API integration for fetching bibliographic data."""

import logging
import os

# import re  # Banned - using string methods instead
from typing import Any

import bibtexparser
import requests

from src.converters.md_to_latex.author_enrichment import AuthorEnricher

logger = logging.getLogger(__name__)


class ZoteroClient:
    """Client for interacting with Zotero API."""

    def __init__(
        self,
        api_key: str | None = None,
        library_id: str | None = None,
        library_type: str = "user",
    ):
        """Initialize Zotero client.

        Args:
            api_key: Zotero API key (optional for public libraries)
            library_id: Zotero library ID (user or group ID)
            library_type: 'user' or 'group' (default: 'user')
        """
        self.api_key = api_key or os.getenv("ZOTERO_API_KEY")
        self.library_id = library_id or os.getenv("ZOTERO_LIBRARY_ID")
        self.library_type = library_type or os.getenv(
            "ZOTERO_LIBRARY_TYPE", "user"
        )
        self.base_url = "https://api.zotero.org"

        if not self.api_key or not self.library_id:
            logger.warning(
                "Zotero credentials not found. Set ZOTERO_API_KEY and ZOTERO_LIBRARY_ID in .env"
            )

    def get_collection_items(
        self, collection_name: str
    ) -> list[dict[str, Any]]:
        """Load all items from a Zotero collection in CSL JSON format.

        Args:
            collection_name: Name of the collection (e.g., 'dpp-fashion')

        Returns:
            List of items in CSL JSON format

        Raises:
            ValueError: If credentials are missing or collection not found
        """
        if not self.api_key or not self.library_id:
            raise ValueError(
                "Zotero credentials required. Set ZOTERO_API_KEY and ZOTERO_LIBRARY_ID in .env"
            )

        # Step 1: Find collection ID by name
        collection_id = self._find_collection_id(collection_name)
        if not collection_id:
            raise ValueError(
                f"Collection '{collection_name}' not found in Zotero library"
            )

        logger.info(
            f"Found collection '{collection_name}' with ID: {collection_id}"
        )

        # Step 2: Fetch all items from collection
        items = self._fetch_all_collection_items(collection_id)

        logger.info(
            f"Loaded {len(items)} items from collection '{collection_name}'"
        )
        return items

    def get_collection_bibtex(self, collection_name: str) -> str:
        """Fetch BibTeX export from Zotero collection with Better BibTeX keys.

        If Better BibTeX plugin is installed, this will include citation keys
        generated by Better BibTeX. Otherwise, falls back to standard Zotero keys.

        Args:
            collection_name: Name of the collection (e.g., 'dpp-fashion')

        Returns:
            Complete BibTeX file content as string

        Raises:
            ValueError: If credentials are missing or collection not found
        """
        if not self.api_key or not self.library_id:
            raise ValueError(
                "Zotero credentials required. Set ZOTERO_API_KEY and ZOTERO_LIBRARY_ID in .env"
            )

        # Step 1: Find collection ID by name
        collection_id = self._find_collection_id(collection_name)
        if not collection_id:
            raise ValueError(
                f"Collection '{collection_name}' not found in Zotero library"
            )

        logger.info(
            f"Found collection '{collection_name}' with ID: {collection_id}"
        )

        # Step 2: Fetch BibTeX from collection
        bibtex_content = self._fetch_collection_bibtex(collection_id)

        logger.info(
            f"Fetched BibTeX export from collection '{collection_name}' ({len(bibtex_content)} chars)"
        )
        return bibtex_content

    def load_collection_with_keys(
        self, collection_name: str
    ) -> dict[str, dict[str, Any]]:
        """Load collection and extract Better BibTeX keys.

        Fetches BibTeX export from Zotero and parses it to extract citation keys.
        If Better BibTeX plugin is installed in Zotero, this will return proper
        Better BibTeX keys (e.g., 'adisornDigitalProductPassport2021').

        Args:
            collection_name: Name of the collection (e.g., 'dpp-fashion')

        Returns:
            Dict mapping citation keys to parsed BibTeX entries
            Example: {
                'adisornDigitalProductPassport2021': {
                    'author': 'Adisorn, Leelaphongwatana and ...',
                    'title': 'Digital Product Passport...',
                    'year': '2021',
                    ...
                }
            }

        Raises:
            ValueError: If credentials are missing or collection not found
        """
        # Fetch BibTeX export from Zotero
        bibtex_content = self.get_collection_bibtex(collection_name)

        if not bibtex_content or not bibtex_content.strip():
            logger.warning(
                f"Empty BibTeX export from collection '{collection_name}'"
            )
            return {}

        # Parse BibTeX using bibtexparser (AST-based, no regex)
        # Configure parser to accept ALL entry types (including patents, etc.)
        try:
            parser = bibtexparser.bparser.BibTexParser()
            parser.ignore_nonstandard_types = False  # Accept patents and other non-standard types
            parser.homogenize_fields = False  # Keep field names as-is
            bib_database = bibtexparser.loads(bibtex_content, parser=parser)
            entries_dict = {}

            for entry in bib_database.entries:
                cite_key = entry.get("ID")
                if not cite_key:
                    logger.warning(
                        f"BibTeX entry missing ID field: {entry.get('title', 'Unknown')}"
                    )
                    continue

                # Store the full entry dict with all fields
                entries_dict[cite_key] = entry

                logger.debug(
                    f"Loaded citation key: {cite_key} (type: {entry.get('ENTRYTYPE', 'unknown')})"
                )

            logger.info(
                f"Loaded {len(entries_dict)} entries with Better BibTeX keys from '{collection_name}'"
            )

            # Enrich entries with complete author lists
            logger.info("Enriching BibTeX entries with complete author lists...")
            enricher = AuthorEnricher()
            enriched_dict = enricher.enrich_bibtex_entries(entries_dict)

            return enriched_dict

        except Exception as e:
            logger.error(f"Failed to parse BibTeX export: {e}")
            raise

    def _find_collection_id(self, collection_name: str) -> str | None:
        """Find collection ID by name.

        Args:
            collection_name: Name of the collection

        Returns:
            Collection ID (key) if found, None otherwise
        """
        url = f"{self.base_url}/{self.library_type}s/{self.library_id}/collections"

        headers = {"Zotero-API-Key": self.api_key}

        try:
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()

            collections = response.json()

            for coll in collections:
                if coll.get("data", {}).get("name") == collection_name:
                    return coll["key"]

            logger.warning(
                f"Collection '{collection_name}' not found. Available collections:"
            )
            for coll in collections[:10]:
                logger.warning(f"  - {coll.get('data', {}).get('name')}")

            return None

        except Exception as e:
            logger.error(f"Failed to fetch collections: {e}")
            raise

    def _fetch_all_collection_items(
        self, collection_id: str
    ) -> list[dict[str, Any]]:
        """Fetch all items from a collection, handling pagination.

        Args:
            collection_id: Zotero collection key

        Returns:
            List of items in CSL JSON format
        """
        url = f"{self.base_url}/{self.library_type}s/{self.library_id}/collections/{collection_id}/items"

        headers = {
            "Zotero-API-Key": self.api_key,
        }

        params = {
            "format": "csljson",
            "limit": 100,
            "start": 0,
        }

        all_items = []

        while True:
            try:
                response = requests.get(
                    url, headers=headers, params=params, timeout=30
                )
                response.raise_for_status()

                batch = response.json()

                if not batch or not batch.get("items"):
                    break

                items = batch["items"]
                all_items.extend(items)

                logger.debug(
                    f"Fetched {len(items)} items (total: {len(all_items)})"
                )

                if len(items) < params["limit"]:
                    break

                params["start"] += params["limit"]

            except Exception as e:
                logger.error(
                    f"Failed to fetch items at start={params['start']}: {e}"
                )
                raise

        return all_items

    def _fetch_collection_bibtex(self, collection_id: str) -> str:
        """Fetch BibTeX export for a collection with pagination.

        IMPORTANT: Zotero API paginates results. This method fetches ALL items
        by paginating through the collection until no more items are returned.

        Args:
            collection_id: Zotero collection key

        Returns:
            BibTeX content as string (all items concatenated)
        """
        url = f"{self.base_url}/{self.library_type}s/{self.library_id}/collections/{collection_id}/items"

        headers = {
            "Zotero-API-Key": self.api_key,
        }

        # Start with first page
        params = {
            "format": "bibtex",
            "limit": 100,  # Max items per request
            "start": 0,
        }

        all_bibtex = []
        total_fetched = 0

        try:
            while True:
                response = requests.get(
                    url, headers=headers, params=params, timeout=30
                )
                response.raise_for_status()

                # Get BibTeX content for this page
                bibtex_chunk = response.text.strip()

                if not bibtex_chunk:
                    logger.debug(f"Empty response at start={params['start']}, stopping pagination")
                    break

                all_bibtex.append(bibtex_chunk)

                # Count entries in this chunk (crude but works)
                entries_in_chunk = bibtex_chunk.count("@")
                total_fetched += entries_in_chunk

                logger.debug(
                    f"Fetched {entries_in_chunk} entries (total so far: {total_fetched})"
                )

                # Move to next page
                # Note: We can't use "entries < limit" as stopping condition because
                # BibTeX export filters to only citable items, so we may get less than
                # limit even if there are more pages. Instead, keep going until we get
                # an empty response.
                params["start"] += params["limit"]

                # Safety limit: stop after 1000 pages (100,000 items)
                if params["start"] > 100000:
                    logger.warning("Hit safety limit of 100k items, stopping pagination")
                    break

            # Combine all BibTeX chunks
            combined_bibtex = "\n\n".join(all_bibtex)

            logger.info(
                f"Fetched {total_fetched} BibTeX entries from collection "
                f"({len(combined_bibtex)} chars total)"
            )

            return combined_bibtex

        except Exception as e:
            logger.error(f"Failed to fetch BibTeX export: {e}")
            raise

    def search_by_identifier(self, identifier: str) -> dict[str, Any] | None:
        """Search for an item by DOI, ISBN, arXiv ID, etc.

        Args:
            identifier: DOI, ISBN, arXiv ID, or other identifier

        Returns:
            Item data if found, None otherwise
        """
        logger.debug(
            f"ZoteroClient.search_by_identifier called with: {identifier}"
        )
        # Use Zotero translation server if available (for automatic metadata extraction)
        try:
            # First try the Zotero translation server
            translation_url = "https://translate.zotero.org/search"

            headers = {
                "Content-Type": "text/plain",
                "Accept": "application/json",
            }

            logger.debug(
                f"Sending identifier to Zotero translation server: {identifier}"
            )
            # Send identifier to translation server
            response = requests.post(
                translation_url, data=identifier, headers=headers, timeout=10
            )
            logger.debug(
                f"Zotero translation server response: status={response.status_code}"
            )

            if response.status_code == 200:
                items = response.json()
                logger.debug(
                    f"Zotero translation server returned {len(items) if items else 0} items"
                )
                if items and len(items) > 0:
                    logger.debug(
                        f"Returning first item with title: {items[0].get('title', 'No title')}"
                    )
                    return items[0]  # Return first match

        except Exception as e:
            logger.warning(
                f"Failed to fetch from Zotero translation server: {e}"
            )

        # If translation server fails, try library search if configured
        if self.library_id:
            return self._search_library(identifier)

        return None

    def _search_library(self, query: str) -> dict[str, Any] | None:
        """Search user's Zotero library.

        Args:
            query: Search query (DOI, title, etc.)

        Returns:
            Item data if found, None otherwise
        """
        if not self.library_id:
            return None

        # Determine library type (user or group)
        library_type = "users" if self.library_id.isdigit() else "groups"

        url = f"{self.base_url}/{library_type}/{self.library_id}/items"

        params = {"q": query, "format": "json", "limit": 1}

        headers = {}
        if self.api_key:
            headers["Zotero-API-Key"] = self.api_key

        try:
            response = requests.get(
                url, params=params, headers=headers, timeout=10
            )

            if response.status_code == 200:
                items = response.json()
                if items and len(items) > 0:
                    return items[0]["data"]

        except Exception as e:
            logger.warning(f"Failed to search Zotero library: {e}")

        return None

    def format_bibtex(self, item_data: dict[str, Any]) -> str:
        """Convert Zotero item data to BibTeX format.

        DEPRECATED: This method generates citation keys and violates Better BibTeX principle.
        Only use when use_better_bibtex_keys=False.

        Args:
            item_data: Zotero item data

        Returns:
            BibTeX entry string
        """
        logger.warning(
            "format_bibtex() generates keys - should not be used with Better BibTeX mode"
        )
        # Map Zotero item types to BibTeX types
        type_map = {
            "journalArticle": "article",
            "book": "book",
            "bookSection": "incollection",
            "conferencePaper": "inproceedings",
            "thesis": "phdthesis",
            "report": "techreport",
            "webpage": "misc",
            "preprint": "article",
        }

        item_type = item_data.get("itemType", "misc")
        bibtex_type = type_map.get(item_type, "misc")

        # Generate citation key
        creators = item_data.get("creators", [])
        first_author = ""
        if creators:
            creator = creators[0]
            if "lastName" in creator:
                first_author = creator["lastName"]
            elif "name" in creator:
                first_author = creator["name"].split()[-1]

        year = self._extract_year(item_data.get("date", ""))
        title_word = self._get_first_title_word(item_data.get("title", ""))

        key = f"{first_author.lower()}{year}{title_word}"
        # Remove non-alphanumeric characters without regex
        clean_key = []
        for char in key:
            if char.isalnum():
                clean_key.append(char)
        key = "".join(clean_key)

        # Build BibTeX entry
        lines = [f"@{bibtex_type}{{{key},"]

        # Authors
        if creators:
            author_names = []
            for creator in creators:
                if creator.get("creatorType") == "author":
                    if "firstName" in creator and "lastName" in creator:
                        name = f"{creator['firstName']} {creator['lastName']}"
                    elif "name" in creator:
                        name = creator["name"]
                    else:
                        continue
                    author_names.append(name)

            if author_names:
                lines.append(f'  author = "{" and ".join(author_names)}",')

        # Title
        if "title" in item_data:
            title = item_data["title"].replace('"', '{"}')
            lines.append(f'  title = "{title}",')

        # Year
        if year:
            lines.append(f'  year = "{year}",')

        # Journal
        if "publicationTitle" in item_data:
            lines.append(f'  journal = "{item_data["publicationTitle"]}",')

        # Volume
        if "volume" in item_data:
            lines.append(f'  volume = "{item_data["volume"]}",')

        # Number/Issue
        if "issue" in item_data:
            lines.append(f'  number = "{item_data["issue"]}",')

        # Pages
        if "pages" in item_data:
            lines.append(f'  pages = "{item_data["pages"]}",')

        # DOI
        if "DOI" in item_data:
            lines.append(f'  doi = "{item_data["DOI"]}",')

        # URL
        if "url" in item_data:
            lines.append(f'  url = "{item_data["url"]}",')

        # ISBN
        if "ISBN" in item_data:
            lines.append(f'  isbn = "{item_data["ISBN"]}",')

        # Publisher
        if "publisher" in item_data:
            lines.append(f'  publisher = "{item_data["publisher"]}",')

        # Abstract
        if "abstractNote" in item_data:
            abstract = item_data["abstractNote"].replace('"', '{"}')
            abstract = abstract.replace("\n", " ")
            lines.append(f'  abstract = "{abstract}",')

        lines.append("}")

        return "\n".join(lines)

    def _extract_year(self, date_str: str) -> str:
        """Extract year from date string."""
        if not date_str:
            return ""

        # Try to find 4-digit year without regex
        # Look for years starting with 19 or 20
        for i in range(len(date_str) - 3):
            if date_str[i : i + 2] in ["19", "20"]:
                # Check if next 2 characters are digits
                if date_str[i + 2 : i + 4].isdigit():
                    # Check boundaries - should not be part of a longer number
                    if (i == 0 or not date_str[i - 1].isdigit()) and (
                        i + 4 >= len(date_str) or not date_str[i + 4].isdigit()
                    ):
                        return date_str[i : i + 4]

        return ""

    def _get_first_title_word(self, title: str) -> str:
        """Get first significant word from title."""
        skip_words = {
            "a",
            "an",
            "the",
            "of",
            "in",
            "on",
            "at",
            "to",
            "for",
            "with",
            "by",
        }

        # Clean title without regex
        clean_chars = []
        for char in title:
            if char.isalpha() or char.isspace():
                clean_chars.append(char)
            else:
                clean_chars.append(" ")

        clean_title = "".join(clean_chars)
        words = clean_title.split()

        for word in words:
            if word.lower() not in skip_words and len(word) > 2:
                return word[0].upper() + word[1:].lower()

        return ""
